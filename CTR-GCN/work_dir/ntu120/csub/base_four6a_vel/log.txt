[ Tue Jul  5 09:01:52 2022 ] using warm up, epoch: 5
[ Tue Jul  5 09:04:16 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four6a_vel', 'model_saved_name': 'work_dir/ntu120/csub/base_four6a_vel/runs', 'config': 'config/nturgbd120-cross-subject/velocity.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': True, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': True, 'bone': False, 'debug': False}, 'model': 'model.fourier6a.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jul  5 09:04:16 2022 ] # Parameters: 2128482
[ Tue Jul  5 09:04:16 2022 ] Training epoch: 1
[ Tue Jul  5 09:07:14 2022 ] 	Mean training loss: 2.9753.  Mean training acc: 26.79%.
[ Tue Jul  5 09:07:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jul  5 09:07:14 2022 ] Eval epoch: 1
[ Tue Jul  5 09:08:00 2022 ] 	Mean test loss of 796 batches: 2.3382200445961114.
[ Tue Jul  5 09:08:00 2022 ] 	Top1: 34.99%
[ Tue Jul  5 09:08:01 2022 ] 	Top5: 69.60%
[ Tue Jul  5 09:08:01 2022 ] Training epoch: 2
[ Tue Jul  5 09:11:00 2022 ] 	Mean training loss: 1.9646.  Mean training acc: 45.86%.
[ Tue Jul  5 09:11:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:11:00 2022 ] Eval epoch: 2
[ Tue Jul  5 09:11:45 2022 ] 	Mean test loss of 796 batches: 2.168601167860942.
[ Tue Jul  5 09:11:46 2022 ] 	Top1: 40.81%
[ Tue Jul  5 09:11:46 2022 ] 	Top5: 73.44%
[ Tue Jul  5 09:11:46 2022 ] Training epoch: 3
[ Tue Jul  5 09:14:46 2022 ] 	Mean training loss: 1.6580.  Mean training acc: 53.23%.
[ Tue Jul  5 09:14:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:14:46 2022 ] Eval epoch: 3
[ Tue Jul  5 09:15:31 2022 ] 	Mean test loss of 796 batches: 1.8285323941527898.
[ Tue Jul  5 09:15:32 2022 ] 	Top1: 48.94%
[ Tue Jul  5 09:15:32 2022 ] 	Top5: 80.88%
[ Tue Jul  5 09:15:32 2022 ] Training epoch: 4
[ Tue Jul  5 09:18:32 2022 ] 	Mean training loss: 1.4832.  Mean training acc: 57.56%.
[ Tue Jul  5 09:18:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:18:32 2022 ] Eval epoch: 4
[ Tue Jul  5 09:19:17 2022 ] 	Mean test loss of 796 batches: 2.3807733150283297.
[ Tue Jul  5 09:19:17 2022 ] 	Top1: 37.92%
[ Tue Jul  5 09:19:18 2022 ] 	Top5: 76.88%
[ Tue Jul  5 09:19:18 2022 ] Training epoch: 5
[ Tue Jul  5 09:22:17 2022 ] 	Mean training loss: 1.3772.  Mean training acc: 60.41%.
[ Tue Jul  5 09:22:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jul  5 09:22:17 2022 ] Eval epoch: 5
[ Tue Jul  5 09:23:03 2022 ] 	Mean test loss of 796 batches: 1.6226336763582039.
[ Tue Jul  5 09:23:03 2022 ] 	Top1: 54.39%
[ Tue Jul  5 09:23:03 2022 ] 	Top5: 84.55%
[ Tue Jul  5 09:23:03 2022 ] Training epoch: 6
[ Tue Jul  5 09:26:03 2022 ] 	Mean training loss: 1.2555.  Mean training acc: 63.43%.
[ Tue Jul  5 09:26:03 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:26:03 2022 ] Eval epoch: 6
[ Tue Jul  5 09:26:48 2022 ] 	Mean test loss of 796 batches: 1.6567976542902951.
[ Tue Jul  5 09:26:49 2022 ] 	Top1: 54.06%
[ Tue Jul  5 09:26:49 2022 ] 	Top5: 83.03%
[ Tue Jul  5 09:26:49 2022 ] Training epoch: 7
[ Tue Jul  5 09:29:48 2022 ] 	Mean training loss: 1.1880.  Mean training acc: 65.36%.
[ Tue Jul  5 09:29:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:29:48 2022 ] Eval epoch: 7
[ Tue Jul  5 09:30:34 2022 ] 	Mean test loss of 796 batches: 1.6317423672682076.
[ Tue Jul  5 09:30:34 2022 ] 	Top1: 54.59%
[ Tue Jul  5 09:30:34 2022 ] 	Top5: 84.63%
[ Tue Jul  5 09:30:34 2022 ] Training epoch: 8
[ Tue Jul  5 09:33:34 2022 ] 	Mean training loss: 1.1399.  Mean training acc: 66.77%.
[ Tue Jul  5 09:33:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:33:34 2022 ] Eval epoch: 8
[ Tue Jul  5 09:34:20 2022 ] 	Mean test loss of 796 batches: 1.4584147020350748.
[ Tue Jul  5 09:34:20 2022 ] 	Top1: 58.39%
[ Tue Jul  5 09:34:21 2022 ] 	Top5: 87.50%
[ Tue Jul  5 09:34:21 2022 ] Training epoch: 9
[ Tue Jul  5 09:37:21 2022 ] 	Mean training loss: 1.0994.  Mean training acc: 67.95%.
[ Tue Jul  5 09:37:21 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 09:37:21 2022 ] Eval epoch: 9
[ Tue Jul  5 09:38:07 2022 ] 	Mean test loss of 796 batches: 1.3989840623871166.
[ Tue Jul  5 09:38:07 2022 ] 	Top1: 59.64%
[ Tue Jul  5 09:38:07 2022 ] 	Top5: 87.92%
[ Tue Jul  5 09:38:07 2022 ] Training epoch: 10
[ Tue Jul  5 09:41:07 2022 ] 	Mean training loss: 1.0618.  Mean training acc: 68.93%.
[ Tue Jul  5 09:41:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 09:41:07 2022 ] Eval epoch: 10
[ Tue Jul  5 09:41:53 2022 ] 	Mean test loss of 796 batches: 1.364654508779696.
[ Tue Jul  5 09:41:53 2022 ] 	Top1: 60.60%
[ Tue Jul  5 09:41:54 2022 ] 	Top5: 87.07%
[ Tue Jul  5 09:41:54 2022 ] Training epoch: 11
[ Tue Jul  5 09:44:53 2022 ] 	Mean training loss: 1.0398.  Mean training acc: 69.34%.
[ Tue Jul  5 09:44:53 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:44:53 2022 ] Eval epoch: 11
[ Tue Jul  5 09:45:38 2022 ] 	Mean test loss of 796 batches: 1.5033595544758753.
[ Tue Jul  5 09:45:39 2022 ] 	Top1: 58.84%
[ Tue Jul  5 09:45:39 2022 ] 	Top5: 84.77%
[ Tue Jul  5 09:45:39 2022 ] Training epoch: 12
[ Tue Jul  5 09:48:39 2022 ] 	Mean training loss: 1.0167.  Mean training acc: 70.08%.
[ Tue Jul  5 09:48:39 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 09:48:39 2022 ] Eval epoch: 12
[ Tue Jul  5 09:49:25 2022 ] 	Mean test loss of 796 batches: 1.4117172705617982.
[ Tue Jul  5 09:49:26 2022 ] 	Top1: 59.44%
[ Tue Jul  5 09:49:26 2022 ] 	Top5: 88.55%
[ Tue Jul  5 09:49:26 2022 ] Training epoch: 13
[ Tue Jul  5 09:52:30 2022 ] 	Mean training loss: 0.9982.  Mean training acc: 70.63%.
[ Tue Jul  5 09:52:30 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 09:52:30 2022 ] Eval epoch: 13
[ Tue Jul  5 09:53:17 2022 ] 	Mean test loss of 796 batches: 1.261712703647925.
[ Tue Jul  5 09:53:17 2022 ] 	Top1: 63.19%
[ Tue Jul  5 09:53:17 2022 ] 	Top5: 89.98%
[ Tue Jul  5 09:53:18 2022 ] Training epoch: 14
[ Tue Jul  5 09:56:20 2022 ] 	Mean training loss: 0.9818.  Mean training acc: 71.03%.
[ Tue Jul  5 09:56:20 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 09:56:20 2022 ] Eval epoch: 14
[ Tue Jul  5 09:57:05 2022 ] 	Mean test loss of 796 batches: 1.4622010743647964.
[ Tue Jul  5 09:57:05 2022 ] 	Top1: 59.83%
[ Tue Jul  5 09:57:06 2022 ] 	Top5: 87.01%
[ Tue Jul  5 09:57:06 2022 ] Training epoch: 15
[ Tue Jul  5 10:00:05 2022 ] 	Mean training loss: 0.9632.  Mean training acc: 71.64%.
[ Tue Jul  5 10:00:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jul  5 10:00:05 2022 ] Eval epoch: 15
[ Tue Jul  5 10:00:50 2022 ] 	Mean test loss of 796 batches: 1.2209939778824548.
[ Tue Jul  5 10:00:51 2022 ] 	Top1: 65.19%
[ Tue Jul  5 10:00:51 2022 ] 	Top5: 89.93%
[ Tue Jul  5 10:00:51 2022 ] Training epoch: 16
[ Tue Jul  5 10:03:51 2022 ] 	Mean training loss: 0.9527.  Mean training acc: 72.01%.
[ Tue Jul  5 10:03:51 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 10:03:51 2022 ] Eval epoch: 16
[ Tue Jul  5 10:04:36 2022 ] 	Mean test loss of 796 batches: 1.8165275207416496.
[ Tue Jul  5 10:04:37 2022 ] 	Top1: 53.59%
[ Tue Jul  5 10:04:37 2022 ] 	Top5: 82.03%
[ Tue Jul  5 10:04:37 2022 ] Training epoch: 17
[ Tue Jul  5 10:07:36 2022 ] 	Mean training loss: 0.9386.  Mean training acc: 72.27%.
[ Tue Jul  5 10:07:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:07:36 2022 ] Eval epoch: 17
[ Tue Jul  5 10:08:22 2022 ] 	Mean test loss of 796 batches: 1.4592078005398936.
[ Tue Jul  5 10:08:23 2022 ] 	Top1: 58.89%
[ Tue Jul  5 10:08:23 2022 ] 	Top5: 86.29%
[ Tue Jul  5 10:08:23 2022 ] Training epoch: 18
[ Tue Jul  5 10:11:22 2022 ] 	Mean training loss: 0.9268.  Mean training acc: 72.65%.
[ Tue Jul  5 10:11:22 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:11:22 2022 ] Eval epoch: 18
[ Tue Jul  5 10:12:07 2022 ] 	Mean test loss of 796 batches: 1.3136524979642887.
[ Tue Jul  5 10:12:08 2022 ] 	Top1: 62.01%
[ Tue Jul  5 10:12:08 2022 ] 	Top5: 89.06%
[ Tue Jul  5 10:12:08 2022 ] Training epoch: 19
[ Tue Jul  5 10:15:10 2022 ] 	Mean training loss: 0.9173.  Mean training acc: 72.91%.
[ Tue Jul  5 10:15:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 10:15:10 2022 ] Eval epoch: 19
[ Tue Jul  5 10:15:56 2022 ] 	Mean test loss of 796 batches: 1.3765526090060647.
[ Tue Jul  5 10:15:56 2022 ] 	Top1: 61.43%
[ Tue Jul  5 10:15:57 2022 ] 	Top5: 88.54%
[ Tue Jul  5 10:15:57 2022 ] Training epoch: 20
[ Tue Jul  5 10:19:01 2022 ] 	Mean training loss: 0.9104.  Mean training acc: 73.10%.
[ Tue Jul  5 10:19:01 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 10:19:01 2022 ] Eval epoch: 20
[ Tue Jul  5 10:19:47 2022 ] 	Mean test loss of 796 batches: 1.175578366422174.
[ Tue Jul  5 10:19:48 2022 ] 	Top1: 65.77%
[ Tue Jul  5 10:19:48 2022 ] 	Top5: 90.35%
[ Tue Jul  5 10:19:48 2022 ] Training epoch: 21
[ Tue Jul  5 10:22:49 2022 ] 	Mean training loss: 0.8999.  Mean training acc: 73.42%.
[ Tue Jul  5 10:22:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 10:22:49 2022 ] Eval epoch: 21
[ Tue Jul  5 10:23:36 2022 ] 	Mean test loss of 796 batches: 1.89847362625539.
[ Tue Jul  5 10:23:36 2022 ] 	Top1: 51.62%
[ Tue Jul  5 10:23:36 2022 ] 	Top5: 80.61%
[ Tue Jul  5 10:23:36 2022 ] Training epoch: 22
[ Tue Jul  5 10:26:41 2022 ] 	Mean training loss: 0.8911.  Mean training acc: 73.69%.
[ Tue Jul  5 10:26:41 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 10:26:41 2022 ] Eval epoch: 22
[ Tue Jul  5 10:27:27 2022 ] 	Mean test loss of 796 batches: 1.4095295859341646.
[ Tue Jul  5 10:27:27 2022 ] 	Top1: 60.39%
[ Tue Jul  5 10:27:28 2022 ] 	Top5: 86.23%
[ Tue Jul  5 10:27:28 2022 ] Training epoch: 23
[ Tue Jul  5 10:30:28 2022 ] 	Mean training loss: 0.8813.  Mean training acc: 73.85%.
[ Tue Jul  5 10:30:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:30:28 2022 ] Eval epoch: 23
[ Tue Jul  5 10:31:14 2022 ] 	Mean test loss of 796 batches: 1.6041705323074331.
[ Tue Jul  5 10:31:14 2022 ] 	Top1: 55.28%
[ Tue Jul  5 10:31:15 2022 ] 	Top5: 84.98%
[ Tue Jul  5 10:31:15 2022 ] Training epoch: 24
[ Tue Jul  5 10:34:14 2022 ] 	Mean training loss: 0.8740.  Mean training acc: 73.90%.
[ Tue Jul  5 10:34:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jul  5 10:34:14 2022 ] Eval epoch: 24
[ Tue Jul  5 10:34:59 2022 ] 	Mean test loss of 796 batches: 1.3557723462581635.
[ Tue Jul  5 10:34:59 2022 ] 	Top1: 61.58%
[ Tue Jul  5 10:35:00 2022 ] 	Top5: 88.34%
[ Tue Jul  5 10:35:00 2022 ] Training epoch: 25
[ Tue Jul  5 10:37:59 2022 ] 	Mean training loss: 0.8717.  Mean training acc: 74.17%.
[ Tue Jul  5 10:37:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:37:59 2022 ] Eval epoch: 25
[ Tue Jul  5 10:38:45 2022 ] 	Mean test loss of 796 batches: 1.4739158026237584.
[ Tue Jul  5 10:38:45 2022 ] 	Top1: 58.88%
[ Tue Jul  5 10:38:45 2022 ] 	Top5: 86.85%
[ Tue Jul  5 10:38:45 2022 ] Training epoch: 26
[ Tue Jul  5 10:41:45 2022 ] 	Mean training loss: 0.8732.  Mean training acc: 74.20%.
[ Tue Jul  5 10:41:45 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:41:45 2022 ] Eval epoch: 26
[ Tue Jul  5 10:42:31 2022 ] 	Mean test loss of 796 batches: 1.5740390495589032.
[ Tue Jul  5 10:42:31 2022 ] 	Top1: 58.17%
[ Tue Jul  5 10:42:31 2022 ] 	Top5: 85.32%
[ Tue Jul  5 10:42:31 2022 ] Training epoch: 27
[ Tue Jul  5 10:45:31 2022 ] 	Mean training loss: 0.8592.  Mean training acc: 74.36%.
[ Tue Jul  5 10:45:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:45:31 2022 ] Eval epoch: 27
[ Tue Jul  5 10:46:17 2022 ] 	Mean test loss of 796 batches: 1.2074456000747393.
[ Tue Jul  5 10:46:17 2022 ] 	Top1: 65.06%
[ Tue Jul  5 10:46:18 2022 ] 	Top5: 90.44%
[ Tue Jul  5 10:46:18 2022 ] Training epoch: 28
[ Tue Jul  5 10:49:17 2022 ] 	Mean training loss: 0.8548.  Mean training acc: 74.79%.
[ Tue Jul  5 10:49:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jul  5 10:49:17 2022 ] Eval epoch: 28
[ Tue Jul  5 10:50:03 2022 ] 	Mean test loss of 796 batches: 1.2627746058094442.
[ Tue Jul  5 10:50:04 2022 ] 	Top1: 63.83%
[ Tue Jul  5 10:50:04 2022 ] 	Top5: 90.29%
[ Tue Jul  5 10:50:04 2022 ] Training epoch: 29
[ Tue Jul  5 10:53:04 2022 ] 	Mean training loss: 0.8528.  Mean training acc: 74.74%.
[ Tue Jul  5 10:53:04 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 10:53:04 2022 ] Eval epoch: 29
[ Tue Jul  5 10:53:49 2022 ] 	Mean test loss of 796 batches: 1.6738397544203092.
[ Tue Jul  5 10:53:49 2022 ] 	Top1: 57.90%
[ Tue Jul  5 10:53:50 2022 ] 	Top5: 84.04%
[ Tue Jul  5 10:53:50 2022 ] Training epoch: 30
[ Tue Jul  5 10:56:50 2022 ] 	Mean training loss: 0.8545.  Mean training acc: 74.72%.
[ Tue Jul  5 10:56:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 10:56:50 2022 ] Eval epoch: 30
[ Tue Jul  5 10:57:35 2022 ] 	Mean test loss of 796 batches: 1.5622880638169883.
[ Tue Jul  5 10:57:35 2022 ] 	Top1: 57.11%
[ Tue Jul  5 10:57:35 2022 ] 	Top5: 85.23%
[ Tue Jul  5 10:57:36 2022 ] Training epoch: 31
[ Tue Jul  5 11:00:35 2022 ] 	Mean training loss: 0.8410.  Mean training acc: 75.16%.
[ Tue Jul  5 11:00:35 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:00:35 2022 ] Eval epoch: 31
[ Tue Jul  5 11:01:21 2022 ] 	Mean test loss of 796 batches: 1.176815317878172.
[ Tue Jul  5 11:01:21 2022 ] 	Top1: 65.90%
[ Tue Jul  5 11:01:22 2022 ] 	Top5: 91.04%
[ Tue Jul  5 11:01:22 2022 ] Training epoch: 32
[ Tue Jul  5 11:04:22 2022 ] 	Mean training loss: 0.8465.  Mean training acc: 74.70%.
[ Tue Jul  5 11:04:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:04:22 2022 ] Eval epoch: 32
[ Tue Jul  5 11:05:08 2022 ] 	Mean test loss of 796 batches: 1.7790589769132172.
[ Tue Jul  5 11:05:08 2022 ] 	Top1: 54.89%
[ Tue Jul  5 11:05:08 2022 ] 	Top5: 83.33%
[ Tue Jul  5 11:05:08 2022 ] Training epoch: 33
[ Tue Jul  5 11:08:08 2022 ] 	Mean training loss: 0.8439.  Mean training acc: 74.92%.
[ Tue Jul  5 11:08:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:08:08 2022 ] Eval epoch: 33
[ Tue Jul  5 11:08:53 2022 ] 	Mean test loss of 796 batches: 1.3977216977869447.
[ Tue Jul  5 11:08:54 2022 ] 	Top1: 61.70%
[ Tue Jul  5 11:08:54 2022 ] 	Top5: 87.04%
[ Tue Jul  5 11:08:54 2022 ] Training epoch: 34
[ Tue Jul  5 11:11:54 2022 ] 	Mean training loss: 0.8402.  Mean training acc: 75.21%.
[ Tue Jul  5 11:11:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:11:54 2022 ] Eval epoch: 34
[ Tue Jul  5 11:12:40 2022 ] 	Mean test loss of 796 batches: 1.6438166234810747.
[ Tue Jul  5 11:12:41 2022 ] 	Top1: 55.96%
[ Tue Jul  5 11:12:41 2022 ] 	Top5: 83.29%
[ Tue Jul  5 11:12:41 2022 ] Training epoch: 35
[ Tue Jul  5 11:15:42 2022 ] 	Mean training loss: 0.8367.  Mean training acc: 75.11%.
[ Tue Jul  5 11:15:42 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:15:42 2022 ] Eval epoch: 35
[ Tue Jul  5 11:16:28 2022 ] 	Mean test loss of 796 batches: 1.2777764308242943.
[ Tue Jul  5 11:16:28 2022 ] 	Top1: 63.75%
[ Tue Jul  5 11:16:29 2022 ] 	Top5: 89.72%
[ Tue Jul  5 11:16:29 2022 ] Training epoch: 36
[ Tue Jul  5 11:19:30 2022 ] 	Mean training loss: 0.5010.  Mean training acc: 85.32%.
[ Tue Jul  5 11:19:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:19:30 2022 ] Eval epoch: 36
[ Tue Jul  5 11:20:16 2022 ] 	Mean test loss of 796 batches: 0.6930352127432224.
[ Tue Jul  5 11:20:16 2022 ] 	Top1: 78.87%
[ Tue Jul  5 11:20:17 2022 ] 	Top5: 95.74%
[ Tue Jul  5 11:20:17 2022 ] Training epoch: 37
[ Tue Jul  5 11:23:18 2022 ] 	Mean training loss: 0.4046.  Mean training acc: 88.07%.
[ Tue Jul  5 11:23:18 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:23:18 2022 ] Eval epoch: 37
[ Tue Jul  5 11:24:05 2022 ] 	Mean test loss of 796 batches: 0.6874280498180557.
[ Tue Jul  5 11:24:05 2022 ] 	Top1: 79.12%
[ Tue Jul  5 11:24:05 2022 ] 	Top5: 95.92%
[ Tue Jul  5 11:24:05 2022 ] Training epoch: 38
[ Tue Jul  5 11:27:07 2022 ] 	Mean training loss: 0.3587.  Mean training acc: 89.42%.
[ Tue Jul  5 11:27:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:27:07 2022 ] Eval epoch: 38
[ Tue Jul  5 11:27:52 2022 ] 	Mean test loss of 796 batches: 0.71943278129601.
[ Tue Jul  5 11:27:53 2022 ] 	Top1: 78.53%
[ Tue Jul  5 11:27:53 2022 ] 	Top5: 95.55%
[ Tue Jul  5 11:27:53 2022 ] Training epoch: 39
[ Tue Jul  5 11:30:55 2022 ] 	Mean training loss: 0.3319.  Mean training acc: 90.28%.
[ Tue Jul  5 11:30:55 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:30:55 2022 ] Eval epoch: 39
[ Tue Jul  5 11:31:41 2022 ] 	Mean test loss of 796 batches: 0.6651067551805745.
[ Tue Jul  5 11:31:41 2022 ] 	Top1: 80.17%
[ Tue Jul  5 11:31:42 2022 ] 	Top5: 96.13%
[ Tue Jul  5 11:31:42 2022 ] Training epoch: 40
[ Tue Jul  5 11:34:44 2022 ] 	Mean training loss: 0.3101.  Mean training acc: 90.97%.
[ Tue Jul  5 11:34:44 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 11:34:44 2022 ] Eval epoch: 40
[ Tue Jul  5 11:35:31 2022 ] 	Mean test loss of 796 batches: 0.7197349970720371.
[ Tue Jul  5 11:35:31 2022 ] 	Top1: 78.94%
[ Tue Jul  5 11:35:32 2022 ] 	Top5: 95.56%
[ Tue Jul  5 11:35:32 2022 ] Training epoch: 41
[ Tue Jul  5 11:38:33 2022 ] 	Mean training loss: 0.2907.  Mean training acc: 91.52%.
[ Tue Jul  5 11:38:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:38:33 2022 ] Eval epoch: 41
[ Tue Jul  5 11:39:19 2022 ] 	Mean test loss of 796 batches: 0.7021154267385826.
[ Tue Jul  5 11:39:19 2022 ] 	Top1: 79.56%
[ Tue Jul  5 11:39:19 2022 ] 	Top5: 95.80%
[ Tue Jul  5 11:39:20 2022 ] Training epoch: 42
[ Tue Jul  5 11:42:21 2022 ] 	Mean training loss: 0.2688.  Mean training acc: 92.30%.
[ Tue Jul  5 11:42:21 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:42:21 2022 ] Eval epoch: 42
[ Tue Jul  5 11:43:07 2022 ] 	Mean test loss of 796 batches: 0.7076356860542268.
[ Tue Jul  5 11:43:07 2022 ] 	Top1: 79.33%
[ Tue Jul  5 11:43:08 2022 ] 	Top5: 95.64%
[ Tue Jul  5 11:43:08 2022 ] Training epoch: 43
[ Tue Jul  5 11:46:09 2022 ] 	Mean training loss: 0.2567.  Mean training acc: 92.69%.
[ Tue Jul  5 11:46:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:46:09 2022 ] Eval epoch: 43
[ Tue Jul  5 11:46:55 2022 ] 	Mean test loss of 796 batches: 0.7294531445388668.
[ Tue Jul  5 11:46:55 2022 ] 	Top1: 79.01%
[ Tue Jul  5 11:46:55 2022 ] 	Top5: 95.62%
[ Tue Jul  5 11:46:55 2022 ] Training epoch: 44
[ Tue Jul  5 11:49:57 2022 ] 	Mean training loss: 0.2411.  Mean training acc: 93.20%.
[ Tue Jul  5 11:49:57 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:49:57 2022 ] Eval epoch: 44
[ Tue Jul  5 11:50:43 2022 ] 	Mean test loss of 796 batches: 0.7316929870776495.
[ Tue Jul  5 11:50:44 2022 ] 	Top1: 78.82%
[ Tue Jul  5 11:50:44 2022 ] 	Top5: 95.60%
[ Tue Jul  5 11:50:44 2022 ] Training epoch: 45
[ Tue Jul  5 11:53:46 2022 ] 	Mean training loss: 0.2307.  Mean training acc: 93.38%.
[ Tue Jul  5 11:53:46 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 11:53:46 2022 ] Eval epoch: 45
[ Tue Jul  5 11:54:33 2022 ] 	Mean test loss of 796 batches: 0.7254009972415377.
[ Tue Jul  5 11:54:33 2022 ] 	Top1: 79.09%
[ Tue Jul  5 11:54:33 2022 ] 	Top5: 95.57%
[ Tue Jul  5 11:54:34 2022 ] Training epoch: 46
[ Tue Jul  5 11:57:36 2022 ] 	Mean training loss: 0.2260.  Mean training acc: 93.69%.
[ Tue Jul  5 11:57:36 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 11:57:36 2022 ] Eval epoch: 46
[ Tue Jul  5 11:58:22 2022 ] 	Mean test loss of 796 batches: 0.7650786139370509.
[ Tue Jul  5 11:58:23 2022 ] 	Top1: 78.25%
[ Tue Jul  5 11:58:23 2022 ] 	Top5: 95.40%
[ Tue Jul  5 11:58:23 2022 ] Training epoch: 47
[ Tue Jul  5 12:01:26 2022 ] 	Mean training loss: 0.2162.  Mean training acc: 94.00%.
[ Tue Jul  5 12:01:26 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 12:01:26 2022 ] Eval epoch: 47
[ Tue Jul  5 12:02:13 2022 ] 	Mean test loss of 796 batches: 0.7767313905060291.
[ Tue Jul  5 12:02:14 2022 ] 	Top1: 78.11%
[ Tue Jul  5 12:02:14 2022 ] 	Top5: 95.35%
[ Tue Jul  5 12:02:14 2022 ] Training epoch: 48
[ Tue Jul  5 12:05:17 2022 ] 	Mean training loss: 0.2179.  Mean training acc: 93.85%.
[ Tue Jul  5 12:05:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 12:05:17 2022 ] Eval epoch: 48
[ Tue Jul  5 12:06:04 2022 ] 	Mean test loss of 796 batches: 0.7643110766426553.
[ Tue Jul  5 12:06:05 2022 ] 	Top1: 78.70%
[ Tue Jul  5 12:06:05 2022 ] 	Top5: 95.29%
[ Tue Jul  5 12:06:05 2022 ] Training epoch: 49
[ Tue Jul  5 12:09:09 2022 ] 	Mean training loss: 0.2145.  Mean training acc: 94.02%.
[ Tue Jul  5 12:09:09 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Tue Jul  5 12:09:09 2022 ] Eval epoch: 49
[ Tue Jul  5 12:09:56 2022 ] 	Mean test loss of 796 batches: 0.7871317303734808.
[ Tue Jul  5 12:09:56 2022 ] 	Top1: 78.65%
[ Tue Jul  5 12:09:57 2022 ] 	Top5: 94.91%
[ Tue Jul  5 12:09:57 2022 ] Training epoch: 50
[ Tue Jul  5 12:12:59 2022 ] 	Mean training loss: 0.2075.  Mean training acc: 94.21%.
[ Tue Jul  5 12:12:59 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 12:12:59 2022 ] Eval epoch: 50
[ Tue Jul  5 12:13:45 2022 ] 	Mean test loss of 796 batches: 0.8754261657221234.
[ Tue Jul  5 12:13:45 2022 ] 	Top1: 76.23%
[ Tue Jul  5 12:13:45 2022 ] 	Top5: 94.38%
[ Tue Jul  5 12:13:45 2022 ] Training epoch: 51
[ Tue Jul  5 12:16:47 2022 ] 	Mean training loss: 0.2051.  Mean training acc: 94.28%.
[ Tue Jul  5 12:16:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:16:47 2022 ] Eval epoch: 51
[ Tue Jul  5 12:17:33 2022 ] 	Mean test loss of 796 batches: 0.8125575026824846.
[ Tue Jul  5 12:17:34 2022 ] 	Top1: 77.66%
[ Tue Jul  5 12:17:34 2022 ] 	Top5: 94.78%
[ Tue Jul  5 12:17:34 2022 ] Training epoch: 52
[ Tue Jul  5 12:20:36 2022 ] 	Mean training loss: 0.2068.  Mean training acc: 94.19%.
[ Tue Jul  5 12:20:36 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:20:36 2022 ] Eval epoch: 52
[ Tue Jul  5 12:21:22 2022 ] 	Mean test loss of 796 batches: 0.8285259469669668.
[ Tue Jul  5 12:21:22 2022 ] 	Top1: 77.42%
[ Tue Jul  5 12:21:23 2022 ] 	Top5: 94.92%
[ Tue Jul  5 12:21:23 2022 ] Training epoch: 53
[ Tue Jul  5 12:24:24 2022 ] 	Mean training loss: 0.2088.  Mean training acc: 94.18%.
[ Tue Jul  5 12:24:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:24:24 2022 ] Eval epoch: 53
[ Tue Jul  5 12:25:10 2022 ] 	Mean test loss of 796 batches: 0.8117536426189557.
[ Tue Jul  5 12:25:10 2022 ] 	Top1: 78.13%
[ Tue Jul  5 12:25:11 2022 ] 	Top5: 95.14%
[ Tue Jul  5 12:25:11 2022 ] Training epoch: 54
[ Tue Jul  5 12:28:12 2022 ] 	Mean training loss: 0.2067.  Mean training acc: 94.27%.
[ Tue Jul  5 12:28:12 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:28:12 2022 ] Eval epoch: 54
[ Tue Jul  5 12:28:58 2022 ] 	Mean test loss of 796 batches: 0.8322493475510846.
[ Tue Jul  5 12:28:58 2022 ] 	Top1: 77.26%
[ Tue Jul  5 12:28:59 2022 ] 	Top5: 94.69%
[ Tue Jul  5 12:28:59 2022 ] Training epoch: 55
[ Tue Jul  5 12:32:00 2022 ] 	Mean training loss: 0.2030.  Mean training acc: 94.34%.
[ Tue Jul  5 12:32:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:32:00 2022 ] Eval epoch: 55
[ Tue Jul  5 12:32:46 2022 ] 	Mean test loss of 796 batches: 0.8666298733134965.
[ Tue Jul  5 12:32:46 2022 ] 	Top1: 76.43%
[ Tue Jul  5 12:32:46 2022 ] 	Top5: 94.70%
[ Tue Jul  5 12:32:46 2022 ] Training epoch: 56
[ Tue Jul  5 12:35:48 2022 ] 	Mean training loss: 0.1179.  Mean training acc: 97.24%.
[ Tue Jul  5 12:35:48 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:35:48 2022 ] Eval epoch: 56
[ Tue Jul  5 12:36:33 2022 ] 	Mean test loss of 796 batches: 0.7370454496399841.
[ Tue Jul  5 12:36:34 2022 ] 	Top1: 79.96%
[ Tue Jul  5 12:36:35 2022 ] 	Top5: 95.65%
[ Tue Jul  5 12:36:35 2022 ] Training epoch: 57
[ Tue Jul  5 12:39:36 2022 ] 	Mean training loss: 0.0916.  Mean training acc: 98.01%.
[ Tue Jul  5 12:39:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:39:38 2022 ] Eval epoch: 57
[ Tue Jul  5 12:40:24 2022 ] 	Mean test loss of 796 batches: 0.7369284007192856.
[ Tue Jul  5 12:42:01 2022 ] 	Top1: 79.96%
[ Tue Jul  5 12:42:02 2022 ] 	Top5: 95.62%
[ Tue Jul  5 12:42:02 2022 ] Training epoch: 58
[ Tue Jul  5 12:45:03 2022 ] 	Mean training loss: 0.0824.  Mean training acc: 98.28%.
[ Tue Jul  5 12:45:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:45:19 2022 ] Eval epoch: 58
[ Tue Jul  5 12:46:04 2022 ] 	Mean test loss of 796 batches: 0.7262449039698545.
[ Tue Jul  5 12:48:17 2022 ] 	Top1: 80.40%
[ Tue Jul  5 12:48:17 2022 ] 	Top5: 95.66%
[ Tue Jul  5 12:48:17 2022 ] Training epoch: 59
[ Tue Jul  5 12:51:18 2022 ] 	Mean training loss: 0.0758.  Mean training acc: 98.50%.
[ Tue Jul  5 12:51:18 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:51:26 2022 ] Eval epoch: 59
[ Tue Jul  5 12:52:11 2022 ] 	Mean test loss of 796 batches: 0.7504879399460165.
[ Tue Jul  5 12:52:12 2022 ] 	Top1: 79.85%
[ Tue Jul  5 12:52:12 2022 ] 	Top5: 95.50%
[ Tue Jul  5 12:52:12 2022 ] Training epoch: 60
[ Tue Jul  5 12:55:14 2022 ] 	Mean training loss: 0.0707.  Mean training acc: 98.59%.
[ Tue Jul  5 12:55:14 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:55:14 2022 ] Eval epoch: 60
[ Tue Jul  5 12:56:00 2022 ] 	Mean test loss of 796 batches: 0.7414856493922334.
[ Tue Jul  5 12:56:00 2022 ] 	Top1: 80.18%
[ Tue Jul  5 12:56:01 2022 ] 	Top5: 95.60%
[ Tue Jul  5 12:56:01 2022 ] Training epoch: 61
[ Tue Jul  5 12:59:03 2022 ] 	Mean training loss: 0.0682.  Mean training acc: 98.71%.
[ Tue Jul  5 12:59:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 12:59:03 2022 ] Eval epoch: 61
[ Tue Jul  5 12:59:49 2022 ] 	Mean test loss of 796 batches: 0.7418166872993786.
[ Tue Jul  5 12:59:53 2022 ] 	Top1: 80.09%
[ Tue Jul  5 12:59:53 2022 ] 	Top5: 95.61%
[ Tue Jul  5 12:59:53 2022 ] Training epoch: 62
[ Tue Jul  5 13:02:55 2022 ] 	Mean training loss: 0.0636.  Mean training acc: 98.83%.
[ Tue Jul  5 13:02:55 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jul  5 13:02:55 2022 ] Eval epoch: 62
[ Tue Jul  5 13:03:42 2022 ] 	Mean test loss of 796 batches: 0.7542604056921736.
[ Tue Jul  5 13:03:43 2022 ] 	Top1: 79.79%
[ Tue Jul  5 13:03:43 2022 ] 	Top5: 95.45%
[ Tue Jul  5 13:03:43 2022 ] Training epoch: 63
[ Tue Jul  5 13:07:16 2022 ] 	Mean training loss: 0.0630.  Mean training acc: 98.76%.
[ Tue Jul  5 13:07:25 2022 ] 	Time consumption: [Data]03%, [Network]83%
[ Tue Jul  5 13:07:31 2022 ] Eval epoch: 63
[ Tue Jul  5 13:08:19 2022 ] 	Mean test loss of 796 batches: 0.7378825320108752.
[ Tue Jul  5 13:08:21 2022 ] 	Top1: 80.16%
[ Tue Jul  5 13:08:21 2022 ] 	Top5: 95.58%
[ Tue Jul  5 13:08:21 2022 ] Training epoch: 64
[ Tue Jul  5 13:11:25 2022 ] 	Mean training loss: 0.0578.  Mean training acc: 99.01%.
[ Tue Jul  5 13:11:25 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 13:11:25 2022 ] Eval epoch: 64
[ Tue Jul  5 13:12:12 2022 ] 	Mean test loss of 796 batches: 0.7435028480749634.
[ Tue Jul  5 13:12:13 2022 ] 	Top1: 80.15%
[ Tue Jul  5 13:12:13 2022 ] 	Top5: 95.55%
[ Tue Jul  5 13:12:13 2022 ] Training epoch: 65
[ Tue Jul  5 13:15:17 2022 ] 	Mean training loss: 0.0566.  Mean training acc: 98.99%.
[ Tue Jul  5 13:15:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Jul  5 13:15:17 2022 ] Eval epoch: 65
[ Tue Jul  5 13:16:04 2022 ] 	Mean test loss of 796 batches: 0.7423454224688923.
[ Tue Jul  5 13:16:04 2022 ] 	Top1: 80.27%
[ Tue Jul  5 13:16:05 2022 ] 	Top5: 95.57%
[ Tue Jul  5 13:16:54 2022 ] Best accuracy: 0.8040417133093737
[ Tue Jul  5 13:16:54 2022 ] Epoch number: 58
[ Tue Jul  5 13:16:54 2022 ] Model name: work_dir/ntu120/csub/base_four6a_vel
[ Tue Jul  5 13:16:54 2022 ] Model total number of params: 2128482
[ Tue Jul  5 13:16:54 2022 ] Weight decay: 0.0004
[ Tue Jul  5 13:16:54 2022 ] Base LR: 0.1
[ Tue Jul  5 13:16:54 2022 ] Batch Size: 64
[ Tue Jul  5 13:16:54 2022 ] Test Batch Size: 64
[ Tue Jul  5 13:16:54 2022 ] seed: 1
