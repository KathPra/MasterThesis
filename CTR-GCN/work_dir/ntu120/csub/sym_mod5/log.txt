[ Mon Aug  1 10:52:39 2022 ] using warm up, epoch: 5
[ Mon Aug  1 10:54:30 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Aug  1 10:54:30 2022 ] # Parameters: 2187826
[ Mon Aug  1 10:54:30 2022 ] Training epoch: 1
[ Mon Aug  1 10:59:11 2022 ] using warm up, epoch: 5
[ Mon Aug  1 11:01:01 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Aug  1 11:01:01 2022 ] # Parameters: 2187826
[ Mon Aug  1 11:01:01 2022 ] Training epoch: 1
[ Mon Aug  1 11:13:25 2022 ] using warm up, epoch: 5
[ Mon Aug  1 11:13:39 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Aug  1 11:13:39 2022 ] # Parameters: 2204594
[ Mon Aug  1 11:13:39 2022 ] Training epoch: 1
[ Mon Aug  1 11:15:09 2022 ] using warm up, epoch: 5
[ Mon Aug  1 11:15:22 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Aug  1 11:15:22 2022 ] # Parameters: 2192114
[ Mon Aug  1 11:15:22 2022 ] Training epoch: 1
[ Mon Aug  1 11:16:01 2022 ] using warm up, epoch: 5
[ Mon Aug  1 11:16:15 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Aug  1 11:16:15 2022 ] # Parameters: 2204402
[ Mon Aug  1 11:16:15 2022 ] Training epoch: 1
[ Mon Aug  1 11:19:21 2022 ] 	Mean training loss: 3.1331.  Mean training acc: 21.69%.
[ Mon Aug  1 11:19:21 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 11:19:21 2022 ] Eval epoch: 1
[ Mon Aug  1 11:20:08 2022 ] 	Mean test loss of 796 batches: 2.7017125349547997.
[ Mon Aug  1 11:20:08 2022 ] 	Top1: 26.90%
[ Mon Aug  1 11:20:09 2022 ] 	Top5: 60.57%
[ Mon Aug  1 11:20:09 2022 ] Training epoch: 2
[ Mon Aug  1 11:23:16 2022 ] 	Mean training loss: 2.0665.  Mean training acc: 42.41%.
[ Mon Aug  1 11:23:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:23:16 2022 ] Eval epoch: 2
[ Mon Aug  1 11:24:02 2022 ] 	Mean test loss of 796 batches: 1.949180348135119.
[ Mon Aug  1 11:24:03 2022 ] 	Top1: 42.98%
[ Mon Aug  1 11:24:03 2022 ] 	Top5: 78.93%
[ Mon Aug  1 11:24:03 2022 ] Training epoch: 3
[ Mon Aug  1 11:27:10 2022 ] 	Mean training loss: 1.6679.  Mean training acc: 51.91%.
[ Mon Aug  1 11:27:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:27:10 2022 ] Eval epoch: 3
[ Mon Aug  1 11:27:57 2022 ] 	Mean test loss of 796 batches: 2.32577812896302.
[ Mon Aug  1 11:27:57 2022 ] 	Top1: 43.24%
[ Mon Aug  1 11:27:58 2022 ] 	Top5: 77.69%
[ Mon Aug  1 11:27:58 2022 ] Training epoch: 4
[ Mon Aug  1 11:31:06 2022 ] 	Mean training loss: 1.4694.  Mean training acc: 57.18%.
[ Mon Aug  1 11:31:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:31:06 2022 ] Eval epoch: 4
[ Mon Aug  1 11:31:52 2022 ] 	Mean test loss of 796 batches: 1.636278001806844.
[ Mon Aug  1 11:31:52 2022 ] 	Top1: 51.80%
[ Mon Aug  1 11:31:53 2022 ] 	Top5: 84.37%
[ Mon Aug  1 11:31:53 2022 ] Training epoch: 5
[ Mon Aug  1 11:35:00 2022 ] 	Mean training loss: 1.3321.  Mean training acc: 61.05%.
[ Mon Aug  1 11:35:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:35:00 2022 ] Eval epoch: 5
[ Mon Aug  1 11:36:18 2022 ] 	Mean test loss of 796 batches: 1.5892965916413158.
[ Mon Aug  1 11:36:19 2022 ] 	Top1: 55.77%
[ Mon Aug  1 11:36:19 2022 ] 	Top5: 84.29%
[ Mon Aug  1 11:36:19 2022 ] Training epoch: 6
[ Mon Aug  1 11:40:32 2022 ] 	Mean training loss: 1.1946.  Mean training acc: 64.56%.
[ Mon Aug  1 11:40:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:40:32 2022 ] Eval epoch: 6
[ Mon Aug  1 11:41:18 2022 ] 	Mean test loss of 796 batches: 1.3637464426495323.
[ Mon Aug  1 11:41:19 2022 ] 	Top1: 59.53%
[ Mon Aug  1 11:41:19 2022 ] 	Top5: 88.99%
[ Mon Aug  1 11:41:19 2022 ] Training epoch: 7
[ Mon Aug  1 11:44:26 2022 ] 	Mean training loss: 1.1133.  Mean training acc: 66.74%.
[ Mon Aug  1 11:44:26 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:44:26 2022 ] Eval epoch: 7
[ Mon Aug  1 11:45:13 2022 ] 	Mean test loss of 796 batches: 1.4203154284825277.
[ Mon Aug  1 11:45:13 2022 ] 	Top1: 58.75%
[ Mon Aug  1 11:45:14 2022 ] 	Top5: 87.77%
[ Mon Aug  1 11:45:14 2022 ] Training epoch: 8
[ Mon Aug  1 11:48:21 2022 ] 	Mean training loss: 1.0446.  Mean training acc: 68.73%.
[ Mon Aug  1 11:48:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 11:48:21 2022 ] Eval epoch: 8
[ Mon Aug  1 11:49:08 2022 ] 	Mean test loss of 796 batches: 1.391568478777181.
[ Mon Aug  1 11:49:09 2022 ] 	Top1: 59.72%
[ Mon Aug  1 11:49:09 2022 ] 	Top5: 89.57%
[ Mon Aug  1 11:49:09 2022 ] Training epoch: 9
[ Mon Aug  1 11:52:21 2022 ] 	Mean training loss: 1.0077.  Mean training acc: 69.80%.
[ Mon Aug  1 11:52:21 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 11:52:21 2022 ] Eval epoch: 9
[ Mon Aug  1 11:53:42 2022 ] 	Mean test loss of 796 batches: 1.2736609652638435.
[ Mon Aug  1 11:53:43 2022 ] 	Top1: 63.13%
[ Mon Aug  1 11:53:43 2022 ] 	Top5: 90.01%
[ Mon Aug  1 11:53:43 2022 ] Training epoch: 10
[ Mon Aug  1 11:58:52 2022 ] 	Mean training loss: 0.9697.  Mean training acc: 70.87%.
[ Mon Aug  1 11:58:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 11:58:52 2022 ] Eval epoch: 10
[ Mon Aug  1 12:00:10 2022 ] 	Mean test loss of 796 batches: 1.349609419890684.
[ Mon Aug  1 12:00:10 2022 ] 	Top1: 62.84%
[ Mon Aug  1 12:00:11 2022 ] 	Top5: 87.96%
[ Mon Aug  1 12:00:11 2022 ] Training epoch: 11
[ Mon Aug  1 12:05:18 2022 ] 	Mean training loss: 0.9482.  Mean training acc: 71.36%.
[ Mon Aug  1 12:05:18 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:05:18 2022 ] Eval epoch: 11
[ Mon Aug  1 12:06:39 2022 ] 	Mean test loss of 796 batches: 1.2490256079028.
[ Mon Aug  1 12:06:40 2022 ] 	Top1: 63.95%
[ Mon Aug  1 12:06:41 2022 ] 	Top5: 89.72%
[ Mon Aug  1 12:06:41 2022 ] Training epoch: 12
[ Mon Aug  1 12:11:44 2022 ] 	Mean training loss: 0.9306.  Mean training acc: 72.11%.
[ Mon Aug  1 12:11:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:11:44 2022 ] Eval epoch: 12
[ Mon Aug  1 12:13:06 2022 ] 	Mean test loss of 796 batches: 1.199725187678433.
[ Mon Aug  1 12:13:06 2022 ] 	Top1: 64.28%
[ Mon Aug  1 12:13:06 2022 ] 	Top5: 90.51%
[ Mon Aug  1 12:13:06 2022 ] Training epoch: 13
[ Mon Aug  1 12:18:09 2022 ] 	Mean training loss: 0.9129.  Mean training acc: 72.70%.
[ Mon Aug  1 12:18:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:18:09 2022 ] Eval epoch: 13
[ Mon Aug  1 12:19:30 2022 ] 	Mean test loss of 796 batches: 1.286014564934388.
[ Mon Aug  1 12:19:31 2022 ] 	Top1: 62.14%
[ Mon Aug  1 12:19:31 2022 ] 	Top5: 89.81%
[ Mon Aug  1 12:19:31 2022 ] Training epoch: 14
[ Mon Aug  1 12:24:41 2022 ] 	Mean training loss: 0.8952.  Mean training acc: 72.90%.
[ Mon Aug  1 12:24:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:24:41 2022 ] Eval epoch: 14
[ Mon Aug  1 12:25:55 2022 ] 	Mean test loss of 796 batches: 1.3959040064832673.
[ Mon Aug  1 12:25:55 2022 ] 	Top1: 59.98%
[ Mon Aug  1 12:25:56 2022 ] 	Top5: 89.76%
[ Mon Aug  1 12:25:56 2022 ] Training epoch: 15
[ Mon Aug  1 12:31:05 2022 ] 	Mean training loss: 0.8799.  Mean training acc: 73.52%.
[ Mon Aug  1 12:31:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:31:05 2022 ] Eval epoch: 15
[ Mon Aug  1 12:32:27 2022 ] 	Mean test loss of 796 batches: 1.049072984437547.
[ Mon Aug  1 12:32:28 2022 ] 	Top1: 68.69%
[ Mon Aug  1 12:32:28 2022 ] 	Top5: 91.84%
[ Mon Aug  1 12:32:28 2022 ] Training epoch: 16
[ Mon Aug  1 12:37:30 2022 ] 	Mean training loss: 0.8701.  Mean training acc: 73.87%.
[ Mon Aug  1 12:37:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:37:30 2022 ] Eval epoch: 16
[ Mon Aug  1 12:38:51 2022 ] 	Mean test loss of 796 batches: 1.0491724715909767.
[ Mon Aug  1 12:38:51 2022 ] 	Top1: 69.29%
[ Mon Aug  1 12:38:52 2022 ] 	Top5: 92.20%
[ Mon Aug  1 12:38:52 2022 ] Training epoch: 17
[ Mon Aug  1 12:43:58 2022 ] 	Mean training loss: 0.8637.  Mean training acc: 73.69%.
[ Mon Aug  1 12:43:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:43:58 2022 ] Eval epoch: 17
[ Mon Aug  1 12:45:18 2022 ] 	Mean test loss of 796 batches: 1.1875869111349835.
[ Mon Aug  1 12:45:18 2022 ] 	Top1: 65.82%
[ Mon Aug  1 12:45:19 2022 ] 	Top5: 90.95%
[ Mon Aug  1 12:45:19 2022 ] Training epoch: 18
[ Mon Aug  1 12:50:23 2022 ] 	Mean training loss: 0.8464.  Mean training acc: 74.45%.
[ Mon Aug  1 12:50:23 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:50:23 2022 ] Eval epoch: 18
[ Mon Aug  1 12:51:43 2022 ] 	Mean test loss of 796 batches: 1.2915321839739329.
[ Mon Aug  1 12:51:44 2022 ] 	Top1: 63.80%
[ Mon Aug  1 12:51:44 2022 ] 	Top5: 90.21%
[ Mon Aug  1 12:51:44 2022 ] Training epoch: 19
[ Mon Aug  1 12:56:54 2022 ] 	Mean training loss: 0.8399.  Mean training acc: 74.51%.
[ Mon Aug  1 12:56:54 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 12:56:54 2022 ] Eval epoch: 19
[ Mon Aug  1 12:58:07 2022 ] 	Mean test loss of 796 batches: 1.2646314720038194.
[ Mon Aug  1 12:58:08 2022 ] 	Top1: 65.49%
[ Mon Aug  1 12:58:08 2022 ] 	Top5: 90.55%
[ Mon Aug  1 12:58:08 2022 ] Training epoch: 20
[ Mon Aug  1 13:03:19 2022 ] 	Mean training loss: 0.8413.  Mean training acc: 74.47%.
[ Mon Aug  1 13:03:19 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:03:19 2022 ] Eval epoch: 20
[ Mon Aug  1 13:04:40 2022 ] 	Mean test loss of 796 batches: 1.1807442711825347.
[ Mon Aug  1 13:04:41 2022 ] 	Top1: 65.73%
[ Mon Aug  1 13:04:41 2022 ] 	Top5: 91.55%
[ Mon Aug  1 13:04:41 2022 ] Training epoch: 21
[ Mon Aug  1 13:09:46 2022 ] 	Mean training loss: 0.8331.  Mean training acc: 74.73%.
[ Mon Aug  1 13:09:46 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:09:46 2022 ] Eval epoch: 21
[ Mon Aug  1 13:11:07 2022 ] 	Mean test loss of 796 batches: 0.9597126030218062.
[ Mon Aug  1 13:11:07 2022 ] 	Top1: 71.13%
[ Mon Aug  1 13:11:07 2022 ] 	Top5: 93.07%
[ Mon Aug  1 13:11:07 2022 ] Training epoch: 22
[ Mon Aug  1 13:16:07 2022 ] 	Mean training loss: 0.8327.  Mean training acc: 74.74%.
[ Mon Aug  1 13:16:07 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:16:07 2022 ] Eval epoch: 22
[ Mon Aug  1 13:17:28 2022 ] 	Mean test loss of 796 batches: 1.174735301029143.
[ Mon Aug  1 13:17:28 2022 ] 	Top1: 66.03%
[ Mon Aug  1 13:17:28 2022 ] 	Top5: 91.31%
[ Mon Aug  1 13:17:28 2022 ] Training epoch: 23
[ Mon Aug  1 13:22:33 2022 ] 	Mean training loss: 0.8245.  Mean training acc: 74.87%.
[ Mon Aug  1 13:22:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:22:33 2022 ] Eval epoch: 23
[ Mon Aug  1 13:23:53 2022 ] 	Mean test loss of 796 batches: 1.233097815277738.
[ Mon Aug  1 13:23:54 2022 ] 	Top1: 65.48%
[ Mon Aug  1 13:23:54 2022 ] 	Top5: 89.63%
[ Mon Aug  1 13:23:54 2022 ] Training epoch: 24
[ Mon Aug  1 13:29:05 2022 ] 	Mean training loss: 0.8186.  Mean training acc: 75.04%.
[ Mon Aug  1 13:29:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:29:05 2022 ] Eval epoch: 24
[ Mon Aug  1 13:30:20 2022 ] 	Mean test loss of 796 batches: 1.055496860201934.
[ Mon Aug  1 13:30:20 2022 ] 	Top1: 69.58%
[ Mon Aug  1 13:30:20 2022 ] 	Top5: 92.44%
[ Mon Aug  1 13:30:20 2022 ] Training epoch: 25
[ Mon Aug  1 13:35:33 2022 ] 	Mean training loss: 0.8166.  Mean training acc: 75.20%.
[ Mon Aug  1 13:35:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:35:33 2022 ] Eval epoch: 25
[ Mon Aug  1 13:36:53 2022 ] 	Mean test loss of 796 batches: 1.231916441802104.
[ Mon Aug  1 13:36:53 2022 ] 	Top1: 63.88%
[ Mon Aug  1 13:36:54 2022 ] 	Top5: 90.25%
[ Mon Aug  1 13:36:54 2022 ] Training epoch: 26
[ Mon Aug  1 13:41:56 2022 ] 	Mean training loss: 0.8104.  Mean training acc: 75.39%.
[ Mon Aug  1 13:41:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:41:56 2022 ] Eval epoch: 26
[ Mon Aug  1 13:43:16 2022 ] 	Mean test loss of 796 batches: 1.900070949939627.
[ Mon Aug  1 13:43:16 2022 ] 	Top1: 53.94%
[ Mon Aug  1 13:43:17 2022 ] 	Top5: 80.42%
[ Mon Aug  1 13:43:17 2022 ] Training epoch: 27
[ Mon Aug  1 13:48:22 2022 ] 	Mean training loss: 0.8107.  Mean training acc: 75.34%.
[ Mon Aug  1 13:48:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:48:22 2022 ] Eval epoch: 27
[ Mon Aug  1 13:49:42 2022 ] 	Mean test loss of 796 batches: 1.1115499883890152.
[ Mon Aug  1 13:49:42 2022 ] 	Top1: 68.32%
[ Mon Aug  1 13:49:42 2022 ] 	Top5: 91.52%
[ Mon Aug  1 13:49:42 2022 ] Training epoch: 28
[ Mon Aug  1 13:54:51 2022 ] 	Mean training loss: 0.7996.  Mean training acc: 75.72%.
[ Mon Aug  1 13:54:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 13:54:51 2022 ] Eval epoch: 28
[ Mon Aug  1 13:56:10 2022 ] 	Mean test loss of 796 batches: 1.0904848255479156.
[ Mon Aug  1 13:56:10 2022 ] 	Top1: 67.65%
[ Mon Aug  1 13:56:10 2022 ] 	Top5: 91.79%
[ Mon Aug  1 13:56:10 2022 ] Training epoch: 29
[ Mon Aug  1 14:01:22 2022 ] 	Mean training loss: 0.7978.  Mean training acc: 75.76%.
[ Mon Aug  1 14:01:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:01:22 2022 ] Eval epoch: 29
[ Mon Aug  1 14:02:43 2022 ] 	Mean test loss of 796 batches: 1.033531217606523.
[ Mon Aug  1 14:02:43 2022 ] 	Top1: 70.12%
[ Mon Aug  1 14:02:43 2022 ] 	Top5: 92.32%
[ Mon Aug  1 14:02:43 2022 ] Training epoch: 30
[ Mon Aug  1 14:07:50 2022 ] 	Mean training loss: 0.8021.  Mean training acc: 75.65%.
[ Mon Aug  1 14:07:50 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:07:50 2022 ] Eval epoch: 30
[ Mon Aug  1 14:09:11 2022 ] 	Mean test loss of 796 batches: 1.099977478497292.
[ Mon Aug  1 14:09:11 2022 ] 	Top1: 67.35%
[ Mon Aug  1 14:09:11 2022 ] 	Top5: 91.78%
[ Mon Aug  1 14:09:11 2022 ] Training epoch: 31
[ Mon Aug  1 14:14:18 2022 ] 	Mean training loss: 0.7973.  Mean training acc: 75.61%.
[ Mon Aug  1 14:14:18 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:14:18 2022 ] Eval epoch: 31
[ Mon Aug  1 14:15:37 2022 ] 	Mean test loss of 796 batches: 1.0115934098186206.
[ Mon Aug  1 14:15:37 2022 ] 	Top1: 70.71%
[ Mon Aug  1 14:15:38 2022 ] 	Top5: 92.41%
[ Mon Aug  1 14:15:38 2022 ] Training epoch: 32
[ Mon Aug  1 14:20:43 2022 ] 	Mean training loss: 0.7939.  Mean training acc: 75.90%.
[ Mon Aug  1 14:20:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:20:44 2022 ] Eval epoch: 32
[ Mon Aug  1 14:22:04 2022 ] 	Mean test loss of 796 batches: 1.0593297214588928.
[ Mon Aug  1 14:22:04 2022 ] 	Top1: 68.81%
[ Mon Aug  1 14:22:05 2022 ] 	Top5: 91.96%
[ Mon Aug  1 14:22:05 2022 ] Training epoch: 33
[ Mon Aug  1 14:27:13 2022 ] 	Mean training loss: 0.7984.  Mean training acc: 75.72%.
[ Mon Aug  1 14:27:13 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:27:14 2022 ] Eval epoch: 33
[ Mon Aug  1 14:28:33 2022 ] 	Mean test loss of 796 batches: 1.099395266916584.
[ Mon Aug  1 14:28:33 2022 ] 	Top1: 67.79%
[ Mon Aug  1 14:28:33 2022 ] 	Top5: 91.50%
[ Mon Aug  1 14:28:33 2022 ] Training epoch: 34
[ Mon Aug  1 14:33:44 2022 ] 	Mean training loss: 0.7896.  Mean training acc: 75.99%.
[ Mon Aug  1 14:33:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:33:45 2022 ] Eval epoch: 34
[ Mon Aug  1 14:35:05 2022 ] 	Mean test loss of 796 batches: 1.1836769621276377.
[ Mon Aug  1 14:35:05 2022 ] 	Top1: 66.25%
[ Mon Aug  1 14:35:06 2022 ] 	Top5: 90.47%
[ Mon Aug  1 14:35:06 2022 ] Training epoch: 35
[ Mon Aug  1 14:40:12 2022 ] 	Mean training loss: 0.7902.  Mean training acc: 75.95%.
[ Mon Aug  1 14:40:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:40:12 2022 ] Eval epoch: 35
[ Mon Aug  1 14:41:32 2022 ] 	Mean test loss of 796 batches: 1.0145290460643457.
[ Mon Aug  1 14:41:32 2022 ] 	Top1: 69.90%
[ Mon Aug  1 14:41:33 2022 ] 	Top5: 92.37%
[ Mon Aug  1 14:41:33 2022 ] Training epoch: 36
[ Mon Aug  1 14:46:40 2022 ] 	Mean training loss: 0.4532.  Mean training acc: 85.99%.
[ Mon Aug  1 14:46:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 14:46:40 2022 ] Eval epoch: 36
[ Mon Aug  1 14:48:00 2022 ] 	Mean test loss of 796 batches: 0.6080092346230194.
[ Mon Aug  1 14:48:00 2022 ] 	Top1: 81.24%
[ Mon Aug  1 14:48:01 2022 ] 	Top5: 96.47%
[ Mon Aug  1 14:48:01 2022 ] Training epoch: 37
[ Mon Aug  1 14:53:07 2022 ] 	Mean training loss: 0.3649.  Mean training acc: 88.46%.
[ Mon Aug  1 14:53:08 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:53:08 2022 ] Eval epoch: 37
[ Mon Aug  1 14:54:29 2022 ] 	Mean test loss of 796 batches: 0.5979682902931868.
[ Mon Aug  1 14:54:29 2022 ] 	Top1: 81.85%
[ Mon Aug  1 14:54:30 2022 ] 	Top5: 96.59%
[ Mon Aug  1 14:54:30 2022 ] Training epoch: 38
[ Mon Aug  1 14:59:39 2022 ] 	Mean training loss: 0.3261.  Mean training acc: 89.72%.
[ Mon Aug  1 14:59:39 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 14:59:39 2022 ] Eval epoch: 38
[ Mon Aug  1 15:00:57 2022 ] 	Mean test loss of 796 batches: 0.5956247536250245.
[ Mon Aug  1 15:00:58 2022 ] 	Top1: 82.09%
[ Mon Aug  1 15:00:58 2022 ] 	Top5: 96.61%
[ Mon Aug  1 15:00:58 2022 ] Training epoch: 39
[ Mon Aug  1 15:06:09 2022 ] 	Mean training loss: 0.3011.  Mean training acc: 90.57%.
[ Mon Aug  1 15:06:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:06:09 2022 ] Eval epoch: 39
[ Mon Aug  1 15:07:30 2022 ] 	Mean test loss of 796 batches: 0.608352832046885.
[ Mon Aug  1 15:07:30 2022 ] 	Top1: 81.70%
[ Mon Aug  1 15:07:31 2022 ] 	Top5: 96.62%
[ Mon Aug  1 15:07:31 2022 ] Training epoch: 40
[ Mon Aug  1 15:12:37 2022 ] 	Mean training loss: 0.2803.  Mean training acc: 91.22%.
[ Mon Aug  1 15:12:37 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:12:37 2022 ] Eval epoch: 40
[ Mon Aug  1 15:13:58 2022 ] 	Mean test loss of 796 batches: 0.6060999522463011.
[ Mon Aug  1 15:13:58 2022 ] 	Top1: 81.99%
[ Mon Aug  1 15:13:59 2022 ] 	Top5: 96.64%
[ Mon Aug  1 15:13:59 2022 ] Training epoch: 41
[ Mon Aug  1 15:19:04 2022 ] 	Mean training loss: 0.2607.  Mean training acc: 91.88%.
[ Mon Aug  1 15:19:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:19:04 2022 ] Eval epoch: 41
[ Mon Aug  1 15:20:24 2022 ] 	Mean test loss of 796 batches: 0.634063345235047.
[ Mon Aug  1 15:20:25 2022 ] 	Top1: 81.66%
[ Mon Aug  1 15:20:25 2022 ] 	Top5: 96.41%
[ Mon Aug  1 15:20:25 2022 ] Training epoch: 42
[ Mon Aug  1 15:25:31 2022 ] 	Mean training loss: 0.2514.  Mean training acc: 92.14%.
[ Mon Aug  1 15:25:31 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:25:31 2022 ] Eval epoch: 42
[ Mon Aug  1 15:26:52 2022 ] 	Mean test loss of 796 batches: 0.6416654424489143.
[ Mon Aug  1 15:26:53 2022 ] 	Top1: 81.48%
[ Mon Aug  1 15:26:53 2022 ] 	Top5: 96.30%
[ Mon Aug  1 15:26:53 2022 ] Training epoch: 43
[ Mon Aug  1 15:32:04 2022 ] 	Mean training loss: 0.2310.  Mean training acc: 92.76%.
[ Mon Aug  1 15:32:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:32:04 2022 ] Eval epoch: 43
[ Mon Aug  1 15:33:19 2022 ] 	Mean test loss of 796 batches: 0.6434055713646526.
[ Mon Aug  1 15:33:20 2022 ] 	Top1: 81.75%
[ Mon Aug  1 15:33:20 2022 ] 	Top5: 96.33%
[ Mon Aug  1 15:33:20 2022 ] Training epoch: 44
[ Mon Aug  1 15:38:31 2022 ] 	Mean training loss: 0.2239.  Mean training acc: 92.97%.
[ Mon Aug  1 15:38:31 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:38:31 2022 ] Eval epoch: 44
[ Mon Aug  1 15:39:52 2022 ] 	Mean test loss of 796 batches: 0.6583928860976693.
[ Mon Aug  1 15:39:53 2022 ] 	Top1: 81.50%
[ Mon Aug  1 15:39:53 2022 ] 	Top5: 96.38%
[ Mon Aug  1 15:39:53 2022 ] Training epoch: 45
[ Mon Aug  1 15:45:00 2022 ] 	Mean training loss: 0.2135.  Mean training acc: 93.30%.
[ Mon Aug  1 15:45:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 15:45:00 2022 ] Eval epoch: 45
[ Mon Aug  1 15:46:21 2022 ] 	Mean test loss of 796 batches: 0.6773311115108692.
[ Mon Aug  1 15:46:22 2022 ] 	Top1: 81.35%
[ Mon Aug  1 15:46:22 2022 ] 	Top5: 96.12%
[ Mon Aug  1 15:46:22 2022 ] Training epoch: 46
[ Mon Aug  1 15:51:29 2022 ] 	Mean training loss: 0.2097.  Mean training acc: 93.37%.
[ Mon Aug  1 15:51:29 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:51:29 2022 ] Eval epoch: 46
[ Mon Aug  1 15:52:50 2022 ] 	Mean test loss of 796 batches: 0.6737268777779448.
[ Mon Aug  1 15:52:50 2022 ] 	Top1: 81.07%
[ Mon Aug  1 15:52:51 2022 ] 	Top5: 96.14%
[ Mon Aug  1 15:52:51 2022 ] Training epoch: 47
[ Mon Aug  1 15:57:57 2022 ] 	Mean training loss: 0.2020.  Mean training acc: 93.75%.
[ Mon Aug  1 15:57:57 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 15:57:57 2022 ] Eval epoch: 47
[ Mon Aug  1 15:59:18 2022 ] 	Mean test loss of 796 batches: 0.6753412594915784.
[ Mon Aug  1 15:59:19 2022 ] 	Top1: 80.91%
[ Mon Aug  1 15:59:19 2022 ] 	Top5: 96.03%
[ Mon Aug  1 15:59:19 2022 ] Training epoch: 48
[ Mon Aug  1 16:04:30 2022 ] 	Mean training loss: 0.2001.  Mean training acc: 93.76%.
[ Mon Aug  1 16:04:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:04:30 2022 ] Eval epoch: 48
[ Mon Aug  1 16:05:44 2022 ] 	Mean test loss of 796 batches: 0.740606527738086.
[ Mon Aug  1 16:05:45 2022 ] 	Top1: 80.05%
[ Mon Aug  1 16:05:45 2022 ] 	Top5: 95.52%
[ Mon Aug  1 16:05:45 2022 ] Training epoch: 49
[ Mon Aug  1 16:10:54 2022 ] 	Mean training loss: 0.2057.  Mean training acc: 93.62%.
[ Mon Aug  1 16:10:54 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:10:55 2022 ] Eval epoch: 49
[ Mon Aug  1 16:12:15 2022 ] 	Mean test loss of 796 batches: 0.7058264112296566.
[ Mon Aug  1 16:12:16 2022 ] 	Top1: 80.49%
[ Mon Aug  1 16:12:16 2022 ] 	Top5: 95.96%
[ Mon Aug  1 16:12:16 2022 ] Training epoch: 50
[ Mon Aug  1 16:17:23 2022 ] 	Mean training loss: 0.1958.  Mean training acc: 93.98%.
[ Mon Aug  1 16:17:23 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:17:23 2022 ] Eval epoch: 50
[ Mon Aug  1 16:18:44 2022 ] 	Mean test loss of 796 batches: 0.8013944085593798.
[ Mon Aug  1 16:18:45 2022 ] 	Top1: 78.49%
[ Mon Aug  1 16:18:45 2022 ] 	Top5: 95.03%
[ Mon Aug  1 16:18:45 2022 ] Training epoch: 51
[ Mon Aug  1 16:23:51 2022 ] 	Mean training loss: 0.1968.  Mean training acc: 93.87%.
[ Mon Aug  1 16:23:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:23:51 2022 ] Eval epoch: 51
[ Mon Aug  1 16:25:12 2022 ] 	Mean test loss of 796 batches: 0.7220188869097873.
[ Mon Aug  1 16:25:13 2022 ] 	Top1: 80.19%
[ Mon Aug  1 16:25:13 2022 ] 	Top5: 95.72%
[ Mon Aug  1 16:25:13 2022 ] Training epoch: 52
[ Mon Aug  1 16:30:20 2022 ] 	Mean training loss: 0.1972.  Mean training acc: 93.80%.
[ Mon Aug  1 16:30:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Aug  1 16:30:20 2022 ] Eval epoch: 52
[ Mon Aug  1 16:31:41 2022 ] 	Mean test loss of 796 batches: 0.712219246265352.
[ Mon Aug  1 16:31:42 2022 ] 	Top1: 80.89%
[ Mon Aug  1 16:31:42 2022 ] 	Top5: 95.87%
[ Mon Aug  1 16:31:42 2022 ] Training epoch: 53
[ Mon Aug  1 16:36:47 2022 ] 	Mean training loss: 0.1999.  Mean training acc: 93.69%.
[ Mon Aug  1 16:36:47 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:36:47 2022 ] Eval epoch: 53
[ Mon Aug  1 16:38:05 2022 ] 	Mean test loss of 796 batches: 0.8503540124950097.
[ Mon Aug  1 16:38:05 2022 ] 	Top1: 77.56%
[ Mon Aug  1 16:38:06 2022 ] 	Top5: 94.22%
[ Mon Aug  1 16:38:06 2022 ] Training epoch: 54
[ Mon Aug  1 16:43:10 2022 ] 	Mean training loss: 0.1950.  Mean training acc: 93.93%.
[ Mon Aug  1 16:43:10 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:43:10 2022 ] Eval epoch: 54
[ Mon Aug  1 16:44:26 2022 ] 	Mean test loss of 796 batches: 0.7936169770195256.
[ Mon Aug  1 16:44:26 2022 ] 	Top1: 78.63%
[ Mon Aug  1 16:44:27 2022 ] 	Top5: 95.15%
[ Mon Aug  1 16:44:27 2022 ] Training epoch: 55
[ Mon Aug  1 16:49:33 2022 ] 	Mean training loss: 0.1917.  Mean training acc: 94.04%.
[ Mon Aug  1 16:49:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:49:33 2022 ] Eval epoch: 55
[ Mon Aug  1 16:50:52 2022 ] 	Mean test loss of 796 batches: 0.8031326960585076.
[ Mon Aug  1 16:50:52 2022 ] 	Top1: 79.19%
[ Mon Aug  1 16:50:52 2022 ] 	Top5: 95.08%
[ Mon Aug  1 16:50:53 2022 ] Training epoch: 56
[ Mon Aug  1 16:55:51 2022 ] 	Mean training loss: 0.1088.  Mean training acc: 97.05%.
[ Mon Aug  1 16:55:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 16:55:51 2022 ] Eval epoch: 56
[ Mon Aug  1 16:57:11 2022 ] 	Mean test loss of 796 batches: 0.6627953576869402.
[ Mon Aug  1 16:57:11 2022 ] 	Top1: 82.19%
[ Mon Aug  1 16:57:12 2022 ] 	Top5: 96.29%
[ Mon Aug  1 16:57:12 2022 ] Training epoch: 57
[ Mon Aug  1 17:02:13 2022 ] 	Mean training loss: 0.0816.  Mean training acc: 97.98%.
[ Mon Aug  1 17:02:13 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:02:13 2022 ] Eval epoch: 57
[ Mon Aug  1 17:03:31 2022 ] 	Mean test loss of 796 batches: 0.6713042757637686.
[ Mon Aug  1 17:03:32 2022 ] 	Top1: 82.11%
[ Mon Aug  1 17:03:32 2022 ] 	Top5: 96.33%
[ Mon Aug  1 17:03:32 2022 ] Training epoch: 58
[ Mon Aug  1 17:08:32 2022 ] 	Mean training loss: 0.0719.  Mean training acc: 98.29%.
[ Mon Aug  1 17:08:32 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:08:32 2022 ] Eval epoch: 58
[ Mon Aug  1 17:09:52 2022 ] 	Mean test loss of 796 batches: 0.6712296496533868.
[ Mon Aug  1 17:09:52 2022 ] 	Top1: 82.28%
[ Mon Aug  1 17:09:52 2022 ] 	Top5: 96.28%
[ Mon Aug  1 17:09:52 2022 ] Training epoch: 59
[ Mon Aug  1 17:14:57 2022 ] 	Mean training loss: 0.0637.  Mean training acc: 98.56%.
[ Mon Aug  1 17:14:57 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:14:57 2022 ] Eval epoch: 59
[ Mon Aug  1 17:16:11 2022 ] 	Mean test loss of 796 batches: 0.6707682335964549.
[ Mon Aug  1 17:16:12 2022 ] 	Top1: 82.42%
[ Mon Aug  1 17:16:12 2022 ] 	Top5: 96.33%
[ Mon Aug  1 17:16:12 2022 ] Training epoch: 60
[ Mon Aug  1 17:21:18 2022 ] 	Mean training loss: 0.0590.  Mean training acc: 98.68%.
[ Mon Aug  1 17:21:18 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:21:18 2022 ] Eval epoch: 60
[ Mon Aug  1 17:22:39 2022 ] 	Mean test loss of 796 batches: 0.6774412038450565.
[ Mon Aug  1 17:22:39 2022 ] 	Top1: 82.39%
[ Mon Aug  1 17:22:40 2022 ] 	Top5: 96.29%
[ Mon Aug  1 17:22:40 2022 ] Training epoch: 61
[ Mon Aug  1 17:27:41 2022 ] 	Mean training loss: 0.0562.  Mean training acc: 98.79%.
[ Mon Aug  1 17:27:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:27:41 2022 ] Eval epoch: 61
[ Mon Aug  1 17:29:00 2022 ] 	Mean test loss of 796 batches: 0.6781993772666058.
[ Mon Aug  1 17:29:01 2022 ] 	Top1: 82.39%
[ Mon Aug  1 17:29:01 2022 ] 	Top5: 96.25%
[ Mon Aug  1 17:29:01 2022 ] Training epoch: 62
[ Mon Aug  1 17:34:02 2022 ] 	Mean training loss: 0.0527.  Mean training acc: 98.86%.
[ Mon Aug  1 17:34:02 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:34:02 2022 ] Eval epoch: 62
[ Mon Aug  1 17:35:21 2022 ] 	Mean test loss of 796 batches: 0.6841042754076534.
[ Mon Aug  1 17:35:21 2022 ] 	Top1: 82.54%
[ Mon Aug  1 17:35:22 2022 ] 	Top5: 96.22%
[ Mon Aug  1 17:35:22 2022 ] Training epoch: 63
[ Mon Aug  1 17:40:21 2022 ] 	Mean training loss: 0.0493.  Mean training acc: 98.92%.
[ Mon Aug  1 17:40:21 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:40:21 2022 ] Eval epoch: 63
[ Mon Aug  1 17:41:40 2022 ] 	Mean test loss of 796 batches: 0.69786488222679.
[ Mon Aug  1 17:41:41 2022 ] 	Top1: 82.23%
[ Mon Aug  1 17:41:41 2022 ] 	Top5: 96.14%
[ Mon Aug  1 17:41:41 2022 ] Training epoch: 64
[ Mon Aug  1 17:46:42 2022 ] 	Mean training loss: 0.0485.  Mean training acc: 98.98%.
[ Mon Aug  1 17:46:42 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:46:42 2022 ] Eval epoch: 64
[ Mon Aug  1 17:48:03 2022 ] 	Mean test loss of 796 batches: 0.6791201304064025.
[ Mon Aug  1 17:48:03 2022 ] 	Top1: 82.52%
[ Mon Aug  1 17:48:03 2022 ] 	Top5: 96.26%
[ Mon Aug  1 17:48:04 2022 ] Training epoch: 65
[ Mon Aug  1 17:53:08 2022 ] 	Mean training loss: 0.0472.  Mean training acc: 99.01%.
[ Mon Aug  1 17:53:08 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Mon Aug  1 17:53:08 2022 ] Eval epoch: 65
[ Mon Aug  1 17:54:20 2022 ] 	Mean test loss of 796 batches: 0.6933295359582308.
[ Mon Aug  1 17:54:20 2022 ] 	Top1: 82.37%
[ Mon Aug  1 17:54:21 2022 ] 	Top5: 96.18%
[ Mon Aug  1 17:55:41 2022 ] Best accuracy: 0.8253893438598559
[ Mon Aug  1 17:55:41 2022 ] Epoch number: 62
[ Mon Aug  1 17:55:41 2022 ] Model name: work_dir/ntu120/csub/sym_mod5
[ Mon Aug  1 17:55:41 2022 ] Model total number of params: 2204402
[ Mon Aug  1 17:55:41 2022 ] Weight decay: 0.0004
[ Mon Aug  1 17:55:41 2022 ] Base LR: 0.1
[ Mon Aug  1 17:55:41 2022 ] Batch Size: 64
[ Mon Aug  1 17:55:41 2022 ] Test Batch Size: 64
[ Mon Aug  1 17:55:41 2022 ] seed: 1
