[ Wed Aug  3 10:00:02 2022 ] using warm up, epoch: 5
[ Wed Aug  3 10:00:33 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod5a_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod5a_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module5a_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Aug  3 10:00:33 2022 ] # Parameters: 2204274
[ Wed Aug  3 10:00:33 2022 ] Training epoch: 1
[ Wed Aug  3 10:04:39 2022 ] 	Mean training loss: 3.0668.  Mean training acc: 23.50%.
[ Wed Aug  3 10:04:39 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:04:39 2022 ] Eval epoch: 1
[ Wed Aug  3 10:06:12 2022 ] 	Mean test loss of 796 batches: 2.595378551650886.
[ Wed Aug  3 10:06:13 2022 ] 	Top1: 29.04%
[ Wed Aug  3 10:06:13 2022 ] 	Top5: 64.01%
[ Wed Aug  3 10:06:13 2022 ] Training epoch: 2
[ Wed Aug  3 10:10:14 2022 ] 	Mean training loss: 2.0294.  Mean training acc: 43.23%.
[ Wed Aug  3 10:10:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:10:14 2022 ] Eval epoch: 2
[ Wed Aug  3 10:11:47 2022 ] 	Mean test loss of 796 batches: 1.901307972906223.
[ Wed Aug  3 10:11:47 2022 ] 	Top1: 47.04%
[ Wed Aug  3 10:11:48 2022 ] 	Top5: 78.92%
[ Wed Aug  3 10:11:48 2022 ] Training epoch: 3
[ Wed Aug  3 10:15:50 2022 ] 	Mean training loss: 1.6485.  Mean training acc: 52.35%.
[ Wed Aug  3 10:15:50 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:15:50 2022 ] Eval epoch: 3
[ Wed Aug  3 10:17:22 2022 ] 	Mean test loss of 796 batches: 1.9427833721116559.
[ Wed Aug  3 10:17:22 2022 ] 	Top1: 45.25%
[ Wed Aug  3 10:17:23 2022 ] 	Top5: 80.78%
[ Wed Aug  3 10:17:23 2022 ] Training epoch: 4
[ Wed Aug  3 10:21:24 2022 ] 	Mean training loss: 1.4511.  Mean training acc: 57.39%.
[ Wed Aug  3 10:21:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:21:24 2022 ] Eval epoch: 4
[ Wed Aug  3 10:22:57 2022 ] 	Mean test loss of 796 batches: 1.3590422036809537.
[ Wed Aug  3 10:22:57 2022 ] 	Top1: 60.00%
[ Wed Aug  3 10:22:57 2022 ] 	Top5: 88.24%
[ Wed Aug  3 10:22:57 2022 ] Training epoch: 5
[ Wed Aug  3 10:26:58 2022 ] 	Mean training loss: 1.3265.  Mean training acc: 61.09%.
[ Wed Aug  3 10:26:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:26:58 2022 ] Eval epoch: 5
[ Wed Aug  3 10:28:31 2022 ] 	Mean test loss of 796 batches: 1.7484559058843545.
[ Wed Aug  3 10:28:31 2022 ] 	Top1: 49.47%
[ Wed Aug  3 10:28:31 2022 ] 	Top5: 83.46%
[ Wed Aug  3 10:28:32 2022 ] Training epoch: 6
[ Wed Aug  3 10:32:33 2022 ] 	Mean training loss: 1.1834.  Mean training acc: 64.91%.
[ Wed Aug  3 10:32:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:32:33 2022 ] Eval epoch: 6
[ Wed Aug  3 10:34:07 2022 ] 	Mean test loss of 796 batches: 1.4921051029059755.
[ Wed Aug  3 10:34:07 2022 ] 	Top1: 57.40%
[ Wed Aug  3 10:34:08 2022 ] 	Top5: 86.74%
[ Wed Aug  3 10:34:08 2022 ] Training epoch: 7
[ Wed Aug  3 10:38:09 2022 ] 	Mean training loss: 1.0955.  Mean training acc: 67.09%.
[ Wed Aug  3 10:38:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:38:09 2022 ] Eval epoch: 7
[ Wed Aug  3 10:39:41 2022 ] 	Mean test loss of 796 batches: 1.3932989890401686.
[ Wed Aug  3 10:39:42 2022 ] 	Top1: 59.63%
[ Wed Aug  3 10:39:42 2022 ] 	Top5: 88.47%
[ Wed Aug  3 10:39:42 2022 ] Training epoch: 8
[ Wed Aug  3 10:43:42 2022 ] 	Mean training loss: 1.0516.  Mean training acc: 68.45%.
[ Wed Aug  3 10:43:42 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:43:42 2022 ] Eval epoch: 8
[ Wed Aug  3 10:45:15 2022 ] 	Mean test loss of 796 batches: 1.2806729975357727.
[ Wed Aug  3 10:45:15 2022 ] 	Top1: 62.20%
[ Wed Aug  3 10:45:15 2022 ] 	Top5: 89.55%
[ Wed Aug  3 10:45:16 2022 ] Training epoch: 9
[ Wed Aug  3 10:49:16 2022 ] 	Mean training loss: 1.0067.  Mean training acc: 69.79%.
[ Wed Aug  3 10:49:16 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:49:16 2022 ] Eval epoch: 9
[ Wed Aug  3 10:50:49 2022 ] 	Mean test loss of 796 batches: 1.3956836683666287.
[ Wed Aug  3 10:50:49 2022 ] 	Top1: 60.66%
[ Wed Aug  3 10:50:49 2022 ] 	Top5: 86.78%
[ Wed Aug  3 10:50:49 2022 ] Training epoch: 10
[ Wed Aug  3 10:54:50 2022 ] 	Mean training loss: 0.9629.  Mean training acc: 70.85%.
[ Wed Aug  3 10:54:50 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:54:50 2022 ] Eval epoch: 10
[ Wed Aug  3 10:56:25 2022 ] 	Mean test loss of 796 batches: 1.111219754957374.
[ Wed Aug  3 10:56:25 2022 ] 	Top1: 66.77%
[ Wed Aug  3 10:56:25 2022 ] 	Top5: 91.47%
[ Wed Aug  3 10:56:25 2022 ] Training epoch: 11
[ Wed Aug  3 11:00:35 2022 ] 	Mean training loss: 0.9446.  Mean training acc: 71.56%.
[ Wed Aug  3 11:00:35 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:00:35 2022 ] Eval epoch: 11
[ Wed Aug  3 11:02:15 2022 ] 	Mean test loss of 796 batches: 1.1486616269802328.
[ Wed Aug  3 11:02:16 2022 ] 	Top1: 66.84%
[ Wed Aug  3 11:02:16 2022 ] 	Top5: 91.30%
[ Wed Aug  3 11:02:16 2022 ] Training epoch: 12
[ Wed Aug  3 11:06:28 2022 ] 	Mean training loss: 0.9254.  Mean training acc: 72.08%.
[ Wed Aug  3 11:06:28 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:06:28 2022 ] Eval epoch: 12
[ Wed Aug  3 11:08:10 2022 ] 	Mean test loss of 796 batches: 1.1356461032775778.
[ Wed Aug  3 11:08:10 2022 ] 	Top1: 66.57%
[ Wed Aug  3 11:08:11 2022 ] 	Top5: 91.20%
[ Wed Aug  3 11:08:11 2022 ] Training epoch: 13
[ Wed Aug  3 11:12:24 2022 ] 	Mean training loss: 0.9070.  Mean training acc: 72.43%.
[ Wed Aug  3 11:12:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:12:24 2022 ] Eval epoch: 13
[ Wed Aug  3 11:13:58 2022 ] 	Mean test loss of 796 batches: 1.0483526946536859.
[ Wed Aug  3 11:13:58 2022 ] 	Top1: 68.28%
[ Wed Aug  3 11:13:59 2022 ] 	Top5: 92.51%
[ Wed Aug  3 11:13:59 2022 ] Training epoch: 14
[ Wed Aug  3 11:18:02 2022 ] 	Mean training loss: 0.8884.  Mean training acc: 73.17%.
[ Wed Aug  3 11:18:02 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:18:02 2022 ] Eval epoch: 14
[ Wed Aug  3 11:19:38 2022 ] 	Mean test loss of 796 batches: 1.1872231174803258.
[ Wed Aug  3 11:19:38 2022 ] 	Top1: 65.93%
[ Wed Aug  3 11:19:39 2022 ] 	Top5: 91.13%
[ Wed Aug  3 11:19:39 2022 ] Training epoch: 15
[ Wed Aug  3 11:23:41 2022 ] 	Mean training loss: 0.8815.  Mean training acc: 73.16%.
[ Wed Aug  3 11:23:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:23:41 2022 ] Eval epoch: 15
[ Wed Aug  3 11:25:12 2022 ] 	Mean test loss of 796 batches: 1.1038423253962741.
[ Wed Aug  3 11:25:13 2022 ] 	Top1: 66.52%
[ Wed Aug  3 11:25:13 2022 ] 	Top5: 91.55%
[ Wed Aug  3 11:25:13 2022 ] Training epoch: 16
[ Wed Aug  3 11:29:17 2022 ] 	Mean training loss: 0.8619.  Mean training acc: 73.71%.
[ Wed Aug  3 11:29:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:29:17 2022 ] Eval epoch: 16
[ Wed Aug  3 11:30:50 2022 ] 	Mean test loss of 796 batches: 1.1752050396560425.
[ Wed Aug  3 11:30:51 2022 ] 	Top1: 65.77%
[ Wed Aug  3 11:30:51 2022 ] 	Top5: 91.31%
[ Wed Aug  3 11:30:51 2022 ] Training epoch: 17
[ Wed Aug  3 11:34:54 2022 ] 	Mean training loss: 0.8546.  Mean training acc: 74.17%.
[ Wed Aug  3 11:34:54 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:34:54 2022 ] Eval epoch: 17
[ Wed Aug  3 11:36:26 2022 ] 	Mean test loss of 796 batches: 1.1174383104296786.
[ Wed Aug  3 11:36:27 2022 ] 	Top1: 67.92%
[ Wed Aug  3 11:36:27 2022 ] 	Top5: 90.96%
[ Wed Aug  3 11:36:27 2022 ] Training epoch: 18
[ Wed Aug  3 11:40:29 2022 ] 	Mean training loss: 0.8515.  Mean training acc: 74.28%.
[ Wed Aug  3 11:40:29 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:40:29 2022 ] Eval epoch: 18
[ Wed Aug  3 11:42:04 2022 ] 	Mean test loss of 796 batches: 1.2239819072074627.
[ Wed Aug  3 11:42:04 2022 ] 	Top1: 64.42%
[ Wed Aug  3 11:42:04 2022 ] 	Top5: 90.18%
[ Wed Aug  3 11:42:04 2022 ] Training epoch: 19
[ Wed Aug  3 11:46:14 2022 ] 	Mean training loss: 0.8389.  Mean training acc: 74.46%.
[ Wed Aug  3 11:46:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:46:14 2022 ] Eval epoch: 19
[ Wed Aug  3 11:47:50 2022 ] 	Mean test loss of 796 batches: 1.3414882281093141.
[ Wed Aug  3 11:47:51 2022 ] 	Top1: 62.73%
[ Wed Aug  3 11:47:51 2022 ] 	Top5: 89.83%
[ Wed Aug  3 11:47:51 2022 ] Training epoch: 20
[ Wed Aug  3 11:52:01 2022 ] 	Mean training loss: 0.8335.  Mean training acc: 74.57%.
[ Wed Aug  3 11:52:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:52:01 2022 ] Eval epoch: 20
[ Wed Aug  3 11:53:44 2022 ] 	Mean test loss of 796 batches: 1.253227882199551.
[ Wed Aug  3 11:53:44 2022 ] 	Top1: 64.88%
[ Wed Aug  3 11:53:44 2022 ] 	Top5: 90.04%
[ Wed Aug  3 11:53:45 2022 ] Training epoch: 21
[ Wed Aug  3 11:58:03 2022 ] 	Mean training loss: 0.8249.  Mean training acc: 74.99%.
[ Wed Aug  3 11:58:03 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:58:03 2022 ] Eval epoch: 21
[ Wed Aug  3 11:59:48 2022 ] 	Mean test loss of 796 batches: 1.134361539541477.
[ Wed Aug  3 11:59:49 2022 ] 	Top1: 67.70%
[ Wed Aug  3 11:59:49 2022 ] 	Top5: 91.39%
[ Wed Aug  3 11:59:49 2022 ] Training epoch: 22
[ Wed Aug  3 12:04:12 2022 ] 	Mean training loss: 0.8259.  Mean training acc: 75.03%.
[ Wed Aug  3 12:04:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:04:12 2022 ] Eval epoch: 22
[ Wed Aug  3 12:05:56 2022 ] 	Mean test loss of 796 batches: 1.18735303164427.
[ Wed Aug  3 12:05:56 2022 ] 	Top1: 65.90%
[ Wed Aug  3 12:05:57 2022 ] 	Top5: 90.03%
[ Wed Aug  3 12:05:57 2022 ] Training epoch: 23
[ Wed Aug  3 12:10:20 2022 ] 	Mean training loss: 0.8165.  Mean training acc: 75.26%.
[ Wed Aug  3 12:10:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:10:20 2022 ] Eval epoch: 23
[ Wed Aug  3 12:12:08 2022 ] 	Mean test loss of 796 batches: 1.067536267840383.
[ Wed Aug  3 12:12:08 2022 ] 	Top1: 68.24%
[ Wed Aug  3 12:12:09 2022 ] 	Top5: 91.85%
[ Wed Aug  3 12:12:09 2022 ] Training epoch: 24
[ Wed Aug  3 12:16:29 2022 ] 	Mean training loss: 0.8119.  Mean training acc: 75.37%.
[ Wed Aug  3 12:16:29 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:16:29 2022 ] Eval epoch: 24
[ Wed Aug  3 12:18:12 2022 ] 	Mean test loss of 796 batches: 1.1559107087215585.
[ Wed Aug  3 12:18:13 2022 ] 	Top1: 66.63%
[ Wed Aug  3 12:18:13 2022 ] 	Top5: 91.22%
[ Wed Aug  3 12:18:13 2022 ] Training epoch: 25
[ Wed Aug  3 12:23:01 2022 ] 	Mean training loss: 0.8106.  Mean training acc: 75.18%.
[ Wed Aug  3 12:23:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:23:01 2022 ] Eval epoch: 25
[ Wed Aug  3 12:24:33 2022 ] 	Mean test loss of 796 batches: 1.3450036332310744.
[ Wed Aug  3 12:24:33 2022 ] 	Top1: 62.95%
[ Wed Aug  3 12:24:34 2022 ] 	Top5: 88.65%
[ Wed Aug  3 12:24:34 2022 ] Training epoch: 26
[ Wed Aug  3 12:28:50 2022 ] 	Mean training loss: 0.8041.  Mean training acc: 75.47%.
[ Wed Aug  3 12:28:50 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:28:50 2022 ] Eval epoch: 26
[ Wed Aug  3 12:30:33 2022 ] 	Mean test loss of 796 batches: 1.1041254752769543.
[ Wed Aug  3 12:30:34 2022 ] 	Top1: 67.28%
[ Wed Aug  3 12:30:34 2022 ] 	Top5: 91.99%
[ Wed Aug  3 12:30:34 2022 ] Training epoch: 27
[ Wed Aug  3 12:34:53 2022 ] 	Mean training loss: 0.7980.  Mean training acc: 75.66%.
[ Wed Aug  3 12:34:53 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:34:53 2022 ] Eval epoch: 27
[ Wed Aug  3 12:36:39 2022 ] 	Mean test loss of 796 batches: 1.3198808309570629.
[ Wed Aug  3 12:36:39 2022 ] 	Top1: 62.94%
[ Wed Aug  3 12:36:40 2022 ] 	Top5: 89.15%
[ Wed Aug  3 12:36:40 2022 ] Training epoch: 28
[ Wed Aug  3 12:41:07 2022 ] 	Mean training loss: 0.7954.  Mean training acc: 75.93%.
[ Wed Aug  3 12:41:07 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:41:07 2022 ] Eval epoch: 28
[ Wed Aug  3 12:42:56 2022 ] 	Mean test loss of 796 batches: 1.0415793070990835.
[ Wed Aug  3 12:42:57 2022 ] 	Top1: 69.02%
[ Wed Aug  3 12:42:57 2022 ] 	Top5: 92.17%
[ Wed Aug  3 12:42:57 2022 ] Training epoch: 29
[ Wed Aug  3 12:47:32 2022 ] 	Mean training loss: 0.7949.  Mean training acc: 75.73%.
[ Wed Aug  3 12:47:32 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:47:32 2022 ] Eval epoch: 29
[ Wed Aug  3 12:49:13 2022 ] 	Mean test loss of 796 batches: 1.131106475003101.
[ Wed Aug  3 12:49:14 2022 ] 	Top1: 67.01%
[ Wed Aug  3 12:49:14 2022 ] 	Top5: 91.61%
[ Wed Aug  3 12:49:14 2022 ] Training epoch: 30
[ Wed Aug  3 12:53:47 2022 ] 	Mean training loss: 0.7877.  Mean training acc: 75.83%.
[ Wed Aug  3 12:53:47 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:53:47 2022 ] Eval epoch: 30
[ Wed Aug  3 12:55:29 2022 ] 	Mean test loss of 796 batches: 0.9743686629150381.
[ Wed Aug  3 12:55:29 2022 ] 	Top1: 70.72%
[ Wed Aug  3 12:55:29 2022 ] 	Top5: 93.12%
[ Wed Aug  3 12:55:29 2022 ] Training epoch: 31
[ Wed Aug  3 13:00:06 2022 ] 	Mean training loss: 0.7946.  Mean training acc: 75.80%.
[ Wed Aug  3 13:00:06 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Aug  3 13:00:06 2022 ] Eval epoch: 31
[ Wed Aug  3 13:01:53 2022 ] 	Mean test loss of 796 batches: 1.1700644288305662.
[ Wed Aug  3 13:01:53 2022 ] 	Top1: 66.40%
[ Wed Aug  3 13:01:54 2022 ] 	Top5: 90.52%
[ Wed Aug  3 13:01:54 2022 ] Training epoch: 32
[ Wed Aug  3 13:06:33 2022 ] 	Mean training loss: 0.7891.  Mean training acc: 75.91%.
[ Wed Aug  3 13:06:33 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Aug  3 13:06:34 2022 ] Eval epoch: 32
[ Wed Aug  3 13:08:18 2022 ] 	Mean test loss of 796 batches: 1.3499906943671067.
[ Wed Aug  3 13:08:19 2022 ] 	Top1: 63.10%
[ Wed Aug  3 13:08:19 2022 ] 	Top5: 88.53%
[ Wed Aug  3 13:08:19 2022 ] Training epoch: 33
[ Wed Aug  3 13:12:20 2022 ] 	Mean training loss: 0.7887.  Mean training acc: 76.02%.
[ Wed Aug  3 13:12:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:12:20 2022 ] Eval epoch: 33
[ Wed Aug  3 13:13:54 2022 ] 	Mean test loss of 796 batches: 1.0553311036534645.
[ Wed Aug  3 13:13:54 2022 ] 	Top1: 69.19%
[ Wed Aug  3 13:13:54 2022 ] 	Top5: 92.53%
[ Wed Aug  3 13:13:54 2022 ] Training epoch: 34
[ Wed Aug  3 13:17:56 2022 ] 	Mean training loss: 0.7857.  Mean training acc: 76.04%.
[ Wed Aug  3 13:17:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:17:56 2022 ] Eval epoch: 34
[ Wed Aug  3 13:19:28 2022 ] 	Mean test loss of 796 batches: 1.0145971261563913.
[ Wed Aug  3 13:19:29 2022 ] 	Top1: 70.28%
[ Wed Aug  3 13:19:29 2022 ] 	Top5: 92.68%
[ Wed Aug  3 13:19:29 2022 ] Training epoch: 35
[ Wed Aug  3 13:23:31 2022 ] 	Mean training loss: 0.7829.  Mean training acc: 76.16%.
[ Wed Aug  3 13:23:31 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:23:31 2022 ] Eval epoch: 35
[ Wed Aug  3 13:25:02 2022 ] 	Mean test loss of 796 batches: 1.080548302275152.
[ Wed Aug  3 13:25:03 2022 ] 	Top1: 68.41%
[ Wed Aug  3 13:25:03 2022 ] 	Top5: 92.08%
[ Wed Aug  3 13:25:03 2022 ] Training epoch: 36
[ Wed Aug  3 13:29:09 2022 ] 	Mean training loss: 0.4512.  Mean training acc: 86.03%.
[ Wed Aug  3 13:29:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:29:09 2022 ] Eval epoch: 36
[ Wed Aug  3 13:30:46 2022 ] 	Mean test loss of 796 batches: 0.5947258691654433.
[ Wed Aug  3 13:30:47 2022 ] 	Top1: 81.63%
[ Wed Aug  3 13:30:47 2022 ] 	Top5: 96.66%
[ Wed Aug  3 13:30:47 2022 ] Training epoch: 37
[ Wed Aug  3 13:34:59 2022 ] 	Mean training loss: 0.3598.  Mean training acc: 88.68%.
[ Wed Aug  3 13:34:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:34:59 2022 ] Eval epoch: 37
[ Wed Aug  3 13:36:36 2022 ] 	Mean test loss of 796 batches: 0.5748356932858426.
[ Wed Aug  3 13:36:37 2022 ] 	Top1: 82.36%
[ Wed Aug  3 13:36:37 2022 ] 	Top5: 96.77%
[ Wed Aug  3 13:36:37 2022 ] Training epoch: 38
[ Wed Aug  3 13:40:44 2022 ] 	Mean training loss: 0.3268.  Mean training acc: 89.72%.
[ Wed Aug  3 13:40:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:40:44 2022 ] Eval epoch: 38
[ Wed Aug  3 13:42:20 2022 ] 	Mean test loss of 796 batches: 0.5868442398144971.
[ Wed Aug  3 13:42:20 2022 ] 	Top1: 82.14%
[ Wed Aug  3 13:42:20 2022 ] 	Top5: 96.71%
[ Wed Aug  3 13:42:20 2022 ] Training epoch: 39
[ Wed Aug  3 13:46:55 2022 ] 	Mean training loss: 0.3015.  Mean training acc: 90.50%.
[ Wed Aug  3 13:46:55 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:46:55 2022 ] Eval epoch: 39
[ Wed Aug  3 13:48:37 2022 ] 	Mean test loss of 796 batches: 0.5821665058183909.
[ Wed Aug  3 13:48:38 2022 ] 	Top1: 82.32%
[ Wed Aug  3 13:48:38 2022 ] 	Top5: 96.72%
[ Wed Aug  3 13:48:38 2022 ] Training epoch: 40
[ Wed Aug  3 13:52:40 2022 ] 	Mean training loss: 0.2777.  Mean training acc: 91.24%.
[ Wed Aug  3 13:52:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:52:40 2022 ] Eval epoch: 40
[ Wed Aug  3 13:54:13 2022 ] 	Mean test loss of 796 batches: 0.6006929193010282.
[ Wed Aug  3 13:54:14 2022 ] 	Top1: 82.11%
[ Wed Aug  3 13:54:14 2022 ] 	Top5: 96.64%
[ Wed Aug  3 13:54:14 2022 ] Training epoch: 41
[ Wed Aug  3 13:58:15 2022 ] 	Mean training loss: 0.2549.  Mean training acc: 92.01%.
[ Wed Aug  3 13:58:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:58:15 2022 ] Eval epoch: 41
[ Wed Aug  3 13:59:47 2022 ] 	Mean test loss of 796 batches: 0.6175417434424162.
[ Wed Aug  3 13:59:48 2022 ] 	Top1: 81.89%
[ Wed Aug  3 13:59:48 2022 ] 	Top5: 96.48%
[ Wed Aug  3 13:59:48 2022 ] Training epoch: 42
[ Wed Aug  3 14:03:49 2022 ] 	Mean training loss: 0.2458.  Mean training acc: 92.30%.
[ Wed Aug  3 14:03:49 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:03:49 2022 ] Eval epoch: 42
[ Wed Aug  3 14:05:22 2022 ] 	Mean test loss of 796 batches: 0.6184892922490086.
[ Wed Aug  3 14:05:22 2022 ] 	Top1: 82.09%
[ Wed Aug  3 14:05:23 2022 ] 	Top5: 96.55%
[ Wed Aug  3 14:05:23 2022 ] Training epoch: 43
[ Wed Aug  3 14:09:56 2022 ] 	Mean training loss: 0.2347.  Mean training acc: 92.65%.
[ Wed Aug  3 14:09:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:09:56 2022 ] Eval epoch: 43
[ Wed Aug  3 14:11:45 2022 ] 	Mean test loss of 796 batches: 0.6323772855009415.
[ Wed Aug  3 14:11:45 2022 ] 	Top1: 81.60%
[ Wed Aug  3 14:11:46 2022 ] 	Top5: 96.44%
[ Wed Aug  3 14:11:46 2022 ] Training epoch: 44
[ Wed Aug  3 14:16:43 2022 ] 	Mean training loss: 0.2238.  Mean training acc: 92.96%.
[ Wed Aug  3 14:16:43 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:16:43 2022 ] Eval epoch: 44
[ Wed Aug  3 14:18:34 2022 ] 	Mean test loss of 796 batches: 0.6441231586188827.
[ Wed Aug  3 14:18:34 2022 ] 	Top1: 81.40%
[ Wed Aug  3 14:18:34 2022 ] 	Top5: 96.56%
[ Wed Aug  3 14:18:34 2022 ] Training epoch: 45
[ Wed Aug  3 14:23:29 2022 ] 	Mean training loss: 0.2182.  Mean training acc: 93.21%.
[ Wed Aug  3 14:23:29 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:23:29 2022 ] Eval epoch: 45
[ Wed Aug  3 14:25:17 2022 ] 	Mean test loss of 796 batches: 0.6757321471638565.
[ Wed Aug  3 14:25:17 2022 ] 	Top1: 80.96%
[ Wed Aug  3 14:25:18 2022 ] 	Top5: 96.38%
[ Wed Aug  3 14:25:18 2022 ] Training epoch: 46
[ Wed Aug  3 14:30:18 2022 ] 	Mean training loss: 0.2112.  Mean training acc: 93.33%.
[ Wed Aug  3 14:30:18 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:30:18 2022 ] Eval epoch: 46
[ Wed Aug  3 14:32:08 2022 ] 	Mean test loss of 796 batches: 0.6654571535711612.
[ Wed Aug  3 14:32:09 2022 ] 	Top1: 81.28%
[ Wed Aug  3 14:32:09 2022 ] 	Top5: 96.25%
[ Wed Aug  3 14:32:09 2022 ] Training epoch: 47
[ Wed Aug  3 14:37:11 2022 ] 	Mean training loss: 0.2057.  Mean training acc: 93.45%.
[ Wed Aug  3 14:37:11 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:37:11 2022 ] Eval epoch: 47
[ Wed Aug  3 14:39:05 2022 ] 	Mean test loss of 796 batches: 0.7050736450388952.
[ Wed Aug  3 14:39:06 2022 ] 	Top1: 80.48%
[ Wed Aug  3 14:39:06 2022 ] 	Top5: 95.88%
[ Wed Aug  3 14:39:06 2022 ] Training epoch: 48
[ Wed Aug  3 14:44:10 2022 ] 	Mean training loss: 0.2010.  Mean training acc: 93.66%.
[ Wed Aug  3 14:44:10 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 14:44:10 2022 ] Eval epoch: 48
[ Wed Aug  3 14:46:10 2022 ] 	Mean test loss of 796 batches: 0.7056947385789312.
[ Wed Aug  3 14:46:10 2022 ] 	Top1: 80.62%
[ Wed Aug  3 14:46:11 2022 ] 	Top5: 95.98%
[ Wed Aug  3 14:46:11 2022 ] Training epoch: 49
[ Wed Aug  3 14:51:28 2022 ] 	Mean training loss: 0.2033.  Mean training acc: 93.61%.
[ Wed Aug  3 14:51:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 14:51:28 2022 ] Eval epoch: 49
[ Wed Aug  3 14:53:31 2022 ] 	Mean test loss of 796 batches: 0.7339264293804989.
[ Wed Aug  3 14:53:31 2022 ] 	Top1: 80.47%
[ Wed Aug  3 14:53:32 2022 ] 	Top5: 95.79%
[ Wed Aug  3 14:53:32 2022 ] Training epoch: 50
[ Wed Aug  3 14:58:47 2022 ] 	Mean training loss: 0.1957.  Mean training acc: 93.90%.
[ Wed Aug  3 14:58:47 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 14:58:47 2022 ] Eval epoch: 50
[ Wed Aug  3 15:00:47 2022 ] 	Mean test loss of 796 batches: 0.7206123984189489.
[ Wed Aug  3 15:00:47 2022 ] 	Top1: 80.26%
[ Wed Aug  3 15:00:47 2022 ] 	Top5: 95.63%
[ Wed Aug  3 15:00:47 2022 ] Training epoch: 51
[ Wed Aug  3 15:05:07 2022 ] 	Mean training loss: 0.1990.  Mean training acc: 93.72%.
[ Wed Aug  3 15:05:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 15:05:07 2022 ] Eval epoch: 51
[ Wed Aug  3 15:06:40 2022 ] 	Mean test loss of 796 batches: 0.74861144568378.
[ Wed Aug  3 15:06:40 2022 ] 	Top1: 80.11%
[ Wed Aug  3 15:06:41 2022 ] 	Top5: 95.69%
[ Wed Aug  3 15:06:41 2022 ] Training epoch: 52
[ Wed Aug  3 15:10:45 2022 ] 	Mean training loss: 0.1947.  Mean training acc: 93.81%.
[ Wed Aug  3 15:10:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:10:45 2022 ] Eval epoch: 52
[ Wed Aug  3 15:12:25 2022 ] 	Mean test loss of 796 batches: 0.7293110947269741.
[ Wed Aug  3 15:12:25 2022 ] 	Top1: 80.25%
[ Wed Aug  3 15:12:25 2022 ] 	Top5: 95.81%
[ Wed Aug  3 15:12:25 2022 ] Training epoch: 53
[ Wed Aug  3 15:16:30 2022 ] 	Mean training loss: 0.1928.  Mean training acc: 94.04%.
[ Wed Aug  3 15:16:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:16:30 2022 ] Eval epoch: 53
[ Wed Aug  3 15:18:09 2022 ] 	Mean test loss of 796 batches: 0.7164915914006119.
[ Wed Aug  3 15:18:09 2022 ] 	Top1: 80.83%
[ Wed Aug  3 15:18:09 2022 ] 	Top5: 95.80%
[ Wed Aug  3 15:18:10 2022 ] Training epoch: 54
[ Wed Aug  3 15:22:22 2022 ] 	Mean training loss: 0.1962.  Mean training acc: 93.90%.
[ Wed Aug  3 15:22:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:22:22 2022 ] Eval epoch: 54
[ Wed Aug  3 15:24:00 2022 ] 	Mean test loss of 796 batches: 0.7375671128138676.
[ Wed Aug  3 15:24:01 2022 ] 	Top1: 79.79%
[ Wed Aug  3 15:24:01 2022 ] 	Top5: 95.64%
[ Wed Aug  3 15:24:01 2022 ] Training epoch: 55
[ Wed Aug  3 15:28:12 2022 ] 	Mean training loss: 0.1908.  Mean training acc: 94.03%.
[ Wed Aug  3 15:28:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:28:12 2022 ] Eval epoch: 55
[ Wed Aug  3 15:29:52 2022 ] 	Mean test loss of 796 batches: 0.7397958207594689.
[ Wed Aug  3 15:29:53 2022 ] 	Top1: 80.02%
[ Wed Aug  3 15:29:53 2022 ] 	Top5: 95.81%
[ Wed Aug  3 15:29:53 2022 ] Training epoch: 56
[ Wed Aug  3 15:34:05 2022 ] 	Mean training loss: 0.1057.  Mean training acc: 97.15%.
[ Wed Aug  3 15:34:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:34:05 2022 ] Eval epoch: 56
[ Wed Aug  3 15:35:44 2022 ] 	Mean test loss of 796 batches: 0.6497694532007877.
[ Wed Aug  3 15:35:45 2022 ] 	Top1: 82.44%
[ Wed Aug  3 15:35:45 2022 ] 	Top5: 96.50%
[ Wed Aug  3 15:35:45 2022 ] Training epoch: 57
[ Wed Aug  3 15:39:56 2022 ] 	Mean training loss: 0.0781.  Mean training acc: 98.11%.
[ Wed Aug  3 15:39:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:39:56 2022 ] Eval epoch: 57
[ Wed Aug  3 15:41:35 2022 ] 	Mean test loss of 796 batches: 0.6344571899828599.
[ Wed Aug  3 15:41:36 2022 ] 	Top1: 82.91%
[ Wed Aug  3 15:41:36 2022 ] 	Top5: 96.63%
[ Wed Aug  3 15:41:36 2022 ] Training epoch: 58
[ Wed Aug  3 15:45:59 2022 ] 	Mean training loss: 0.0707.  Mean training acc: 98.33%.
[ Wed Aug  3 15:45:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:45:59 2022 ] Eval epoch: 58
[ Wed Aug  3 15:47:44 2022 ] 	Mean test loss of 796 batches: 0.6465759397900883.
[ Wed Aug  3 15:47:44 2022 ] 	Top1: 82.79%
[ Wed Aug  3 15:47:45 2022 ] 	Top5: 96.55%
[ Wed Aug  3 15:47:45 2022 ] Training epoch: 59
[ Wed Aug  3 15:52:41 2022 ] 	Mean training loss: 0.0635.  Mean training acc: 98.58%.
[ Wed Aug  3 15:52:41 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Aug  3 15:52:41 2022 ] Eval epoch: 59
[ Wed Aug  3 15:54:25 2022 ] 	Mean test loss of 796 batches: 0.6485079292058196.
[ Wed Aug  3 15:54:26 2022 ] 	Top1: 82.87%
[ Wed Aug  3 15:54:26 2022 ] 	Top5: 96.45%
[ Wed Aug  3 15:54:26 2022 ] Training epoch: 60
[ Wed Aug  3 15:59:24 2022 ] 	Mean training loss: 0.0605.  Mean training acc: 98.66%.
[ Wed Aug  3 15:59:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 15:59:24 2022 ] Eval epoch: 60
[ Wed Aug  3 16:01:10 2022 ] 	Mean test loss of 796 batches: 0.6596135483521163.
[ Wed Aug  3 16:01:10 2022 ] 	Top1: 82.71%
[ Wed Aug  3 16:01:11 2022 ] 	Top5: 96.40%
[ Wed Aug  3 16:01:11 2022 ] Training epoch: 61
[ Wed Aug  3 16:06:10 2022 ] 	Mean training loss: 0.0565.  Mean training acc: 98.73%.
[ Wed Aug  3 16:06:10 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Aug  3 16:06:10 2022 ] Eval epoch: 61
[ Wed Aug  3 16:07:57 2022 ] 	Mean test loss of 796 batches: 0.664097730201393.
[ Wed Aug  3 16:07:57 2022 ] 	Top1: 82.66%
[ Wed Aug  3 16:07:57 2022 ] 	Top5: 96.41%
[ Wed Aug  3 16:07:57 2022 ] Training epoch: 62
[ Wed Aug  3 16:12:58 2022 ] 	Mean training loss: 0.0537.  Mean training acc: 98.81%.
[ Wed Aug  3 16:12:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 16:12:58 2022 ] Eval epoch: 62
[ Wed Aug  3 16:14:47 2022 ] 	Mean test loss of 796 batches: 0.665297920230645.
[ Wed Aug  3 16:14:48 2022 ] 	Top1: 82.79%
[ Wed Aug  3 16:14:48 2022 ] 	Top5: 96.45%
[ Wed Aug  3 16:14:48 2022 ] Training epoch: 63
[ Wed Aug  3 16:19:51 2022 ] 	Mean training loss: 0.0512.  Mean training acc: 98.90%.
[ Wed Aug  3 16:19:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 16:19:51 2022 ] Eval epoch: 63
[ Wed Aug  3 16:21:40 2022 ] 	Mean test loss of 796 batches: 0.6689981109926.
[ Wed Aug  3 16:21:40 2022 ] 	Top1: 82.71%
[ Wed Aug  3 16:21:40 2022 ] 	Top5: 96.42%
[ Wed Aug  3 16:21:40 2022 ] Training epoch: 64
[ Wed Aug  3 16:26:42 2022 ] 	Mean training loss: 0.0496.  Mean training acc: 98.97%.
[ Wed Aug  3 16:26:42 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 16:26:42 2022 ] Eval epoch: 64
[ Wed Aug  3 16:28:32 2022 ] 	Mean test loss of 796 batches: 0.6677092250024703.
[ Wed Aug  3 16:28:32 2022 ] 	Top1: 82.78%
[ Wed Aug  3 16:28:33 2022 ] 	Top5: 96.45%
[ Wed Aug  3 16:28:33 2022 ] Training epoch: 65
[ Wed Aug  3 16:33:33 2022 ] 	Mean training loss: 0.0461.  Mean training acc: 99.03%.
[ Wed Aug  3 16:33:33 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Aug  3 16:33:33 2022 ] Eval epoch: 65
[ Wed Aug  3 16:35:22 2022 ] 	Mean test loss of 796 batches: 0.6770833069131003.
[ Wed Aug  3 16:35:22 2022 ] 	Top1: 82.61%
[ Wed Aug  3 16:35:23 2022 ] 	Top5: 96.30%
[ Wed Aug  3 16:37:15 2022 ] Best accuracy: 0.8291207604234175
[ Wed Aug  3 16:37:15 2022 ] Epoch number: 57
[ Wed Aug  3 16:37:15 2022 ] Model name: work_dir/ntu120/csub/sym_mod5a_BL
[ Wed Aug  3 16:37:15 2022 ] Model total number of params: 2204274
[ Wed Aug  3 16:37:15 2022 ] Weight decay: 0.0004
[ Wed Aug  3 16:37:15 2022 ] Base LR: 0.1
[ Wed Aug  3 16:37:15 2022 ] Batch Size: 64
[ Wed Aug  3 16:37:15 2022 ] Test Batch Size: 64
[ Wed Aug  3 16:37:15 2022 ] seed: 1
