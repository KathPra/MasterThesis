[ Wed Jun 29 17:41:38 2022 ] using warm up, epoch: 5
[ Wed Jun 29 17:42:06 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four7_BL', 'model_saved_name': 'work_dir/ntu120/csub/base_four7_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier7_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jun 29 17:42:06 2022 ] # Parameters: 2118562
[ Wed Jun 29 17:42:06 2022 ] Training epoch: 1
[ Wed Jun 29 17:54:34 2022 ] 	Mean training loss: 3.1572.  Mean training acc: 22.27%.
[ Wed Jun 29 17:54:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 17:54:34 2022 ] Eval epoch: 1
[ Wed Jun 29 17:58:09 2022 ] 	Mean test loss of 796 batches: 2.413272699369258.
[ Wed Jun 29 17:58:09 2022 ] 	Top1: 31.24%
[ Wed Jun 29 17:58:10 2022 ] 	Top5: 68.64%
[ Wed Jun 29 17:58:10 2022 ] Training epoch: 2
[ Wed Jun 29 18:10:33 2022 ] 	Mean training loss: 2.0038.  Mean training acc: 44.07%.
[ Wed Jun 29 18:10:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 18:10:33 2022 ] Eval epoch: 2
[ Wed Jun 29 18:14:00 2022 ] 	Mean test loss of 796 batches: 1.8373556611076671.
[ Wed Jun 29 18:14:01 2022 ] 	Top1: 46.29%
[ Wed Jun 29 18:14:02 2022 ] 	Top5: 80.83%
[ Wed Jun 29 18:14:02 2022 ] Training epoch: 3
[ Wed Jun 29 18:26:25 2022 ] 	Mean training loss: 1.6224.  Mean training acc: 53.55%.
[ Wed Jun 29 18:26:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 18:26:25 2022 ] Eval epoch: 3
[ Wed Jun 29 18:29:58 2022 ] 	Mean test loss of 796 batches: 1.8718897122983358.
[ Wed Jun 29 18:29:59 2022 ] 	Top1: 46.81%
[ Wed Jun 29 18:29:59 2022 ] 	Top5: 80.72%
[ Wed Jun 29 18:29:59 2022 ] Training epoch: 4
[ Wed Jun 29 18:42:31 2022 ] 	Mean training loss: 1.4391.  Mean training acc: 58.10%.
[ Wed Jun 29 18:42:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 18:42:31 2022 ] Eval epoch: 4
[ Wed Jun 29 18:46:10 2022 ] 	Mean test loss of 796 batches: 1.4211424734424707.
[ Wed Jun 29 18:46:11 2022 ] 	Top1: 58.05%
[ Wed Jun 29 18:46:12 2022 ] 	Top5: 87.41%
[ Wed Jun 29 18:46:12 2022 ] Training epoch: 5
[ Wed Jun 29 18:58:50 2022 ] 	Mean training loss: 1.2995.  Mean training acc: 62.11%.
[ Wed Jun 29 18:58:50 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 18:58:50 2022 ] Eval epoch: 5
[ Wed Jun 29 19:02:11 2022 ] 	Mean test loss of 796 batches: 1.3769580432068762.
[ Wed Jun 29 19:02:12 2022 ] 	Top1: 59.63%
[ Wed Jun 29 19:02:12 2022 ] 	Top5: 87.75%
[ Wed Jun 29 19:02:13 2022 ] Training epoch: 6
[ Wed Jun 29 19:14:21 2022 ] 	Mean training loss: 1.1232.  Mean training acc: 66.71%.
[ Wed Jun 29 19:14:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 19:14:21 2022 ] Eval epoch: 6
[ Wed Jun 29 19:17:47 2022 ] 	Mean test loss of 796 batches: 1.420260958560747.
[ Wed Jun 29 19:17:48 2022 ] 	Top1: 59.32%
[ Wed Jun 29 19:17:48 2022 ] 	Top5: 88.33%
[ Wed Jun 29 19:17:48 2022 ] Training epoch: 7
[ Wed Jun 29 19:30:02 2022 ] 	Mean training loss: 1.0335.  Mean training acc: 69.41%.
[ Wed Jun 29 19:30:02 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jun 29 19:30:02 2022 ] Eval epoch: 7
[ Wed Jun 29 19:33:40 2022 ] 	Mean test loss of 796 batches: 1.2174489240550517.
[ Wed Jun 29 19:33:41 2022 ] 	Top1: 65.00%
[ Wed Jun 29 19:33:41 2022 ] 	Top5: 90.00%
[ Wed Jun 29 19:33:41 2022 ] Training epoch: 8
[ Wed Jun 29 19:46:04 2022 ] 	Mean training loss: 0.9677.  Mean training acc: 71.18%.
[ Wed Jun 29 19:46:04 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 19:46:04 2022 ] Eval epoch: 8
[ Wed Jun 29 19:49:39 2022 ] 	Mean test loss of 796 batches: 1.033421167326932.
[ Wed Jun 29 19:49:39 2022 ] 	Top1: 68.49%
[ Wed Jun 29 19:49:40 2022 ] 	Top5: 92.60%
[ Wed Jun 29 19:49:40 2022 ] Training epoch: 9
[ Wed Jun 29 20:01:50 2022 ] 	Mean training loss: 0.9203.  Mean training acc: 72.44%.
[ Wed Jun 29 20:01:50 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 20:01:50 2022 ] Eval epoch: 9
[ Wed Jun 29 20:05:14 2022 ] 	Mean test loss of 796 batches: 1.0890589336579168.
[ Wed Jun 29 20:05:15 2022 ] 	Top1: 67.50%
[ Wed Jun 29 20:05:15 2022 ] 	Top5: 91.70%
[ Wed Jun 29 20:05:15 2022 ] Training epoch: 10
[ Wed Jun 29 20:17:27 2022 ] 	Mean training loss: 0.8896.  Mean training acc: 73.43%.
[ Wed Jun 29 20:17:27 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 20:17:27 2022 ] Eval epoch: 10
[ Wed Jun 29 20:20:55 2022 ] 	Mean test loss of 796 batches: 1.0889898598119243.
[ Wed Jun 29 20:20:55 2022 ] 	Top1: 67.97%
[ Wed Jun 29 20:20:56 2022 ] 	Top5: 91.67%
[ Wed Jun 29 20:20:56 2022 ] Training epoch: 11
[ Wed Jun 29 20:32:49 2022 ] 	Mean training loss: 0.8575.  Mean training acc: 74.01%.
[ Wed Jun 29 20:32:49 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 20:32:49 2022 ] Eval epoch: 11
[ Wed Jun 29 20:36:20 2022 ] 	Mean test loss of 796 batches: 1.0811198725173221.
[ Wed Jun 29 20:36:20 2022 ] 	Top1: 67.95%
[ Wed Jun 29 20:36:21 2022 ] 	Top5: 91.82%
[ Wed Jun 29 20:36:21 2022 ] Training epoch: 12
[ Wed Jun 29 20:48:14 2022 ] 	Mean training loss: 0.8492.  Mean training acc: 74.65%.
[ Wed Jun 29 20:48:14 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 20:48:14 2022 ] Eval epoch: 12
[ Wed Jun 29 20:51:40 2022 ] 	Mean test loss of 796 batches: 1.0885665168115242.
[ Wed Jun 29 20:51:41 2022 ] 	Top1: 67.92%
[ Wed Jun 29 20:51:41 2022 ] 	Top5: 91.69%
[ Wed Jun 29 20:51:41 2022 ] Training epoch: 13
[ Wed Jun 29 21:03:55 2022 ] 	Mean training loss: 0.8239.  Mean training acc: 75.17%.
[ Wed Jun 29 21:03:55 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 21:03:55 2022 ] Eval epoch: 13
[ Wed Jun 29 21:07:16 2022 ] 	Mean test loss of 796 batches: 1.0380762242267478.
[ Wed Jun 29 21:07:17 2022 ] 	Top1: 68.87%
[ Wed Jun 29 21:07:17 2022 ] 	Top5: 92.17%
[ Wed Jun 29 21:07:17 2022 ] Training epoch: 14
[ Wed Jun 29 21:19:29 2022 ] 	Mean training loss: 0.8075.  Mean training acc: 75.71%.
[ Wed Jun 29 21:19:29 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 21:19:29 2022 ] Eval epoch: 14
[ Wed Jun 29 21:22:55 2022 ] 	Mean test loss of 796 batches: 1.1654565907528054.
[ Wed Jun 29 21:22:56 2022 ] 	Top1: 66.93%
[ Wed Jun 29 21:22:56 2022 ] 	Top5: 90.82%
[ Wed Jun 29 21:22:57 2022 ] Training epoch: 15
[ Wed Jun 29 21:34:51 2022 ] 	Mean training loss: 0.7958.  Mean training acc: 76.21%.
[ Wed Jun 29 21:34:51 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 21:34:51 2022 ] Eval epoch: 15
[ Wed Jun 29 21:38:17 2022 ] 	Mean test loss of 796 batches: 1.0942790166442118.
[ Wed Jun 29 21:38:17 2022 ] 	Top1: 68.03%
[ Wed Jun 29 21:38:18 2022 ] 	Top5: 91.52%
[ Wed Jun 29 21:38:18 2022 ] Training epoch: 16
[ Wed Jun 29 21:49:41 2022 ] 	Mean training loss: 0.7877.  Mean training acc: 76.37%.
[ Wed Jun 29 21:49:41 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 21:49:41 2022 ] Eval epoch: 16
[ Wed Jun 29 21:52:37 2022 ] 	Mean test loss of 796 batches: 1.3270249484322179.
[ Wed Jun 29 21:52:38 2022 ] 	Top1: 63.54%
[ Wed Jun 29 21:52:38 2022 ] 	Top5: 90.09%
[ Wed Jun 29 21:52:38 2022 ] Training epoch: 17
[ Wed Jun 29 22:02:59 2022 ] 	Mean training loss: 0.7720.  Mean training acc: 76.63%.
[ Wed Jun 29 22:02:59 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 22:02:59 2022 ] Eval epoch: 17
[ Wed Jun 29 22:05:55 2022 ] 	Mean test loss of 796 batches: 0.9821305249129707.
[ Wed Jun 29 22:05:56 2022 ] 	Top1: 70.94%
[ Wed Jun 29 22:05:56 2022 ] 	Top5: 92.72%
[ Wed Jun 29 22:05:56 2022 ] Training epoch: 18
[ Wed Jun 29 22:16:13 2022 ] 	Mean training loss: 0.7753.  Mean training acc: 76.68%.
[ Wed Jun 29 22:16:13 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 22:16:13 2022 ] Eval epoch: 18
[ Wed Jun 29 22:19:11 2022 ] 	Mean test loss of 796 batches: 1.1576529822906656.
[ Wed Jun 29 22:19:12 2022 ] 	Top1: 66.33%
[ Wed Jun 29 22:19:12 2022 ] 	Top5: 91.11%
[ Wed Jun 29 22:19:12 2022 ] Training epoch: 19
[ Wed Jun 29 22:29:29 2022 ] 	Mean training loss: 0.7692.  Mean training acc: 76.85%.
[ Wed Jun 29 22:29:29 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 22:29:29 2022 ] Eval epoch: 19
[ Wed Jun 29 22:32:27 2022 ] 	Mean test loss of 796 batches: 1.4136506898618824.
[ Wed Jun 29 22:32:27 2022 ] 	Top1: 62.47%
[ Wed Jun 29 22:32:28 2022 ] 	Top5: 88.64%
[ Wed Jun 29 22:32:28 2022 ] Training epoch: 20
[ Wed Jun 29 22:42:49 2022 ] 	Mean training loss: 0.7545.  Mean training acc: 77.09%.
[ Wed Jun 29 22:42:49 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 22:42:49 2022 ] Eval epoch: 20
[ Wed Jun 29 22:45:45 2022 ] 	Mean test loss of 796 batches: 0.9604253090131822.
[ Wed Jun 29 22:45:45 2022 ] 	Top1: 71.39%
[ Wed Jun 29 22:45:46 2022 ] 	Top5: 93.19%
[ Wed Jun 29 22:45:46 2022 ] Training epoch: 21
[ Wed Jun 29 22:56:08 2022 ] 	Mean training loss: 0.7531.  Mean training acc: 77.33%.
[ Wed Jun 29 22:56:08 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 22:56:08 2022 ] Eval epoch: 21
[ Wed Jun 29 22:59:04 2022 ] 	Mean test loss of 796 batches: 0.9915072592209332.
[ Wed Jun 29 22:59:05 2022 ] 	Top1: 70.78%
[ Wed Jun 29 22:59:05 2022 ] 	Top5: 92.59%
[ Wed Jun 29 22:59:05 2022 ] Training epoch: 22
[ Wed Jun 29 23:09:25 2022 ] 	Mean training loss: 0.7517.  Mean training acc: 77.38%.
[ Wed Jun 29 23:09:25 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 23:09:25 2022 ] Eval epoch: 22
[ Wed Jun 29 23:12:20 2022 ] 	Mean test loss of 796 batches: 1.3091308550918521.
[ Wed Jun 29 23:12:21 2022 ] 	Top1: 65.55%
[ Wed Jun 29 23:12:21 2022 ] 	Top5: 89.62%
[ Wed Jun 29 23:12:21 2022 ] Training epoch: 23
[ Wed Jun 29 23:22:40 2022 ] 	Mean training loss: 0.7462.  Mean training acc: 77.47%.
[ Wed Jun 29 23:22:40 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 23:22:40 2022 ] Eval epoch: 23
[ Wed Jun 29 23:25:35 2022 ] 	Mean test loss of 796 batches: 1.2230443419448693.
[ Wed Jun 29 23:25:35 2022 ] 	Top1: 64.77%
[ Wed Jun 29 23:25:35 2022 ] 	Top5: 90.51%
[ Wed Jun 29 23:25:36 2022 ] Training epoch: 24
[ Wed Jun 29 23:35:58 2022 ] 	Mean training loss: 0.7391.  Mean training acc: 77.61%.
[ Wed Jun 29 23:35:58 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 23:35:58 2022 ] Eval epoch: 24
[ Wed Jun 29 23:38:51 2022 ] 	Mean test loss of 796 batches: 0.9700791717848586.
[ Wed Jun 29 23:38:51 2022 ] 	Top1: 71.57%
[ Wed Jun 29 23:38:52 2022 ] 	Top5: 92.81%
[ Wed Jun 29 23:38:52 2022 ] Training epoch: 25
[ Wed Jun 29 23:49:13 2022 ] 	Mean training loss: 0.7397.  Mean training acc: 77.53%.
[ Wed Jun 29 23:49:13 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Jun 29 23:49:13 2022 ] Eval epoch: 25
[ Wed Jun 29 23:52:07 2022 ] 	Mean test loss of 796 batches: 0.9979137344351366.
[ Wed Jun 29 23:52:07 2022 ] 	Top1: 70.28%
[ Wed Jun 29 23:52:08 2022 ] 	Top5: 92.69%
[ Wed Jun 29 23:52:08 2022 ] Training epoch: 26
[ Thu Jun 30 00:02:26 2022 ] 	Mean training loss: 0.7346.  Mean training acc: 77.83%.
[ Thu Jun 30 00:02:26 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 00:02:26 2022 ] Eval epoch: 26
[ Thu Jun 30 00:05:19 2022 ] 	Mean test loss of 796 batches: 1.0728791649617142.
[ Thu Jun 30 00:05:20 2022 ] 	Top1: 68.64%
[ Thu Jun 30 00:05:20 2022 ] 	Top5: 92.07%
[ Thu Jun 30 00:05:20 2022 ] Training epoch: 27
[ Thu Jun 30 00:15:42 2022 ] 	Mean training loss: 0.7334.  Mean training acc: 77.88%.
[ Thu Jun 30 00:15:42 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 00:15:42 2022 ] Eval epoch: 27
[ Thu Jun 30 00:18:34 2022 ] 	Mean test loss of 796 batches: 1.0636233281924496.
[ Thu Jun 30 00:18:34 2022 ] 	Top1: 68.80%
[ Thu Jun 30 00:18:35 2022 ] 	Top5: 92.37%
[ Thu Jun 30 00:18:35 2022 ] Training epoch: 28
[ Thu Jun 30 00:28:59 2022 ] 	Mean training loss: 0.7338.  Mean training acc: 77.78%.
[ Thu Jun 30 00:28:59 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 00:28:59 2022 ] Eval epoch: 28
[ Thu Jun 30 00:31:52 2022 ] 	Mean test loss of 796 batches: 1.1379459645954808.
[ Thu Jun 30 00:31:53 2022 ] 	Top1: 67.55%
[ Thu Jun 30 00:31:53 2022 ] 	Top5: 91.61%
[ Thu Jun 30 00:31:53 2022 ] Training epoch: 29
[ Thu Jun 30 00:42:16 2022 ] 	Mean training loss: 0.7220.  Mean training acc: 78.08%.
[ Thu Jun 30 00:42:16 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 00:42:16 2022 ] Eval epoch: 29
[ Thu Jun 30 00:45:08 2022 ] 	Mean test loss of 796 batches: 1.0892005452708384.
[ Thu Jun 30 00:45:08 2022 ] 	Top1: 69.07%
[ Thu Jun 30 00:45:08 2022 ] 	Top5: 91.37%
[ Thu Jun 30 00:45:09 2022 ] Training epoch: 30
[ Thu Jun 30 00:55:29 2022 ] 	Mean training loss: 0.7234.  Mean training acc: 78.24%.
[ Thu Jun 30 00:55:29 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 00:55:29 2022 ] Eval epoch: 30
[ Thu Jun 30 00:58:22 2022 ] 	Mean test loss of 796 batches: 1.1053500124557534.
[ Thu Jun 30 00:58:22 2022 ] 	Top1: 68.20%
[ Thu Jun 30 00:58:23 2022 ] 	Top5: 91.63%
[ Thu Jun 30 00:58:23 2022 ] Training epoch: 31
[ Thu Jun 30 01:08:46 2022 ] 	Mean training loss: 0.7256.  Mean training acc: 77.98%.
[ Thu Jun 30 01:08:46 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 01:08:46 2022 ] Eval epoch: 31
[ Thu Jun 30 01:11:38 2022 ] 	Mean test loss of 796 batches: 1.1872844106363292.
[ Thu Jun 30 01:11:38 2022 ] 	Top1: 67.06%
[ Thu Jun 30 01:11:39 2022 ] 	Top5: 90.87%
[ Thu Jun 30 01:11:39 2022 ] Training epoch: 32
[ Thu Jun 30 01:21:59 2022 ] 	Mean training loss: 0.7224.  Mean training acc: 78.28%.
[ Thu Jun 30 01:21:59 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 01:21:59 2022 ] Eval epoch: 32
[ Thu Jun 30 01:24:52 2022 ] 	Mean test loss of 796 batches: 0.9306036551394056.
[ Thu Jun 30 01:24:53 2022 ] 	Top1: 72.94%
[ Thu Jun 30 01:24:53 2022 ] 	Top5: 93.34%
[ Thu Jun 30 01:24:53 2022 ] Training epoch: 33
[ Thu Jun 30 01:35:11 2022 ] 	Mean training loss: 0.7198.  Mean training acc: 78.15%.
[ Thu Jun 30 01:35:11 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 01:35:11 2022 ] Eval epoch: 33
[ Thu Jun 30 01:38:05 2022 ] 	Mean test loss of 796 batches: 1.079592133100009.
[ Thu Jun 30 01:38:05 2022 ] 	Top1: 68.21%
[ Thu Jun 30 01:38:06 2022 ] 	Top5: 92.19%
[ Thu Jun 30 01:38:06 2022 ] Training epoch: 34
[ Thu Jun 30 01:48:25 2022 ] 	Mean training loss: 0.7142.  Mean training acc: 78.22%.
[ Thu Jun 30 01:48:25 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 01:48:25 2022 ] Eval epoch: 34
[ Thu Jun 30 01:51:18 2022 ] 	Mean test loss of 796 batches: 1.2355718803989828.
[ Thu Jun 30 01:51:18 2022 ] 	Top1: 65.43%
[ Thu Jun 30 01:51:19 2022 ] 	Top5: 90.36%
[ Thu Jun 30 01:51:19 2022 ] Training epoch: 35
[ Thu Jun 30 02:01:40 2022 ] 	Mean training loss: 0.7168.  Mean training acc: 78.06%.
[ Thu Jun 30 02:01:41 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 02:01:41 2022 ] Eval epoch: 35
[ Thu Jun 30 02:04:34 2022 ] 	Mean test loss of 796 batches: 1.05480577208888.
[ Thu Jun 30 02:04:35 2022 ] 	Top1: 70.53%
[ Thu Jun 30 02:04:35 2022 ] 	Top5: 91.95%
[ Thu Jun 30 02:04:35 2022 ] Training epoch: 36
[ Thu Jun 30 02:14:53 2022 ] 	Mean training loss: 0.4190.  Mean training acc: 87.53%.
[ Thu Jun 30 02:14:53 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 02:14:53 2022 ] Eval epoch: 36
[ Thu Jun 30 02:17:48 2022 ] 	Mean test loss of 796 batches: 0.5601507999639416.
[ Thu Jun 30 02:17:49 2022 ] 	Top1: 82.70%
[ Thu Jun 30 02:17:49 2022 ] 	Top5: 96.88%
[ Thu Jun 30 02:17:49 2022 ] Training epoch: 37
[ Thu Jun 30 02:28:06 2022 ] 	Mean training loss: 0.3327.  Mean training acc: 90.00%.
[ Thu Jun 30 02:28:06 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 02:28:06 2022 ] Eval epoch: 37
[ Thu Jun 30 02:31:01 2022 ] 	Mean test loss of 796 batches: 0.5478209160623988.
[ Thu Jun 30 02:31:01 2022 ] 	Top1: 83.07%
[ Thu Jun 30 02:31:02 2022 ] 	Top5: 97.01%
[ Thu Jun 30 02:31:02 2022 ] Training epoch: 38
[ Thu Jun 30 02:41:21 2022 ] 	Mean training loss: 0.2989.  Mean training acc: 91.04%.
[ Thu Jun 30 02:41:21 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 02:41:21 2022 ] Eval epoch: 38
[ Thu Jun 30 02:44:16 2022 ] 	Mean test loss of 796 batches: 0.5479917758560959.
[ Thu Jun 30 02:44:17 2022 ] 	Top1: 83.09%
[ Thu Jun 30 02:44:17 2022 ] 	Top5: 96.97%
[ Thu Jun 30 02:44:17 2022 ] Training epoch: 39
[ Thu Jun 30 02:54:34 2022 ] 	Mean training loss: 0.2725.  Mean training acc: 91.79%.
[ Thu Jun 30 02:54:34 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 02:54:34 2022 ] Eval epoch: 39
[ Thu Jun 30 02:57:30 2022 ] 	Mean test loss of 796 batches: 0.5537151627888407.
[ Thu Jun 30 02:57:31 2022 ] 	Top1: 83.08%
[ Thu Jun 30 02:57:31 2022 ] 	Top5: 96.99%
[ Thu Jun 30 02:57:31 2022 ] Training epoch: 40
[ Thu Jun 30 03:07:45 2022 ] 	Mean training loss: 0.2535.  Mean training acc: 92.53%.
[ Thu Jun 30 03:07:45 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 03:07:45 2022 ] Eval epoch: 40
[ Thu Jun 30 03:10:41 2022 ] 	Mean test loss of 796 batches: 0.5646539247739855.
[ Thu Jun 30 03:10:41 2022 ] 	Top1: 82.93%
[ Thu Jun 30 03:10:42 2022 ] 	Top5: 96.81%
[ Thu Jun 30 03:10:42 2022 ] Training epoch: 41
[ Thu Jun 30 03:20:58 2022 ] 	Mean training loss: 0.2354.  Mean training acc: 93.15%.
[ Thu Jun 30 03:20:58 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 03:20:58 2022 ] Eval epoch: 41
[ Thu Jun 30 03:23:53 2022 ] 	Mean test loss of 796 batches: 0.5702345026797385.
[ Thu Jun 30 03:23:53 2022 ] 	Top1: 83.08%
[ Thu Jun 30 03:23:54 2022 ] 	Top5: 96.80%
[ Thu Jun 30 03:23:54 2022 ] Training epoch: 42
[ Thu Jun 30 03:34:12 2022 ] 	Mean training loss: 0.2222.  Mean training acc: 93.59%.
[ Thu Jun 30 03:34:12 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 03:34:12 2022 ] Eval epoch: 42
[ Thu Jun 30 03:37:08 2022 ] 	Mean test loss of 796 batches: 0.5581224519740696.
[ Thu Jun 30 03:37:08 2022 ] 	Top1: 83.48%
[ Thu Jun 30 03:37:09 2022 ] 	Top5: 96.92%
[ Thu Jun 30 03:37:09 2022 ] Training epoch: 43
[ Thu Jun 30 03:47:25 2022 ] 	Mean training loss: 0.2105.  Mean training acc: 93.92%.
[ Thu Jun 30 03:47:25 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 03:47:25 2022 ] Eval epoch: 43
[ Thu Jun 30 03:50:21 2022 ] 	Mean test loss of 796 batches: 0.571263935847498.
[ Thu Jun 30 03:50:21 2022 ] 	Top1: 83.10%
[ Thu Jun 30 03:50:22 2022 ] 	Top5: 96.84%
[ Thu Jun 30 03:50:22 2022 ] Training epoch: 44
[ Thu Jun 30 04:00:37 2022 ] 	Mean training loss: 0.1985.  Mean training acc: 94.33%.
[ Thu Jun 30 04:00:37 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 04:00:37 2022 ] Eval epoch: 44
[ Thu Jun 30 04:03:33 2022 ] 	Mean test loss of 796 batches: 0.6009878678500054.
[ Thu Jun 30 04:03:33 2022 ] 	Top1: 82.39%
[ Thu Jun 30 04:03:34 2022 ] 	Top5: 96.59%
[ Thu Jun 30 04:03:34 2022 ] Training epoch: 45
[ Thu Jun 30 04:13:51 2022 ] 	Mean training loss: 0.1931.  Mean training acc: 94.52%.
[ Thu Jun 30 04:13:51 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 04:13:51 2022 ] Eval epoch: 45
[ Thu Jun 30 04:16:47 2022 ] 	Mean test loss of 796 batches: 0.6020156321438712.
[ Thu Jun 30 04:16:47 2022 ] 	Top1: 82.69%
[ Thu Jun 30 04:16:48 2022 ] 	Top5: 96.55%
[ Thu Jun 30 04:16:48 2022 ] Training epoch: 46
[ Thu Jun 30 04:27:05 2022 ] 	Mean training loss: 0.1854.  Mean training acc: 94.82%.
[ Thu Jun 30 04:27:05 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 04:27:05 2022 ] Eval epoch: 46
[ Thu Jun 30 04:30:01 2022 ] 	Mean test loss of 796 batches: 0.6077804025309395.
[ Thu Jun 30 04:30:01 2022 ] 	Top1: 82.39%
[ Thu Jun 30 04:30:02 2022 ] 	Top5: 96.58%
[ Thu Jun 30 04:30:02 2022 ] Training epoch: 47
[ Thu Jun 30 04:39:48 2022 ] 	Mean training loss: 0.1807.  Mean training acc: 94.99%.
[ Thu Jun 30 04:39:48 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 04:39:48 2022 ] Eval epoch: 47
[ Thu Jun 30 04:42:01 2022 ] 	Mean test loss of 796 batches: 0.601948693404021.
[ Thu Jun 30 04:42:01 2022 ] 	Top1: 82.62%
[ Thu Jun 30 04:42:02 2022 ] 	Top5: 96.59%
[ Thu Jun 30 04:42:02 2022 ] Training epoch: 48
[ Thu Jun 30 04:49:12 2022 ] 	Mean training loss: 0.1756.  Mean training acc: 95.10%.
[ Thu Jun 30 04:49:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 04:49:12 2022 ] Eval epoch: 48
[ Thu Jun 30 04:51:24 2022 ] 	Mean test loss of 796 batches: 0.6254009882072408.
[ Thu Jun 30 04:51:24 2022 ] 	Top1: 82.06%
[ Thu Jun 30 04:51:25 2022 ] 	Top5: 96.31%
[ Thu Jun 30 04:51:25 2022 ] Training epoch: 49
[ Thu Jun 30 04:58:40 2022 ] 	Mean training loss: 0.1750.  Mean training acc: 95.19%.
[ Thu Jun 30 04:58:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 04:58:40 2022 ] Eval epoch: 49
[ Thu Jun 30 05:00:45 2022 ] 	Mean test loss of 796 batches: 0.6589263327485279.
[ Thu Jun 30 05:00:45 2022 ] 	Top1: 81.76%
[ Thu Jun 30 05:00:46 2022 ] 	Top5: 96.10%
[ Thu Jun 30 05:00:46 2022 ] Training epoch: 50
[ Thu Jun 30 05:04:40 2022 ] 	Mean training loss: 0.1724.  Mean training acc: 95.17%.
[ Thu Jun 30 05:04:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 05:04:41 2022 ] Eval epoch: 50
[ Thu Jun 30 05:05:46 2022 ] 	Mean test loss of 796 batches: 0.623614782299004.
[ Thu Jun 30 05:05:47 2022 ] 	Top1: 82.49%
[ Thu Jun 30 05:05:48 2022 ] 	Top5: 96.30%
[ Thu Jun 30 05:05:48 2022 ] Training epoch: 51
[ Thu Jun 30 05:09:11 2022 ] 	Mean training loss: 0.1684.  Mean training acc: 95.36%.
[ Thu Jun 30 05:09:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 05:09:11 2022 ] Eval epoch: 51
[ Thu Jun 30 05:10:16 2022 ] 	Mean test loss of 796 batches: 0.6484888433736173.
[ Thu Jun 30 05:10:16 2022 ] 	Top1: 81.94%
[ Thu Jun 30 05:10:17 2022 ] 	Top5: 96.09%
[ Thu Jun 30 05:10:17 2022 ] Training epoch: 52
[ Thu Jun 30 05:13:40 2022 ] 	Mean training loss: 0.1711.  Mean training acc: 95.25%.
[ Thu Jun 30 05:13:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 05:13:40 2022 ] Eval epoch: 52
[ Thu Jun 30 05:14:47 2022 ] 	Mean test loss of 796 batches: 0.6625849547604071.
[ Thu Jun 30 05:14:47 2022 ] 	Top1: 81.43%
[ Thu Jun 30 05:14:48 2022 ] 	Top5: 96.21%
[ Thu Jun 30 05:14:48 2022 ] Training epoch: 53
[ Thu Jun 30 05:18:11 2022 ] 	Mean training loss: 0.1678.  Mean training acc: 95.39%.
[ Thu Jun 30 05:18:11 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 05:18:11 2022 ] Eval epoch: 53
[ Thu Jun 30 05:19:17 2022 ] 	Mean test loss of 796 batches: 0.6679102399821707.
[ Thu Jun 30 05:19:17 2022 ] 	Top1: 81.32%
[ Thu Jun 30 05:19:18 2022 ] 	Top5: 95.97%
[ Thu Jun 30 05:19:18 2022 ] Training epoch: 54
[ Thu Jun 30 05:22:41 2022 ] 	Mean training loss: 0.1657.  Mean training acc: 95.42%.
[ Thu Jun 30 05:22:41 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 05:22:41 2022 ] Eval epoch: 54
[ Thu Jun 30 05:23:48 2022 ] 	Mean test loss of 796 batches: 0.6496316216249561.
[ Thu Jun 30 05:23:48 2022 ] 	Top1: 81.95%
[ Thu Jun 30 05:23:48 2022 ] 	Top5: 96.19%
[ Thu Jun 30 05:23:48 2022 ] Training epoch: 55
[ Thu Jun 30 05:27:12 2022 ] 	Mean training loss: 0.1702.  Mean training acc: 95.27%.
[ Thu Jun 30 05:27:12 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 05:27:12 2022 ] Eval epoch: 55
[ Thu Jun 30 05:28:19 2022 ] 	Mean test loss of 796 batches: 0.6768297537056794.
[ Thu Jun 30 05:28:19 2022 ] 	Top1: 81.30%
[ Thu Jun 30 05:28:20 2022 ] 	Top5: 95.93%
[ Thu Jun 30 05:28:20 2022 ] Training epoch: 56
[ Thu Jun 30 05:31:43 2022 ] 	Mean training loss: 0.0967.  Mean training acc: 97.81%.
[ Thu Jun 30 05:31:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 05:31:43 2022 ] Eval epoch: 56
[ Thu Jun 30 05:32:50 2022 ] 	Mean test loss of 796 batches: 0.5893622778646236.
[ Thu Jun 30 05:32:50 2022 ] 	Top1: 83.62%
[ Thu Jun 30 05:32:50 2022 ] 	Top5: 96.70%
[ Thu Jun 30 05:32:50 2022 ] Training epoch: 57
[ Thu Jun 30 05:36:18 2022 ] 	Mean training loss: 0.0721.  Mean training acc: 98.57%.
[ Thu Jun 30 05:36:18 2022 ] 	Time consumption: [Data]02%, [Network]95%
[ Thu Jun 30 05:36:18 2022 ] Eval epoch: 57
[ Thu Jun 30 05:37:24 2022 ] 	Mean test loss of 796 batches: 0.5898797170273099.
[ Thu Jun 30 05:37:24 2022 ] 	Top1: 83.85%
[ Thu Jun 30 05:37:25 2022 ] 	Top5: 96.63%
[ Thu Jun 30 05:37:25 2022 ] Training epoch: 58
[ Thu Jun 30 05:40:48 2022 ] 	Mean training loss: 0.0643.  Mean training acc: 98.83%.
[ Thu Jun 30 05:40:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 05:40:48 2022 ] Eval epoch: 58
[ Thu Jun 30 05:41:54 2022 ] 	Mean test loss of 796 batches: 0.596608970230024.
[ Thu Jun 30 05:41:54 2022 ] 	Top1: 83.62%
[ Thu Jun 30 05:41:55 2022 ] 	Top5: 96.65%
[ Thu Jun 30 05:41:55 2022 ] Training epoch: 59
[ Thu Jun 30 05:45:19 2022 ] 	Mean training loss: 0.0595.  Mean training acc: 98.92%.
[ Thu Jun 30 05:45:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 05:45:19 2022 ] Eval epoch: 59
[ Thu Jun 30 05:46:25 2022 ] 	Mean test loss of 796 batches: 0.5926909738327915.
[ Thu Jun 30 05:46:26 2022 ] 	Top1: 83.76%
[ Thu Jun 30 05:46:26 2022 ] 	Top5: 96.58%
[ Thu Jun 30 05:46:26 2022 ] Training epoch: 60
[ Thu Jun 30 05:49:50 2022 ] 	Mean training loss: 0.0534.  Mean training acc: 99.10%.
[ Thu Jun 30 05:49:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 05:49:50 2022 ] Eval epoch: 60
[ Thu Jun 30 05:50:56 2022 ] 	Mean test loss of 796 batches: 0.5877993295212561.
[ Thu Jun 30 05:50:56 2022 ] 	Top1: 83.92%
[ Thu Jun 30 05:50:57 2022 ] 	Top5: 96.72%
[ Thu Jun 30 05:50:57 2022 ] Training epoch: 61
[ Thu Jun 30 05:54:20 2022 ] 	Mean training loss: 0.0527.  Mean training acc: 99.12%.
[ Thu Jun 30 05:54:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 05:54:33 2022 ] Eval epoch: 61
[ Thu Jun 30 05:55:38 2022 ] 	Mean test loss of 796 batches: 0.602272821463944.
[ Thu Jun 30 05:55:38 2022 ] 	Top1: 83.71%
[ Thu Jun 30 05:55:39 2022 ] 	Top5: 96.56%
[ Thu Jun 30 05:55:39 2022 ] Training epoch: 62
[ Thu Jun 30 05:59:09 2022 ] 	Mean training loss: 0.0496.  Mean training acc: 99.19%.
[ Thu Jun 30 05:59:09 2022 ] 	Time consumption: [Data]02%, [Network]94%
[ Thu Jun 30 05:59:09 2022 ] Eval epoch: 62
[ Thu Jun 30 06:00:15 2022 ] 	Mean test loss of 796 batches: 0.5996630606030924.
[ Thu Jun 30 06:00:16 2022 ] 	Top1: 83.74%
[ Thu Jun 30 06:00:17 2022 ] 	Top5: 96.58%
[ Thu Jun 30 06:00:17 2022 ] Training epoch: 63
[ Thu Jun 30 06:03:40 2022 ] 	Mean training loss: 0.0466.  Mean training acc: 99.28%.
[ Thu Jun 30 06:03:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 06:03:40 2022 ] Eval epoch: 63
[ Thu Jun 30 06:04:45 2022 ] 	Mean test loss of 796 batches: 0.593437052420785.
[ Thu Jun 30 06:04:46 2022 ] 	Top1: 83.96%
[ Thu Jun 30 06:04:46 2022 ] 	Top5: 96.58%
[ Thu Jun 30 06:04:46 2022 ] Training epoch: 64
[ Thu Jun 30 06:08:11 2022 ] 	Mean training loss: 0.0471.  Mean training acc: 99.29%.
[ Thu Jun 30 06:08:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jun 30 06:08:11 2022 ] Eval epoch: 64
[ Thu Jun 30 06:09:19 2022 ] 	Mean test loss of 796 batches: 0.602847818360107.
[ Thu Jun 30 06:09:19 2022 ] 	Top1: 83.79%
[ Thu Jun 30 06:09:20 2022 ] 	Top5: 96.50%
[ Thu Jun 30 06:09:20 2022 ] Training epoch: 65
[ Thu Jun 30 06:12:42 2022 ] 	Mean training loss: 0.0445.  Mean training acc: 99.33%.
[ Thu Jun 30 06:12:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 06:12:42 2022 ] Eval epoch: 65
[ Thu Jun 30 06:13:47 2022 ] 	Mean test loss of 796 batches: 0.5976220577084763.
[ Thu Jun 30 06:13:48 2022 ] 	Top1: 83.82%
[ Thu Jun 30 06:13:48 2022 ] 	Top5: 96.62%
[ Thu Jun 30 06:14:56 2022 ] Best accuracy: 0.8396472829395707
[ Thu Jun 30 06:14:56 2022 ] Epoch number: 63
[ Thu Jun 30 06:14:56 2022 ] Model name: work_dir/ntu120/csub/base_four7_BL
[ Thu Jun 30 06:14:56 2022 ] Model total number of params: 2118562
[ Thu Jun 30 06:14:56 2022 ] Weight decay: 0.0004
[ Thu Jun 30 06:14:56 2022 ] Base LR: 0.1
[ Thu Jun 30 06:14:56 2022 ] Batch Size: 64
[ Thu Jun 30 06:14:56 2022 ] Test Batch Size: 64
[ Thu Jun 30 06:14:56 2022 ] seed: 1
