[ Tue Jun 21 13:36:22 2022 ] using warm up, epoch: 5
[ Tue Jun 21 13:36:36 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four14b', 'model_saved_name': 'work_dir/ntu120/csub/base_four14b/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier14b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jun 21 13:36:36 2022 ] # Parameters: 2112610
[ Tue Jun 21 13:36:36 2022 ] Training epoch: 1
[ Tue Jun 21 13:41:21 2022 ] 	Mean training loss: 3.0249.  Mean training acc: 24.01%.
[ Tue Jun 21 13:41:21 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jun 21 13:41:21 2022 ] Eval epoch: 1
[ Tue Jun 21 13:42:42 2022 ] 	Mean test loss of 796 batches: 2.348577779591383.
[ Tue Jun 21 13:42:43 2022 ] 	Top1: 35.01%
[ Tue Jun 21 13:42:43 2022 ] 	Top5: 69.49%
[ Tue Jun 21 13:42:43 2022 ] Training epoch: 2
[ Tue Jun 21 13:47:29 2022 ] 	Mean training loss: 2.0102.  Mean training acc: 43.53%.
[ Tue Jun 21 13:47:29 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jun 21 13:47:29 2022 ] Eval epoch: 2
[ Tue Jun 21 13:48:50 2022 ] 	Mean test loss of 796 batches: 1.8788922605053264.
[ Tue Jun 21 13:48:50 2022 ] 	Top1: 45.53%
[ Tue Jun 21 13:48:51 2022 ] 	Top5: 79.72%
[ Tue Jun 21 13:48:51 2022 ] Training epoch: 3
[ Tue Jun 21 13:53:37 2022 ] 	Mean training loss: 1.6156.  Mean training acc: 53.25%.
[ Tue Jun 21 13:53:37 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 13:53:37 2022 ] Eval epoch: 3
[ Tue Jun 21 13:54:58 2022 ] 	Mean test loss of 796 batches: 1.6942190749561368.
[ Tue Jun 21 13:54:58 2022 ] 	Top1: 50.22%
[ Tue Jun 21 13:54:59 2022 ] 	Top5: 83.48%
[ Tue Jun 21 13:54:59 2022 ] Training epoch: 4
[ Tue Jun 21 13:59:45 2022 ] 	Mean training loss: 1.4118.  Mean training acc: 58.56%.
[ Tue Jun 21 13:59:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 13:59:45 2022 ] Eval epoch: 4
[ Tue Jun 21 14:01:06 2022 ] 	Mean test loss of 796 batches: 1.485596072434181.
[ Tue Jun 21 14:01:06 2022 ] 	Top1: 56.88%
[ Tue Jun 21 14:01:06 2022 ] 	Top5: 86.75%
[ Tue Jun 21 14:01:07 2022 ] Training epoch: 5
[ Tue Jun 21 14:05:52 2022 ] 	Mean training loss: 1.2879.  Mean training acc: 62.02%.
[ Tue Jun 21 14:05:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:05:52 2022 ] Eval epoch: 5
[ Tue Jun 21 14:07:14 2022 ] 	Mean test loss of 796 batches: 1.5495233138152702.
[ Tue Jun 21 14:07:14 2022 ] 	Top1: 56.75%
[ Tue Jun 21 14:07:14 2022 ] 	Top5: 84.39%
[ Tue Jun 21 14:07:15 2022 ] Training epoch: 6
[ Tue Jun 21 14:12:01 2022 ] 	Mean training loss: 1.1730.  Mean training acc: 65.20%.
[ Tue Jun 21 14:12:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:12:01 2022 ] Eval epoch: 6
[ Tue Jun 21 14:13:22 2022 ] 	Mean test loss of 796 batches: 1.5359706218218683.
[ Tue Jun 21 14:13:22 2022 ] 	Top1: 56.50%
[ Tue Jun 21 14:13:23 2022 ] 	Top5: 85.72%
[ Tue Jun 21 14:13:23 2022 ] Training epoch: 7
[ Tue Jun 21 14:18:08 2022 ] 	Mean training loss: 1.0862.  Mean training acc: 67.50%.
[ Tue Jun 21 14:18:08 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Tue Jun 21 14:18:08 2022 ] Eval epoch: 7
[ Tue Jun 21 14:19:29 2022 ] 	Mean test loss of 796 batches: 1.2550672923949495.
[ Tue Jun 21 14:19:30 2022 ] 	Top1: 62.28%
[ Tue Jun 21 14:19:30 2022 ] 	Top5: 89.90%
[ Tue Jun 21 14:19:30 2022 ] Training epoch: 8
[ Tue Jun 21 14:24:16 2022 ] 	Mean training loss: 1.0314.  Mean training acc: 69.26%.
[ Tue Jun 21 14:24:16 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:24:16 2022 ] Eval epoch: 8
[ Tue Jun 21 14:25:37 2022 ] 	Mean test loss of 796 batches: 1.1944364906854965.
[ Tue Jun 21 14:25:38 2022 ] 	Top1: 64.27%
[ Tue Jun 21 14:25:38 2022 ] 	Top5: 90.70%
[ Tue Jun 21 14:25:38 2022 ] Training epoch: 9
[ Tue Jun 21 14:30:24 2022 ] 	Mean training loss: 0.9906.  Mean training acc: 70.45%.
[ Tue Jun 21 14:30:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:30:24 2022 ] Eval epoch: 9
[ Tue Jun 21 14:31:45 2022 ] 	Mean test loss of 796 batches: 1.275168065711781.
[ Tue Jun 21 14:31:47 2022 ] 	Top1: 62.81%
[ Tue Jun 21 14:31:48 2022 ] 	Top5: 89.53%
[ Tue Jun 21 14:31:48 2022 ] Training epoch: 10
[ Tue Jun 21 14:36:33 2022 ] 	Mean training loss: 0.9514.  Mean training acc: 71.30%.
[ Tue Jun 21 14:36:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:36:33 2022 ] Eval epoch: 10
[ Tue Jun 21 14:37:55 2022 ] 	Mean test loss of 796 batches: 1.330436332965616.
[ Tue Jun 21 14:37:55 2022 ] 	Top1: 62.46%
[ Tue Jun 21 14:37:55 2022 ] 	Top5: 89.45%
[ Tue Jun 21 14:37:56 2022 ] Training epoch: 11
[ Tue Jun 21 14:42:41 2022 ] 	Mean training loss: 0.9294.  Mean training acc: 72.09%.
[ Tue Jun 21 14:42:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:42:41 2022 ] Eval epoch: 11
[ Tue Jun 21 14:44:03 2022 ] 	Mean test loss of 796 batches: 1.157257637523826.
[ Tue Jun 21 14:44:03 2022 ] 	Top1: 66.17%
[ Tue Jun 21 14:44:03 2022 ] 	Top5: 90.43%
[ Tue Jun 21 14:44:03 2022 ] Training epoch: 12
[ Tue Jun 21 14:48:49 2022 ] 	Mean training loss: 0.8967.  Mean training acc: 73.02%.
[ Tue Jun 21 14:48:49 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:48:49 2022 ] Eval epoch: 12
[ Tue Jun 21 14:50:10 2022 ] 	Mean test loss of 796 batches: 1.0456240152818475.
[ Tue Jun 21 14:50:12 2022 ] 	Top1: 68.52%
[ Tue Jun 21 14:50:13 2022 ] 	Top5: 92.46%
[ Tue Jun 21 14:50:13 2022 ] Training epoch: 13
[ Tue Jun 21 14:54:59 2022 ] 	Mean training loss: 0.8825.  Mean training acc: 73.45%.
[ Tue Jun 21 14:54:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 14:54:59 2022 ] Eval epoch: 13
[ Tue Jun 21 14:56:20 2022 ] 	Mean test loss of 796 batches: 1.1538403411606448.
[ Tue Jun 21 14:56:20 2022 ] 	Top1: 66.25%
[ Tue Jun 21 14:56:21 2022 ] 	Top5: 90.90%
[ Tue Jun 21 14:56:21 2022 ] Training epoch: 14
[ Tue Jun 21 15:01:06 2022 ] 	Mean training loss: 0.8615.  Mean training acc: 73.93%.
[ Tue Jun 21 15:01:06 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:01:06 2022 ] Eval epoch: 14
[ Tue Jun 21 15:02:27 2022 ] 	Mean test loss of 796 batches: 1.0735584014100046.
[ Tue Jun 21 15:02:28 2022 ] 	Top1: 67.98%
[ Tue Jun 21 15:02:28 2022 ] 	Top5: 92.00%
[ Tue Jun 21 15:02:28 2022 ] Training epoch: 15
[ Tue Jun 21 15:07:14 2022 ] 	Mean training loss: 0.8497.  Mean training acc: 74.11%.
[ Tue Jun 21 15:07:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:07:14 2022 ] Eval epoch: 15
[ Tue Jun 21 15:08:36 2022 ] 	Mean test loss of 796 batches: 1.0832424581275513.
[ Tue Jun 21 15:08:36 2022 ] 	Top1: 68.36%
[ Tue Jun 21 15:08:36 2022 ] 	Top5: 91.90%
[ Tue Jun 21 15:08:36 2022 ] Training epoch: 16
[ Tue Jun 21 15:13:23 2022 ] 	Mean training loss: 0.8266.  Mean training acc: 74.98%.
[ Tue Jun 21 15:13:23 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:13:23 2022 ] Eval epoch: 16
[ Tue Jun 21 15:14:44 2022 ] 	Mean test loss of 796 batches: 1.169097815775991.
[ Tue Jun 21 15:14:44 2022 ] 	Top1: 67.15%
[ Tue Jun 21 15:14:45 2022 ] 	Top5: 90.69%
[ Tue Jun 21 15:14:45 2022 ] Training epoch: 17
[ Tue Jun 21 15:19:31 2022 ] 	Mean training loss: 0.8204.  Mean training acc: 75.25%.
[ Tue Jun 21 15:19:31 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:19:31 2022 ] Eval epoch: 17
[ Tue Jun 21 15:20:52 2022 ] 	Mean test loss of 796 batches: 1.1969654215265757.
[ Tue Jun 21 15:20:52 2022 ] 	Top1: 65.85%
[ Tue Jun 21 15:20:53 2022 ] 	Top5: 89.99%
[ Tue Jun 21 15:20:53 2022 ] Training epoch: 18
[ Tue Jun 21 15:25:38 2022 ] 	Mean training loss: 0.8152.  Mean training acc: 75.24%.
[ Tue Jun 21 15:25:38 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:25:38 2022 ] Eval epoch: 18
[ Tue Jun 21 15:27:00 2022 ] 	Mean test loss of 796 batches: 1.2415196247885574.
[ Tue Jun 21 15:27:00 2022 ] 	Top1: 64.64%
[ Tue Jun 21 15:27:01 2022 ] 	Top5: 88.76%
[ Tue Jun 21 15:27:01 2022 ] Training epoch: 19
[ Tue Jun 21 15:31:46 2022 ] 	Mean training loss: 0.8062.  Mean training acc: 75.82%.
[ Tue Jun 21 15:31:46 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:31:46 2022 ] Eval epoch: 19
[ Tue Jun 21 15:33:08 2022 ] 	Mean test loss of 796 batches: 1.0796722345915273.
[ Tue Jun 21 15:33:08 2022 ] 	Top1: 68.46%
[ Tue Jun 21 15:33:09 2022 ] 	Top5: 91.94%
[ Tue Jun 21 15:33:09 2022 ] Training epoch: 20
[ Tue Jun 21 15:37:56 2022 ] 	Mean training loss: 0.8022.  Mean training acc: 75.82%.
[ Tue Jun 21 15:37:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:37:56 2022 ] Eval epoch: 20
[ Tue Jun 21 15:39:17 2022 ] 	Mean test loss of 796 batches: 1.0776880930117028.
[ Tue Jun 21 15:39:18 2022 ] 	Top1: 69.22%
[ Tue Jun 21 15:39:18 2022 ] 	Top5: 91.43%
[ Tue Jun 21 15:39:18 2022 ] Training epoch: 21
[ Tue Jun 21 15:44:05 2022 ] 	Mean training loss: 0.7911.  Mean training acc: 75.98%.
[ Tue Jun 21 15:44:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:44:05 2022 ] Eval epoch: 21
[ Tue Jun 21 15:45:26 2022 ] 	Mean test loss of 796 batches: 1.1514369543248684.
[ Tue Jun 21 15:45:26 2022 ] 	Top1: 67.91%
[ Tue Jun 21 15:45:27 2022 ] 	Top5: 91.50%
[ Tue Jun 21 15:45:27 2022 ] Training epoch: 22
[ Tue Jun 21 15:50:12 2022 ] 	Mean training loss: 0.7775.  Mean training acc: 76.61%.
[ Tue Jun 21 15:50:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:50:12 2022 ] Eval epoch: 22
[ Tue Jun 21 15:51:34 2022 ] 	Mean test loss of 796 batches: 1.1152606098795657.
[ Tue Jun 21 15:51:34 2022 ] 	Top1: 67.52%
[ Tue Jun 21 15:51:34 2022 ] 	Top5: 91.07%
[ Tue Jun 21 15:51:35 2022 ] Training epoch: 23
[ Tue Jun 21 15:56:20 2022 ] 	Mean training loss: 0.7854.  Mean training acc: 76.08%.
[ Tue Jun 21 15:56:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 15:56:20 2022 ] Eval epoch: 23
[ Tue Jun 21 15:57:41 2022 ] 	Mean test loss of 796 batches: 1.000261488272317.
[ Tue Jun 21 15:57:42 2022 ] 	Top1: 70.29%
[ Tue Jun 21 15:57:42 2022 ] 	Top5: 92.86%
[ Tue Jun 21 15:57:42 2022 ] Training epoch: 24
[ Tue Jun 21 16:02:28 2022 ] 	Mean training loss: 0.7740.  Mean training acc: 76.77%.
[ Tue Jun 21 16:02:28 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:02:28 2022 ] Eval epoch: 24
[ Tue Jun 21 16:03:50 2022 ] 	Mean test loss of 796 batches: 1.0423715978336694.
[ Tue Jun 21 16:03:50 2022 ] 	Top1: 69.52%
[ Tue Jun 21 16:03:50 2022 ] 	Top5: 91.74%
[ Tue Jun 21 16:03:50 2022 ] Training epoch: 25
[ Tue Jun 21 16:08:36 2022 ] 	Mean training loss: 0.7698.  Mean training acc: 76.63%.
[ Tue Jun 21 16:08:36 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:08:36 2022 ] Eval epoch: 25
[ Tue Jun 21 16:09:57 2022 ] 	Mean test loss of 796 batches: 1.1659728288650513.
[ Tue Jun 21 16:09:58 2022 ] 	Top1: 66.50%
[ Tue Jun 21 16:09:58 2022 ] 	Top5: 90.30%
[ Tue Jun 21 16:09:58 2022 ] Training epoch: 26
[ Tue Jun 21 16:14:44 2022 ] 	Mean training loss: 0.7632.  Mean training acc: 76.92%.
[ Tue Jun 21 16:14:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:14:44 2022 ] Eval epoch: 26
[ Tue Jun 21 16:16:06 2022 ] 	Mean test loss of 796 batches: 1.0400372203720274.
[ Tue Jun 21 16:16:06 2022 ] 	Top1: 69.79%
[ Tue Jun 21 16:16:06 2022 ] 	Top5: 92.45%
[ Tue Jun 21 16:16:06 2022 ] Training epoch: 27
[ Tue Jun 21 16:20:52 2022 ] 	Mean training loss: 0.7544.  Mean training acc: 77.17%.
[ Tue Jun 21 16:20:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:20:52 2022 ] Eval epoch: 27
[ Tue Jun 21 16:22:13 2022 ] 	Mean test loss of 796 batches: 1.0289219599123576.
[ Tue Jun 21 16:22:14 2022 ] 	Top1: 70.09%
[ Tue Jun 21 16:22:14 2022 ] 	Top5: 92.33%
[ Tue Jun 21 16:22:14 2022 ] Training epoch: 28
[ Tue Jun 21 16:27:00 2022 ] 	Mean training loss: 0.7571.  Mean training acc: 76.98%.
[ Tue Jun 21 16:27:00 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:27:00 2022 ] Eval epoch: 28
[ Tue Jun 21 16:28:21 2022 ] 	Mean test loss of 796 batches: 1.1167662598604533.
[ Tue Jun 21 16:28:21 2022 ] 	Top1: 67.51%
[ Tue Jun 21 16:28:22 2022 ] 	Top5: 91.92%
[ Tue Jun 21 16:28:22 2022 ] Training epoch: 29
[ Tue Jun 21 16:33:08 2022 ] 	Mean training loss: 0.7554.  Mean training acc: 77.35%.
[ Tue Jun 21 16:33:08 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:33:08 2022 ] Eval epoch: 29
[ Tue Jun 21 16:34:29 2022 ] 	Mean test loss of 796 batches: 1.0591463041140805.
[ Tue Jun 21 16:34:29 2022 ] 	Top1: 69.13%
[ Tue Jun 21 16:34:30 2022 ] 	Top5: 92.42%
[ Tue Jun 21 16:34:30 2022 ] Training epoch: 30
[ Tue Jun 21 16:39:15 2022 ] 	Mean training loss: 0.7462.  Mean training acc: 77.42%.
[ Tue Jun 21 16:39:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:39:15 2022 ] Eval epoch: 30
[ Tue Jun 21 16:40:37 2022 ] 	Mean test loss of 796 batches: 1.0931587868262476.
[ Tue Jun 21 16:40:37 2022 ] 	Top1: 67.60%
[ Tue Jun 21 16:40:37 2022 ] 	Top5: 92.59%
[ Tue Jun 21 16:40:38 2022 ] Training epoch: 31
[ Tue Jun 21 16:45:23 2022 ] 	Mean training loss: 0.7510.  Mean training acc: 77.15%.
[ Tue Jun 21 16:45:23 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:45:23 2022 ] Eval epoch: 31
[ Tue Jun 21 16:46:45 2022 ] 	Mean test loss of 796 batches: 1.0358169866566682.
[ Tue Jun 21 16:46:47 2022 ] 	Top1: 69.70%
[ Tue Jun 21 16:46:47 2022 ] 	Top5: 92.35%
[ Tue Jun 21 16:46:47 2022 ] Training epoch: 32
[ Tue Jun 21 16:51:33 2022 ] 	Mean training loss: 0.7422.  Mean training acc: 77.51%.
[ Tue Jun 21 16:51:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:51:33 2022 ] Eval epoch: 32
[ Tue Jun 21 16:52:55 2022 ] 	Mean test loss of 796 batches: 1.1834003762833436.
[ Tue Jun 21 16:52:55 2022 ] 	Top1: 66.01%
[ Tue Jun 21 16:52:55 2022 ] 	Top5: 92.00%
[ Tue Jun 21 16:52:55 2022 ] Training epoch: 33
[ Tue Jun 21 16:57:41 2022 ] 	Mean training loss: 0.7455.  Mean training acc: 77.61%.
[ Tue Jun 21 16:57:55 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 16:57:58 2022 ] Eval epoch: 33
[ Tue Jun 21 16:59:20 2022 ] 	Mean test loss of 796 batches: 1.0521357574654584.
[ Tue Jun 21 16:59:20 2022 ] 	Top1: 68.73%
[ Tue Jun 21 16:59:20 2022 ] 	Top5: 92.04%
[ Tue Jun 21 16:59:21 2022 ] Training epoch: 34
[ Tue Jun 21 17:04:06 2022 ] 	Mean training loss: 0.7321.  Mean training acc: 77.73%.
[ Tue Jun 21 17:04:06 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:04:06 2022 ] Eval epoch: 34
[ Tue Jun 21 17:05:28 2022 ] 	Mean test loss of 796 batches: 0.9652622082275362.
[ Tue Jun 21 17:05:28 2022 ] 	Top1: 71.00%
[ Tue Jun 21 17:05:28 2022 ] 	Top5: 93.20%
[ Tue Jun 21 17:05:28 2022 ] Training epoch: 35
[ Tue Jun 21 17:10:14 2022 ] 	Mean training loss: 0.7380.  Mean training acc: 77.61%.
[ Tue Jun 21 17:10:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:10:14 2022 ] Eval epoch: 35
[ Tue Jun 21 17:11:35 2022 ] 	Mean test loss of 796 batches: 1.1149570748359714.
[ Tue Jun 21 17:11:36 2022 ] 	Top1: 67.65%
[ Tue Jun 21 17:11:36 2022 ] 	Top5: 91.21%
[ Tue Jun 21 17:11:36 2022 ] Training epoch: 36
[ Tue Jun 21 17:16:22 2022 ] 	Mean training loss: 0.4383.  Mean training acc: 86.91%.
[ Tue Jun 21 17:16:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:16:22 2022 ] Eval epoch: 36
[ Tue Jun 21 17:17:44 2022 ] 	Mean test loss of 796 batches: 0.6084712156136731.
[ Tue Jun 21 17:17:44 2022 ] 	Top1: 81.42%
[ Tue Jun 21 17:17:45 2022 ] 	Top5: 96.37%
[ Tue Jun 21 17:17:45 2022 ] Training epoch: 37
[ Tue Jun 21 17:22:31 2022 ] 	Mean training loss: 0.3530.  Mean training acc: 89.35%.
[ Tue Jun 21 17:22:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:22:44 2022 ] Eval epoch: 37
[ Tue Jun 21 17:24:05 2022 ] 	Mean test loss of 796 batches: 0.5793222019439517.
[ Tue Jun 21 17:24:06 2022 ] 	Top1: 82.44%
[ Tue Jun 21 17:24:06 2022 ] 	Top5: 96.55%
[ Tue Jun 21 17:24:06 2022 ] Training epoch: 38
[ Tue Jun 21 17:28:52 2022 ] 	Mean training loss: 0.3190.  Mean training acc: 90.62%.
[ Tue Jun 21 17:28:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:28:52 2022 ] Eval epoch: 38
[ Tue Jun 21 17:30:14 2022 ] 	Mean test loss of 796 batches: 0.5780729582935722.
[ Tue Jun 21 17:30:14 2022 ] 	Top1: 82.54%
[ Tue Jun 21 17:30:14 2022 ] 	Top5: 96.61%
[ Tue Jun 21 17:30:15 2022 ] Training epoch: 39
[ Tue Jun 21 17:35:00 2022 ] 	Mean training loss: 0.2950.  Mean training acc: 91.23%.
[ Tue Jun 21 17:35:00 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:35:00 2022 ] Eval epoch: 39
[ Tue Jun 21 17:36:22 2022 ] 	Mean test loss of 796 batches: 0.5757344779113879.
[ Tue Jun 21 17:36:22 2022 ] 	Top1: 82.67%
[ Tue Jun 21 17:36:23 2022 ] 	Top5: 96.70%
[ Tue Jun 21 17:36:23 2022 ] Training epoch: 40
[ Tue Jun 21 17:41:09 2022 ] 	Mean training loss: 0.2713.  Mean training acc: 91.96%.
[ Tue Jun 21 17:41:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:41:09 2022 ] Eval epoch: 40
[ Tue Jun 21 17:42:30 2022 ] 	Mean test loss of 796 batches: 0.559124671942999.
[ Tue Jun 21 17:42:31 2022 ] 	Top1: 83.16%
[ Tue Jun 21 17:42:31 2022 ] 	Top5: 96.77%
[ Tue Jun 21 17:42:31 2022 ] Training epoch: 41
[ Tue Jun 21 17:47:17 2022 ] 	Mean training loss: 0.2550.  Mean training acc: 92.46%.
[ Tue Jun 21 17:47:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:47:17 2022 ] Eval epoch: 41
[ Tue Jun 21 17:48:38 2022 ] 	Mean test loss of 796 batches: 0.6026339824007234.
[ Tue Jun 21 17:48:39 2022 ] 	Top1: 82.10%
[ Tue Jun 21 17:48:39 2022 ] 	Top5: 96.44%
[ Tue Jun 21 17:48:39 2022 ] Training epoch: 42
[ Tue Jun 21 17:53:25 2022 ] 	Mean training loss: 0.2369.  Mean training acc: 93.12%.
[ Tue Jun 21 17:53:25 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:53:25 2022 ] Eval epoch: 42
[ Tue Jun 21 17:54:46 2022 ] 	Mean test loss of 796 batches: 0.5864908351052796.
[ Tue Jun 21 17:54:46 2022 ] 	Top1: 82.86%
[ Tue Jun 21 17:54:47 2022 ] 	Top5: 96.66%
[ Tue Jun 21 17:54:47 2022 ] Training epoch: 43
[ Tue Jun 21 17:59:33 2022 ] 	Mean training loss: 0.2284.  Mean training acc: 93.46%.
[ Tue Jun 21 17:59:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 17:59:33 2022 ] Eval epoch: 43
[ Tue Jun 21 18:00:54 2022 ] 	Mean test loss of 796 batches: 0.6042965265393407.
[ Tue Jun 21 18:00:54 2022 ] 	Top1: 82.37%
[ Tue Jun 21 18:00:55 2022 ] 	Top5: 96.51%
[ Tue Jun 21 18:00:55 2022 ] Training epoch: 44
[ Tue Jun 21 18:05:41 2022 ] 	Mean training loss: 0.2176.  Mean training acc: 93.88%.
[ Tue Jun 21 18:05:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:05:41 2022 ] Eval epoch: 44
[ Tue Jun 21 18:07:02 2022 ] 	Mean test loss of 796 batches: 0.6064972128513171.
[ Tue Jun 21 18:07:02 2022 ] 	Top1: 82.30%
[ Tue Jun 21 18:07:03 2022 ] 	Top5: 96.45%
[ Tue Jun 21 18:07:03 2022 ] Training epoch: 45
[ Tue Jun 21 18:11:48 2022 ] 	Mean training loss: 0.2068.  Mean training acc: 94.12%.
[ Tue Jun 21 18:11:48 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:11:49 2022 ] Eval epoch: 45
[ Tue Jun 21 18:13:10 2022 ] 	Mean test loss of 796 batches: 0.6726277232469626.
[ Tue Jun 21 18:13:10 2022 ] 	Top1: 80.75%
[ Tue Jun 21 18:13:10 2022 ] 	Top5: 95.85%
[ Tue Jun 21 18:13:10 2022 ] Training epoch: 46
[ Tue Jun 21 18:17:56 2022 ] 	Mean training loss: 0.1990.  Mean training acc: 94.40%.
[ Tue Jun 21 18:17:56 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:17:56 2022 ] Eval epoch: 46
[ Tue Jun 21 18:19:17 2022 ] 	Mean test loss of 796 batches: 0.6396557051295312.
[ Tue Jun 21 18:19:18 2022 ] 	Top1: 81.57%
[ Tue Jun 21 18:19:18 2022 ] 	Top5: 96.27%
[ Tue Jun 21 18:19:18 2022 ] Training epoch: 47
[ Tue Jun 21 18:24:04 2022 ] 	Mean training loss: 0.1961.  Mean training acc: 94.53%.
[ Tue Jun 21 18:24:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:24:04 2022 ] Eval epoch: 47
[ Tue Jun 21 18:25:25 2022 ] 	Mean test loss of 796 batches: 0.6426455410918099.
[ Tue Jun 21 18:25:25 2022 ] 	Top1: 81.72%
[ Tue Jun 21 18:25:26 2022 ] 	Top5: 96.27%
[ Tue Jun 21 18:25:26 2022 ] Training epoch: 48
[ Tue Jun 21 18:30:12 2022 ] 	Mean training loss: 0.1951.  Mean training acc: 94.60%.
[ Tue Jun 21 18:30:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:30:12 2022 ] Eval epoch: 48
[ Tue Jun 21 18:31:33 2022 ] 	Mean test loss of 796 batches: 0.6386042107458241.
[ Tue Jun 21 18:31:34 2022 ] 	Top1: 81.68%
[ Tue Jun 21 18:31:34 2022 ] 	Top5: 96.14%
[ Tue Jun 21 18:31:34 2022 ] Training epoch: 49
[ Tue Jun 21 18:36:20 2022 ] 	Mean training loss: 0.1918.  Mean training acc: 94.65%.
[ Tue Jun 21 18:36:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:36:20 2022 ] Eval epoch: 49
[ Tue Jun 21 18:37:42 2022 ] 	Mean test loss of 796 batches: 0.6534343529679817.
[ Tue Jun 21 18:37:42 2022 ] 	Top1: 81.13%
[ Tue Jun 21 18:37:42 2022 ] 	Top5: 96.30%
[ Tue Jun 21 18:37:42 2022 ] Training epoch: 50
[ Tue Jun 21 18:42:29 2022 ] 	Mean training loss: 0.1859.  Mean training acc: 94.76%.
[ Tue Jun 21 18:42:29 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:42:29 2022 ] Eval epoch: 50
[ Tue Jun 21 18:43:50 2022 ] 	Mean test loss of 796 batches: 0.6694287318249593.
[ Tue Jun 21 18:43:50 2022 ] 	Top1: 81.18%
[ Tue Jun 21 18:43:51 2022 ] 	Top5: 96.09%
[ Tue Jun 21 18:43:51 2022 ] Training epoch: 51
[ Tue Jun 21 18:48:36 2022 ] 	Mean training loss: 0.1849.  Mean training acc: 94.93%.
[ Tue Jun 21 18:48:36 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:48:37 2022 ] Eval epoch: 51
[ Tue Jun 21 18:49:58 2022 ] 	Mean test loss of 796 batches: 0.6730080686378569.
[ Tue Jun 21 18:49:58 2022 ] 	Top1: 80.88%
[ Tue Jun 21 18:49:59 2022 ] 	Top5: 96.10%
[ Tue Jun 21 18:49:59 2022 ] Training epoch: 52
[ Tue Jun 21 18:54:45 2022 ] 	Mean training loss: 0.1866.  Mean training acc: 94.82%.
[ Tue Jun 21 18:54:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 18:54:45 2022 ] Eval epoch: 52
[ Tue Jun 21 18:56:06 2022 ] 	Mean test loss of 796 batches: 0.6695102998359719.
[ Tue Jun 21 18:56:07 2022 ] 	Top1: 81.27%
[ Tue Jun 21 18:56:07 2022 ] 	Top5: 96.07%
[ Tue Jun 21 18:56:07 2022 ] Training epoch: 53
[ Tue Jun 21 19:00:53 2022 ] 	Mean training loss: 0.1775.  Mean training acc: 95.14%.
[ Tue Jun 21 19:00:53 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:00:53 2022 ] Eval epoch: 53
[ Tue Jun 21 19:02:15 2022 ] 	Mean test loss of 796 batches: 0.6977943364886483.
[ Tue Jun 21 19:02:15 2022 ] 	Top1: 80.51%
[ Tue Jun 21 19:02:15 2022 ] 	Top5: 95.72%
[ Tue Jun 21 19:02:15 2022 ] Training epoch: 54
[ Tue Jun 21 19:07:01 2022 ] 	Mean training loss: 0.1796.  Mean training acc: 95.04%.
[ Tue Jun 21 19:07:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:07:01 2022 ] Eval epoch: 54
[ Tue Jun 21 19:08:23 2022 ] 	Mean test loss of 796 batches: 0.695258965743846.
[ Tue Jun 21 19:08:23 2022 ] 	Top1: 80.95%
[ Tue Jun 21 19:08:23 2022 ] 	Top5: 95.91%
[ Tue Jun 21 19:08:23 2022 ] Training epoch: 55
[ Tue Jun 21 19:13:10 2022 ] 	Mean training loss: 0.1821.  Mean training acc: 95.02%.
[ Tue Jun 21 19:13:10 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:13:10 2022 ] Eval epoch: 55
[ Tue Jun 21 19:14:31 2022 ] 	Mean test loss of 796 batches: 0.7477571039867761.
[ Tue Jun 21 19:14:32 2022 ] 	Top1: 80.03%
[ Tue Jun 21 19:14:32 2022 ] 	Top5: 95.34%
[ Tue Jun 21 19:14:32 2022 ] Training epoch: 56
[ Tue Jun 21 19:19:18 2022 ] 	Mean training loss: 0.1020.  Mean training acc: 97.76%.
[ Tue Jun 21 19:19:18 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:19:18 2022 ] Eval epoch: 56
[ Tue Jun 21 19:20:39 2022 ] 	Mean test loss of 796 batches: 0.613289191850915.
[ Tue Jun 21 19:20:40 2022 ] 	Top1: 82.94%
[ Tue Jun 21 19:20:40 2022 ] 	Top5: 96.39%
[ Tue Jun 21 19:20:40 2022 ] Training epoch: 57
[ Tue Jun 21 19:25:26 2022 ] 	Mean training loss: 0.0748.  Mean training acc: 98.60%.
[ Tue Jun 21 19:25:34 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:25:34 2022 ] Eval epoch: 57
[ Tue Jun 21 19:26:56 2022 ] 	Mean test loss of 796 batches: 0.607254218422438.
[ Tue Jun 21 19:26:57 2022 ] 	Top1: 83.31%
[ Tue Jun 21 19:26:57 2022 ] 	Top5: 96.41%
[ Tue Jun 21 19:26:57 2022 ] Training epoch: 58
[ Tue Jun 21 19:31:43 2022 ] 	Mean training loss: 0.0679.  Mean training acc: 98.71%.
[ Tue Jun 21 19:31:43 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:31:43 2022 ] Eval epoch: 58
[ Tue Jun 21 19:33:05 2022 ] 	Mean test loss of 796 batches: 0.6132404969059791.
[ Tue Jun 21 19:33:05 2022 ] 	Top1: 83.09%
[ Tue Jun 21 19:33:06 2022 ] 	Top5: 96.35%
[ Tue Jun 21 19:33:06 2022 ] Training epoch: 59
[ Tue Jun 21 19:37:52 2022 ] 	Mean training loss: 0.0602.  Mean training acc: 98.98%.
[ Tue Jun 21 19:37:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:37:52 2022 ] Eval epoch: 59
[ Tue Jun 21 19:39:13 2022 ] 	Mean test loss of 796 batches: 0.6140246898609789.
[ Tue Jun 21 19:39:14 2022 ] 	Top1: 83.22%
[ Tue Jun 21 19:39:14 2022 ] 	Top5: 96.36%
[ Tue Jun 21 19:39:14 2022 ] Training epoch: 60
[ Tue Jun 21 19:44:01 2022 ] 	Mean training loss: 0.0570.  Mean training acc: 99.12%.
[ Tue Jun 21 19:44:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:44:01 2022 ] Eval epoch: 60
[ Tue Jun 21 19:45:22 2022 ] 	Mean test loss of 796 batches: 0.6150097150879739.
[ Tue Jun 21 19:45:22 2022 ] 	Top1: 83.24%
[ Tue Jun 21 19:45:23 2022 ] 	Top5: 96.48%
[ Tue Jun 21 19:45:23 2022 ] Training epoch: 61
[ Tue Jun 21 19:50:09 2022 ] 	Mean training loss: 0.0536.  Mean training acc: 99.16%.
[ Tue Jun 21 19:50:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:50:09 2022 ] Eval epoch: 61
[ Tue Jun 21 19:51:30 2022 ] 	Mean test loss of 796 batches: 0.6129379022548247.
[ Tue Jun 21 19:51:31 2022 ] 	Top1: 83.30%
[ Tue Jun 21 19:51:31 2022 ] 	Top5: 96.40%
[ Tue Jun 21 19:51:31 2022 ] Training epoch: 62
[ Tue Jun 21 19:56:17 2022 ] 	Mean training loss: 0.0519.  Mean training acc: 99.20%.
[ Tue Jun 21 19:56:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 19:56:17 2022 ] Eval epoch: 62
[ Tue Jun 21 19:57:39 2022 ] 	Mean test loss of 796 batches: 0.6195070655670148.
[ Tue Jun 21 19:57:39 2022 ] 	Top1: 83.19%
[ Tue Jun 21 19:57:40 2022 ] 	Top5: 96.41%
[ Tue Jun 21 19:57:40 2022 ] Training epoch: 63
[ Tue Jun 21 20:02:26 2022 ] 	Mean training loss: 0.0497.  Mean training acc: 99.28%.
[ Tue Jun 21 20:02:26 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 20:02:26 2022 ] Eval epoch: 63
[ Tue Jun 21 20:03:47 2022 ] 	Mean test loss of 796 batches: 0.6131884201836946.
[ Tue Jun 21 20:03:47 2022 ] 	Top1: 83.41%
[ Tue Jun 21 20:03:48 2022 ] 	Top5: 96.47%
[ Tue Jun 21 20:03:48 2022 ] Training epoch: 64
[ Tue Jun 21 20:08:33 2022 ] 	Mean training loss: 0.0485.  Mean training acc: 99.30%.
[ Tue Jun 21 20:08:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 20:08:33 2022 ] Eval epoch: 64
[ Tue Jun 21 20:09:55 2022 ] 	Mean test loss of 796 batches: 0.6281304276880607.
[ Tue Jun 21 20:09:55 2022 ] 	Top1: 83.08%
[ Tue Jun 21 20:09:55 2022 ] 	Top5: 96.36%
[ Tue Jun 21 20:09:55 2022 ] Training epoch: 65
[ Tue Jun 21 20:14:41 2022 ] 	Mean training loss: 0.0456.  Mean training acc: 99.34%.
[ Tue Jun 21 20:14:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 21 20:14:41 2022 ] Eval epoch: 65
[ Tue Jun 21 20:16:33 2022 ] 	Mean test loss of 796 batches: 0.624487615756728.
[ Tue Jun 21 20:16:33 2022 ] 	Top1: 83.10%
[ Tue Jun 21 20:16:33 2022 ] 	Top5: 96.33%
[ Tue Jun 21 20:18:50 2022 ] Best accuracy: 0.8340894361633182
[ Tue Jun 21 20:18:50 2022 ] Epoch number: 63
[ Tue Jun 21 20:18:50 2022 ] Model name: work_dir/ntu120/csub/base_four14b
[ Tue Jun 21 20:18:50 2022 ] Model total number of params: 2112610
[ Tue Jun 21 20:18:50 2022 ] Weight decay: 0.0004
[ Tue Jun 21 20:18:50 2022 ] Base LR: 0.1
[ Tue Jun 21 20:18:50 2022 ] Batch Size: 64
[ Tue Jun 21 20:18:50 2022 ] Test Batch Size: 64
[ Tue Jun 21 20:18:50 2022 ] seed: 1
[ Fri Jun 24 14:30:12 2022 ] using warm up, epoch: 5
[ Fri Jun 24 14:32:12 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four14b', 'model_saved_name': 'work_dir/ntu120/csub/base_four14b/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier14b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Fri Jun 24 14:32:12 2022 ] # Parameters: 2112610
[ Fri Jun 24 14:32:12 2022 ] Training epoch: 1
[ Fri Jun 24 14:37:42 2022 ] using warm up, epoch: 5
[ Fri Jun 24 14:38:07 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four14b', 'model_saved_name': 'work_dir/ntu120/csub/base_four14b/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier14b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Fri Jun 24 14:38:07 2022 ] # Parameters: 2112610
[ Fri Jun 24 14:38:07 2022 ] Training epoch: 1
[ Fri Jun 24 14:42:57 2022 ] 	Mean training loss: 3.0249.  Mean training acc: 24.01%.
[ Fri Jun 24 14:42:57 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 14:42:57 2022 ] Eval epoch: 1
[ Fri Jun 24 14:44:22 2022 ] 	Mean test loss of 796 batches: 2.348577779591383.
[ Fri Jun 24 14:44:22 2022 ] 	Top1: 35.01%
[ Fri Jun 24 14:44:23 2022 ] 	Top5: 69.49%
[ Fri Jun 24 14:44:23 2022 ] Training epoch: 2
[ Fri Jun 24 14:49:13 2022 ] 	Mean training loss: 2.0102.  Mean training acc: 43.53%.
[ Fri Jun 24 14:49:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 14:49:13 2022 ] Eval epoch: 2
[ Fri Jun 24 14:50:38 2022 ] 	Mean test loss of 796 batches: 1.8788922605053264.
[ Fri Jun 24 14:50:38 2022 ] 	Top1: 45.53%
[ Fri Jun 24 14:50:39 2022 ] 	Top5: 79.72%
[ Fri Jun 24 14:50:39 2022 ] Training epoch: 3
[ Fri Jun 24 14:55:28 2022 ] 	Mean training loss: 1.6156.  Mean training acc: 53.25%.
[ Fri Jun 24 14:55:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 14:55:28 2022 ] Eval epoch: 3
[ Fri Jun 24 14:56:52 2022 ] 	Mean test loss of 796 batches: 1.6942190749561368.
[ Fri Jun 24 14:56:53 2022 ] 	Top1: 50.22%
[ Fri Jun 24 14:56:53 2022 ] 	Top5: 83.48%
[ Fri Jun 24 14:56:53 2022 ] Training epoch: 4
[ Fri Jun 24 15:01:43 2022 ] 	Mean training loss: 1.4118.  Mean training acc: 58.56%.
[ Fri Jun 24 15:01:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 15:01:43 2022 ] Eval epoch: 4
[ Fri Jun 24 15:03:09 2022 ] 	Mean test loss of 796 batches: 1.485596072434181.
[ Fri Jun 24 15:03:09 2022 ] 	Top1: 56.88%
[ Fri Jun 24 15:03:10 2022 ] 	Top5: 86.75%
[ Fri Jun 24 15:03:10 2022 ] Training epoch: 5
[ Fri Jun 24 15:08:00 2022 ] 	Mean training loss: 1.2879.  Mean training acc: 62.02%.
[ Fri Jun 24 15:08:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 15:08:00 2022 ] Eval epoch: 5
[ Fri Jun 24 15:09:25 2022 ] 	Mean test loss of 796 batches: 1.5495233138152702.
[ Fri Jun 24 15:09:25 2022 ] 	Top1: 56.75%
[ Fri Jun 24 15:09:26 2022 ] 	Top5: 84.39%
[ Fri Jun 24 15:09:26 2022 ] Training epoch: 6
[ Fri Jun 24 15:14:16 2022 ] 	Mean training loss: 1.1730.  Mean training acc: 65.20%.
[ Fri Jun 24 15:14:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 15:14:16 2022 ] Eval epoch: 6
[ Fri Jun 24 15:15:39 2022 ] 	Mean test loss of 796 batches: 1.5359706218218683.
[ Fri Jun 24 15:15:39 2022 ] 	Top1: 56.50%
[ Fri Jun 24 15:15:39 2022 ] 	Top5: 85.72%
[ Fri Jun 24 15:15:39 2022 ] Training epoch: 7
[ Fri Jun 24 15:20:29 2022 ] 	Mean training loss: 1.0862.  Mean training acc: 67.50%.
[ Fri Jun 24 15:20:29 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 15:20:29 2022 ] Eval epoch: 7
[ Fri Jun 24 15:21:55 2022 ] 	Mean test loss of 796 batches: 1.2550672923949495.
[ Fri Jun 24 15:21:55 2022 ] 	Top1: 62.28%
[ Fri Jun 24 15:21:56 2022 ] 	Top5: 89.90%
[ Fri Jun 24 15:21:56 2022 ] Training epoch: 8
[ Fri Jun 24 15:26:43 2022 ] 	Mean training loss: 1.0314.  Mean training acc: 69.26%.
[ Fri Jun 24 15:26:43 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:26:43 2022 ] Eval epoch: 8
[ Fri Jun 24 15:28:04 2022 ] 	Mean test loss of 796 batches: 1.1944364906854965.
[ Fri Jun 24 15:28:05 2022 ] 	Top1: 64.27%
[ Fri Jun 24 15:28:05 2022 ] 	Top5: 90.70%
[ Fri Jun 24 15:28:05 2022 ] Training epoch: 9
[ Fri Jun 24 15:32:50 2022 ] 	Mean training loss: 0.9906.  Mean training acc: 70.45%.
[ Fri Jun 24 15:32:50 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:32:50 2022 ] Eval epoch: 9
[ Fri Jun 24 15:34:12 2022 ] 	Mean test loss of 796 batches: 1.275168065711781.
[ Fri Jun 24 15:34:12 2022 ] 	Top1: 62.81%
[ Fri Jun 24 15:34:12 2022 ] 	Top5: 89.53%
[ Fri Jun 24 15:34:12 2022 ] Training epoch: 10
[ Fri Jun 24 15:38:57 2022 ] 	Mean training loss: 0.9514.  Mean training acc: 71.30%.
[ Fri Jun 24 15:38:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:38:58 2022 ] Eval epoch: 10
[ Fri Jun 24 15:40:19 2022 ] 	Mean test loss of 796 batches: 1.330436332965616.
[ Fri Jun 24 15:40:19 2022 ] 	Top1: 62.46%
[ Fri Jun 24 15:40:19 2022 ] 	Top5: 89.45%
[ Fri Jun 24 15:40:19 2022 ] Training epoch: 11
[ Fri Jun 24 15:45:05 2022 ] 	Mean training loss: 0.9294.  Mean training acc: 72.09%.
[ Fri Jun 24 15:45:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:45:05 2022 ] Eval epoch: 11
[ Fri Jun 24 15:46:26 2022 ] 	Mean test loss of 796 batches: 1.157257637523826.
[ Fri Jun 24 15:46:27 2022 ] 	Top1: 66.17%
[ Fri Jun 24 15:46:27 2022 ] 	Top5: 90.43%
[ Fri Jun 24 15:46:27 2022 ] Training epoch: 12
[ Fri Jun 24 15:51:12 2022 ] 	Mean training loss: 0.8967.  Mean training acc: 73.02%.
[ Fri Jun 24 15:51:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:51:12 2022 ] Eval epoch: 12
[ Fri Jun 24 15:52:34 2022 ] 	Mean test loss of 796 batches: 1.0456240152818475.
[ Fri Jun 24 15:52:34 2022 ] 	Top1: 68.52%
[ Fri Jun 24 15:52:34 2022 ] 	Top5: 92.46%
[ Fri Jun 24 15:52:34 2022 ] Training epoch: 13
[ Fri Jun 24 15:57:20 2022 ] 	Mean training loss: 0.8825.  Mean training acc: 73.45%.
[ Fri Jun 24 15:57:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 15:57:20 2022 ] Eval epoch: 13
[ Fri Jun 24 15:58:42 2022 ] 	Mean test loss of 796 batches: 1.1538403411606448.
[ Fri Jun 24 15:58:43 2022 ] 	Top1: 66.25%
[ Fri Jun 24 15:58:43 2022 ] 	Top5: 90.90%
[ Fri Jun 24 15:58:44 2022 ] Training epoch: 14
[ Fri Jun 24 16:03:32 2022 ] 	Mean training loss: 0.8615.  Mean training acc: 73.93%.
[ Fri Jun 24 16:03:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:03:32 2022 ] Eval epoch: 14
[ Fri Jun 24 16:04:55 2022 ] 	Mean test loss of 796 batches: 1.0735584014100046.
[ Fri Jun 24 16:04:56 2022 ] 	Top1: 67.98%
[ Fri Jun 24 16:04:56 2022 ] 	Top5: 92.00%
[ Fri Jun 24 16:04:56 2022 ] Training epoch: 15
[ Fri Jun 24 16:09:45 2022 ] 	Mean training loss: 0.8497.  Mean training acc: 74.11%.
[ Fri Jun 24 16:09:45 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:09:45 2022 ] Eval epoch: 15
[ Fri Jun 24 16:11:09 2022 ] 	Mean test loss of 796 batches: 1.0832424581275513.
[ Fri Jun 24 16:11:10 2022 ] 	Top1: 68.36%
[ Fri Jun 24 16:11:10 2022 ] 	Top5: 91.90%
[ Fri Jun 24 16:11:10 2022 ] Training epoch: 16
[ Fri Jun 24 16:15:59 2022 ] 	Mean training loss: 0.8266.  Mean training acc: 74.98%.
[ Fri Jun 24 16:15:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:15:59 2022 ] Eval epoch: 16
[ Fri Jun 24 16:17:23 2022 ] 	Mean test loss of 796 batches: 1.169097815775991.
[ Fri Jun 24 16:17:24 2022 ] 	Top1: 67.15%
[ Fri Jun 24 16:17:24 2022 ] 	Top5: 90.69%
[ Fri Jun 24 16:17:24 2022 ] Training epoch: 17
[ Fri Jun 24 16:22:14 2022 ] 	Mean training loss: 0.8204.  Mean training acc: 75.25%.
[ Fri Jun 24 16:22:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:22:14 2022 ] Eval epoch: 17
[ Fri Jun 24 16:23:38 2022 ] 	Mean test loss of 796 batches: 1.1969654215265757.
[ Fri Jun 24 16:23:38 2022 ] 	Top1: 65.85%
[ Fri Jun 24 16:23:39 2022 ] 	Top5: 89.99%
[ Fri Jun 24 16:23:39 2022 ] Training epoch: 18
[ Fri Jun 24 16:28:28 2022 ] 	Mean training loss: 0.8152.  Mean training acc: 75.24%.
[ Fri Jun 24 16:28:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:28:28 2022 ] Eval epoch: 18
[ Fri Jun 24 16:29:53 2022 ] 	Mean test loss of 796 batches: 1.2415196247885574.
[ Fri Jun 24 16:29:54 2022 ] 	Top1: 64.64%
[ Fri Jun 24 16:29:54 2022 ] 	Top5: 88.76%
[ Fri Jun 24 16:29:54 2022 ] Training epoch: 19
[ Fri Jun 24 16:34:43 2022 ] 	Mean training loss: 0.8062.  Mean training acc: 75.82%.
[ Fri Jun 24 16:34:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:34:43 2022 ] Eval epoch: 19
[ Fri Jun 24 16:36:08 2022 ] 	Mean test loss of 796 batches: 1.0796722345915273.
[ Fri Jun 24 16:36:09 2022 ] 	Top1: 68.46%
[ Fri Jun 24 16:36:09 2022 ] 	Top5: 91.94%
[ Fri Jun 24 16:36:09 2022 ] Training epoch: 20
[ Fri Jun 24 16:40:59 2022 ] 	Mean training loss: 0.8022.  Mean training acc: 75.82%.
[ Fri Jun 24 16:40:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:40:59 2022 ] Eval epoch: 20
[ Fri Jun 24 16:42:23 2022 ] 	Mean test loss of 796 batches: 1.0776880930117028.
[ Fri Jun 24 16:42:24 2022 ] 	Top1: 69.22%
[ Fri Jun 24 16:42:24 2022 ] 	Top5: 91.43%
[ Fri Jun 24 16:42:25 2022 ] Training epoch: 21
[ Fri Jun 24 16:47:15 2022 ] 	Mean training loss: 0.7911.  Mean training acc: 75.98%.
[ Fri Jun 24 16:47:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 16:47:15 2022 ] Eval epoch: 21
[ Fri Jun 24 16:48:39 2022 ] 	Mean test loss of 796 batches: 1.1514369543248684.
[ Fri Jun 24 16:48:39 2022 ] 	Top1: 67.91%
[ Fri Jun 24 16:48:40 2022 ] 	Top5: 91.50%
[ Fri Jun 24 16:48:40 2022 ] Training epoch: 22
[ Fri Jun 24 16:53:30 2022 ] 	Mean training loss: 0.7775.  Mean training acc: 76.61%.
[ Fri Jun 24 16:53:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 16:53:30 2022 ] Eval epoch: 22
[ Fri Jun 24 16:54:55 2022 ] 	Mean test loss of 796 batches: 1.1152606098795657.
[ Fri Jun 24 16:54:55 2022 ] 	Top1: 67.52%
[ Fri Jun 24 16:54:56 2022 ] 	Top5: 91.07%
[ Fri Jun 24 16:54:56 2022 ] Training epoch: 23
[ Fri Jun 24 16:59:46 2022 ] 	Mean training loss: 0.7854.  Mean training acc: 76.08%.
[ Fri Jun 24 16:59:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 16:59:46 2022 ] Eval epoch: 23
[ Fri Jun 24 17:01:11 2022 ] 	Mean test loss of 796 batches: 1.000261488272317.
[ Fri Jun 24 17:01:11 2022 ] 	Top1: 70.29%
[ Fri Jun 24 17:01:12 2022 ] 	Top5: 92.86%
[ Fri Jun 24 17:01:12 2022 ] Training epoch: 24
[ Fri Jun 24 17:06:01 2022 ] 	Mean training loss: 0.7740.  Mean training acc: 76.77%.
[ Fri Jun 24 17:06:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:06:01 2022 ] Eval epoch: 24
[ Fri Jun 24 17:07:24 2022 ] 	Mean test loss of 796 batches: 1.0423715978336694.
[ Fri Jun 24 17:07:25 2022 ] 	Top1: 69.52%
[ Fri Jun 24 17:07:25 2022 ] 	Top5: 91.74%
[ Fri Jun 24 17:07:25 2022 ] Training epoch: 25
[ Fri Jun 24 17:12:16 2022 ] 	Mean training loss: 0.7698.  Mean training acc: 76.63%.
[ Fri Jun 24 17:12:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 17:12:16 2022 ] Eval epoch: 25
[ Fri Jun 24 17:13:40 2022 ] 	Mean test loss of 796 batches: 1.1659728288650513.
[ Fri Jun 24 17:13:41 2022 ] 	Top1: 66.50%
[ Fri Jun 24 17:13:41 2022 ] 	Top5: 90.30%
[ Fri Jun 24 17:13:41 2022 ] Training epoch: 26
[ Fri Jun 24 17:18:31 2022 ] 	Mean training loss: 0.7632.  Mean training acc: 76.92%.
[ Fri Jun 24 17:18:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:18:31 2022 ] Eval epoch: 26
[ Fri Jun 24 17:19:54 2022 ] 	Mean test loss of 796 batches: 1.0400372203720274.
[ Fri Jun 24 17:19:55 2022 ] 	Top1: 69.79%
[ Fri Jun 24 17:19:55 2022 ] 	Top5: 92.45%
[ Fri Jun 24 17:19:55 2022 ] Training epoch: 27
[ Fri Jun 24 17:24:45 2022 ] 	Mean training loss: 0.7544.  Mean training acc: 77.17%.
[ Fri Jun 24 17:24:45 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:24:45 2022 ] Eval epoch: 27
[ Fri Jun 24 17:26:11 2022 ] 	Mean test loss of 796 batches: 1.0289219599123576.
[ Fri Jun 24 17:26:11 2022 ] 	Top1: 70.09%
[ Fri Jun 24 17:26:12 2022 ] 	Top5: 92.33%
[ Fri Jun 24 17:26:12 2022 ] Training epoch: 28
[ Fri Jun 24 17:31:02 2022 ] 	Mean training loss: 0.7571.  Mean training acc: 76.98%.
[ Fri Jun 24 17:31:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 17:31:02 2022 ] Eval epoch: 28
[ Fri Jun 24 17:32:27 2022 ] 	Mean test loss of 796 batches: 1.1167662598604533.
[ Fri Jun 24 17:32:27 2022 ] 	Top1: 67.51%
[ Fri Jun 24 17:32:28 2022 ] 	Top5: 91.92%
[ Fri Jun 24 17:32:28 2022 ] Training epoch: 29
[ Fri Jun 24 17:37:17 2022 ] 	Mean training loss: 0.7554.  Mean training acc: 77.35%.
[ Fri Jun 24 17:37:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:37:17 2022 ] Eval epoch: 29
[ Fri Jun 24 17:38:42 2022 ] 	Mean test loss of 796 batches: 1.0591463041140805.
[ Fri Jun 24 17:38:42 2022 ] 	Top1: 69.13%
[ Fri Jun 24 17:38:43 2022 ] 	Top5: 92.42%
[ Fri Jun 24 17:38:43 2022 ] Training epoch: 30
[ Fri Jun 24 17:43:33 2022 ] 	Mean training loss: 0.7462.  Mean training acc: 77.42%.
[ Fri Jun 24 17:43:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:43:33 2022 ] Eval epoch: 30
[ Fri Jun 24 17:44:56 2022 ] 	Mean test loss of 796 batches: 1.0931587868262476.
[ Fri Jun 24 17:44:57 2022 ] 	Top1: 67.60%
[ Fri Jun 24 17:44:57 2022 ] 	Top5: 92.59%
[ Fri Jun 24 17:44:57 2022 ] Training epoch: 31
[ Fri Jun 24 17:49:47 2022 ] 	Mean training loss: 0.7510.  Mean training acc: 77.15%.
[ Fri Jun 24 17:49:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 17:49:48 2022 ] Eval epoch: 31
[ Fri Jun 24 17:51:12 2022 ] 	Mean test loss of 796 batches: 1.0358169866566682.
[ Fri Jun 24 17:51:13 2022 ] 	Top1: 69.70%
[ Fri Jun 24 17:51:13 2022 ] 	Top5: 92.35%
[ Fri Jun 24 17:51:13 2022 ] Training epoch: 32
[ Fri Jun 24 17:56:02 2022 ] 	Mean training loss: 0.7422.  Mean training acc: 77.51%.
[ Fri Jun 24 17:56:02 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 17:56:02 2022 ] Eval epoch: 32
[ Fri Jun 24 17:57:26 2022 ] 	Mean test loss of 796 batches: 1.1834003762833436.
[ Fri Jun 24 17:57:26 2022 ] 	Top1: 66.01%
[ Fri Jun 24 17:57:27 2022 ] 	Top5: 92.00%
[ Fri Jun 24 17:57:27 2022 ] Training epoch: 33
[ Fri Jun 24 18:02:16 2022 ] 	Mean training loss: 0.7455.  Mean training acc: 77.61%.
[ Fri Jun 24 18:02:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:02:16 2022 ] Eval epoch: 33
[ Fri Jun 24 18:03:40 2022 ] 	Mean test loss of 796 batches: 1.0521357574654584.
[ Fri Jun 24 18:03:40 2022 ] 	Top1: 68.73%
[ Fri Jun 24 18:03:41 2022 ] 	Top5: 92.04%
[ Fri Jun 24 18:03:41 2022 ] Training epoch: 34
[ Fri Jun 24 18:08:31 2022 ] 	Mean training loss: 0.7321.  Mean training acc: 77.73%.
[ Fri Jun 24 18:08:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:08:31 2022 ] Eval epoch: 34
[ Fri Jun 24 18:09:55 2022 ] 	Mean test loss of 796 batches: 0.9652622082275362.
[ Fri Jun 24 18:09:56 2022 ] 	Top1: 71.00%
[ Fri Jun 24 18:09:56 2022 ] 	Top5: 93.20%
[ Fri Jun 24 18:09:56 2022 ] Training epoch: 35
[ Fri Jun 24 18:14:47 2022 ] 	Mean training loss: 0.7380.  Mean training acc: 77.61%.
[ Fri Jun 24 18:14:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 18:14:47 2022 ] Eval epoch: 35
[ Fri Jun 24 18:16:12 2022 ] 	Mean test loss of 796 batches: 1.1149570748359714.
[ Fri Jun 24 18:16:13 2022 ] 	Top1: 67.65%
[ Fri Jun 24 18:16:13 2022 ] 	Top5: 91.21%
[ Fri Jun 24 18:16:14 2022 ] Training epoch: 36
[ Fri Jun 24 18:21:04 2022 ] 	Mean training loss: 0.4383.  Mean training acc: 86.91%.
[ Fri Jun 24 18:21:04 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 18:21:04 2022 ] Eval epoch: 36
[ Fri Jun 24 18:22:28 2022 ] 	Mean test loss of 796 batches: 0.6084712156136731.
[ Fri Jun 24 18:22:29 2022 ] 	Top1: 81.42%
[ Fri Jun 24 18:22:29 2022 ] 	Top5: 96.37%
[ Fri Jun 24 18:22:29 2022 ] Training epoch: 37
[ Fri Jun 24 18:27:19 2022 ] 	Mean training loss: 0.3530.  Mean training acc: 89.35%.
[ Fri Jun 24 18:27:19 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:27:19 2022 ] Eval epoch: 37
[ Fri Jun 24 18:28:44 2022 ] 	Mean test loss of 796 batches: 0.5793222019439517.
[ Fri Jun 24 18:28:44 2022 ] 	Top1: 82.44%
[ Fri Jun 24 18:28:45 2022 ] 	Top5: 96.55%
[ Fri Jun 24 18:28:45 2022 ] Training epoch: 38
[ Fri Jun 24 18:33:34 2022 ] 	Mean training loss: 0.3190.  Mean training acc: 90.62%.
[ Fri Jun 24 18:33:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:33:34 2022 ] Eval epoch: 38
[ Fri Jun 24 18:34:59 2022 ] 	Mean test loss of 796 batches: 0.5780729582935722.
[ Fri Jun 24 18:34:59 2022 ] 	Top1: 82.54%
[ Fri Jun 24 18:35:00 2022 ] 	Top5: 96.61%
[ Fri Jun 24 18:35:00 2022 ] Training epoch: 39
[ Fri Jun 24 18:39:50 2022 ] 	Mean training loss: 0.2950.  Mean training acc: 91.23%.
[ Fri Jun 24 18:39:50 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:39:50 2022 ] Eval epoch: 39
[ Fri Jun 24 18:41:16 2022 ] 	Mean test loss of 796 batches: 0.5757344779113879.
[ Fri Jun 24 18:41:16 2022 ] 	Top1: 82.67%
[ Fri Jun 24 18:41:16 2022 ] 	Top5: 96.70%
[ Fri Jun 24 18:41:16 2022 ] Training epoch: 40
[ Fri Jun 24 18:46:06 2022 ] 	Mean training loss: 0.2713.  Mean training acc: 91.96%.
[ Fri Jun 24 18:46:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:46:06 2022 ] Eval epoch: 40
[ Fri Jun 24 18:47:30 2022 ] 	Mean test loss of 796 batches: 0.559124671942999.
[ Fri Jun 24 18:47:30 2022 ] 	Top1: 83.16%
[ Fri Jun 24 18:47:31 2022 ] 	Top5: 96.77%
[ Fri Jun 24 18:47:31 2022 ] Training epoch: 41
[ Fri Jun 24 18:52:21 2022 ] 	Mean training loss: 0.2550.  Mean training acc: 92.46%.
[ Fri Jun 24 18:52:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:52:21 2022 ] Eval epoch: 41
[ Fri Jun 24 18:53:46 2022 ] 	Mean test loss of 796 batches: 0.6026339824007234.
[ Fri Jun 24 18:53:46 2022 ] 	Top1: 82.10%
[ Fri Jun 24 18:53:47 2022 ] 	Top5: 96.44%
[ Fri Jun 24 18:53:47 2022 ] Training epoch: 42
[ Fri Jun 24 18:58:37 2022 ] 	Mean training loss: 0.2369.  Mean training acc: 93.12%.
[ Fri Jun 24 18:58:37 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 18:58:37 2022 ] Eval epoch: 42
[ Fri Jun 24 19:00:01 2022 ] 	Mean test loss of 796 batches: 0.5864908351052796.
[ Fri Jun 24 19:00:02 2022 ] 	Top1: 82.86%
[ Fri Jun 24 19:00:02 2022 ] 	Top5: 96.66%
[ Fri Jun 24 19:00:02 2022 ] Training epoch: 43
[ Fri Jun 24 19:04:51 2022 ] 	Mean training loss: 0.2284.  Mean training acc: 93.46%.
[ Fri Jun 24 19:04:51 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 19:04:51 2022 ] Eval epoch: 43
[ Fri Jun 24 19:06:12 2022 ] 	Mean test loss of 796 batches: 0.6042965265393407.
[ Fri Jun 24 19:06:12 2022 ] 	Top1: 82.37%
[ Fri Jun 24 19:06:13 2022 ] 	Top5: 96.51%
[ Fri Jun 24 19:06:13 2022 ] Training epoch: 44
[ Fri Jun 24 19:10:58 2022 ] 	Mean training loss: 0.2176.  Mean training acc: 93.88%.
[ Fri Jun 24 19:10:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:10:58 2022 ] Eval epoch: 44
[ Fri Jun 24 19:12:19 2022 ] 	Mean test loss of 796 batches: 0.6064972128513171.
[ Fri Jun 24 19:12:19 2022 ] 	Top1: 82.30%
[ Fri Jun 24 19:12:20 2022 ] 	Top5: 96.45%
[ Fri Jun 24 19:12:20 2022 ] Training epoch: 45
[ Fri Jun 24 19:17:05 2022 ] 	Mean training loss: 0.2068.  Mean training acc: 94.12%.
[ Fri Jun 24 19:17:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:17:05 2022 ] Eval epoch: 45
[ Fri Jun 24 19:18:27 2022 ] 	Mean test loss of 796 batches: 0.6726277232469626.
[ Fri Jun 24 19:18:27 2022 ] 	Top1: 80.75%
[ Fri Jun 24 19:18:27 2022 ] 	Top5: 95.85%
[ Fri Jun 24 19:18:27 2022 ] Training epoch: 46
[ Fri Jun 24 19:23:13 2022 ] 	Mean training loss: 0.1990.  Mean training acc: 94.40%.
[ Fri Jun 24 19:23:13 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:23:13 2022 ] Eval epoch: 46
[ Fri Jun 24 19:24:34 2022 ] 	Mean test loss of 796 batches: 0.6396557051295312.
[ Fri Jun 24 19:24:35 2022 ] 	Top1: 81.57%
[ Fri Jun 24 19:24:35 2022 ] 	Top5: 96.27%
[ Fri Jun 24 19:24:35 2022 ] Training epoch: 47
[ Fri Jun 24 19:29:20 2022 ] 	Mean training loss: 0.1961.  Mean training acc: 94.53%.
[ Fri Jun 24 19:29:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:29:20 2022 ] Eval epoch: 47
[ Fri Jun 24 19:30:41 2022 ] 	Mean test loss of 796 batches: 0.6426455410918099.
[ Fri Jun 24 19:30:42 2022 ] 	Top1: 81.72%
[ Fri Jun 24 19:30:42 2022 ] 	Top5: 96.27%
[ Fri Jun 24 19:30:42 2022 ] Training epoch: 48
[ Fri Jun 24 19:35:28 2022 ] 	Mean training loss: 0.1951.  Mean training acc: 94.60%.
[ Fri Jun 24 19:35:28 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:35:28 2022 ] Eval epoch: 48
[ Fri Jun 24 19:36:50 2022 ] 	Mean test loss of 796 batches: 0.6386042107458241.
[ Fri Jun 24 19:36:51 2022 ] 	Top1: 81.68%
[ Fri Jun 24 19:36:51 2022 ] 	Top5: 96.14%
[ Fri Jun 24 19:36:51 2022 ] Training epoch: 49
[ Fri Jun 24 19:41:40 2022 ] 	Mean training loss: 0.1918.  Mean training acc: 94.65%.
[ Fri Jun 24 19:41:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 19:41:40 2022 ] Eval epoch: 49
[ Fri Jun 24 19:43:01 2022 ] 	Mean test loss of 796 batches: 0.6534343529679817.
[ Fri Jun 24 19:43:02 2022 ] 	Top1: 81.13%
[ Fri Jun 24 19:43:02 2022 ] 	Top5: 96.30%
[ Fri Jun 24 19:43:02 2022 ] Training epoch: 50
[ Fri Jun 24 19:47:49 2022 ] 	Mean training loss: 0.1859.  Mean training acc: 94.76%.
[ Fri Jun 24 19:47:49 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jun 24 19:47:49 2022 ] Eval epoch: 50
[ Fri Jun 24 19:49:13 2022 ] 	Mean test loss of 796 batches: 0.6694287318249593.
[ Fri Jun 24 19:49:14 2022 ] 	Top1: 81.18%
[ Fri Jun 24 19:49:14 2022 ] 	Top5: 96.09%
[ Fri Jun 24 19:49:14 2022 ] Training epoch: 51
[ Fri Jun 24 19:54:03 2022 ] 	Mean training loss: 0.1849.  Mean training acc: 94.93%.
[ Fri Jun 24 19:54:03 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 19:54:03 2022 ] Eval epoch: 51
[ Fri Jun 24 19:55:26 2022 ] 	Mean test loss of 796 batches: 0.6730080686378569.
[ Fri Jun 24 19:55:27 2022 ] 	Top1: 80.88%
[ Fri Jun 24 19:55:27 2022 ] 	Top5: 96.10%
[ Fri Jun 24 19:55:27 2022 ] Training epoch: 52
[ Fri Jun 24 20:00:16 2022 ] 	Mean training loss: 0.1866.  Mean training acc: 94.82%.
[ Fri Jun 24 20:00:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:00:16 2022 ] Eval epoch: 52
[ Fri Jun 24 20:01:40 2022 ] 	Mean test loss of 796 batches: 0.6695102998359719.
[ Fri Jun 24 20:01:40 2022 ] 	Top1: 81.27%
[ Fri Jun 24 20:01:41 2022 ] 	Top5: 96.07%
[ Fri Jun 24 20:01:41 2022 ] Training epoch: 53
[ Fri Jun 24 20:06:31 2022 ] 	Mean training loss: 0.1775.  Mean training acc: 95.14%.
[ Fri Jun 24 20:06:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:06:31 2022 ] Eval epoch: 53
[ Fri Jun 24 20:07:55 2022 ] 	Mean test loss of 796 batches: 0.6977943364886483.
[ Fri Jun 24 20:07:55 2022 ] 	Top1: 80.51%
[ Fri Jun 24 20:07:56 2022 ] 	Top5: 95.72%
[ Fri Jun 24 20:07:56 2022 ] Training epoch: 54
[ Fri Jun 24 20:12:44 2022 ] 	Mean training loss: 0.1796.  Mean training acc: 95.04%.
[ Fri Jun 24 20:12:44 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:12:45 2022 ] Eval epoch: 54
[ Fri Jun 24 20:14:08 2022 ] 	Mean test loss of 796 batches: 0.695258965743846.
[ Fri Jun 24 20:14:09 2022 ] 	Top1: 80.95%
[ Fri Jun 24 20:14:09 2022 ] 	Top5: 95.91%
[ Fri Jun 24 20:14:09 2022 ] Training epoch: 55
[ Fri Jun 24 20:18:59 2022 ] 	Mean training loss: 0.1821.  Mean training acc: 95.02%.
[ Fri Jun 24 20:18:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:18:59 2022 ] Eval epoch: 55
[ Fri Jun 24 20:20:22 2022 ] 	Mean test loss of 796 batches: 0.7477571039867761.
[ Fri Jun 24 20:20:23 2022 ] 	Top1: 80.03%
[ Fri Jun 24 20:20:23 2022 ] 	Top5: 95.34%
[ Fri Jun 24 20:20:23 2022 ] Training epoch: 56
[ Fri Jun 24 20:25:13 2022 ] 	Mean training loss: 0.1020.  Mean training acc: 97.76%.
[ Fri Jun 24 20:25:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:25:13 2022 ] Eval epoch: 56
[ Fri Jun 24 20:26:38 2022 ] 	Mean test loss of 796 batches: 0.613289191850915.
[ Fri Jun 24 20:26:38 2022 ] 	Top1: 82.94%
[ Fri Jun 24 20:26:39 2022 ] 	Top5: 96.39%
[ Fri Jun 24 20:26:39 2022 ] Training epoch: 57
[ Fri Jun 24 20:31:28 2022 ] 	Mean training loss: 0.0748.  Mean training acc: 98.60%.
[ Fri Jun 24 20:31:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:31:29 2022 ] Eval epoch: 57
[ Fri Jun 24 20:32:52 2022 ] 	Mean test loss of 796 batches: 0.607254218422438.
[ Fri Jun 24 20:32:53 2022 ] 	Top1: 83.31%
[ Fri Jun 24 20:32:53 2022 ] 	Top5: 96.41%
[ Fri Jun 24 20:32:53 2022 ] Training epoch: 58
[ Fri Jun 24 20:37:43 2022 ] 	Mean training loss: 0.0679.  Mean training acc: 98.71%.
[ Fri Jun 24 20:37:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:37:43 2022 ] Eval epoch: 58
[ Fri Jun 24 20:39:09 2022 ] 	Mean test loss of 796 batches: 0.6132404969059791.
[ Fri Jun 24 20:39:09 2022 ] 	Top1: 83.09%
[ Fri Jun 24 20:39:10 2022 ] 	Top5: 96.35%
[ Fri Jun 24 20:39:10 2022 ] Training epoch: 59
[ Fri Jun 24 20:44:00 2022 ] 	Mean training loss: 0.0602.  Mean training acc: 98.98%.
[ Fri Jun 24 20:44:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 20:44:00 2022 ] Eval epoch: 59
[ Fri Jun 24 20:45:24 2022 ] 	Mean test loss of 796 batches: 0.6140246898609789.
[ Fri Jun 24 20:45:24 2022 ] 	Top1: 83.22%
[ Fri Jun 24 20:45:24 2022 ] 	Top5: 96.36%
[ Fri Jun 24 20:45:24 2022 ] Training epoch: 60
[ Fri Jun 24 20:50:13 2022 ] 	Mean training loss: 0.0570.  Mean training acc: 99.12%.
[ Fri Jun 24 20:50:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:50:13 2022 ] Eval epoch: 60
[ Fri Jun 24 20:51:38 2022 ] 	Mean test loss of 796 batches: 0.6150097150879739.
[ Fri Jun 24 20:51:38 2022 ] 	Top1: 83.24%
[ Fri Jun 24 20:51:38 2022 ] 	Top5: 96.48%
[ Fri Jun 24 20:51:38 2022 ] Training epoch: 61
[ Fri Jun 24 20:56:27 2022 ] 	Mean training loss: 0.0536.  Mean training acc: 99.16%.
[ Fri Jun 24 20:56:27 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 20:56:27 2022 ] Eval epoch: 61
[ Fri Jun 24 20:57:51 2022 ] 	Mean test loss of 796 batches: 0.6129379022548247.
[ Fri Jun 24 20:57:52 2022 ] 	Top1: 83.30%
[ Fri Jun 24 20:57:52 2022 ] 	Top5: 96.40%
[ Fri Jun 24 20:57:52 2022 ] Training epoch: 62
[ Fri Jun 24 21:02:42 2022 ] 	Mean training loss: 0.0519.  Mean training acc: 99.20%.
[ Fri Jun 24 21:02:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 21:02:42 2022 ] Eval epoch: 62
[ Fri Jun 24 21:04:07 2022 ] 	Mean test loss of 796 batches: 0.6195070655670148.
[ Fri Jun 24 21:04:07 2022 ] 	Top1: 83.19%
[ Fri Jun 24 21:04:08 2022 ] 	Top5: 96.41%
[ Fri Jun 24 21:04:08 2022 ] Training epoch: 63
[ Fri Jun 24 21:08:58 2022 ] 	Mean training loss: 0.0497.  Mean training acc: 99.28%.
[ Fri Jun 24 21:08:58 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Fri Jun 24 21:08:58 2022 ] Eval epoch: 63
[ Fri Jun 24 21:10:23 2022 ] 	Mean test loss of 796 batches: 0.6131884201836946.
[ Fri Jun 24 21:10:24 2022 ] 	Top1: 83.41%
[ Fri Jun 24 21:10:24 2022 ] 	Top5: 96.47%
[ Fri Jun 24 21:10:24 2022 ] Training epoch: 64
[ Fri Jun 24 21:15:14 2022 ] 	Mean training loss: 0.0485.  Mean training acc: 99.30%.
[ Fri Jun 24 21:15:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 21:15:14 2022 ] Eval epoch: 64
[ Fri Jun 24 21:16:38 2022 ] 	Mean test loss of 796 batches: 0.6281304276880607.
[ Fri Jun 24 21:16:38 2022 ] 	Top1: 83.08%
[ Fri Jun 24 21:16:38 2022 ] 	Top5: 96.36%
[ Fri Jun 24 21:16:38 2022 ] Training epoch: 65
[ Fri Jun 24 21:21:26 2022 ] 	Mean training loss: 0.0456.  Mean training acc: 99.34%.
[ Fri Jun 24 21:21:26 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jun 24 21:21:26 2022 ] Eval epoch: 65
[ Fri Jun 24 21:22:48 2022 ] 	Mean test loss of 796 batches: 0.624487615756728.
[ Fri Jun 24 21:22:49 2022 ] 	Top1: 83.10%
[ Fri Jun 24 21:22:49 2022 ] 	Top5: 96.33%
[ Fri Jun 24 21:24:14 2022 ] Best accuracy: 0.8340894361633182
[ Fri Jun 24 21:24:14 2022 ] Epoch number: 63
[ Fri Jun 24 21:24:14 2022 ] Model name: work_dir/ntu120/csub/base_four14b
[ Fri Jun 24 21:24:14 2022 ] Model total number of params: 2112610
[ Fri Jun 24 21:24:14 2022 ] Weight decay: 0.0004
[ Fri Jun 24 21:24:14 2022 ] Base LR: 0.1
[ Fri Jun 24 21:24:14 2022 ] Batch Size: 64
[ Fri Jun 24 21:24:14 2022 ] Test Batch Size: 64
[ Fri Jun 24 21:24:14 2022 ] seed: 1
