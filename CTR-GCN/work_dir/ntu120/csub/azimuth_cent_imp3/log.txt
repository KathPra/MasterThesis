[ Wed Sep 28 12:19:54 2022 ] using warm up, epoch: 5
[ Wed Sep 28 12:20:12 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/azimuth_cent_imp3', 'model_saved_name': 'work_dir/ntu120/csub/azimuth_cent_imp3/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.azimuth_BN_G1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Sep 28 12:20:12 2022 ] # Parameters: 2107810
[ Wed Sep 28 12:20:12 2022 ] Training epoch: 1
[ Wed Sep 28 12:20:35 2022 ] using warm up, epoch: 5
[ Wed Sep 28 12:20:51 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/azimuth_cent_imp3', 'model_saved_name': 'work_dir/ntu120/csub/azimuth_cent_imp3/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.azimuth_BN_G1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Sep 28 12:20:51 2022 ] # Parameters: 2107660
[ Wed Sep 28 12:20:51 2022 ] Training epoch: 1
[ Wed Sep 28 12:25:20 2022 ] 	Mean training loss: 3.0049.  Mean training acc: 24.71%.
[ Wed Sep 28 12:25:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:25:20 2022 ] Eval epoch: 1
[ Wed Sep 28 12:26:04 2022 ] 	Mean test loss of 796 batches: 3.4493856582809332.
[ Wed Sep 28 12:26:05 2022 ] 	Top1: 19.22%
[ Wed Sep 28 12:26:05 2022 ] 	Top5: 46.98%
[ Wed Sep 28 12:26:05 2022 ] Training epoch: 2
[ Wed Sep 28 12:29:29 2022 ] 	Mean training loss: 2.0190.  Mean training acc: 43.82%.
[ Wed Sep 28 12:29:29 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:29:29 2022 ] Eval epoch: 2
[ Wed Sep 28 12:30:41 2022 ] 	Mean test loss of 796 batches: 2.086095249533054.
[ Wed Sep 28 12:30:42 2022 ] 	Top1: 40.62%
[ Wed Sep 28 12:30:42 2022 ] 	Top5: 76.25%
[ Wed Sep 28 12:30:42 2022 ] Training epoch: 3
[ Wed Sep 28 12:35:32 2022 ] 	Mean training loss: 1.6838.  Mean training acc: 51.69%.
[ Wed Sep 28 12:35:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:35:32 2022 ] Eval epoch: 3
[ Wed Sep 28 12:36:17 2022 ] 	Mean test loss of 796 batches: 3.288674356799629.
[ Wed Sep 28 12:36:17 2022 ] 	Top1: 30.75%
[ Wed Sep 28 12:36:18 2022 ] 	Top5: 58.60%
[ Wed Sep 28 12:36:18 2022 ] Training epoch: 4
[ Wed Sep 28 12:40:30 2022 ] 	Mean training loss: 1.5348.  Mean training acc: 55.76%.
[ Wed Sep 28 12:40:30 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:40:30 2022 ] Eval epoch: 4
[ Wed Sep 28 12:41:38 2022 ] 	Mean test loss of 796 batches: 2.5770465318282048.
[ Wed Sep 28 12:41:39 2022 ] 	Top1: 37.73%
[ Wed Sep 28 12:41:39 2022 ] 	Top5: 72.39%
[ Wed Sep 28 12:41:39 2022 ] Training epoch: 5
[ Wed Sep 28 12:45:55 2022 ] 	Mean training loss: 1.3973.  Mean training acc: 58.89%.
[ Wed Sep 28 12:45:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:45:55 2022 ] Eval epoch: 5
[ Wed Sep 28 12:46:40 2022 ] 	Mean test loss of 796 batches: 1.5238192235704642.
[ Wed Sep 28 12:46:40 2022 ] 	Top1: 55.60%
[ Wed Sep 28 12:46:40 2022 ] 	Top5: 85.37%
[ Wed Sep 28 12:46:40 2022 ] Training epoch: 6
[ Wed Sep 28 12:50:21 2022 ] 	Mean training loss: 1.2536.  Mean training acc: 62.94%.
[ Wed Sep 28 12:50:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:50:21 2022 ] Eval epoch: 6
[ Wed Sep 28 12:51:33 2022 ] 	Mean test loss of 796 batches: 1.344800998068335.
[ Wed Sep 28 12:51:34 2022 ] 	Top1: 59.26%
[ Wed Sep 28 12:51:34 2022 ] 	Top5: 89.02%
[ Wed Sep 28 12:51:34 2022 ] Training epoch: 7
[ Wed Sep 28 12:55:58 2022 ] 	Mean training loss: 1.1560.  Mean training acc: 65.61%.
[ Wed Sep 28 12:55:58 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 12:55:58 2022 ] Eval epoch: 7
[ Wed Sep 28 12:56:43 2022 ] 	Mean test loss of 796 batches: 1.435376404068578.
[ Wed Sep 28 12:56:43 2022 ] 	Top1: 58.85%
[ Wed Sep 28 12:56:44 2022 ] 	Top5: 88.72%
[ Wed Sep 28 12:56:44 2022 ] Training epoch: 8
[ Wed Sep 28 13:01:29 2022 ] 	Mean training loss: 1.0978.  Mean training acc: 67.46%.
[ Wed Sep 28 13:01:29 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:01:29 2022 ] Eval epoch: 8
[ Wed Sep 28 13:02:42 2022 ] 	Mean test loss of 796 batches: 1.4753783320512004.
[ Wed Sep 28 13:02:43 2022 ] 	Top1: 58.20%
[ Wed Sep 28 13:02:43 2022 ] 	Top5: 86.52%
[ Wed Sep 28 13:02:43 2022 ] Training epoch: 9
[ Wed Sep 28 13:06:15 2022 ] 	Mean training loss: 1.0431.  Mean training acc: 68.87%.
[ Wed Sep 28 13:06:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:06:15 2022 ] Eval epoch: 9
[ Wed Sep 28 13:06:59 2022 ] 	Mean test loss of 796 batches: 1.23364235745303.
[ Wed Sep 28 13:06:59 2022 ] 	Top1: 63.71%
[ Wed Sep 28 13:06:59 2022 ] 	Top5: 90.23%
[ Wed Sep 28 13:06:59 2022 ] Training epoch: 10
[ Wed Sep 28 13:09:56 2022 ] 	Mean training loss: 1.0049.  Mean training acc: 69.89%.
[ Wed Sep 28 13:09:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:09:56 2022 ] Eval epoch: 10
[ Wed Sep 28 13:10:57 2022 ] 	Mean test loss of 796 batches: 1.2582951839545264.
[ Wed Sep 28 13:10:57 2022 ] 	Top1: 64.19%
[ Wed Sep 28 13:10:57 2022 ] 	Top5: 88.81%
[ Wed Sep 28 13:10:57 2022 ] Training epoch: 11
[ Wed Sep 28 13:15:10 2022 ] 	Mean training loss: 0.9705.  Mean training acc: 70.86%.
[ Wed Sep 28 13:15:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:15:10 2022 ] Eval epoch: 11
[ Wed Sep 28 13:16:12 2022 ] 	Mean test loss of 796 batches: 1.4723258255115106.
[ Wed Sep 28 13:16:13 2022 ] 	Top1: 58.86%
[ Wed Sep 28 13:16:13 2022 ] 	Top5: 86.27%
[ Wed Sep 28 13:16:13 2022 ] Training epoch: 12
[ Wed Sep 28 13:20:06 2022 ] 	Mean training loss: 0.9452.  Mean training acc: 71.72%.
[ Wed Sep 28 13:20:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:20:06 2022 ] Eval epoch: 12
[ Wed Sep 28 13:20:50 2022 ] 	Mean test loss of 796 batches: 1.376957206757524.
[ Wed Sep 28 13:20:50 2022 ] 	Top1: 62.29%
[ Wed Sep 28 13:20:51 2022 ] 	Top5: 86.71%
[ Wed Sep 28 13:20:51 2022 ] Training epoch: 13
[ Wed Sep 28 13:23:47 2022 ] 	Mean training loss: 0.9265.  Mean training acc: 72.24%.
[ Wed Sep 28 13:23:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:23:47 2022 ] Eval epoch: 13
[ Wed Sep 28 13:24:31 2022 ] 	Mean test loss of 796 batches: 1.87148111863951.
[ Wed Sep 28 13:24:31 2022 ] 	Top1: 50.29%
[ Wed Sep 28 13:24:32 2022 ] 	Top5: 80.36%
[ Wed Sep 28 13:24:32 2022 ] Training epoch: 14
[ Wed Sep 28 13:27:28 2022 ] 	Mean training loss: 0.9102.  Mean training acc: 72.67%.
[ Wed Sep 28 13:27:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:27:28 2022 ] Eval epoch: 14
[ Wed Sep 28 13:28:12 2022 ] 	Mean test loss of 796 batches: 1.181189884754581.
[ Wed Sep 28 13:28:13 2022 ] 	Top1: 64.14%
[ Wed Sep 28 13:28:13 2022 ] 	Top5: 90.74%
[ Wed Sep 28 13:28:13 2022 ] Training epoch: 15
[ Wed Sep 28 13:31:10 2022 ] 	Mean training loss: 0.8967.  Mean training acc: 73.22%.
[ Wed Sep 28 13:31:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:31:10 2022 ] Eval epoch: 15
[ Wed Sep 28 13:31:54 2022 ] 	Mean test loss of 796 batches: 3.5406709909439087.
[ Wed Sep 28 13:31:55 2022 ] 	Top1: 34.77%
[ Wed Sep 28 13:31:55 2022 ] 	Top5: 62.71%
[ Wed Sep 28 13:31:55 2022 ] Training epoch: 16
[ Wed Sep 28 13:34:52 2022 ] 	Mean training loss: 0.8861.  Mean training acc: 73.41%.
[ Wed Sep 28 13:34:52 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:34:52 2022 ] Eval epoch: 16
[ Wed Sep 28 13:35:36 2022 ] 	Mean test loss of 796 batches: 1.3153811454323667.
[ Wed Sep 28 13:35:36 2022 ] 	Top1: 63.49%
[ Wed Sep 28 13:35:37 2022 ] 	Top5: 88.13%
[ Wed Sep 28 13:35:37 2022 ] Training epoch: 17
[ Wed Sep 28 13:38:33 2022 ] 	Mean training loss: 0.8743.  Mean training acc: 73.71%.
[ Wed Sep 28 13:38:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:38:33 2022 ] Eval epoch: 17
[ Wed Sep 28 13:39:18 2022 ] 	Mean test loss of 796 batches: 1.4476234792315181.
[ Wed Sep 28 13:39:18 2022 ] 	Top1: 59.07%
[ Wed Sep 28 13:39:18 2022 ] 	Top5: 87.33%
[ Wed Sep 28 13:39:18 2022 ] Training epoch: 18
[ Wed Sep 28 13:42:15 2022 ] 	Mean training loss: 0.8686.  Mean training acc: 73.83%.
[ Wed Sep 28 13:42:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:42:15 2022 ] Eval epoch: 18
[ Wed Sep 28 13:42:59 2022 ] 	Mean test loss of 796 batches: 1.6145131959388004.
[ Wed Sep 28 13:42:59 2022 ] 	Top1: 57.55%
[ Wed Sep 28 13:43:00 2022 ] 	Top5: 84.88%
[ Wed Sep 28 13:43:00 2022 ] Training epoch: 19
[ Wed Sep 28 13:45:56 2022 ] 	Mean training loss: 0.8697.  Mean training acc: 73.96%.
[ Wed Sep 28 13:45:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 13:45:56 2022 ] Eval epoch: 19
[ Wed Sep 28 13:46:41 2022 ] 	Mean test loss of 796 batches: 1.218209302979498.
[ Wed Sep 28 13:46:41 2022 ] 	Top1: 65.02%
[ Wed Sep 28 13:46:41 2022 ] 	Top5: 90.00%
[ Wed Sep 28 13:46:41 2022 ] Training epoch: 20
[ Wed Sep 28 13:50:05 2022 ] 	Mean training loss: 0.8508.  Mean training acc: 74.44%.
[ Wed Sep 28 13:50:05 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:50:05 2022 ] Eval epoch: 20
[ Wed Sep 28 13:50:50 2022 ] 	Mean test loss of 796 batches: 1.4246960126574915.
[ Wed Sep 28 13:50:50 2022 ] 	Top1: 59.94%
[ Wed Sep 28 13:50:50 2022 ] 	Top5: 86.71%
[ Wed Sep 28 13:50:50 2022 ] Training epoch: 21
[ Wed Sep 28 13:54:13 2022 ] 	Mean training loss: 0.8425.  Mean training acc: 74.52%.
[ Wed Sep 28 13:54:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:54:13 2022 ] Eval epoch: 21
[ Wed Sep 28 13:54:57 2022 ] 	Mean test loss of 796 batches: 2.674139181123906.
[ Wed Sep 28 13:54:58 2022 ] 	Top1: 39.96%
[ Wed Sep 28 13:54:58 2022 ] 	Top5: 68.37%
[ Wed Sep 28 13:54:58 2022 ] Training epoch: 22
[ Wed Sep 28 13:58:16 2022 ] 	Mean training loss: 0.8437.  Mean training acc: 74.55%.
[ Wed Sep 28 13:58:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:58:16 2022 ] Eval epoch: 22
[ Wed Sep 28 13:59:00 2022 ] 	Mean test loss of 796 batches: 1.2865780606940762.
[ Wed Sep 28 13:59:00 2022 ] 	Top1: 62.80%
[ Wed Sep 28 13:59:00 2022 ] 	Top5: 89.05%
[ Wed Sep 28 13:59:01 2022 ] Training epoch: 23
[ Wed Sep 28 14:02:42 2022 ] 	Mean training loss: 0.8305.  Mean training acc: 74.87%.
[ Wed Sep 28 14:02:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:02:42 2022 ] Eval epoch: 23
[ Wed Sep 28 14:03:26 2022 ] 	Mean test loss of 796 batches: 1.5416689259772325.
[ Wed Sep 28 14:03:27 2022 ] 	Top1: 60.15%
[ Wed Sep 28 14:03:27 2022 ] 	Top5: 85.22%
[ Wed Sep 28 14:03:27 2022 ] Training epoch: 24
[ Wed Sep 28 14:06:35 2022 ] 	Mean training loss: 0.8312.  Mean training acc: 74.96%.
[ Wed Sep 28 14:06:35 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:06:35 2022 ] Eval epoch: 24
[ Wed Sep 28 14:07:32 2022 ] 	Mean test loss of 796 batches: 1.4501894825517232.
[ Wed Sep 28 14:07:33 2022 ] 	Top1: 60.30%
[ Wed Sep 28 14:07:33 2022 ] 	Top5: 87.16%
[ Wed Sep 28 14:07:33 2022 ] Training epoch: 25
[ Wed Sep 28 14:10:30 2022 ] 	Mean training loss: 0.8260.  Mean training acc: 75.33%.
[ Wed Sep 28 14:10:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:10:30 2022 ] Eval epoch: 25
[ Wed Sep 28 14:11:14 2022 ] 	Mean test loss of 796 batches: 1.2278379097056749.
[ Wed Sep 28 14:11:14 2022 ] 	Top1: 64.70%
[ Wed Sep 28 14:11:15 2022 ] 	Top5: 90.57%
[ Wed Sep 28 14:11:15 2022 ] Training epoch: 26
[ Wed Sep 28 14:14:11 2022 ] 	Mean training loss: 0.8289.  Mean training acc: 74.99%.
[ Wed Sep 28 14:14:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:14:11 2022 ] Eval epoch: 26
[ Wed Sep 28 14:14:55 2022 ] 	Mean test loss of 796 batches: 1.915910071089639.
[ Wed Sep 28 14:14:55 2022 ] 	Top1: 53.25%
[ Wed Sep 28 14:14:56 2022 ] 	Top5: 82.10%
[ Wed Sep 28 14:14:56 2022 ] Training epoch: 27
[ Wed Sep 28 14:17:52 2022 ] 	Mean training loss: 0.8191.  Mean training acc: 75.41%.
[ Wed Sep 28 14:17:52 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:17:52 2022 ] Eval epoch: 27
[ Wed Sep 28 14:18:36 2022 ] 	Mean test loss of 796 batches: 1.1662753564703405.
[ Wed Sep 28 14:18:36 2022 ] 	Top1: 66.58%
[ Wed Sep 28 14:18:36 2022 ] 	Top5: 90.09%
[ Wed Sep 28 14:18:36 2022 ] Training epoch: 28
[ Wed Sep 28 14:21:33 2022 ] 	Mean training loss: 0.8114.  Mean training acc: 75.27%.
[ Wed Sep 28 14:21:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:21:33 2022 ] Eval epoch: 28
[ Wed Sep 28 14:22:17 2022 ] 	Mean test loss of 796 batches: 2.1748297846497002.
[ Wed Sep 28 14:22:17 2022 ] 	Top1: 47.35%
[ Wed Sep 28 14:22:18 2022 ] 	Top5: 76.49%
[ Wed Sep 28 14:22:18 2022 ] Training epoch: 29
[ Wed Sep 28 14:26:03 2022 ] 	Mean training loss: 0.8080.  Mean training acc: 75.72%.
[ Wed Sep 28 14:26:03 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:26:03 2022 ] Eval epoch: 29
[ Wed Sep 28 14:26:47 2022 ] 	Mean test loss of 796 batches: 1.0891589220968922.
[ Wed Sep 28 14:26:47 2022 ] 	Top1: 67.83%
[ Wed Sep 28 14:26:48 2022 ] 	Top5: 91.92%
[ Wed Sep 28 14:26:48 2022 ] Training epoch: 30
[ Wed Sep 28 14:31:06 2022 ] 	Mean training loss: 0.8098.  Mean training acc: 75.45%.
[ Wed Sep 28 14:31:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:31:06 2022 ] Eval epoch: 30
[ Wed Sep 28 14:31:59 2022 ] 	Mean test loss of 796 batches: 1.0284040562771073.
[ Wed Sep 28 14:32:00 2022 ] 	Top1: 70.46%
[ Wed Sep 28 14:32:00 2022 ] 	Top5: 92.21%
[ Wed Sep 28 14:32:00 2022 ] Training epoch: 31
[ Wed Sep 28 14:37:49 2022 ] 	Mean training loss: 0.8059.  Mean training acc: 75.57%.
[ Wed Sep 28 14:37:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:37:49 2022 ] Eval epoch: 31
[ Wed Sep 28 14:38:40 2022 ] 	Mean test loss of 796 batches: 1.4050170951827088.
[ Wed Sep 28 14:38:40 2022 ] 	Top1: 61.14%
[ Wed Sep 28 14:38:40 2022 ] 	Top5: 87.75%
[ Wed Sep 28 14:38:40 2022 ] Training epoch: 32
[ Wed Sep 28 14:44:04 2022 ] 	Mean training loss: 0.8093.  Mean training acc: 75.73%.
[ Wed Sep 28 14:44:04 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:44:04 2022 ] Eval epoch: 32
[ Wed Sep 28 14:45:32 2022 ] 	Mean test loss of 796 batches: 2.3845047684171092.
[ Wed Sep 28 14:45:32 2022 ] 	Top1: 43.91%
[ Wed Sep 28 14:45:33 2022 ] 	Top5: 72.10%
[ Wed Sep 28 14:45:33 2022 ] Training epoch: 33
[ Wed Sep 28 14:49:36 2022 ] 	Mean training loss: 0.8027.  Mean training acc: 75.86%.
[ Wed Sep 28 14:49:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:49:36 2022 ] Eval epoch: 33
[ Wed Sep 28 14:50:20 2022 ] 	Mean test loss of 796 batches: 1.116504948380305.
[ Wed Sep 28 14:50:20 2022 ] 	Top1: 67.05%
[ Wed Sep 28 14:50:21 2022 ] 	Top5: 91.26%
[ Wed Sep 28 14:50:21 2022 ] Training epoch: 34
[ Wed Sep 28 14:53:17 2022 ] 	Mean training loss: 0.7957.  Mean training acc: 75.97%.
[ Wed Sep 28 14:53:17 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:53:17 2022 ] Eval epoch: 34
[ Wed Sep 28 14:54:02 2022 ] 	Mean test loss of 796 batches: 1.22013596793515.
[ Wed Sep 28 14:54:02 2022 ] 	Top1: 65.78%
[ Wed Sep 28 14:54:02 2022 ] 	Top5: 89.46%
[ Wed Sep 28 14:54:02 2022 ] Training epoch: 35
[ Wed Sep 28 14:56:59 2022 ] 	Mean training loss: 0.8030.  Mean training acc: 75.89%.
[ Wed Sep 28 14:56:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 14:56:59 2022 ] Eval epoch: 35
[ Wed Sep 28 14:57:43 2022 ] 	Mean test loss of 796 batches: 2.1287439898330365.
[ Wed Sep 28 14:57:43 2022 ] 	Top1: 48.57%
[ Wed Sep 28 14:57:44 2022 ] 	Top5: 76.91%
[ Wed Sep 28 14:57:44 2022 ] Training epoch: 36
[ Wed Sep 28 15:00:40 2022 ] 	Mean training loss: 0.4863.  Mean training acc: 85.29%.
[ Wed Sep 28 15:00:40 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:00:40 2022 ] Eval epoch: 36
[ Wed Sep 28 15:01:24 2022 ] 	Mean test loss of 796 batches: 0.653615764543489.
[ Wed Sep 28 15:01:24 2022 ] 	Top1: 80.06%
[ Wed Sep 28 15:01:25 2022 ] 	Top5: 95.91%
[ Wed Sep 28 15:01:25 2022 ] Training epoch: 37
[ Wed Sep 28 15:04:22 2022 ] 	Mean training loss: 0.4040.  Mean training acc: 87.85%.
[ Wed Sep 28 15:04:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:04:22 2022 ] Eval epoch: 37
[ Wed Sep 28 15:05:06 2022 ] 	Mean test loss of 796 batches: 0.6358974467232898.
[ Wed Sep 28 15:05:06 2022 ] 	Top1: 80.61%
[ Wed Sep 28 15:05:07 2022 ] 	Top5: 96.10%
[ Wed Sep 28 15:05:07 2022 ] Training epoch: 38
[ Wed Sep 28 15:08:03 2022 ] 	Mean training loss: 0.3687.  Mean training acc: 88.76%.
[ Wed Sep 28 15:08:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:08:03 2022 ] Eval epoch: 38
[ Wed Sep 28 15:08:48 2022 ] 	Mean test loss of 796 batches: 0.667501230766276.
[ Wed Sep 28 15:08:48 2022 ] 	Top1: 79.97%
[ Wed Sep 28 15:08:49 2022 ] 	Top5: 95.81%
[ Wed Sep 28 15:08:49 2022 ] Training epoch: 39
[ Wed Sep 28 15:11:45 2022 ] 	Mean training loss: 0.3419.  Mean training acc: 89.82%.
[ Wed Sep 28 15:11:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:11:45 2022 ] Eval epoch: 39
[ Wed Sep 28 15:12:30 2022 ] 	Mean test loss of 796 batches: 0.6435958869830148.
[ Wed Sep 28 15:12:30 2022 ] 	Top1: 80.66%
[ Wed Sep 28 15:12:31 2022 ] 	Top5: 96.11%
[ Wed Sep 28 15:12:31 2022 ] Training epoch: 40
[ Wed Sep 28 15:15:27 2022 ] 	Mean training loss: 0.3180.  Mean training acc: 90.49%.
[ Wed Sep 28 15:15:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:15:27 2022 ] Eval epoch: 40
[ Wed Sep 28 15:16:11 2022 ] 	Mean test loss of 796 batches: 0.6719212543181888.
[ Wed Sep 28 15:16:11 2022 ] 	Top1: 80.01%
[ Wed Sep 28 15:16:12 2022 ] 	Top5: 95.68%
[ Wed Sep 28 15:16:12 2022 ] Training epoch: 41
[ Wed Sep 28 15:19:09 2022 ] 	Mean training loss: 0.3008.  Mean training acc: 91.00%.
[ Wed Sep 28 15:19:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:19:09 2022 ] Eval epoch: 41
[ Wed Sep 28 15:19:53 2022 ] 	Mean test loss of 796 batches: 0.6593456531982476.
[ Wed Sep 28 15:19:54 2022 ] 	Top1: 80.36%
[ Wed Sep 28 15:19:54 2022 ] 	Top5: 96.09%
[ Wed Sep 28 15:19:54 2022 ] Training epoch: 42
[ Wed Sep 28 15:22:51 2022 ] 	Mean training loss: 0.2828.  Mean training acc: 91.52%.
[ Wed Sep 28 15:22:51 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:22:51 2022 ] Eval epoch: 42
[ Wed Sep 28 15:23:35 2022 ] 	Mean test loss of 796 batches: 0.6993387320907272.
[ Wed Sep 28 15:23:36 2022 ] 	Top1: 79.69%
[ Wed Sep 28 15:23:36 2022 ] 	Top5: 95.39%
[ Wed Sep 28 15:23:36 2022 ] Training epoch: 43
[ Wed Sep 28 15:26:33 2022 ] 	Mean training loss: 0.2724.  Mean training acc: 92.13%.
[ Wed Sep 28 15:26:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:26:33 2022 ] Eval epoch: 43
[ Wed Sep 28 15:27:17 2022 ] 	Mean test loss of 796 batches: 0.6741672983982755.
[ Wed Sep 28 15:27:17 2022 ] 	Top1: 80.25%
[ Wed Sep 28 15:27:17 2022 ] 	Top5: 95.90%
[ Wed Sep 28 15:27:18 2022 ] Training epoch: 44
[ Wed Sep 28 15:30:14 2022 ] 	Mean training loss: 0.2576.  Mean training acc: 92.44%.
[ Wed Sep 28 15:30:14 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:30:14 2022 ] Eval epoch: 44
[ Wed Sep 28 15:30:59 2022 ] 	Mean test loss of 796 batches: 0.7153657222793779.
[ Wed Sep 28 15:30:59 2022 ] 	Top1: 79.35%
[ Wed Sep 28 15:30:59 2022 ] 	Top5: 95.52%
[ Wed Sep 28 15:31:00 2022 ] Training epoch: 45
[ Wed Sep 28 15:33:56 2022 ] 	Mean training loss: 0.2508.  Mean training acc: 92.76%.
[ Wed Sep 28 15:33:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:33:56 2022 ] Eval epoch: 45
[ Wed Sep 28 15:34:41 2022 ] 	Mean test loss of 796 batches: 0.7160677077744774.
[ Wed Sep 28 15:34:41 2022 ] 	Top1: 79.33%
[ Wed Sep 28 15:34:41 2022 ] 	Top5: 95.48%
[ Wed Sep 28 15:34:41 2022 ] Training epoch: 46
[ Wed Sep 28 15:37:38 2022 ] 	Mean training loss: 0.2407.  Mean training acc: 93.09%.
[ Wed Sep 28 15:37:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:37:38 2022 ] Eval epoch: 46
[ Wed Sep 28 15:38:23 2022 ] 	Mean test loss of 796 batches: 0.7326593313029214.
[ Wed Sep 28 15:38:23 2022 ] 	Top1: 79.06%
[ Wed Sep 28 15:38:23 2022 ] 	Top5: 95.42%
[ Wed Sep 28 15:38:23 2022 ] Training epoch: 47
[ Wed Sep 28 15:41:20 2022 ] 	Mean training loss: 0.2343.  Mean training acc: 93.34%.
[ Wed Sep 28 15:41:20 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:41:20 2022 ] Eval epoch: 47
[ Wed Sep 28 15:42:04 2022 ] 	Mean test loss of 796 batches: 0.7107381699559976.
[ Wed Sep 28 15:42:05 2022 ] 	Top1: 79.74%
[ Wed Sep 28 15:42:05 2022 ] 	Top5: 95.56%
[ Wed Sep 28 15:42:05 2022 ] Training epoch: 48
[ Wed Sep 28 15:45:02 2022 ] 	Mean training loss: 0.2296.  Mean training acc: 93.32%.
[ Wed Sep 28 15:45:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:45:02 2022 ] Eval epoch: 48
[ Wed Sep 28 15:45:46 2022 ] 	Mean test loss of 796 batches: 0.7461421649210417.
[ Wed Sep 28 15:45:46 2022 ] 	Top1: 78.87%
[ Wed Sep 28 15:45:47 2022 ] 	Top5: 95.28%
[ Wed Sep 28 15:45:47 2022 ] Training epoch: 49
[ Wed Sep 28 15:48:43 2022 ] 	Mean training loss: 0.2302.  Mean training acc: 93.31%.
[ Wed Sep 28 15:48:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:48:43 2022 ] Eval epoch: 49
[ Wed Sep 28 15:49:28 2022 ] 	Mean test loss of 796 batches: 0.8315022468529455.
[ Wed Sep 28 15:49:28 2022 ] 	Top1: 77.11%
[ Wed Sep 28 15:49:29 2022 ] 	Top5: 94.00%
[ Wed Sep 28 15:49:29 2022 ] Training epoch: 50
[ Wed Sep 28 15:52:25 2022 ] 	Mean training loss: 0.2269.  Mean training acc: 93.56%.
[ Wed Sep 28 15:52:25 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:52:25 2022 ] Eval epoch: 50
[ Wed Sep 28 15:53:10 2022 ] 	Mean test loss of 796 batches: 1.0139584522600749.
[ Wed Sep 28 15:53:10 2022 ] 	Top1: 72.96%
[ Wed Sep 28 15:53:10 2022 ] 	Top5: 92.38%
[ Wed Sep 28 15:53:10 2022 ] Training epoch: 51
[ Wed Sep 28 15:56:07 2022 ] 	Mean training loss: 0.2252.  Mean training acc: 93.56%.
[ Wed Sep 28 15:56:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:56:07 2022 ] Eval epoch: 51
[ Wed Sep 28 15:56:51 2022 ] 	Mean test loss of 796 batches: 0.7908103645746433.
[ Wed Sep 28 15:56:52 2022 ] 	Top1: 77.97%
[ Wed Sep 28 15:56:52 2022 ] 	Top5: 94.90%
[ Wed Sep 28 15:56:52 2022 ] Training epoch: 52
[ Wed Sep 28 15:59:49 2022 ] 	Mean training loss: 0.2189.  Mean training acc: 93.67%.
[ Wed Sep 28 15:59:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:59:49 2022 ] Eval epoch: 52
[ Wed Sep 28 16:00:33 2022 ] 	Mean test loss of 796 batches: 0.8462113269965104.
[ Wed Sep 28 16:00:33 2022 ] 	Top1: 77.19%
[ Wed Sep 28 16:00:34 2022 ] 	Top5: 94.13%
[ Wed Sep 28 16:00:34 2022 ] Training epoch: 53
[ Wed Sep 28 16:03:30 2022 ] 	Mean training loss: 0.2232.  Mean training acc: 93.61%.
[ Wed Sep 28 16:03:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:03:30 2022 ] Eval epoch: 53
[ Wed Sep 28 16:04:15 2022 ] 	Mean test loss of 796 batches: 0.8114944483953804.
[ Wed Sep 28 16:04:15 2022 ] 	Top1: 77.75%
[ Wed Sep 28 16:04:15 2022 ] 	Top5: 94.60%
[ Wed Sep 28 16:04:15 2022 ] Training epoch: 54
[ Wed Sep 28 16:07:12 2022 ] 	Mean training loss: 0.2171.  Mean training acc: 93.77%.
[ Wed Sep 28 16:07:12 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:07:12 2022 ] Eval epoch: 54
[ Wed Sep 28 16:07:56 2022 ] 	Mean test loss of 796 batches: 0.802255895241496.
[ Wed Sep 28 16:07:56 2022 ] 	Top1: 78.14%
[ Wed Sep 28 16:07:57 2022 ] 	Top5: 94.81%
[ Wed Sep 28 16:07:57 2022 ] Training epoch: 55
[ Wed Sep 28 16:10:53 2022 ] 	Mean training loss: 0.2175.  Mean training acc: 93.77%.
[ Wed Sep 28 16:10:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:10:53 2022 ] Eval epoch: 55
[ Wed Sep 28 16:11:37 2022 ] 	Mean test loss of 796 batches: 0.8716156671956257.
[ Wed Sep 28 16:11:38 2022 ] 	Top1: 76.89%
[ Wed Sep 28 16:11:38 2022 ] 	Top5: 94.41%
[ Wed Sep 28 16:11:38 2022 ] Training epoch: 56
[ Wed Sep 28 16:14:34 2022 ] 	Mean training loss: 0.1333.  Mean training acc: 96.72%.
[ Wed Sep 28 16:14:34 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:14:34 2022 ] Eval epoch: 56
[ Wed Sep 28 16:15:19 2022 ] 	Mean test loss of 796 batches: 0.6896407102707343.
[ Wed Sep 28 16:15:20 2022 ] 	Top1: 80.74%
[ Wed Sep 28 16:15:20 2022 ] 	Top5: 95.89%
[ Wed Sep 28 16:15:20 2022 ] Training epoch: 57
[ Wed Sep 28 16:18:17 2022 ] 	Mean training loss: 0.1049.  Mean training acc: 97.56%.
[ Wed Sep 28 16:18:17 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:18:17 2022 ] Eval epoch: 57
[ Wed Sep 28 16:19:01 2022 ] 	Mean test loss of 796 batches: 0.6915427938515517.
[ Wed Sep 28 16:19:02 2022 ] 	Top1: 80.83%
[ Wed Sep 28 16:19:02 2022 ] 	Top5: 95.84%
[ Wed Sep 28 16:19:02 2022 ] Training epoch: 58
[ Wed Sep 28 16:21:59 2022 ] 	Mean training loss: 0.0950.  Mean training acc: 97.89%.
[ Wed Sep 28 16:21:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:21:59 2022 ] Eval epoch: 58
[ Wed Sep 28 16:22:43 2022 ] 	Mean test loss of 796 batches: 0.6975466055964031.
[ Wed Sep 28 16:22:43 2022 ] 	Top1: 80.92%
[ Wed Sep 28 16:22:44 2022 ] 	Top5: 95.82%
[ Wed Sep 28 16:22:44 2022 ] Training epoch: 59
[ Wed Sep 28 16:25:40 2022 ] 	Mean training loss: 0.0868.  Mean training acc: 98.17%.
[ Wed Sep 28 16:25:40 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:25:40 2022 ] Eval epoch: 59
[ Wed Sep 28 16:26:25 2022 ] 	Mean test loss of 796 batches: 0.7013192484857299.
[ Wed Sep 28 16:26:25 2022 ] 	Top1: 80.93%
[ Wed Sep 28 16:26:25 2022 ] 	Top5: 95.77%
[ Wed Sep 28 16:26:25 2022 ] Training epoch: 60
[ Wed Sep 28 16:29:22 2022 ] 	Mean training loss: 0.0855.  Mean training acc: 98.22%.
[ Wed Sep 28 16:29:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:29:22 2022 ] Eval epoch: 60
[ Wed Sep 28 16:30:06 2022 ] 	Mean test loss of 796 batches: 0.7042510918711298.
[ Wed Sep 28 16:30:07 2022 ] 	Top1: 80.85%
[ Wed Sep 28 16:30:07 2022 ] 	Top5: 95.76%
[ Wed Sep 28 16:30:07 2022 ] Training epoch: 61
[ Wed Sep 28 16:33:03 2022 ] 	Mean training loss: 0.0773.  Mean training acc: 98.42%.
[ Wed Sep 28 16:33:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:33:03 2022 ] Eval epoch: 61
[ Wed Sep 28 16:33:48 2022 ] 	Mean test loss of 796 batches: 0.7003539025352977.
[ Wed Sep 28 16:33:48 2022 ] 	Top1: 81.08%
[ Wed Sep 28 16:33:48 2022 ] 	Top5: 95.83%
[ Wed Sep 28 16:33:48 2022 ] Training epoch: 62
[ Wed Sep 28 16:36:45 2022 ] 	Mean training loss: 0.0749.  Mean training acc: 98.57%.
[ Wed Sep 28 16:36:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:36:45 2022 ] Eval epoch: 62
[ Wed Sep 28 16:37:29 2022 ] 	Mean test loss of 796 batches: 0.7105757880057372.
[ Wed Sep 28 16:37:30 2022 ] 	Top1: 80.84%
[ Wed Sep 28 16:37:30 2022 ] 	Top5: 95.67%
[ Wed Sep 28 16:37:30 2022 ] Training epoch: 63
[ Wed Sep 28 16:40:27 2022 ] 	Mean training loss: 0.0709.  Mean training acc: 98.66%.
[ Wed Sep 28 16:40:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:40:27 2022 ] Eval epoch: 63
[ Wed Sep 28 16:41:11 2022 ] 	Mean test loss of 796 batches: 0.7153405450733762.
[ Wed Sep 28 16:41:11 2022 ] 	Top1: 80.78%
[ Wed Sep 28 16:41:12 2022 ] 	Top5: 95.65%
[ Wed Sep 28 16:41:12 2022 ] Training epoch: 64
[ Wed Sep 28 16:44:08 2022 ] 	Mean training loss: 0.0697.  Mean training acc: 98.66%.
[ Wed Sep 28 16:44:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:44:08 2022 ] Eval epoch: 64
[ Wed Sep 28 16:44:53 2022 ] 	Mean test loss of 796 batches: 0.7109899170153854.
[ Wed Sep 28 16:44:53 2022 ] 	Top1: 80.93%
[ Wed Sep 28 16:44:54 2022 ] 	Top5: 95.60%
[ Wed Sep 28 16:44:54 2022 ] Training epoch: 65
[ Wed Sep 28 16:47:50 2022 ] 	Mean training loss: 0.0682.  Mean training acc: 98.68%.
[ Wed Sep 28 16:47:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:47:50 2022 ] Eval epoch: 65
[ Wed Sep 28 16:48:34 2022 ] 	Mean test loss of 796 batches: 0.7130561727450122.
[ Wed Sep 28 16:48:35 2022 ] 	Top1: 80.91%
[ Wed Sep 28 16:48:35 2022 ] 	Top5: 95.70%
[ Wed Sep 28 16:49:21 2022 ] Best accuracy: 0.8107582631237849
[ Wed Sep 28 16:49:21 2022 ] Epoch number: 61
[ Wed Sep 28 16:49:21 2022 ] Model name: work_dir/ntu120/csub/azimuth_cent_imp3
[ Wed Sep 28 16:49:21 2022 ] Model total number of params: 2107660
[ Wed Sep 28 16:49:21 2022 ] Weight decay: 0.0004
[ Wed Sep 28 16:49:21 2022 ] Base LR: 0.1
[ Wed Sep 28 16:49:21 2022 ] Batch Size: 64
[ Wed Sep 28 16:49:21 2022 ] Test Batch Size: 64
[ Wed Sep 28 16:49:21 2022 ] seed: 1
