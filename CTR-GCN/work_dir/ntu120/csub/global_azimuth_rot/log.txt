[ Wed Oct  5 15:17:37 2022 ] using warm up, epoch: 5
[ Wed Oct  5 15:17:51 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/global_azimuth_rot', 'model_saved_name': 'work_dir/ntu120/csub/global_azimuth_rot/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.global_azimuth_rot.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Oct  5 15:17:51 2022 ] # Parameters: 2107810
[ Wed Oct  5 15:17:51 2022 ] Training epoch: 1
[ Wed Oct  5 15:20:48 2022 ] 	Mean training loss: 2.8925.  Mean training acc: 26.87%.
[ Wed Oct  5 15:20:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:20:48 2022 ] Eval epoch: 1
[ Wed Oct  5 15:21:33 2022 ] 	Mean test loss of 796 batches: 2.7894934540118403.
[ Wed Oct  5 15:21:33 2022 ] 	Top1: 29.70%
[ Wed Oct  5 15:21:34 2022 ] 	Top5: 63.24%
[ Wed Oct  5 15:21:34 2022 ] Training epoch: 2
[ Wed Oct  5 15:24:31 2022 ] 	Mean training loss: 2.0115.  Mean training acc: 43.69%.
[ Wed Oct  5 15:24:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:24:31 2022 ] Eval epoch: 2
[ Wed Oct  5 15:25:16 2022 ] 	Mean test loss of 796 batches: 1.9503886449576622.
[ Wed Oct  5 15:25:16 2022 ] 	Top1: 45.08%
[ Wed Oct  5 15:25:17 2022 ] 	Top5: 78.63%
[ Wed Oct  5 15:25:17 2022 ] Training epoch: 3
[ Wed Oct  5 15:28:14 2022 ] 	Mean training loss: 1.6828.  Mean training acc: 51.82%.
[ Wed Oct  5 15:28:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:28:14 2022 ] Eval epoch: 3
[ Wed Oct  5 15:28:58 2022 ] 	Mean test loss of 796 batches: 2.2987270346238984.
[ Wed Oct  5 15:28:59 2022 ] 	Top1: 37.16%
[ Wed Oct  5 15:28:59 2022 ] 	Top5: 75.10%
[ Wed Oct  5 15:28:59 2022 ] Training epoch: 4
[ Wed Oct  5 15:31:56 2022 ] 	Mean training loss: 1.4988.  Mean training acc: 56.50%.
[ Wed Oct  5 15:31:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:31:56 2022 ] Eval epoch: 4
[ Wed Oct  5 15:32:40 2022 ] 	Mean test loss of 796 batches: 1.7005308413475602.
[ Wed Oct  5 15:32:41 2022 ] 	Top1: 51.31%
[ Wed Oct  5 15:32:41 2022 ] 	Top5: 83.47%
[ Wed Oct  5 15:32:41 2022 ] Training epoch: 5
[ Wed Oct  5 15:35:39 2022 ] 	Mean training loss: 1.3429.  Mean training acc: 60.32%.
[ Wed Oct  5 15:35:39 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 15:35:39 2022 ] Eval epoch: 5
[ Wed Oct  5 15:36:24 2022 ] 	Mean test loss of 796 batches: 1.8366933939744479.
[ Wed Oct  5 15:36:24 2022 ] 	Top1: 49.62%
[ Wed Oct  5 15:36:25 2022 ] 	Top5: 82.87%
[ Wed Oct  5 15:36:25 2022 ] Training epoch: 6
[ Wed Oct  5 15:39:22 2022 ] 	Mean training loss: 1.1863.  Mean training acc: 64.53%.
[ Wed Oct  5 15:39:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 15:39:22 2022 ] Eval epoch: 6
[ Wed Oct  5 15:40:07 2022 ] 	Mean test loss of 796 batches: 1.661989086911307.
[ Wed Oct  5 15:40:08 2022 ] 	Top1: 52.22%
[ Wed Oct  5 15:40:08 2022 ] 	Top5: 85.60%
[ Wed Oct  5 15:40:08 2022 ] Training epoch: 7
[ Wed Oct  5 15:43:06 2022 ] 	Mean training loss: 1.0925.  Mean training acc: 67.11%.
[ Wed Oct  5 15:43:06 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 15:43:06 2022 ] Eval epoch: 7
[ Wed Oct  5 15:43:51 2022 ] 	Mean test loss of 796 batches: 1.7364508122505256.
[ Wed Oct  5 15:43:51 2022 ] 	Top1: 51.70%
[ Wed Oct  5 15:43:51 2022 ] 	Top5: 85.21%
[ Wed Oct  5 15:43:51 2022 ] Training epoch: 8
[ Wed Oct  5 15:46:49 2022 ] 	Mean training loss: 1.0327.  Mean training acc: 69.04%.
[ Wed Oct  5 15:46:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 15:46:49 2022 ] Eval epoch: 8
[ Wed Oct  5 15:47:34 2022 ] 	Mean test loss of 796 batches: 1.3639157806808626.
[ Wed Oct  5 15:47:34 2022 ] 	Top1: 58.64%
[ Wed Oct  5 15:47:34 2022 ] 	Top5: 89.13%
[ Wed Oct  5 15:47:35 2022 ] Training epoch: 9
[ Wed Oct  5 15:50:32 2022 ] 	Mean training loss: 0.9859.  Mean training acc: 70.36%.
[ Wed Oct  5 15:50:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:50:32 2022 ] Eval epoch: 9
[ Wed Oct  5 15:51:17 2022 ] 	Mean test loss of 796 batches: 1.8475298130482285.
[ Wed Oct  5 15:51:17 2022 ] 	Top1: 49.72%
[ Wed Oct  5 15:51:17 2022 ] 	Top5: 82.31%
[ Wed Oct  5 15:51:17 2022 ] Training epoch: 10
[ Wed Oct  5 15:54:15 2022 ] 	Mean training loss: 0.9557.  Mean training acc: 71.07%.
[ Wed Oct  5 15:54:15 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:54:15 2022 ] Eval epoch: 10
[ Wed Oct  5 15:54:59 2022 ] 	Mean test loss of 796 batches: 1.8148487912650084.
[ Wed Oct  5 15:54:59 2022 ] 	Top1: 52.15%
[ Wed Oct  5 15:55:00 2022 ] 	Top5: 80.87%
[ Wed Oct  5 15:55:00 2022 ] Training epoch: 11
[ Wed Oct  5 15:57:57 2022 ] 	Mean training loss: 0.9287.  Mean training acc: 72.01%.
[ Wed Oct  5 15:57:57 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 15:57:57 2022 ] Eval epoch: 11
[ Wed Oct  5 15:58:43 2022 ] 	Mean test loss of 796 batches: 1.3056947879455796.
[ Wed Oct  5 15:58:43 2022 ] 	Top1: 61.92%
[ Wed Oct  5 15:58:43 2022 ] 	Top5: 88.50%
[ Wed Oct  5 15:58:44 2022 ] Training epoch: 12
[ Wed Oct  5 16:01:41 2022 ] 	Mean training loss: 0.9062.  Mean training acc: 72.76%.
[ Wed Oct  5 16:01:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:01:41 2022 ] Eval epoch: 12
[ Wed Oct  5 16:02:25 2022 ] 	Mean test loss of 796 batches: 1.4475197419149792.
[ Wed Oct  5 16:02:26 2022 ] 	Top1: 60.87%
[ Wed Oct  5 16:02:26 2022 ] 	Top5: 86.98%
[ Wed Oct  5 16:02:26 2022 ] Training epoch: 13
[ Wed Oct  5 16:05:23 2022 ] 	Mean training loss: 0.8866.  Mean training acc: 73.13%.
[ Wed Oct  5 16:05:23 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:05:23 2022 ] Eval epoch: 13
[ Wed Oct  5 16:06:08 2022 ] 	Mean test loss of 796 batches: 1.6805619628135882.
[ Wed Oct  5 16:06:08 2022 ] 	Top1: 55.25%
[ Wed Oct  5 16:06:09 2022 ] 	Top5: 83.95%
[ Wed Oct  5 16:06:09 2022 ] Training epoch: 14
[ Wed Oct  5 16:09:06 2022 ] 	Mean training loss: 0.8735.  Mean training acc: 73.52%.
[ Wed Oct  5 16:09:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:09:06 2022 ] Eval epoch: 14
[ Wed Oct  5 16:09:51 2022 ] 	Mean test loss of 796 batches: 1.3332403004169464.
[ Wed Oct  5 16:09:51 2022 ] 	Top1: 61.58%
[ Wed Oct  5 16:09:51 2022 ] 	Top5: 88.95%
[ Wed Oct  5 16:09:51 2022 ] Training epoch: 15
[ Wed Oct  5 16:12:49 2022 ] 	Mean training loss: 0.8603.  Mean training acc: 73.97%.
[ Wed Oct  5 16:12:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:12:49 2022 ] Eval epoch: 15
[ Wed Oct  5 16:13:33 2022 ] 	Mean test loss of 796 batches: 1.1136955991012967.
[ Wed Oct  5 16:13:34 2022 ] 	Top1: 67.26%
[ Wed Oct  5 16:13:34 2022 ] 	Top5: 91.25%
[ Wed Oct  5 16:13:34 2022 ] Training epoch: 16
[ Wed Oct  5 16:16:31 2022 ] 	Mean training loss: 0.8484.  Mean training acc: 74.42%.
[ Wed Oct  5 16:16:32 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:16:32 2022 ] Eval epoch: 16
[ Wed Oct  5 16:17:16 2022 ] 	Mean test loss of 796 batches: 1.2554944226115792.
[ Wed Oct  5 16:17:16 2022 ] 	Top1: 63.85%
[ Wed Oct  5 16:17:17 2022 ] 	Top5: 89.75%
[ Wed Oct  5 16:17:17 2022 ] Training epoch: 17
[ Wed Oct  5 16:20:14 2022 ] 	Mean training loss: 0.8453.  Mean training acc: 74.48%.
[ Wed Oct  5 16:20:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:20:14 2022 ] Eval epoch: 17
[ Wed Oct  5 16:20:58 2022 ] 	Mean test loss of 796 batches: 1.397528191232801.
[ Wed Oct  5 16:20:58 2022 ] 	Top1: 60.46%
[ Wed Oct  5 16:20:59 2022 ] 	Top5: 88.75%
[ Wed Oct  5 16:20:59 2022 ] Training epoch: 18
[ Wed Oct  5 16:23:56 2022 ] 	Mean training loss: 0.8346.  Mean training acc: 74.74%.
[ Wed Oct  5 16:23:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:23:56 2022 ] Eval epoch: 18
[ Wed Oct  5 16:24:41 2022 ] 	Mean test loss of 796 batches: 1.2059208866040312.
[ Wed Oct  5 16:24:41 2022 ] 	Top1: 64.70%
[ Wed Oct  5 16:24:42 2022 ] 	Top5: 91.29%
[ Wed Oct  5 16:24:42 2022 ] Training epoch: 19
[ Wed Oct  5 16:27:39 2022 ] 	Mean training loss: 0.8242.  Mean training acc: 75.04%.
[ Wed Oct  5 16:27:39 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:27:39 2022 ] Eval epoch: 19
[ Wed Oct  5 16:28:24 2022 ] 	Mean test loss of 796 batches: 1.0711452456649824.
[ Wed Oct  5 16:28:24 2022 ] 	Top1: 68.53%
[ Wed Oct  5 16:28:25 2022 ] 	Top5: 92.04%
[ Wed Oct  5 16:28:25 2022 ] Training epoch: 20
[ Wed Oct  5 16:31:22 2022 ] 	Mean training loss: 0.8232.  Mean training acc: 75.14%.
[ Wed Oct  5 16:31:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:31:22 2022 ] Eval epoch: 20
[ Wed Oct  5 16:32:07 2022 ] 	Mean test loss of 796 batches: 1.0563778217938078.
[ Wed Oct  5 16:32:07 2022 ] 	Top1: 68.78%
[ Wed Oct  5 16:32:08 2022 ] 	Top5: 92.02%
[ Wed Oct  5 16:32:08 2022 ] Training epoch: 21
[ Wed Oct  5 16:35:05 2022 ] 	Mean training loss: 0.8171.  Mean training acc: 75.09%.
[ Wed Oct  5 16:35:05 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:35:05 2022 ] Eval epoch: 21
[ Wed Oct  5 16:35:50 2022 ] 	Mean test loss of 796 batches: 1.2696114181723428.
[ Wed Oct  5 16:35:50 2022 ] 	Top1: 63.41%
[ Wed Oct  5 16:35:51 2022 ] 	Top5: 89.22%
[ Wed Oct  5 16:35:51 2022 ] Training epoch: 22
[ Wed Oct  5 16:38:48 2022 ] 	Mean training loss: 0.8058.  Mean training acc: 75.66%.
[ Wed Oct  5 16:38:48 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:38:48 2022 ] Eval epoch: 22
[ Wed Oct  5 16:39:33 2022 ] 	Mean test loss of 796 batches: 1.1388682669880401.
[ Wed Oct  5 16:39:33 2022 ] 	Top1: 65.95%
[ Wed Oct  5 16:39:33 2022 ] 	Top5: 91.13%
[ Wed Oct  5 16:39:33 2022 ] Training epoch: 23
[ Wed Oct  5 16:42:31 2022 ] 	Mean training loss: 0.8060.  Mean training acc: 75.42%.
[ Wed Oct  5 16:42:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:42:31 2022 ] Eval epoch: 23
[ Wed Oct  5 16:43:15 2022 ] 	Mean test loss of 796 batches: 1.1308336926240419.
[ Wed Oct  5 16:43:15 2022 ] 	Top1: 67.07%
[ Wed Oct  5 16:43:16 2022 ] 	Top5: 91.05%
[ Wed Oct  5 16:43:16 2022 ] Training epoch: 24
[ Wed Oct  5 16:46:13 2022 ] 	Mean training loss: 0.8002.  Mean training acc: 75.64%.
[ Wed Oct  5 16:46:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:46:13 2022 ] Eval epoch: 24
[ Wed Oct  5 16:46:58 2022 ] 	Mean test loss of 796 batches: 1.3561730281491975.
[ Wed Oct  5 16:46:58 2022 ] 	Top1: 62.89%
[ Wed Oct  5 16:46:58 2022 ] 	Top5: 89.09%
[ Wed Oct  5 16:46:58 2022 ] Training epoch: 25
[ Wed Oct  5 16:49:56 2022 ] 	Mean training loss: 0.7944.  Mean training acc: 75.98%.
[ Wed Oct  5 16:49:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 16:49:56 2022 ] Eval epoch: 25
[ Wed Oct  5 16:50:40 2022 ] 	Mean test loss of 796 batches: 1.7819093289836567.
[ Wed Oct  5 16:50:40 2022 ] 	Top1: 52.55%
[ Wed Oct  5 16:50:41 2022 ] 	Top5: 82.35%
[ Wed Oct  5 16:50:41 2022 ] Training epoch: 26
[ Wed Oct  5 16:53:38 2022 ] 	Mean training loss: 0.7907.  Mean training acc: 75.85%.
[ Wed Oct  5 16:53:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:53:38 2022 ] Eval epoch: 26
[ Wed Oct  5 16:54:22 2022 ] 	Mean test loss of 796 batches: 1.5151309290872745.
[ Wed Oct  5 16:54:23 2022 ] 	Top1: 59.16%
[ Wed Oct  5 16:54:23 2022 ] 	Top5: 84.83%
[ Wed Oct  5 16:54:23 2022 ] Training epoch: 27
[ Wed Oct  5 16:57:21 2022 ] 	Mean training loss: 0.7891.  Mean training acc: 76.08%.
[ Wed Oct  5 16:57:21 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 16:57:21 2022 ] Eval epoch: 27
[ Wed Oct  5 16:58:05 2022 ] 	Mean test loss of 796 batches: 1.3447524217430071.
[ Wed Oct  5 16:58:06 2022 ] 	Top1: 61.54%
[ Wed Oct  5 16:58:06 2022 ] 	Top5: 88.11%
[ Wed Oct  5 16:58:06 2022 ] Training epoch: 28
[ Wed Oct  5 17:01:03 2022 ] 	Mean training loss: 0.7786.  Mean training acc: 76.40%.
[ Wed Oct  5 17:01:03 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:01:03 2022 ] Eval epoch: 28
[ Wed Oct  5 17:01:47 2022 ] 	Mean test loss of 796 batches: 1.2126318770062983.
[ Wed Oct  5 17:01:48 2022 ] 	Top1: 65.99%
[ Wed Oct  5 17:01:48 2022 ] 	Top5: 91.38%
[ Wed Oct  5 17:01:48 2022 ] Training epoch: 29
[ Wed Oct  5 17:04:46 2022 ] 	Mean training loss: 0.7841.  Mean training acc: 76.31%.
[ Wed Oct  5 17:04:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:04:46 2022 ] Eval epoch: 29
[ Wed Oct  5 17:05:30 2022 ] 	Mean test loss of 796 batches: 1.4358197664046408.
[ Wed Oct  5 17:05:30 2022 ] 	Top1: 60.37%
[ Wed Oct  5 17:05:31 2022 ] 	Top5: 89.13%
[ Wed Oct  5 17:05:31 2022 ] Training epoch: 30
[ Wed Oct  5 17:08:28 2022 ] 	Mean training loss: 0.7777.  Mean training acc: 76.38%.
[ Wed Oct  5 17:08:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:08:28 2022 ] Eval epoch: 30
[ Wed Oct  5 17:09:12 2022 ] 	Mean test loss of 796 batches: 1.1972391299491552.
[ Wed Oct  5 17:09:12 2022 ] 	Top1: 66.18%
[ Wed Oct  5 17:09:13 2022 ] 	Top5: 90.49%
[ Wed Oct  5 17:09:13 2022 ] Training epoch: 31
[ Wed Oct  5 17:12:10 2022 ] 	Mean training loss: 0.8562.  Mean training acc: 74.30%.
[ Wed Oct  5 17:12:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:12:10 2022 ] Eval epoch: 31
[ Wed Oct  5 17:12:54 2022 ] 	Mean test loss of 796 batches: 1.3198530632047798.
[ Wed Oct  5 17:12:55 2022 ] 	Top1: 62.28%
[ Wed Oct  5 17:12:55 2022 ] 	Top5: 88.85%
[ Wed Oct  5 17:12:55 2022 ] Training epoch: 32
[ Wed Oct  5 17:15:52 2022 ] 	Mean training loss: 0.7953.  Mean training acc: 75.98%.
[ Wed Oct  5 17:15:52 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:15:52 2022 ] Eval epoch: 32
[ Wed Oct  5 17:16:37 2022 ] 	Mean test loss of 796 batches: 2.2916430324390906.
[ Wed Oct  5 17:16:37 2022 ] 	Top1: 43.78%
[ Wed Oct  5 17:16:37 2022 ] 	Top5: 73.48%
[ Wed Oct  5 17:16:37 2022 ] Training epoch: 33
[ Wed Oct  5 17:19:35 2022 ] 	Mean training loss: 0.7793.  Mean training acc: 76.39%.
[ Wed Oct  5 17:19:35 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:19:35 2022 ] Eval epoch: 33
[ Wed Oct  5 17:20:19 2022 ] 	Mean test loss of 796 batches: 1.5050966141736088.
[ Wed Oct  5 17:20:20 2022 ] 	Top1: 57.28%
[ Wed Oct  5 17:20:20 2022 ] 	Top5: 85.92%
[ Wed Oct  5 17:20:20 2022 ] Training epoch: 34
[ Wed Oct  5 17:23:18 2022 ] 	Mean training loss: 0.7698.  Mean training acc: 76.61%.
[ Wed Oct  5 17:23:18 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:23:18 2022 ] Eval epoch: 34
[ Wed Oct  5 17:24:02 2022 ] 	Mean test loss of 796 batches: 1.609193276707551.
[ Wed Oct  5 17:24:03 2022 ] 	Top1: 59.22%
[ Wed Oct  5 17:24:03 2022 ] 	Top5: 85.52%
[ Wed Oct  5 17:24:03 2022 ] Training epoch: 35
[ Wed Oct  5 17:27:01 2022 ] 	Mean training loss: 0.7702.  Mean training acc: 76.80%.
[ Wed Oct  5 17:27:01 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:27:01 2022 ] Eval epoch: 35
[ Wed Oct  5 17:27:45 2022 ] 	Mean test loss of 796 batches: 1.0581777102908296.
[ Wed Oct  5 17:27:46 2022 ] 	Top1: 69.70%
[ Wed Oct  5 17:27:46 2022 ] 	Top5: 92.86%
[ Wed Oct  5 17:27:46 2022 ] Training epoch: 36
[ Wed Oct  5 17:30:43 2022 ] 	Mean training loss: 0.4601.  Mean training acc: 85.99%.
[ Wed Oct  5 17:30:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:30:43 2022 ] Eval epoch: 36
[ Wed Oct  5 17:31:28 2022 ] 	Mean test loss of 796 batches: 0.622852942134118.
[ Wed Oct  5 17:31:28 2022 ] 	Top1: 80.82%
[ Wed Oct  5 17:31:28 2022 ] 	Top5: 96.28%
[ Wed Oct  5 17:31:28 2022 ] Training epoch: 37
[ Wed Oct  5 17:34:26 2022 ] 	Mean training loss: 0.3856.  Mean training acc: 88.31%.
[ Wed Oct  5 17:34:26 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:34:26 2022 ] Eval epoch: 37
[ Wed Oct  5 17:35:10 2022 ] 	Mean test loss of 796 batches: 0.613249087650048.
[ Wed Oct  5 17:35:11 2022 ] 	Top1: 81.14%
[ Wed Oct  5 17:35:11 2022 ] 	Top5: 96.47%
[ Wed Oct  5 17:35:11 2022 ] Training epoch: 38
[ Wed Oct  5 17:38:09 2022 ] 	Mean training loss: 0.3533.  Mean training acc: 89.20%.
[ Wed Oct  5 17:38:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:38:09 2022 ] Eval epoch: 38
[ Wed Oct  5 17:38:53 2022 ] 	Mean test loss of 796 batches: 0.6375658415894413.
[ Wed Oct  5 17:38:53 2022 ] 	Top1: 80.43%
[ Wed Oct  5 17:38:54 2022 ] 	Top5: 96.22%
[ Wed Oct  5 17:38:54 2022 ] Training epoch: 39
[ Wed Oct  5 17:41:51 2022 ] 	Mean training loss: 0.3306.  Mean training acc: 89.99%.
[ Wed Oct  5 17:41:51 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:41:51 2022 ] Eval epoch: 39
[ Wed Oct  5 17:42:36 2022 ] 	Mean test loss of 796 batches: 0.6250323579183326.
[ Wed Oct  5 17:42:36 2022 ] 	Top1: 81.07%
[ Wed Oct  5 17:42:37 2022 ] 	Top5: 96.40%
[ Wed Oct  5 17:42:37 2022 ] Training epoch: 40
[ Wed Oct  5 17:45:34 2022 ] 	Mean training loss: 0.3043.  Mean training acc: 90.92%.
[ Wed Oct  5 17:45:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 17:45:34 2022 ] Eval epoch: 40
[ Wed Oct  5 17:46:19 2022 ] 	Mean test loss of 796 batches: 0.6401351011690483.
[ Wed Oct  5 17:46:19 2022 ] 	Top1: 80.97%
[ Wed Oct  5 17:46:19 2022 ] 	Top5: 96.14%
[ Wed Oct  5 17:46:19 2022 ] Training epoch: 41
[ Wed Oct  5 17:49:17 2022 ] 	Mean training loss: 0.2936.  Mean training acc: 91.08%.
[ Wed Oct  5 17:49:17 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:49:17 2022 ] Eval epoch: 41
[ Wed Oct  5 17:50:02 2022 ] 	Mean test loss of 796 batches: 0.6369481328219625.
[ Wed Oct  5 17:50:02 2022 ] 	Top1: 80.84%
[ Wed Oct  5 17:50:02 2022 ] 	Top5: 96.31%
[ Wed Oct  5 17:50:02 2022 ] Training epoch: 42
[ Wed Oct  5 17:52:59 2022 ] 	Mean training loss: 0.2752.  Mean training acc: 91.81%.
[ Wed Oct  5 17:52:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:53:00 2022 ] Eval epoch: 42
[ Wed Oct  5 17:53:44 2022 ] 	Mean test loss of 796 batches: 0.6570500060635146.
[ Wed Oct  5 17:53:44 2022 ] 	Top1: 80.38%
[ Wed Oct  5 17:53:45 2022 ] 	Top5: 96.01%
[ Wed Oct  5 17:53:45 2022 ] Training epoch: 43
[ Wed Oct  5 17:56:42 2022 ] 	Mean training loss: 0.2665.  Mean training acc: 92.22%.
[ Wed Oct  5 17:56:42 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 17:56:42 2022 ] Eval epoch: 43
[ Wed Oct  5 17:57:27 2022 ] 	Mean test loss of 796 batches: 0.8744450489330531.
[ Wed Oct  5 17:57:27 2022 ] 	Top1: 75.29%
[ Wed Oct  5 17:57:27 2022 ] 	Top5: 93.76%
[ Wed Oct  5 17:57:27 2022 ] Training epoch: 44
[ Wed Oct  5 18:00:25 2022 ] 	Mean training loss: 0.2529.  Mean training acc: 92.55%.
[ Wed Oct  5 18:00:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:00:25 2022 ] Eval epoch: 44
[ Wed Oct  5 18:01:09 2022 ] 	Mean test loss of 796 batches: 0.760665487498045.
[ Wed Oct  5 18:01:09 2022 ] 	Top1: 78.52%
[ Wed Oct  5 18:01:10 2022 ] 	Top5: 95.09%
[ Wed Oct  5 18:01:10 2022 ] Training epoch: 45
[ Wed Oct  5 18:04:07 2022 ] 	Mean training loss: 0.2458.  Mean training acc: 92.81%.
[ Wed Oct  5 18:04:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:04:07 2022 ] Eval epoch: 45
[ Wed Oct  5 18:04:52 2022 ] 	Mean test loss of 796 batches: 0.6932222981792149.
[ Wed Oct  5 18:04:52 2022 ] 	Top1: 79.73%
[ Wed Oct  5 18:04:52 2022 ] 	Top5: 95.80%
[ Wed Oct  5 18:04:52 2022 ] Training epoch: 46
[ Wed Oct  5 18:07:50 2022 ] 	Mean training loss: 0.2306.  Mean training acc: 93.32%.
[ Wed Oct  5 18:07:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:07:50 2022 ] Eval epoch: 46
[ Wed Oct  5 18:08:35 2022 ] 	Mean test loss of 796 batches: 0.7111468874292457.
[ Wed Oct  5 18:08:35 2022 ] 	Top1: 79.63%
[ Wed Oct  5 18:08:35 2022 ] 	Top5: 95.80%
[ Wed Oct  5 18:08:35 2022 ] Training epoch: 47
[ Wed Oct  5 18:11:33 2022 ] 	Mean training loss: 0.2347.  Mean training acc: 93.19%.
[ Wed Oct  5 18:11:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:11:33 2022 ] Eval epoch: 47
[ Wed Oct  5 18:12:17 2022 ] 	Mean test loss of 796 batches: 0.6847588392021369.
[ Wed Oct  5 18:12:17 2022 ] 	Top1: 80.25%
[ Wed Oct  5 18:12:18 2022 ] 	Top5: 95.98%
[ Wed Oct  5 18:12:18 2022 ] Training epoch: 48
[ Wed Oct  5 18:15:15 2022 ] 	Mean training loss: 0.2242.  Mean training acc: 93.45%.
[ Wed Oct  5 18:15:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:15:15 2022 ] Eval epoch: 48
[ Wed Oct  5 18:16:00 2022 ] 	Mean test loss of 796 batches: 0.8542440565649289.
[ Wed Oct  5 18:16:00 2022 ] 	Top1: 76.63%
[ Wed Oct  5 18:16:01 2022 ] 	Top5: 94.15%
[ Wed Oct  5 18:16:01 2022 ] Training epoch: 49
[ Wed Oct  5 18:18:58 2022 ] 	Mean training loss: 0.2253.  Mean training acc: 93.57%.
[ Wed Oct  5 18:18:58 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:18:58 2022 ] Eval epoch: 49
[ Wed Oct  5 18:19:43 2022 ] 	Mean test loss of 796 batches: 0.8342038284069929.
[ Wed Oct  5 18:19:43 2022 ] 	Top1: 76.70%
[ Wed Oct  5 18:19:44 2022 ] 	Top5: 94.36%
[ Wed Oct  5 18:19:44 2022 ] Training epoch: 50
[ Wed Oct  5 18:22:41 2022 ] 	Mean training loss: 0.2212.  Mean training acc: 93.59%.
[ Wed Oct  5 18:22:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:22:41 2022 ] Eval epoch: 50
[ Wed Oct  5 18:23:26 2022 ] 	Mean test loss of 796 batches: 0.7064483155070538.
[ Wed Oct  5 18:23:26 2022 ] 	Top1: 79.72%
[ Wed Oct  5 18:23:26 2022 ] 	Top5: 95.63%
[ Wed Oct  5 18:23:27 2022 ] Training epoch: 51
[ Wed Oct  5 18:26:24 2022 ] 	Mean training loss: 0.2175.  Mean training acc: 93.65%.
[ Wed Oct  5 18:26:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:26:24 2022 ] Eval epoch: 51
[ Wed Oct  5 18:27:09 2022 ] 	Mean test loss of 796 batches: 0.7601004265173895.
[ Wed Oct  5 18:27:09 2022 ] 	Top1: 78.23%
[ Wed Oct  5 18:27:09 2022 ] 	Top5: 95.37%
[ Wed Oct  5 18:27:09 2022 ] Training epoch: 52
[ Wed Oct  5 18:30:07 2022 ] 	Mean training loss: 0.2100.  Mean training acc: 94.00%.
[ Wed Oct  5 18:30:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:30:07 2022 ] Eval epoch: 52
[ Wed Oct  5 18:30:51 2022 ] 	Mean test loss of 796 batches: 0.7574701816143103.
[ Wed Oct  5 18:30:52 2022 ] 	Top1: 78.78%
[ Wed Oct  5 18:30:52 2022 ] 	Top5: 95.43%
[ Wed Oct  5 18:30:52 2022 ] Training epoch: 53
[ Wed Oct  5 18:33:50 2022 ] 	Mean training loss: 0.2141.  Mean training acc: 93.71%.
[ Wed Oct  5 18:33:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:33:50 2022 ] Eval epoch: 53
[ Wed Oct  5 18:34:34 2022 ] 	Mean test loss of 796 batches: 0.7442373004297366.
[ Wed Oct  5 18:34:35 2022 ] 	Top1: 79.10%
[ Wed Oct  5 18:34:35 2022 ] 	Top5: 95.52%
[ Wed Oct  5 18:34:35 2022 ] Training epoch: 54
[ Wed Oct  5 18:37:33 2022 ] 	Mean training loss: 0.2084.  Mean training acc: 94.11%.
[ Wed Oct  5 18:37:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:37:33 2022 ] Eval epoch: 54
[ Wed Oct  5 18:38:18 2022 ] 	Mean test loss of 796 batches: 0.8257989774472151.
[ Wed Oct  5 18:38:18 2022 ] 	Top1: 77.60%
[ Wed Oct  5 18:38:18 2022 ] 	Top5: 94.61%
[ Wed Oct  5 18:38:18 2022 ] Training epoch: 55
[ Wed Oct  5 18:41:16 2022 ] 	Mean training loss: 0.2124.  Mean training acc: 93.80%.
[ Wed Oct  5 18:41:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:41:16 2022 ] Eval epoch: 55
[ Wed Oct  5 18:42:01 2022 ] 	Mean test loss of 796 batches: 0.7534976385758451.
[ Wed Oct  5 18:42:01 2022 ] 	Top1: 79.36%
[ Wed Oct  5 18:42:02 2022 ] 	Top5: 95.51%
[ Wed Oct  5 18:42:02 2022 ] Training epoch: 56
[ Wed Oct  5 18:44:59 2022 ] 	Mean training loss: 0.1290.  Mean training acc: 96.78%.
[ Wed Oct  5 18:44:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:45:00 2022 ] Eval epoch: 56
[ Wed Oct  5 18:45:44 2022 ] 	Mean test loss of 796 batches: 0.6622169712492868.
[ Wed Oct  5 18:45:45 2022 ] 	Top1: 81.59%
[ Wed Oct  5 18:45:45 2022 ] 	Top5: 96.16%
[ Wed Oct  5 18:45:45 2022 ] Training epoch: 57
[ Wed Oct  5 18:48:43 2022 ] 	Mean training loss: 0.0997.  Mean training acc: 97.77%.
[ Wed Oct  5 18:48:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:48:43 2022 ] Eval epoch: 57
[ Wed Oct  5 18:49:27 2022 ] 	Mean test loss of 796 batches: 0.6577393646965075.
[ Wed Oct  5 18:49:27 2022 ] 	Top1: 81.76%
[ Wed Oct  5 18:49:28 2022 ] 	Top5: 96.21%
[ Wed Oct  5 18:49:28 2022 ] Training epoch: 58
[ Wed Oct  5 18:52:25 2022 ] 	Mean training loss: 0.0905.  Mean training acc: 97.98%.
[ Wed Oct  5 18:52:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:52:25 2022 ] Eval epoch: 58
[ Wed Oct  5 18:53:09 2022 ] 	Mean test loss of 796 batches: 0.6649600030227223.
[ Wed Oct  5 18:53:10 2022 ] 	Top1: 81.63%
[ Wed Oct  5 18:53:10 2022 ] 	Top5: 96.12%
[ Wed Oct  5 18:53:10 2022 ] Training epoch: 59
[ Wed Oct  5 18:56:07 2022 ] 	Mean training loss: 0.0851.  Mean training acc: 98.24%.
[ Wed Oct  5 18:56:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 18:56:07 2022 ] Eval epoch: 59
[ Wed Oct  5 18:56:52 2022 ] 	Mean test loss of 796 batches: 0.6728798062563991.
[ Wed Oct  5 18:56:52 2022 ] 	Top1: 81.57%
[ Wed Oct  5 18:56:52 2022 ] 	Top5: 96.09%
[ Wed Oct  5 18:56:53 2022 ] Training epoch: 60
[ Wed Oct  5 18:59:50 2022 ] 	Mean training loss: 0.0807.  Mean training acc: 98.38%.
[ Wed Oct  5 18:59:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 18:59:50 2022 ] Eval epoch: 60
[ Wed Oct  5 19:00:35 2022 ] 	Mean test loss of 796 batches: 0.6703203896238427.
[ Wed Oct  5 19:00:35 2022 ] 	Top1: 81.66%
[ Wed Oct  5 19:00:35 2022 ] 	Top5: 96.06%
[ Wed Oct  5 19:00:35 2022 ] Training epoch: 61
[ Wed Oct  5 19:03:33 2022 ] 	Mean training loss: 0.0760.  Mean training acc: 98.46%.
[ Wed Oct  5 19:03:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 19:03:33 2022 ] Eval epoch: 61
[ Wed Oct  5 19:04:18 2022 ] 	Mean test loss of 796 batches: 0.6749633356329784.
[ Wed Oct  5 19:04:18 2022 ] 	Top1: 81.68%
[ Wed Oct  5 19:04:18 2022 ] 	Top5: 96.13%
[ Wed Oct  5 19:04:18 2022 ] Training epoch: 62
[ Wed Oct  5 19:07:16 2022 ] 	Mean training loss: 0.0728.  Mean training acc: 98.56%.
[ Wed Oct  5 19:07:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 19:07:16 2022 ] Eval epoch: 62
[ Wed Oct  5 19:08:00 2022 ] 	Mean test loss of 796 batches: 0.6804789923243786.
[ Wed Oct  5 19:08:00 2022 ] 	Top1: 81.41%
[ Wed Oct  5 19:08:01 2022 ] 	Top5: 96.02%
[ Wed Oct  5 19:08:01 2022 ] Training epoch: 63
[ Wed Oct  5 19:10:58 2022 ] 	Mean training loss: 0.0686.  Mean training acc: 98.67%.
[ Wed Oct  5 19:10:58 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 19:10:58 2022 ] Eval epoch: 63
[ Wed Oct  5 19:11:43 2022 ] 	Mean test loss of 796 batches: 0.682620661595284.
[ Wed Oct  5 19:11:44 2022 ] 	Top1: 81.56%
[ Wed Oct  5 19:11:44 2022 ] 	Top5: 95.99%
[ Wed Oct  5 19:11:44 2022 ] Training epoch: 64
[ Wed Oct  5 19:14:41 2022 ] 	Mean training loss: 0.0676.  Mean training acc: 98.67%.
[ Wed Oct  5 19:14:41 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 19:14:41 2022 ] Eval epoch: 64
[ Wed Oct  5 19:15:26 2022 ] 	Mean test loss of 796 batches: 0.6849015255613093.
[ Wed Oct  5 19:15:26 2022 ] 	Top1: 81.54%
[ Wed Oct  5 19:15:26 2022 ] 	Top5: 95.94%
[ Wed Oct  5 19:15:26 2022 ] Training epoch: 65
[ Wed Oct  5 19:18:24 2022 ] 	Mean training loss: 0.0652.  Mean training acc: 98.76%.
[ Wed Oct  5 19:18:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Oct  5 19:18:24 2022 ] Eval epoch: 65
[ Wed Oct  5 19:19:08 2022 ] 	Mean test loss of 796 batches: 0.6863114603949552.
[ Wed Oct  5 19:19:09 2022 ] 	Top1: 81.43%
[ Wed Oct  5 19:19:09 2022 ] 	Top5: 95.93%
[ Wed Oct  5 19:19:55 2022 ] Best accuracy: 0.8176319252145564
[ Wed Oct  5 19:19:55 2022 ] Epoch number: 57
[ Wed Oct  5 19:19:55 2022 ] Model name: work_dir/ntu120/csub/global_azimuth_rot
[ Wed Oct  5 19:19:55 2022 ] Model total number of params: 2107810
[ Wed Oct  5 19:19:55 2022 ] Weight decay: 0.0004
[ Wed Oct  5 19:19:55 2022 ] Base LR: 0.1
[ Wed Oct  5 19:19:55 2022 ] Batch Size: 64
[ Wed Oct  5 19:19:55 2022 ] Test Batch Size: 64
[ Wed Oct  5 19:19:55 2022 ] seed: 1
