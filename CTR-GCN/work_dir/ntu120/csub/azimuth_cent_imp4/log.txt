[ Wed Sep 28 13:39:37 2022 ] using warm up, epoch: 5
[ Wed Sep 28 13:41:41 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/azimuth_cent_imp4', 'model_saved_name': 'work_dir/ntu120/csub/azimuth_cent_imp4/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.azimuth_BN_G2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Sep 28 13:41:41 2022 ] # Parameters: 2107660
[ Wed Sep 28 13:41:41 2022 ] Training epoch: 1
[ Wed Sep 28 13:45:02 2022 ] 	Mean training loss: 3.0049.  Mean training acc: 24.71%.
[ Wed Sep 28 13:45:02 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:45:02 2022 ] Eval epoch: 1
[ Wed Sep 28 13:45:51 2022 ] 	Mean test loss of 796 batches: 3.4493856582809332.
[ Wed Sep 28 13:45:51 2022 ] 	Top1: 19.22%
[ Wed Sep 28 13:45:52 2022 ] 	Top5: 46.98%
[ Wed Sep 28 13:45:52 2022 ] Training epoch: 2
[ Wed Sep 28 13:49:07 2022 ] 	Mean training loss: 2.0190.  Mean training acc: 43.82%.
[ Wed Sep 28 13:49:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:49:07 2022 ] Eval epoch: 2
[ Wed Sep 28 13:49:55 2022 ] 	Mean test loss of 796 batches: 2.086095249533054.
[ Wed Sep 28 13:49:56 2022 ] 	Top1: 40.62%
[ Wed Sep 28 13:49:56 2022 ] 	Top5: 76.25%
[ Wed Sep 28 13:49:56 2022 ] Training epoch: 3
[ Wed Sep 28 13:53:11 2022 ] 	Mean training loss: 1.6838.  Mean training acc: 51.69%.
[ Wed Sep 28 13:53:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:53:11 2022 ] Eval epoch: 3
[ Wed Sep 28 13:54:00 2022 ] 	Mean test loss of 796 batches: 3.288674356799629.
[ Wed Sep 28 13:54:00 2022 ] 	Top1: 30.75%
[ Wed Sep 28 13:54:01 2022 ] 	Top5: 58.60%
[ Wed Sep 28 13:54:01 2022 ] Training epoch: 4
[ Wed Sep 28 13:57:16 2022 ] 	Mean training loss: 1.5348.  Mean training acc: 55.76%.
[ Wed Sep 28 13:57:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 13:57:16 2022 ] Eval epoch: 4
[ Wed Sep 28 13:58:04 2022 ] 	Mean test loss of 796 batches: 2.5770465318282048.
[ Wed Sep 28 13:58:05 2022 ] 	Top1: 37.73%
[ Wed Sep 28 13:58:05 2022 ] 	Top5: 72.39%
[ Wed Sep 28 13:58:05 2022 ] Training epoch: 5
[ Wed Sep 28 14:01:21 2022 ] 	Mean training loss: 1.3973.  Mean training acc: 58.89%.
[ Wed Sep 28 14:01:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:01:21 2022 ] Eval epoch: 5
[ Wed Sep 28 14:02:09 2022 ] 	Mean test loss of 796 batches: 1.5238192235704642.
[ Wed Sep 28 14:02:10 2022 ] 	Top1: 55.60%
[ Wed Sep 28 14:02:10 2022 ] 	Top5: 85.37%
[ Wed Sep 28 14:02:10 2022 ] Training epoch: 6
[ Wed Sep 28 14:05:25 2022 ] 	Mean training loss: 1.2536.  Mean training acc: 62.94%.
[ Wed Sep 28 14:05:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:05:25 2022 ] Eval epoch: 6
[ Wed Sep 28 14:06:14 2022 ] 	Mean test loss of 796 batches: 1.344800998068335.
[ Wed Sep 28 14:06:15 2022 ] 	Top1: 59.26%
[ Wed Sep 28 14:06:15 2022 ] 	Top5: 89.02%
[ Wed Sep 28 14:06:15 2022 ] Training epoch: 7
[ Wed Sep 28 14:09:30 2022 ] 	Mean training loss: 1.1560.  Mean training acc: 65.61%.
[ Wed Sep 28 14:09:30 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:09:30 2022 ] Eval epoch: 7
[ Wed Sep 28 14:10:18 2022 ] 	Mean test loss of 796 batches: 1.435376404068578.
[ Wed Sep 28 14:10:19 2022 ] 	Top1: 58.85%
[ Wed Sep 28 14:10:19 2022 ] 	Top5: 88.72%
[ Wed Sep 28 14:10:19 2022 ] Training epoch: 8
[ Wed Sep 28 14:13:34 2022 ] 	Mean training loss: 1.0978.  Mean training acc: 67.46%.
[ Wed Sep 28 14:13:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:13:34 2022 ] Eval epoch: 8
[ Wed Sep 28 14:14:23 2022 ] 	Mean test loss of 796 batches: 1.4753783320512004.
[ Wed Sep 28 14:14:23 2022 ] 	Top1: 58.20%
[ Wed Sep 28 14:14:24 2022 ] 	Top5: 86.52%
[ Wed Sep 28 14:14:24 2022 ] Training epoch: 9
[ Wed Sep 28 14:17:39 2022 ] 	Mean training loss: 1.0431.  Mean training acc: 68.87%.
[ Wed Sep 28 14:17:39 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:17:39 2022 ] Eval epoch: 9
[ Wed Sep 28 14:18:27 2022 ] 	Mean test loss of 796 batches: 1.23364235745303.
[ Wed Sep 28 14:18:28 2022 ] 	Top1: 63.71%
[ Wed Sep 28 14:18:28 2022 ] 	Top5: 90.23%
[ Wed Sep 28 14:18:28 2022 ] Training epoch: 10
[ Wed Sep 28 14:21:41 2022 ] 	Mean training loss: 1.0049.  Mean training acc: 69.89%.
[ Wed Sep 28 14:21:41 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:21:41 2022 ] Eval epoch: 10
[ Wed Sep 28 14:22:26 2022 ] 	Mean test loss of 796 batches: 1.2582951839545264.
[ Wed Sep 28 14:22:26 2022 ] 	Top1: 64.19%
[ Wed Sep 28 14:22:27 2022 ] 	Top5: 88.81%
[ Wed Sep 28 14:22:27 2022 ] Training epoch: 11
[ Wed Sep 28 14:26:11 2022 ] 	Mean training loss: 0.9705.  Mean training acc: 70.86%.
[ Wed Sep 28 14:26:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:26:11 2022 ] Eval epoch: 11
[ Wed Sep 28 14:26:57 2022 ] 	Mean test loss of 796 batches: 1.4723258255115106.
[ Wed Sep 28 14:26:57 2022 ] 	Top1: 58.86%
[ Wed Sep 28 14:26:57 2022 ] 	Top5: 86.27%
[ Wed Sep 28 14:26:57 2022 ] Training epoch: 12
[ Wed Sep 28 14:30:57 2022 ] 	Mean training loss: 0.9452.  Mean training acc: 71.72%.
[ Wed Sep 28 14:30:57 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:30:57 2022 ] Eval epoch: 12
[ Wed Sep 28 14:32:14 2022 ] 	Mean test loss of 796 batches: 1.376957206757524.
[ Wed Sep 28 14:32:15 2022 ] 	Top1: 62.29%
[ Wed Sep 28 14:32:15 2022 ] 	Top5: 86.71%
[ Wed Sep 28 14:32:15 2022 ] Training epoch: 13
[ Wed Sep 28 14:37:25 2022 ] 	Mean training loss: 0.9265.  Mean training acc: 72.24%.
[ Wed Sep 28 14:37:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:37:25 2022 ] Eval epoch: 13
[ Wed Sep 28 14:38:31 2022 ] 	Mean test loss of 796 batches: 1.87148111863951.
[ Wed Sep 28 14:38:32 2022 ] 	Top1: 50.29%
[ Wed Sep 28 14:38:32 2022 ] 	Top5: 80.36%
[ Wed Sep 28 14:38:32 2022 ] Training epoch: 14
[ Wed Sep 28 14:44:04 2022 ] 	Mean training loss: 0.9102.  Mean training acc: 72.67%.
[ Wed Sep 28 14:44:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Sep 28 14:44:04 2022 ] Eval epoch: 14
[ Wed Sep 28 14:45:44 2022 ] 	Mean test loss of 796 batches: 1.181189884754581.
[ Wed Sep 28 14:45:45 2022 ] 	Top1: 64.14%
[ Wed Sep 28 14:45:45 2022 ] 	Top5: 90.74%
[ Wed Sep 28 14:45:45 2022 ] Training epoch: 15
[ Wed Sep 28 14:49:56 2022 ] 	Mean training loss: 0.8967.  Mean training acc: 73.22%.
[ Wed Sep 28 14:49:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:49:56 2022 ] Eval epoch: 15
[ Wed Sep 28 14:50:42 2022 ] 	Mean test loss of 796 batches: 3.5406709909439087.
[ Wed Sep 28 14:50:42 2022 ] 	Top1: 34.77%
[ Wed Sep 28 14:50:42 2022 ] 	Top5: 62.71%
[ Wed Sep 28 14:50:42 2022 ] Training epoch: 16
[ Wed Sep 28 14:53:55 2022 ] 	Mean training loss: 0.8861.  Mean training acc: 73.41%.
[ Wed Sep 28 14:53:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:53:55 2022 ] Eval epoch: 16
[ Wed Sep 28 14:54:44 2022 ] 	Mean test loss of 796 batches: 1.3153811454323667.
[ Wed Sep 28 14:54:44 2022 ] 	Top1: 63.49%
[ Wed Sep 28 14:54:45 2022 ] 	Top5: 88.13%
[ Wed Sep 28 14:54:45 2022 ] Training epoch: 17
[ Wed Sep 28 14:58:00 2022 ] 	Mean training loss: 0.8743.  Mean training acc: 73.71%.
[ Wed Sep 28 14:58:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 14:58:00 2022 ] Eval epoch: 17
[ Wed Sep 28 14:58:48 2022 ] 	Mean test loss of 796 batches: 1.4476234792315181.
[ Wed Sep 28 14:58:49 2022 ] 	Top1: 59.07%
[ Wed Sep 28 14:58:49 2022 ] 	Top5: 87.33%
[ Wed Sep 28 14:58:49 2022 ] Training epoch: 18
[ Wed Sep 28 15:02:04 2022 ] 	Mean training loss: 0.8686.  Mean training acc: 73.83%.
[ Wed Sep 28 15:02:04 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:02:04 2022 ] Eval epoch: 18
[ Wed Sep 28 15:02:53 2022 ] 	Mean test loss of 796 batches: 1.6145131959388004.
[ Wed Sep 28 15:02:53 2022 ] 	Top1: 57.55%
[ Wed Sep 28 15:02:54 2022 ] 	Top5: 84.88%
[ Wed Sep 28 15:02:54 2022 ] Training epoch: 19
[ Wed Sep 28 15:06:09 2022 ] 	Mean training loss: 0.8697.  Mean training acc: 73.96%.
[ Wed Sep 28 15:06:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:06:09 2022 ] Eval epoch: 19
[ Wed Sep 28 15:06:57 2022 ] 	Mean test loss of 796 batches: 1.218209302979498.
[ Wed Sep 28 15:06:57 2022 ] 	Top1: 65.02%
[ Wed Sep 28 15:06:58 2022 ] 	Top5: 90.00%
[ Wed Sep 28 15:06:58 2022 ] Training epoch: 20
[ Wed Sep 28 15:10:12 2022 ] 	Mean training loss: 0.8508.  Mean training acc: 74.44%.
[ Wed Sep 28 15:10:12 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:10:12 2022 ] Eval epoch: 20
[ Wed Sep 28 15:11:01 2022 ] 	Mean test loss of 796 batches: 1.4246960126574915.
[ Wed Sep 28 15:11:01 2022 ] 	Top1: 59.94%
[ Wed Sep 28 15:11:02 2022 ] 	Top5: 86.71%
[ Wed Sep 28 15:11:02 2022 ] Training epoch: 21
[ Wed Sep 28 15:14:17 2022 ] 	Mean training loss: 0.8425.  Mean training acc: 74.52%.
[ Wed Sep 28 15:14:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:14:17 2022 ] Eval epoch: 21
[ Wed Sep 28 15:15:05 2022 ] 	Mean test loss of 796 batches: 2.674139181123906.
[ Wed Sep 28 15:15:06 2022 ] 	Top1: 39.96%
[ Wed Sep 28 15:15:06 2022 ] 	Top5: 68.37%
[ Wed Sep 28 15:15:06 2022 ] Training epoch: 22
[ Wed Sep 28 15:18:21 2022 ] 	Mean training loss: 0.8437.  Mean training acc: 74.55%.
[ Wed Sep 28 15:18:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:18:21 2022 ] Eval epoch: 22
[ Wed Sep 28 15:19:10 2022 ] 	Mean test loss of 796 batches: 1.2865780606940762.
[ Wed Sep 28 15:19:10 2022 ] 	Top1: 62.80%
[ Wed Sep 28 15:19:11 2022 ] 	Top5: 89.05%
[ Wed Sep 28 15:19:11 2022 ] Training epoch: 23
[ Wed Sep 28 15:22:26 2022 ] 	Mean training loss: 0.8305.  Mean training acc: 74.87%.
[ Wed Sep 28 15:22:26 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:22:26 2022 ] Eval epoch: 23
[ Wed Sep 28 15:23:14 2022 ] 	Mean test loss of 796 batches: 1.5416689259772325.
[ Wed Sep 28 15:23:15 2022 ] 	Top1: 60.15%
[ Wed Sep 28 15:23:15 2022 ] 	Top5: 85.22%
[ Wed Sep 28 15:23:15 2022 ] Training epoch: 24
[ Wed Sep 28 15:26:30 2022 ] 	Mean training loss: 0.8312.  Mean training acc: 74.96%.
[ Wed Sep 28 15:26:30 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:26:30 2022 ] Eval epoch: 24
[ Wed Sep 28 15:27:19 2022 ] 	Mean test loss of 796 batches: 1.4501894825517232.
[ Wed Sep 28 15:27:19 2022 ] 	Top1: 60.30%
[ Wed Sep 28 15:27:20 2022 ] 	Top5: 87.16%
[ Wed Sep 28 15:27:20 2022 ] Training epoch: 25
[ Wed Sep 28 15:30:35 2022 ] 	Mean training loss: 0.8260.  Mean training acc: 75.33%.
[ Wed Sep 28 15:30:35 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:30:35 2022 ] Eval epoch: 25
[ Wed Sep 28 15:31:23 2022 ] 	Mean test loss of 796 batches: 1.2278379097056749.
[ Wed Sep 28 15:31:24 2022 ] 	Top1: 64.70%
[ Wed Sep 28 15:31:24 2022 ] 	Top5: 90.57%
[ Wed Sep 28 15:31:24 2022 ] Training epoch: 26
[ Wed Sep 28 15:34:27 2022 ] 	Mean training loss: 0.8289.  Mean training acc: 74.99%.
[ Wed Sep 28 15:34:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:34:27 2022 ] Eval epoch: 26
[ Wed Sep 28 15:35:13 2022 ] 	Mean test loss of 796 batches: 1.915910071089639.
[ Wed Sep 28 15:35:13 2022 ] 	Top1: 53.25%
[ Wed Sep 28 15:35:13 2022 ] 	Top5: 82.10%
[ Wed Sep 28 15:35:13 2022 ] Training epoch: 27
[ Wed Sep 28 15:38:16 2022 ] 	Mean training loss: 0.8191.  Mean training acc: 75.41%.
[ Wed Sep 28 15:38:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:38:16 2022 ] Eval epoch: 27
[ Wed Sep 28 15:39:03 2022 ] 	Mean test loss of 796 batches: 1.1662753564703405.
[ Wed Sep 28 15:39:03 2022 ] 	Top1: 66.58%
[ Wed Sep 28 15:39:03 2022 ] 	Top5: 90.09%
[ Wed Sep 28 15:39:03 2022 ] Training epoch: 28
[ Wed Sep 28 15:42:06 2022 ] 	Mean training loss: 0.8114.  Mean training acc: 75.27%.
[ Wed Sep 28 15:42:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:42:06 2022 ] Eval epoch: 28
[ Wed Sep 28 15:42:52 2022 ] 	Mean test loss of 796 batches: 2.1748297846497002.
[ Wed Sep 28 15:42:52 2022 ] 	Top1: 47.35%
[ Wed Sep 28 15:42:53 2022 ] 	Top5: 76.49%
[ Wed Sep 28 15:42:53 2022 ] Training epoch: 29
[ Wed Sep 28 15:45:55 2022 ] 	Mean training loss: 0.8080.  Mean training acc: 75.72%.
[ Wed Sep 28 15:45:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:45:55 2022 ] Eval epoch: 29
[ Wed Sep 28 15:46:41 2022 ] 	Mean test loss of 796 batches: 1.0891589220968922.
[ Wed Sep 28 15:46:41 2022 ] 	Top1: 67.83%
[ Wed Sep 28 15:46:41 2022 ] 	Top5: 91.92%
[ Wed Sep 28 15:46:41 2022 ] Training epoch: 30
[ Wed Sep 28 15:49:44 2022 ] 	Mean training loss: 0.8098.  Mean training acc: 75.45%.
[ Wed Sep 28 15:49:44 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:49:44 2022 ] Eval epoch: 30
[ Wed Sep 28 15:50:29 2022 ] 	Mean test loss of 796 batches: 1.0284040562771073.
[ Wed Sep 28 15:50:30 2022 ] 	Top1: 70.46%
[ Wed Sep 28 15:50:30 2022 ] 	Top5: 92.21%
[ Wed Sep 28 15:50:30 2022 ] Training epoch: 31
[ Wed Sep 28 15:53:33 2022 ] 	Mean training loss: 0.8059.  Mean training acc: 75.57%.
[ Wed Sep 28 15:53:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 15:53:33 2022 ] Eval epoch: 31
[ Wed Sep 28 15:54:19 2022 ] 	Mean test loss of 796 batches: 1.4050170951827088.
[ Wed Sep 28 15:54:19 2022 ] 	Top1: 61.14%
[ Wed Sep 28 15:54:19 2022 ] 	Top5: 87.75%
[ Wed Sep 28 15:54:19 2022 ] Training epoch: 32
[ Wed Sep 28 15:57:22 2022 ] 	Mean training loss: 0.8093.  Mean training acc: 75.73%.
[ Wed Sep 28 15:57:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 15:57:22 2022 ] Eval epoch: 32
[ Wed Sep 28 15:58:08 2022 ] 	Mean test loss of 796 batches: 2.3845047684171092.
[ Wed Sep 28 15:58:08 2022 ] 	Top1: 43.91%
[ Wed Sep 28 15:58:08 2022 ] 	Top5: 72.10%
[ Wed Sep 28 15:58:09 2022 ] Training epoch: 33
[ Wed Sep 28 16:01:15 2022 ] 	Mean training loss: 0.8027.  Mean training acc: 75.86%.
[ Wed Sep 28 16:01:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:01:16 2022 ] Eval epoch: 33
[ Wed Sep 28 16:02:04 2022 ] 	Mean test loss of 796 batches: 1.116504948380305.
[ Wed Sep 28 16:02:04 2022 ] 	Top1: 67.05%
[ Wed Sep 28 16:02:05 2022 ] 	Top5: 91.26%
[ Wed Sep 28 16:02:05 2022 ] Training epoch: 34
[ Wed Sep 28 16:05:20 2022 ] 	Mean training loss: 0.7957.  Mean training acc: 75.97%.
[ Wed Sep 28 16:05:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:05:20 2022 ] Eval epoch: 34
[ Wed Sep 28 16:06:09 2022 ] 	Mean test loss of 796 batches: 1.22013596793515.
[ Wed Sep 28 16:06:10 2022 ] 	Top1: 65.78%
[ Wed Sep 28 16:06:10 2022 ] 	Top5: 89.46%
[ Wed Sep 28 16:06:10 2022 ] Training epoch: 35
[ Wed Sep 28 16:09:25 2022 ] 	Mean training loss: 0.8030.  Mean training acc: 75.89%.
[ Wed Sep 28 16:09:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:09:25 2022 ] Eval epoch: 35
[ Wed Sep 28 16:10:13 2022 ] 	Mean test loss of 796 batches: 2.1287439898330365.
[ Wed Sep 28 16:10:14 2022 ] 	Top1: 48.57%
[ Wed Sep 28 16:10:14 2022 ] 	Top5: 76.91%
[ Wed Sep 28 16:10:14 2022 ] Training epoch: 36
[ Wed Sep 28 16:13:30 2022 ] 	Mean training loss: 0.4863.  Mean training acc: 85.29%.
[ Wed Sep 28 16:13:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:13:30 2022 ] Eval epoch: 36
[ Wed Sep 28 16:14:18 2022 ] 	Mean test loss of 796 batches: 0.653615764543489.
[ Wed Sep 28 16:14:18 2022 ] 	Top1: 80.06%
[ Wed Sep 28 16:14:19 2022 ] 	Top5: 95.91%
[ Wed Sep 28 16:14:19 2022 ] Training epoch: 37
[ Wed Sep 28 16:17:34 2022 ] 	Mean training loss: 0.4040.  Mean training acc: 87.85%.
[ Wed Sep 28 16:17:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:17:34 2022 ] Eval epoch: 37
[ Wed Sep 28 16:18:22 2022 ] 	Mean test loss of 796 batches: 0.6358974467232898.
[ Wed Sep 28 16:18:22 2022 ] 	Top1: 80.61%
[ Wed Sep 28 16:18:23 2022 ] 	Top5: 96.10%
[ Wed Sep 28 16:18:23 2022 ] Training epoch: 38
[ Wed Sep 28 16:21:38 2022 ] 	Mean training loss: 0.3687.  Mean training acc: 88.76%.
[ Wed Sep 28 16:21:38 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:21:38 2022 ] Eval epoch: 38
[ Wed Sep 28 16:22:27 2022 ] 	Mean test loss of 796 batches: 0.667501230766276.
[ Wed Sep 28 16:22:27 2022 ] 	Top1: 79.97%
[ Wed Sep 28 16:22:28 2022 ] 	Top5: 95.81%
[ Wed Sep 28 16:22:28 2022 ] Training epoch: 39
[ Wed Sep 28 16:25:42 2022 ] 	Mean training loss: 0.3419.  Mean training acc: 89.82%.
[ Wed Sep 28 16:25:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:25:43 2022 ] Eval epoch: 39
[ Wed Sep 28 16:26:31 2022 ] 	Mean test loss of 796 batches: 0.6435958869830148.
[ Wed Sep 28 16:26:31 2022 ] 	Top1: 80.66%
[ Wed Sep 28 16:26:32 2022 ] 	Top5: 96.11%
[ Wed Sep 28 16:26:32 2022 ] Training epoch: 40
[ Wed Sep 28 16:29:47 2022 ] 	Mean training loss: 0.3180.  Mean training acc: 90.49%.
[ Wed Sep 28 16:29:47 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:29:47 2022 ] Eval epoch: 40
[ Wed Sep 28 16:30:35 2022 ] 	Mean test loss of 796 batches: 0.6719212543181888.
[ Wed Sep 28 16:30:36 2022 ] 	Top1: 80.01%
[ Wed Sep 28 16:30:36 2022 ] 	Top5: 95.68%
[ Wed Sep 28 16:30:36 2022 ] Training epoch: 41
[ Wed Sep 28 16:33:51 2022 ] 	Mean training loss: 0.3008.  Mean training acc: 91.00%.
[ Wed Sep 28 16:33:51 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:33:51 2022 ] Eval epoch: 41
[ Wed Sep 28 16:34:40 2022 ] 	Mean test loss of 796 batches: 0.6593456531982476.
[ Wed Sep 28 16:34:41 2022 ] 	Top1: 80.36%
[ Wed Sep 28 16:34:41 2022 ] 	Top5: 96.09%
[ Wed Sep 28 16:34:41 2022 ] Training epoch: 42
[ Wed Sep 28 16:37:56 2022 ] 	Mean training loss: 0.2828.  Mean training acc: 91.52%.
[ Wed Sep 28 16:37:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:37:56 2022 ] Eval epoch: 42
[ Wed Sep 28 16:38:45 2022 ] 	Mean test loss of 796 batches: 0.6993387320907272.
[ Wed Sep 28 16:38:45 2022 ] 	Top1: 79.69%
[ Wed Sep 28 16:38:46 2022 ] 	Top5: 95.39%
[ Wed Sep 28 16:38:46 2022 ] Training epoch: 43
[ Wed Sep 28 16:41:54 2022 ] 	Mean training loss: 0.2724.  Mean training acc: 92.13%.
[ Wed Sep 28 16:41:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:41:54 2022 ] Eval epoch: 43
[ Wed Sep 28 16:42:39 2022 ] 	Mean test loss of 796 batches: 0.6741672983982755.
[ Wed Sep 28 16:42:40 2022 ] 	Top1: 80.25%
[ Wed Sep 28 16:42:40 2022 ] 	Top5: 95.90%
[ Wed Sep 28 16:42:40 2022 ] Training epoch: 44
[ Wed Sep 28 16:45:43 2022 ] 	Mean training loss: 0.2576.  Mean training acc: 92.44%.
[ Wed Sep 28 16:45:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:45:43 2022 ] Eval epoch: 44
[ Wed Sep 28 16:46:28 2022 ] 	Mean test loss of 796 batches: 0.7153657222793779.
[ Wed Sep 28 16:46:29 2022 ] 	Top1: 79.35%
[ Wed Sep 28 16:46:29 2022 ] 	Top5: 95.52%
[ Wed Sep 28 16:46:29 2022 ] Training epoch: 45
[ Wed Sep 28 16:49:32 2022 ] 	Mean training loss: 0.2508.  Mean training acc: 92.76%.
[ Wed Sep 28 16:49:32 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 16:49:32 2022 ] Eval epoch: 45
[ Wed Sep 28 16:50:18 2022 ] 	Mean test loss of 796 batches: 0.7160677077744774.
[ Wed Sep 28 16:50:18 2022 ] 	Top1: 79.33%
[ Wed Sep 28 16:50:19 2022 ] 	Top5: 95.48%
[ Wed Sep 28 16:50:19 2022 ] Training epoch: 46
[ Wed Sep 28 16:53:22 2022 ] 	Mean training loss: 0.2407.  Mean training acc: 93.09%.
[ Wed Sep 28 16:53:22 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:53:22 2022 ] Eval epoch: 46
[ Wed Sep 28 16:54:07 2022 ] 	Mean test loss of 796 batches: 0.7326593313029214.
[ Wed Sep 28 16:54:07 2022 ] 	Top1: 79.06%
[ Wed Sep 28 16:54:08 2022 ] 	Top5: 95.42%
[ Wed Sep 28 16:54:08 2022 ] Training epoch: 47
[ Wed Sep 28 16:57:10 2022 ] 	Mean training loss: 0.2343.  Mean training acc: 93.34%.
[ Wed Sep 28 16:57:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 16:57:11 2022 ] Eval epoch: 47
[ Wed Sep 28 16:57:56 2022 ] 	Mean test loss of 796 batches: 0.7107381699559976.
[ Wed Sep 28 16:57:57 2022 ] 	Top1: 79.74%
[ Wed Sep 28 16:57:57 2022 ] 	Top5: 95.56%
[ Wed Sep 28 16:57:57 2022 ] Training epoch: 48
[ Wed Sep 28 17:01:00 2022 ] 	Mean training loss: 0.2296.  Mean training acc: 93.32%.
[ Wed Sep 28 17:01:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:01:00 2022 ] Eval epoch: 48
[ Wed Sep 28 17:01:45 2022 ] 	Mean test loss of 796 batches: 0.7461421649210417.
[ Wed Sep 28 17:01:45 2022 ] 	Top1: 78.87%
[ Wed Sep 28 17:01:46 2022 ] 	Top5: 95.28%
[ Wed Sep 28 17:01:46 2022 ] Training epoch: 49
[ Wed Sep 28 17:04:48 2022 ] 	Mean training loss: 0.2302.  Mean training acc: 93.31%.
[ Wed Sep 28 17:04:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:04:48 2022 ] Eval epoch: 49
[ Wed Sep 28 17:05:34 2022 ] 	Mean test loss of 796 batches: 0.8315022468529455.
[ Wed Sep 28 17:05:34 2022 ] 	Top1: 77.11%
[ Wed Sep 28 17:05:34 2022 ] 	Top5: 94.00%
[ Wed Sep 28 17:05:34 2022 ] Training epoch: 50
[ Wed Sep 28 17:08:37 2022 ] 	Mean training loss: 0.2269.  Mean training acc: 93.56%.
[ Wed Sep 28 17:08:37 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 17:08:37 2022 ] Eval epoch: 50
[ Wed Sep 28 17:09:25 2022 ] 	Mean test loss of 796 batches: 1.0139584522600749.
[ Wed Sep 28 17:09:26 2022 ] 	Top1: 72.96%
[ Wed Sep 28 17:09:26 2022 ] 	Top5: 92.38%
[ Wed Sep 28 17:09:26 2022 ] Training epoch: 51
[ Wed Sep 28 17:12:42 2022 ] 	Mean training loss: 0.2252.  Mean training acc: 93.56%.
[ Wed Sep 28 17:12:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:12:42 2022 ] Eval epoch: 51
[ Wed Sep 28 17:13:30 2022 ] 	Mean test loss of 796 batches: 0.7908103645746433.
[ Wed Sep 28 17:13:31 2022 ] 	Top1: 77.97%
[ Wed Sep 28 17:13:31 2022 ] 	Top5: 94.90%
[ Wed Sep 28 17:13:31 2022 ] Training epoch: 52
[ Wed Sep 28 17:16:47 2022 ] 	Mean training loss: 0.2189.  Mean training acc: 93.67%.
[ Wed Sep 28 17:16:47 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:16:47 2022 ] Eval epoch: 52
[ Wed Sep 28 17:17:36 2022 ] 	Mean test loss of 796 batches: 0.8462113269965104.
[ Wed Sep 28 17:17:36 2022 ] 	Top1: 77.19%
[ Wed Sep 28 17:17:36 2022 ] 	Top5: 94.13%
[ Wed Sep 28 17:17:36 2022 ] Training epoch: 53
[ Wed Sep 28 17:20:52 2022 ] 	Mean training loss: 0.2232.  Mean training acc: 93.61%.
[ Wed Sep 28 17:20:52 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:20:52 2022 ] Eval epoch: 53
[ Wed Sep 28 17:21:40 2022 ] 	Mean test loss of 796 batches: 0.8114944483953804.
[ Wed Sep 28 17:21:41 2022 ] 	Top1: 77.75%
[ Wed Sep 28 17:21:41 2022 ] 	Top5: 94.60%
[ Wed Sep 28 17:21:41 2022 ] Training epoch: 54
[ Wed Sep 28 17:24:56 2022 ] 	Mean training loss: 0.2171.  Mean training acc: 93.77%.
[ Wed Sep 28 17:24:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:24:56 2022 ] Eval epoch: 54
[ Wed Sep 28 17:25:45 2022 ] 	Mean test loss of 796 batches: 0.802255895241496.
[ Wed Sep 28 17:25:45 2022 ] 	Top1: 78.14%
[ Wed Sep 28 17:25:46 2022 ] 	Top5: 94.81%
[ Wed Sep 28 17:25:46 2022 ] Training epoch: 55
[ Wed Sep 28 17:29:01 2022 ] 	Mean training loss: 0.2175.  Mean training acc: 93.77%.
[ Wed Sep 28 17:29:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:29:01 2022 ] Eval epoch: 55
[ Wed Sep 28 17:29:50 2022 ] 	Mean test loss of 796 batches: 0.8716156671956257.
[ Wed Sep 28 17:29:50 2022 ] 	Top1: 76.89%
[ Wed Sep 28 17:29:50 2022 ] 	Top5: 94.41%
[ Wed Sep 28 17:29:50 2022 ] Training epoch: 56
[ Wed Sep 28 17:33:06 2022 ] 	Mean training loss: 0.1333.  Mean training acc: 96.72%.
[ Wed Sep 28 17:33:06 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 17:33:06 2022 ] Eval epoch: 56
[ Wed Sep 28 17:33:55 2022 ] 	Mean test loss of 796 batches: 0.6896407102707343.
[ Wed Sep 28 17:33:55 2022 ] 	Top1: 80.74%
[ Wed Sep 28 17:33:56 2022 ] 	Top5: 95.89%
[ Wed Sep 28 17:33:56 2022 ] Training epoch: 57
[ Wed Sep 28 17:37:11 2022 ] 	Mean training loss: 0.1049.  Mean training acc: 97.56%.
[ Wed Sep 28 17:37:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:37:11 2022 ] Eval epoch: 57
[ Wed Sep 28 17:38:00 2022 ] 	Mean test loss of 796 batches: 0.6915427938515517.
[ Wed Sep 28 17:38:00 2022 ] 	Top1: 80.83%
[ Wed Sep 28 17:38:01 2022 ] 	Top5: 95.84%
[ Wed Sep 28 17:38:01 2022 ] Training epoch: 58
[ Wed Sep 28 17:41:16 2022 ] 	Mean training loss: 0.0950.  Mean training acc: 97.89%.
[ Wed Sep 28 17:41:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:41:16 2022 ] Eval epoch: 58
[ Wed Sep 28 17:42:05 2022 ] 	Mean test loss of 796 batches: 0.6975466055964031.
[ Wed Sep 28 17:42:05 2022 ] 	Top1: 80.92%
[ Wed Sep 28 17:42:05 2022 ] 	Top5: 95.82%
[ Wed Sep 28 17:42:06 2022 ] Training epoch: 59
[ Wed Sep 28 17:45:21 2022 ] 	Mean training loss: 0.0868.  Mean training acc: 98.17%.
[ Wed Sep 28 17:45:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:45:21 2022 ] Eval epoch: 59
[ Wed Sep 28 17:46:09 2022 ] 	Mean test loss of 796 batches: 0.7013192484857299.
[ Wed Sep 28 17:46:10 2022 ] 	Top1: 80.93%
[ Wed Sep 28 17:46:10 2022 ] 	Top5: 95.77%
[ Wed Sep 28 17:46:10 2022 ] Training epoch: 60
[ Wed Sep 28 17:49:22 2022 ] 	Mean training loss: 0.0855.  Mean training acc: 98.22%.
[ Wed Sep 28 17:49:22 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 17:49:22 2022 ] Eval epoch: 60
[ Wed Sep 28 17:50:08 2022 ] 	Mean test loss of 796 batches: 0.7042510918711298.
[ Wed Sep 28 17:50:08 2022 ] 	Top1: 80.85%
[ Wed Sep 28 17:50:08 2022 ] 	Top5: 95.76%
[ Wed Sep 28 17:50:08 2022 ] Training epoch: 61
[ Wed Sep 28 17:53:11 2022 ] 	Mean training loss: 0.0773.  Mean training acc: 98.42%.
[ Wed Sep 28 17:53:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 17:53:11 2022 ] Eval epoch: 61
[ Wed Sep 28 17:53:57 2022 ] 	Mean test loss of 796 batches: 0.7003539025352977.
[ Wed Sep 28 17:53:57 2022 ] 	Top1: 81.08%
[ Wed Sep 28 17:53:57 2022 ] 	Top5: 95.83%
[ Wed Sep 28 17:53:57 2022 ] Training epoch: 62
[ Wed Sep 28 17:57:00 2022 ] 	Mean training loss: 0.0749.  Mean training acc: 98.57%.
[ Wed Sep 28 17:57:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 17:57:00 2022 ] Eval epoch: 62
[ Wed Sep 28 17:57:46 2022 ] 	Mean test loss of 796 batches: 0.7105757880057372.
[ Wed Sep 28 17:57:46 2022 ] 	Top1: 80.84%
[ Wed Sep 28 17:57:46 2022 ] 	Top5: 95.67%
[ Wed Sep 28 17:57:47 2022 ] Training epoch: 63
[ Wed Sep 28 18:00:50 2022 ] 	Mean training loss: 0.0709.  Mean training acc: 98.66%.
[ Wed Sep 28 18:00:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 18:00:50 2022 ] Eval epoch: 63
[ Wed Sep 28 18:01:35 2022 ] 	Mean test loss of 796 batches: 0.7153405450733762.
[ Wed Sep 28 18:01:36 2022 ] 	Top1: 80.78%
[ Wed Sep 28 18:01:36 2022 ] 	Top5: 95.65%
[ Wed Sep 28 18:01:36 2022 ] Training epoch: 64
[ Wed Sep 28 18:04:39 2022 ] 	Mean training loss: 0.0697.  Mean training acc: 98.66%.
[ Wed Sep 28 18:04:39 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Sep 28 18:04:39 2022 ] Eval epoch: 64
[ Wed Sep 28 18:05:24 2022 ] 	Mean test loss of 796 batches: 0.7109899170153854.
[ Wed Sep 28 18:05:25 2022 ] 	Top1: 80.93%
[ Wed Sep 28 18:05:25 2022 ] 	Top5: 95.60%
[ Wed Sep 28 18:05:25 2022 ] Training epoch: 65
[ Wed Sep 28 18:08:28 2022 ] 	Mean training loss: 0.0682.  Mean training acc: 98.68%.
[ Wed Sep 28 18:08:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Sep 28 18:08:28 2022 ] Eval epoch: 65
[ Wed Sep 28 18:09:14 2022 ] 	Mean test loss of 796 batches: 0.7130561727450122.
[ Wed Sep 28 18:09:14 2022 ] 	Top1: 80.91%
[ Wed Sep 28 18:09:14 2022 ] 	Top5: 95.70%
[ Wed Sep 28 18:10:01 2022 ] Best accuracy: 0.8107582631237849
[ Wed Sep 28 18:10:01 2022 ] Epoch number: 61
[ Wed Sep 28 18:10:01 2022 ] Model name: work_dir/ntu120/csub/azimuth_cent_imp4
[ Wed Sep 28 18:10:01 2022 ] Model total number of params: 2107660
[ Wed Sep 28 18:10:01 2022 ] Weight decay: 0.0004
[ Wed Sep 28 18:10:01 2022 ] Base LR: 0.1
[ Wed Sep 28 18:10:01 2022 ] Batch Size: 64
[ Wed Sep 28 18:10:01 2022 ] Test Batch Size: 64
[ Wed Sep 28 18:10:01 2022 ] seed: 1
