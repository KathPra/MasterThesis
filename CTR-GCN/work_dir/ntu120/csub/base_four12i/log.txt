[ Tue Jun 28 20:29:15 2022 ] using warm up, epoch: 5
[ Tue Jun 28 20:29:28 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four12i', 'model_saved_name': 'work_dir/ntu120/csub/base_four12i/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier12i.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Jun 28 20:29:28 2022 ] # Parameters: 2100194
[ Tue Jun 28 20:29:28 2022 ] Training epoch: 1
[ Tue Jun 28 20:32:24 2022 ] 	Mean training loss: 2.9089.  Mean training acc: 25.85%.
[ Tue Jun 28 20:32:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:32:24 2022 ] Eval epoch: 1
[ Tue Jun 28 20:33:08 2022 ] 	Mean test loss of 796 batches: 2.468536844654898.
[ Tue Jun 28 20:33:09 2022 ] 	Top1: 33.51%
[ Tue Jun 28 20:33:09 2022 ] 	Top5: 67.90%
[ Tue Jun 28 20:33:09 2022 ] Training epoch: 2
[ Tue Jun 28 20:36:05 2022 ] 	Mean training loss: 2.0503.  Mean training acc: 42.63%.
[ Tue Jun 28 20:36:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:36:05 2022 ] Eval epoch: 2
[ Tue Jun 28 20:36:50 2022 ] 	Mean test loss of 796 batches: 1.9042766721703899.
[ Tue Jun 28 20:36:50 2022 ] 	Top1: 45.08%
[ Tue Jun 28 20:36:50 2022 ] 	Top5: 79.29%
[ Tue Jun 28 20:36:50 2022 ] Training epoch: 3
[ Tue Jun 28 20:39:47 2022 ] 	Mean training loss: 1.7217.  Mean training acc: 50.29%.
[ Tue Jun 28 20:39:47 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:39:47 2022 ] Eval epoch: 3
[ Tue Jun 28 20:40:31 2022 ] 	Mean test loss of 796 batches: 1.7309985974026685.
[ Tue Jun 28 20:40:32 2022 ] 	Top1: 50.41%
[ Tue Jun 28 20:40:32 2022 ] 	Top5: 82.17%
[ Tue Jun 28 20:40:32 2022 ] Training epoch: 4
[ Tue Jun 28 20:43:28 2022 ] 	Mean training loss: 1.5835.  Mean training acc: 53.89%.
[ Tue Jun 28 20:43:28 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:43:28 2022 ] Eval epoch: 4
[ Tue Jun 28 20:44:12 2022 ] 	Mean test loss of 796 batches: 1.6658601867942955.
[ Tue Jun 28 20:44:13 2022 ] 	Top1: 51.07%
[ Tue Jun 28 20:44:13 2022 ] 	Top5: 83.30%
[ Tue Jun 28 20:44:13 2022 ] Training epoch: 5
[ Tue Jun 28 20:47:09 2022 ] 	Mean training loss: 1.5232.  Mean training acc: 55.32%.
[ Tue Jun 28 20:47:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:47:09 2022 ] Eval epoch: 5
[ Tue Jun 28 20:47:54 2022 ] 	Mean test loss of 796 batches: 1.610948795873915.
[ Tue Jun 28 20:47:54 2022 ] 	Top1: 53.98%
[ Tue Jun 28 20:47:54 2022 ] 	Top5: 84.04%
[ Tue Jun 28 20:47:54 2022 ] Training epoch: 6
[ Tue Jun 28 20:50:51 2022 ] 	Mean training loss: 1.4322.  Mean training acc: 57.74%.
[ Tue Jun 28 20:50:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:50:51 2022 ] Eval epoch: 6
[ Tue Jun 28 20:51:35 2022 ] 	Mean test loss of 796 batches: 1.5520531183960449.
[ Tue Jun 28 20:51:35 2022 ] 	Top1: 54.81%
[ Tue Jun 28 20:51:36 2022 ] 	Top5: 85.26%
[ Tue Jun 28 20:51:36 2022 ] Training epoch: 7
[ Tue Jun 28 20:54:32 2022 ] 	Mean training loss: 1.3700.  Mean training acc: 59.51%.
[ Tue Jun 28 20:54:32 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:54:32 2022 ] Eval epoch: 7
[ Tue Jun 28 20:55:17 2022 ] 	Mean test loss of 796 batches: 1.5500361684279227.
[ Tue Jun 28 20:55:17 2022 ] 	Top1: 54.42%
[ Tue Jun 28 20:55:17 2022 ] 	Top5: 85.73%
[ Tue Jun 28 20:55:17 2022 ] Training epoch: 8
[ Tue Jun 28 20:58:14 2022 ] 	Mean training loss: 1.3186.  Mean training acc: 60.89%.
[ Tue Jun 28 20:58:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 20:58:14 2022 ] Eval epoch: 8
[ Tue Jun 28 20:58:58 2022 ] 	Mean test loss of 796 batches: 1.545284708765284.
[ Tue Jun 28 20:58:58 2022 ] 	Top1: 55.99%
[ Tue Jun 28 20:58:59 2022 ] 	Top5: 85.50%
[ Tue Jun 28 20:58:59 2022 ] Training epoch: 9
[ Tue Jun 28 21:01:55 2022 ] 	Mean training loss: 1.2752.  Mean training acc: 61.91%.
[ Tue Jun 28 21:01:55 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:01:55 2022 ] Eval epoch: 9
[ Tue Jun 28 21:02:39 2022 ] 	Mean test loss of 796 batches: 1.3919979682819328.
[ Tue Jun 28 21:02:40 2022 ] 	Top1: 58.65%
[ Tue Jun 28 21:02:40 2022 ] 	Top5: 88.50%
[ Tue Jun 28 21:02:40 2022 ] Training epoch: 10
[ Tue Jun 28 21:05:36 2022 ] 	Mean training loss: 1.2408.  Mean training acc: 62.94%.
[ Tue Jun 28 21:05:36 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:05:36 2022 ] Eval epoch: 10
[ Tue Jun 28 21:06:20 2022 ] 	Mean test loss of 796 batches: 1.4280759664486402.
[ Tue Jun 28 21:06:21 2022 ] 	Top1: 57.95%
[ Tue Jun 28 21:06:21 2022 ] 	Top5: 87.41%
[ Tue Jun 28 21:06:21 2022 ] Training epoch: 11
[ Tue Jun 28 21:09:17 2022 ] 	Mean training loss: 1.2150.  Mean training acc: 63.48%.
[ Tue Jun 28 21:09:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:09:17 2022 ] Eval epoch: 11
[ Tue Jun 28 21:10:02 2022 ] 	Mean test loss of 796 batches: 1.4547539081555516.
[ Tue Jun 28 21:10:02 2022 ] 	Top1: 58.05%
[ Tue Jun 28 21:10:02 2022 ] 	Top5: 87.10%
[ Tue Jun 28 21:10:02 2022 ] Training epoch: 12
[ Tue Jun 28 21:12:59 2022 ] 	Mean training loss: 1.1963.  Mean training acc: 64.14%.
[ Tue Jun 28 21:12:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:12:59 2022 ] Eval epoch: 12
[ Tue Jun 28 21:13:43 2022 ] 	Mean test loss of 796 batches: 1.3896414001832655.
[ Tue Jun 28 21:13:43 2022 ] 	Top1: 59.09%
[ Tue Jun 28 21:13:44 2022 ] 	Top5: 88.15%
[ Tue Jun 28 21:13:44 2022 ] Training epoch: 13
[ Tue Jun 28 21:16:40 2022 ] 	Mean training loss: 1.1733.  Mean training acc: 64.73%.
[ Tue Jun 28 21:16:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 21:16:40 2022 ] Eval epoch: 13
[ Tue Jun 28 21:17:25 2022 ] 	Mean test loss of 796 batches: 1.4334748191150588.
[ Tue Jun 28 21:17:25 2022 ] 	Top1: 58.49%
[ Tue Jun 28 21:17:25 2022 ] 	Top5: 87.19%
[ Tue Jun 28 21:17:25 2022 ] Training epoch: 14
[ Tue Jun 28 21:20:22 2022 ] 	Mean training loss: 1.1596.  Mean training acc: 64.82%.
[ Tue Jun 28 21:20:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:20:22 2022 ] Eval epoch: 14
[ Tue Jun 28 21:21:07 2022 ] 	Mean test loss of 796 batches: 1.347380141966307.
[ Tue Jun 28 21:21:07 2022 ] 	Top1: 59.73%
[ Tue Jun 28 21:21:07 2022 ] 	Top5: 88.95%
[ Tue Jun 28 21:21:07 2022 ] Training epoch: 15
[ Tue Jun 28 21:24:04 2022 ] 	Mean training loss: 1.1410.  Mean training acc: 65.32%.
[ Tue Jun 28 21:24:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:24:04 2022 ] Eval epoch: 15
[ Tue Jun 28 21:24:48 2022 ] 	Mean test loss of 796 batches: 1.3670954096257386.
[ Tue Jun 28 21:24:48 2022 ] 	Top1: 60.35%
[ Tue Jun 28 21:24:49 2022 ] 	Top5: 88.28%
[ Tue Jun 28 21:24:49 2022 ] Training epoch: 16
[ Tue Jun 28 21:27:45 2022 ] 	Mean training loss: 1.1296.  Mean training acc: 65.79%.
[ Tue Jun 28 21:27:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:27:45 2022 ] Eval epoch: 16
[ Tue Jun 28 21:28:30 2022 ] 	Mean test loss of 796 batches: 1.2947403943568618.
[ Tue Jun 28 21:28:30 2022 ] 	Top1: 62.48%
[ Tue Jun 28 21:28:30 2022 ] 	Top5: 89.69%
[ Tue Jun 28 21:28:30 2022 ] Training epoch: 17
[ Tue Jun 28 21:31:27 2022 ] 	Mean training loss: 1.1154.  Mean training acc: 66.08%.
[ Tue Jun 28 21:31:27 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 21:31:27 2022 ] Eval epoch: 17
[ Tue Jun 28 21:32:11 2022 ] 	Mean test loss of 796 batches: 1.3322501872951662.
[ Tue Jun 28 21:32:12 2022 ] 	Top1: 61.28%
[ Tue Jun 28 21:32:12 2022 ] 	Top5: 89.51%
[ Tue Jun 28 21:32:12 2022 ] Training epoch: 18
[ Tue Jun 28 21:35:09 2022 ] 	Mean training loss: 1.1106.  Mean training acc: 66.32%.
[ Tue Jun 28 21:35:09 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:35:09 2022 ] Eval epoch: 18
[ Tue Jun 28 21:35:53 2022 ] 	Mean test loss of 796 batches: 1.2643390805203112.
[ Tue Jun 28 21:35:54 2022 ] 	Top1: 62.27%
[ Tue Jun 28 21:35:54 2022 ] 	Top5: 89.73%
[ Tue Jun 28 21:35:54 2022 ] Training epoch: 19
[ Tue Jun 28 21:38:51 2022 ] 	Mean training loss: 1.0950.  Mean training acc: 66.57%.
[ Tue Jun 28 21:38:51 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:38:51 2022 ] Eval epoch: 19
[ Tue Jun 28 21:39:35 2022 ] 	Mean test loss of 796 batches: 1.2922986252748188.
[ Tue Jun 28 21:39:35 2022 ] 	Top1: 62.99%
[ Tue Jun 28 21:39:36 2022 ] 	Top5: 89.57%
[ Tue Jun 28 21:39:36 2022 ] Training epoch: 20
[ Tue Jun 28 21:42:32 2022 ] 	Mean training loss: 1.0941.  Mean training acc: 66.77%.
[ Tue Jun 28 21:42:48 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:42:48 2022 ] Eval epoch: 20
[ Tue Jun 28 21:43:32 2022 ] 	Mean test loss of 796 batches: 1.3177901642705927.
[ Tue Jun 28 21:43:33 2022 ] 	Top1: 62.07%
[ Tue Jun 28 21:43:33 2022 ] 	Top5: 89.01%
[ Tue Jun 28 21:43:33 2022 ] Training epoch: 21
[ Tue Jun 28 21:46:30 2022 ] 	Mean training loss: 1.0858.  Mean training acc: 66.89%.
[ Tue Jun 28 21:46:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:46:30 2022 ] Eval epoch: 21
[ Tue Jun 28 21:47:14 2022 ] 	Mean test loss of 796 batches: 1.3386338791955057.
[ Tue Jun 28 21:47:14 2022 ] 	Top1: 61.22%
[ Tue Jun 28 21:47:15 2022 ] 	Top5: 89.04%
[ Tue Jun 28 21:47:15 2022 ] Training epoch: 22
[ Tue Jun 28 21:50:11 2022 ] 	Mean training loss: 1.0724.  Mean training acc: 67.35%.
[ Tue Jun 28 21:50:11 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:50:11 2022 ] Eval epoch: 22
[ Tue Jun 28 21:50:56 2022 ] 	Mean test loss of 796 batches: 1.3130402821841551.
[ Tue Jun 28 21:50:56 2022 ] 	Top1: 62.32%
[ Tue Jun 28 21:50:56 2022 ] 	Top5: 88.62%
[ Tue Jun 28 21:50:56 2022 ] Training epoch: 23
[ Tue Jun 28 21:53:53 2022 ] 	Mean training loss: 1.0719.  Mean training acc: 67.66%.
[ Tue Jun 28 21:53:53 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:53:53 2022 ] Eval epoch: 23
[ Tue Jun 28 21:54:37 2022 ] 	Mean test loss of 796 batches: 1.3036182844009832.
[ Tue Jun 28 21:54:38 2022 ] 	Top1: 61.95%
[ Tue Jun 28 21:54:38 2022 ] 	Top5: 89.84%
[ Tue Jun 28 21:54:38 2022 ] Training epoch: 24
[ Tue Jun 28 21:57:35 2022 ] 	Mean training loss: 1.0600.  Mean training acc: 67.73%.
[ Tue Jun 28 21:57:35 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 21:57:35 2022 ] Eval epoch: 24
[ Tue Jun 28 21:58:19 2022 ] 	Mean test loss of 796 batches: 1.4197267764552155.
[ Tue Jun 28 21:58:19 2022 ] 	Top1: 58.42%
[ Tue Jun 28 21:58:20 2022 ] 	Top5: 89.67%
[ Tue Jun 28 21:58:20 2022 ] Training epoch: 25
[ Tue Jun 28 22:01:17 2022 ] 	Mean training loss: 1.0632.  Mean training acc: 67.66%.
[ Tue Jun 28 22:01:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 22:01:17 2022 ] Eval epoch: 25
[ Tue Jun 28 22:02:01 2022 ] 	Mean test loss of 796 batches: 1.1915745154846853.
[ Tue Jun 28 22:02:01 2022 ] 	Top1: 64.16%
[ Tue Jun 28 22:02:02 2022 ] 	Top5: 90.84%
[ Tue Jun 28 22:02:02 2022 ] Training epoch: 26
[ Tue Jun 28 22:04:59 2022 ] 	Mean training loss: 1.0526.  Mean training acc: 68.06%.
[ Tue Jun 28 22:04:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:04:59 2022 ] Eval epoch: 26
[ Tue Jun 28 22:05:43 2022 ] 	Mean test loss of 796 batches: 1.290403045826222.
[ Tue Jun 28 22:05:43 2022 ] 	Top1: 62.52%
[ Tue Jun 28 22:05:44 2022 ] 	Top5: 90.24%
[ Tue Jun 28 22:05:44 2022 ] Training epoch: 27
[ Tue Jun 28 22:08:41 2022 ] 	Mean training loss: 1.0412.  Mean training acc: 68.17%.
[ Tue Jun 28 22:08:41 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:08:41 2022 ] Eval epoch: 27
[ Tue Jun 28 22:09:25 2022 ] 	Mean test loss of 796 batches: 1.412137935658795.
[ Tue Jun 28 22:09:25 2022 ] 	Top1: 59.99%
[ Tue Jun 28 22:09:26 2022 ] 	Top5: 88.03%
[ Tue Jun 28 22:09:26 2022 ] Training epoch: 28
[ Tue Jun 28 22:12:24 2022 ] 	Mean training loss: 1.0481.  Mean training acc: 68.04%.
[ Tue Jun 28 22:12:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 22:12:24 2022 ] Eval epoch: 28
[ Tue Jun 28 22:13:09 2022 ] 	Mean test loss of 796 batches: 1.365444162532912.
[ Tue Jun 28 22:13:09 2022 ] 	Top1: 60.79%
[ Tue Jun 28 22:13:10 2022 ] 	Top5: 88.68%
[ Tue Jun 28 22:13:10 2022 ] Training epoch: 29
[ Tue Jun 28 22:16:07 2022 ] 	Mean training loss: 1.0443.  Mean training acc: 68.36%.
[ Tue Jun 28 22:16:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 22:16:07 2022 ] Eval epoch: 29
[ Tue Jun 28 22:16:51 2022 ] 	Mean test loss of 796 batches: 1.2187848444185665.
[ Tue Jun 28 22:16:52 2022 ] 	Top1: 63.53%
[ Tue Jun 28 22:16:52 2022 ] 	Top5: 90.74%
[ Tue Jun 28 22:16:52 2022 ] Training epoch: 30
[ Tue Jun 28 22:19:49 2022 ] 	Mean training loss: 1.0348.  Mean training acc: 68.47%.
[ Tue Jun 28 22:19:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 22:19:49 2022 ] Eval epoch: 30
[ Tue Jun 28 22:20:33 2022 ] 	Mean test loss of 796 batches: 1.2676609496974467.
[ Tue Jun 28 22:20:33 2022 ] 	Top1: 63.30%
[ Tue Jun 28 22:20:34 2022 ] 	Top5: 89.57%
[ Tue Jun 28 22:20:34 2022 ] Training epoch: 31
[ Tue Jun 28 22:23:30 2022 ] 	Mean training loss: 1.0367.  Mean training acc: 68.44%.
[ Tue Jun 28 22:23:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:23:30 2022 ] Eval epoch: 31
[ Tue Jun 28 22:24:14 2022 ] 	Mean test loss of 796 batches: 1.3157803845315723.
[ Tue Jun 28 22:24:14 2022 ] 	Top1: 62.23%
[ Tue Jun 28 22:24:15 2022 ] 	Top5: 88.85%
[ Tue Jun 28 22:24:15 2022 ] Training epoch: 32
[ Tue Jun 28 22:27:12 2022 ] 	Mean training loss: 1.0316.  Mean training acc: 68.41%.
[ Tue Jun 28 22:27:12 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:27:12 2022 ] Eval epoch: 32
[ Tue Jun 28 22:27:56 2022 ] 	Mean test loss of 796 batches: 1.2530623563195593.
[ Tue Jun 28 22:27:56 2022 ] 	Top1: 63.67%
[ Tue Jun 28 22:27:56 2022 ] 	Top5: 89.30%
[ Tue Jun 28 22:27:56 2022 ] Training epoch: 33
[ Tue Jun 28 22:30:54 2022 ] 	Mean training loss: 1.0286.  Mean training acc: 68.69%.
[ Tue Jun 28 22:30:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 22:30:54 2022 ] Eval epoch: 33
[ Tue Jun 28 22:31:38 2022 ] 	Mean test loss of 796 batches: 1.2788036843789883.
[ Tue Jun 28 22:31:38 2022 ] 	Top1: 62.32%
[ Tue Jun 28 22:31:39 2022 ] 	Top5: 90.11%
[ Tue Jun 28 22:31:39 2022 ] Training epoch: 34
[ Tue Jun 28 22:34:35 2022 ] 	Mean training loss: 1.0307.  Mean training acc: 68.48%.
[ Tue Jun 28 22:34:35 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:34:35 2022 ] Eval epoch: 34
[ Tue Jun 28 22:35:20 2022 ] 	Mean test loss of 796 batches: 1.2204594114917007.
[ Tue Jun 28 22:35:20 2022 ] 	Top1: 63.39%
[ Tue Jun 28 22:35:20 2022 ] 	Top5: 90.59%
[ Tue Jun 28 22:35:20 2022 ] Training epoch: 35
[ Tue Jun 28 22:38:17 2022 ] 	Mean training loss: 1.0218.  Mean training acc: 68.84%.
[ Tue Jun 28 22:38:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:38:17 2022 ] Eval epoch: 35
[ Tue Jun 28 22:39:01 2022 ] 	Mean test loss of 796 batches: 1.2686324681918226.
[ Tue Jun 28 22:39:02 2022 ] 	Top1: 63.23%
[ Tue Jun 28 22:39:02 2022 ] 	Top5: 90.38%
[ Tue Jun 28 22:39:02 2022 ] Training epoch: 36
[ Tue Jun 28 22:41:59 2022 ] 	Mean training loss: 0.6518.  Mean training acc: 79.70%.
[ Tue Jun 28 22:41:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:41:59 2022 ] Eval epoch: 36
[ Tue Jun 28 22:42:43 2022 ] 	Mean test loss of 796 batches: 0.8639628175440146.
[ Tue Jun 28 22:42:44 2022 ] 	Top1: 74.10%
[ Tue Jun 28 22:42:44 2022 ] 	Top5: 94.25%
[ Tue Jun 28 22:42:44 2022 ] Training epoch: 37
[ Tue Jun 28 22:45:40 2022 ] 	Mean training loss: 0.5441.  Mean training acc: 82.75%.
[ Tue Jun 28 22:45:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:45:40 2022 ] Eval epoch: 37
[ Tue Jun 28 22:46:24 2022 ] 	Mean test loss of 796 batches: 0.8307932760173352.
[ Tue Jun 28 22:46:25 2022 ] 	Top1: 75.05%
[ Tue Jun 28 22:46:25 2022 ] 	Top5: 94.50%
[ Tue Jun 28 22:46:25 2022 ] Training epoch: 38
[ Tue Jun 28 22:49:22 2022 ] 	Mean training loss: 0.5013.  Mean training acc: 83.82%.
[ Tue Jun 28 22:49:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:49:22 2022 ] Eval epoch: 38
[ Tue Jun 28 22:50:06 2022 ] 	Mean test loss of 796 batches: 0.8460647700981578.
[ Tue Jun 28 22:50:07 2022 ] 	Top1: 75.01%
[ Tue Jun 28 22:50:07 2022 ] 	Top5: 94.34%
[ Tue Jun 28 22:50:07 2022 ] Training epoch: 39
[ Tue Jun 28 22:53:04 2022 ] 	Mean training loss: 0.4690.  Mean training acc: 84.95%.
[ Tue Jun 28 22:53:04 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:53:04 2022 ] Eval epoch: 39
[ Tue Jun 28 22:53:48 2022 ] 	Mean test loss of 796 batches: 0.8941371388845707.
[ Tue Jun 28 22:53:48 2022 ] 	Top1: 73.93%
[ Tue Jun 28 22:53:49 2022 ] 	Top5: 94.09%
[ Tue Jun 28 22:53:49 2022 ] Training epoch: 40
[ Tue Jun 28 22:56:45 2022 ] 	Mean training loss: 0.4374.  Mean training acc: 85.95%.
[ Tue Jun 28 22:56:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 22:56:45 2022 ] Eval epoch: 40
[ Tue Jun 28 22:57:29 2022 ] 	Mean test loss of 796 batches: 0.8565306520866389.
[ Tue Jun 28 22:57:30 2022 ] 	Top1: 75.02%
[ Tue Jun 28 22:57:30 2022 ] 	Top5: 94.40%
[ Tue Jun 28 22:57:30 2022 ] Training epoch: 41
[ Tue Jun 28 23:00:27 2022 ] 	Mean training loss: 0.4173.  Mean training acc: 86.64%.
[ Tue Jun 28 23:00:27 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:00:27 2022 ] Eval epoch: 41
[ Tue Jun 28 23:01:11 2022 ] 	Mean test loss of 796 batches: 0.8746333368234898.
[ Tue Jun 28 23:01:11 2022 ] 	Top1: 74.57%
[ Tue Jun 28 23:01:12 2022 ] 	Top5: 94.44%
[ Tue Jun 28 23:01:12 2022 ] Training epoch: 42
[ Tue Jun 28 23:04:09 2022 ] 	Mean training loss: 0.3965.  Mean training acc: 87.14%.
[ Tue Jun 28 23:04:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:04:09 2022 ] Eval epoch: 42
[ Tue Jun 28 23:04:54 2022 ] 	Mean test loss of 796 batches: 0.8701145283166488.
[ Tue Jun 28 23:04:54 2022 ] 	Top1: 74.96%
[ Tue Jun 28 23:04:54 2022 ] 	Top5: 94.39%
[ Tue Jun 28 23:04:55 2022 ] Training epoch: 43
[ Tue Jun 28 23:07:53 2022 ] 	Mean training loss: 0.3797.  Mean training acc: 87.75%.
[ Tue Jun 28 23:07:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 23:07:53 2022 ] Eval epoch: 43
[ Tue Jun 28 23:08:37 2022 ] 	Mean test loss of 796 batches: 0.9200423928211682.
[ Tue Jun 28 23:08:38 2022 ] 	Top1: 73.96%
[ Tue Jun 28 23:08:38 2022 ] 	Top5: 94.13%
[ Tue Jun 28 23:08:38 2022 ] Training epoch: 44
[ Tue Jun 28 23:11:36 2022 ] 	Mean training loss: 0.3713.  Mean training acc: 87.93%.
[ Tue Jun 28 23:11:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:11:36 2022 ] Eval epoch: 44
[ Tue Jun 28 23:12:20 2022 ] 	Mean test loss of 796 batches: 0.9266427469313444.
[ Tue Jun 28 23:12:20 2022 ] 	Top1: 73.94%
[ Tue Jun 28 23:12:20 2022 ] 	Top5: 93.79%
[ Tue Jun 28 23:12:21 2022 ] Training epoch: 45
[ Tue Jun 28 23:15:19 2022 ] 	Mean training loss: 0.3581.  Mean training acc: 88.26%.
[ Tue Jun 28 23:15:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 23:15:19 2022 ] Eval epoch: 45
[ Tue Jun 28 23:16:05 2022 ] 	Mean test loss of 796 batches: 0.968062389922801.
[ Tue Jun 28 23:16:06 2022 ] 	Top1: 73.23%
[ Tue Jun 28 23:16:06 2022 ] 	Top5: 93.69%
[ Tue Jun 28 23:16:06 2022 ] Training epoch: 46
[ Tue Jun 28 23:19:04 2022 ] 	Mean training loss: 0.3502.  Mean training acc: 88.62%.
[ Tue Jun 28 23:19:04 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 23:19:04 2022 ] Eval epoch: 46
[ Tue Jun 28 23:19:48 2022 ] 	Mean test loss of 796 batches: 0.940448320728151.
[ Tue Jun 28 23:19:48 2022 ] 	Top1: 74.25%
[ Tue Jun 28 23:19:49 2022 ] 	Top5: 93.86%
[ Tue Jun 28 23:19:49 2022 ] Training epoch: 47
[ Tue Jun 28 23:22:45 2022 ] 	Mean training loss: 0.3434.  Mean training acc: 88.82%.
[ Tue Jun 28 23:22:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:22:47 2022 ] Eval epoch: 47
[ Tue Jun 28 23:23:31 2022 ] 	Mean test loss of 796 batches: 0.9989908660513971.
[ Tue Jun 28 23:23:31 2022 ] 	Top1: 72.99%
[ Tue Jun 28 23:23:32 2022 ] 	Top5: 93.38%
[ Tue Jun 28 23:23:32 2022 ] Training epoch: 48
[ Tue Jun 28 23:26:28 2022 ] 	Mean training loss: 0.3342.  Mean training acc: 89.19%.
[ Tue Jun 28 23:26:28 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:26:28 2022 ] Eval epoch: 48
[ Tue Jun 28 23:27:12 2022 ] 	Mean test loss of 796 batches: 0.9810209699237167.
[ Tue Jun 28 23:27:13 2022 ] 	Top1: 73.44%
[ Tue Jun 28 23:27:13 2022 ] 	Top5: 93.29%
[ Tue Jun 28 23:27:13 2022 ] Training epoch: 49
[ Tue Jun 28 23:30:10 2022 ] 	Mean training loss: 0.3296.  Mean training acc: 89.36%.
[ Tue Jun 28 23:30:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:30:10 2022 ] Eval epoch: 49
[ Tue Jun 28 23:30:54 2022 ] 	Mean test loss of 796 batches: 1.0543955862522125.
[ Tue Jun 28 23:30:55 2022 ] 	Top1: 72.17%
[ Tue Jun 28 23:30:55 2022 ] 	Top5: 93.24%
[ Tue Jun 28 23:30:55 2022 ] Training epoch: 50
[ Tue Jun 28 23:33:52 2022 ] 	Mean training loss: 0.3297.  Mean training acc: 89.45%.
[ Tue Jun 28 23:33:52 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:33:52 2022 ] Eval epoch: 50
[ Tue Jun 28 23:34:36 2022 ] 	Mean test loss of 796 batches: 1.0183696817587968.
[ Tue Jun 28 23:34:37 2022 ] 	Top1: 72.56%
[ Tue Jun 28 23:34:37 2022 ] 	Top5: 93.26%
[ Tue Jun 28 23:34:37 2022 ] Training epoch: 51
[ Tue Jun 28 23:37:34 2022 ] 	Mean training loss: 0.3186.  Mean training acc: 89.74%.
[ Tue Jun 28 23:37:34 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:37:34 2022 ] Eval epoch: 51
[ Tue Jun 28 23:38:18 2022 ] 	Mean test loss of 796 batches: 0.9849161268703303.
[ Tue Jun 28 23:38:18 2022 ] 	Top1: 73.28%
[ Tue Jun 28 23:38:19 2022 ] 	Top5: 93.62%
[ Tue Jun 28 23:38:19 2022 ] Training epoch: 52
[ Tue Jun 28 23:41:15 2022 ] 	Mean training loss: 0.3153.  Mean training acc: 89.94%.
[ Tue Jun 28 23:41:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:41:15 2022 ] Eval epoch: 52
[ Tue Jun 28 23:42:00 2022 ] 	Mean test loss of 796 batches: 0.9898371940581643.
[ Tue Jun 28 23:42:00 2022 ] 	Top1: 73.48%
[ Tue Jun 28 23:42:00 2022 ] 	Top5: 93.67%
[ Tue Jun 28 23:42:00 2022 ] Training epoch: 53
[ Tue Jun 28 23:44:57 2022 ] 	Mean training loss: 0.3128.  Mean training acc: 89.94%.
[ Tue Jun 28 23:44:57 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Tue Jun 28 23:44:57 2022 ] Eval epoch: 53
[ Tue Jun 28 23:45:42 2022 ] 	Mean test loss of 796 batches: 1.0233246070805506.
[ Tue Jun 28 23:45:43 2022 ] 	Top1: 72.97%
[ Tue Jun 28 23:45:43 2022 ] 	Top5: 93.42%
[ Tue Jun 28 23:45:43 2022 ] Training epoch: 54
[ Tue Jun 28 23:48:41 2022 ] 	Mean training loss: 0.3092.  Mean training acc: 90.06%.
[ Tue Jun 28 23:48:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 23:48:41 2022 ] Eval epoch: 54
[ Tue Jun 28 23:49:26 2022 ] 	Mean test loss of 796 batches: 1.0090223877648612.
[ Tue Jun 28 23:49:26 2022 ] 	Top1: 72.85%
[ Tue Jun 28 23:49:26 2022 ] 	Top5: 93.39%
[ Tue Jun 28 23:49:26 2022 ] Training epoch: 55
[ Tue Jun 28 23:52:24 2022 ] 	Mean training loss: 0.3053.  Mean training acc: 90.24%.
[ Tue Jun 28 23:52:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Jun 28 23:52:24 2022 ] Eval epoch: 55
[ Tue Jun 28 23:53:09 2022 ] 	Mean test loss of 796 batches: 1.0168422443520784.
[ Tue Jun 28 23:53:09 2022 ] 	Top1: 72.88%
[ Tue Jun 28 23:53:09 2022 ] 	Top5: 93.23%
[ Tue Jun 28 23:53:09 2022 ] Training epoch: 56
[ Tue Jun 28 23:56:06 2022 ] 	Mean training loss: 0.1833.  Mean training acc: 94.60%.
[ Tue Jun 28 23:56:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:56:06 2022 ] Eval epoch: 56
[ Tue Jun 28 23:56:51 2022 ] 	Mean test loss of 796 batches: 0.9508043575713683.
[ Tue Jun 28 23:56:51 2022 ] 	Top1: 74.77%
[ Tue Jun 28 23:56:51 2022 ] 	Top5: 93.94%
[ Tue Jun 28 23:56:51 2022 ] Training epoch: 57
[ Tue Jun 28 23:59:48 2022 ] 	Mean training loss: 0.1435.  Mean training acc: 96.02%.
[ Tue Jun 28 23:59:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Jun 28 23:59:49 2022 ] Eval epoch: 57
[ Wed Jun 29 00:00:33 2022 ] 	Mean test loss of 796 batches: 0.9530117528035713.
[ Wed Jun 29 00:00:34 2022 ] 	Top1: 74.90%
[ Wed Jun 29 00:00:34 2022 ] 	Top5: 93.94%
[ Wed Jun 29 00:00:34 2022 ] Training epoch: 58
[ Wed Jun 29 00:03:32 2022 ] 	Mean training loss: 0.1246.  Mean training acc: 96.69%.
[ Wed Jun 29 00:03:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:03:33 2022 ] Eval epoch: 58
[ Wed Jun 29 00:04:18 2022 ] 	Mean test loss of 796 batches: 0.9509892074119806.
[ Wed Jun 29 00:04:18 2022 ] 	Top1: 75.07%
[ Wed Jun 29 00:04:19 2022 ] 	Top5: 93.99%
[ Wed Jun 29 00:04:19 2022 ] Training epoch: 59
[ Wed Jun 29 00:07:16 2022 ] 	Mean training loss: 0.1139.  Mean training acc: 97.07%.
[ Wed Jun 29 00:07:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 00:07:16 2022 ] Eval epoch: 59
[ Wed Jun 29 00:08:00 2022 ] 	Mean test loss of 796 batches: 0.9630673465754219.
[ Wed Jun 29 00:08:01 2022 ] 	Top1: 75.08%
[ Wed Jun 29 00:08:01 2022 ] 	Top5: 94.01%
[ Wed Jun 29 00:08:01 2022 ] Training epoch: 60
[ Wed Jun 29 00:10:58 2022 ] 	Mean training loss: 0.1086.  Mean training acc: 97.18%.
[ Wed Jun 29 00:10:58 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jun 29 00:10:58 2022 ] Eval epoch: 60
[ Wed Jun 29 00:11:42 2022 ] 	Mean test loss of 796 batches: 0.9696746392166196.
[ Wed Jun 29 00:11:42 2022 ] 	Top1: 74.87%
[ Wed Jun 29 00:11:43 2022 ] 	Top5: 93.90%
[ Wed Jun 29 00:11:43 2022 ] Training epoch: 61
[ Wed Jun 29 00:14:40 2022 ] 	Mean training loss: 0.1006.  Mean training acc: 97.49%.
[ Wed Jun 29 00:14:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 00:14:40 2022 ] Eval epoch: 61
[ Wed Jun 29 00:15:25 2022 ] 	Mean test loss of 796 batches: 0.975474563974831.
[ Wed Jun 29 00:15:25 2022 ] 	Top1: 75.09%
[ Wed Jun 29 00:15:25 2022 ] 	Top5: 93.89%
[ Wed Jun 29 00:15:25 2022 ] Training epoch: 62
[ Wed Jun 29 00:18:25 2022 ] 	Mean training loss: 0.0971.  Mean training acc: 97.61%.
[ Wed Jun 29 00:18:25 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jun 29 00:18:25 2022 ] Eval epoch: 62
[ Wed Jun 29 00:19:09 2022 ] 	Mean test loss of 796 batches: 0.984339860216457.
[ Wed Jun 29 00:19:10 2022 ] 	Top1: 74.94%
[ Wed Jun 29 00:19:10 2022 ] 	Top5: 93.86%
[ Wed Jun 29 00:19:10 2022 ] Training epoch: 63
[ Wed Jun 29 00:22:07 2022 ] 	Mean training loss: 0.0921.  Mean training acc: 97.78%.
[ Wed Jun 29 00:22:07 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jun 29 00:22:07 2022 ] Eval epoch: 63
[ Wed Jun 29 00:22:50 2022 ] 	Mean test loss of 796 batches: 0.991940186588309.
[ Wed Jun 29 00:22:51 2022 ] 	Top1: 74.98%
[ Wed Jun 29 00:22:51 2022 ] 	Top5: 93.76%
[ Wed Jun 29 00:22:51 2022 ] Training epoch: 64
[ Wed Jun 29 00:25:48 2022 ] 	Mean training loss: 0.0894.  Mean training acc: 97.83%.
[ Wed Jun 29 00:25:48 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Jun 29 00:25:48 2022 ] Eval epoch: 64
[ Wed Jun 29 00:26:32 2022 ] 	Mean test loss of 796 batches: 0.994802870006118.
[ Wed Jun 29 00:26:32 2022 ] 	Top1: 74.88%
[ Wed Jun 29 00:26:33 2022 ] 	Top5: 93.72%
[ Wed Jun 29 00:26:33 2022 ] Training epoch: 65
[ Wed Jun 29 00:29:31 2022 ] 	Mean training loss: 0.0831.  Mean training acc: 98.08%.
[ Wed Jun 29 00:29:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:29:31 2022 ] Eval epoch: 65
[ Wed Jun 29 00:30:15 2022 ] 	Mean test loss of 796 batches: 0.996669420813346.
[ Wed Jun 29 00:30:16 2022 ] 	Top1: 75.01%
[ Wed Jun 29 00:30:16 2022 ] 	Top5: 93.80%
[ Wed Jun 29 00:31:03 2022 ] Best accuracy: 0.7508788467958916
[ Wed Jun 29 00:31:03 2022 ] Epoch number: 61
[ Wed Jun 29 00:31:03 2022 ] Model name: work_dir/ntu120/csub/base_four12i
[ Wed Jun 29 00:31:03 2022 ] Model total number of params: 2100194
[ Wed Jun 29 00:31:03 2022 ] Weight decay: 0.0004
[ Wed Jun 29 00:31:03 2022 ] Base LR: 0.1
[ Wed Jun 29 00:31:03 2022 ] Batch Size: 64
[ Wed Jun 29 00:31:03 2022 ] Test Batch Size: 64
[ Wed Jun 29 00:31:03 2022 ] seed: 1
