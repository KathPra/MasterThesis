[ Mon May 23 11:39:26 2022 ] using warm up, epoch: 5
[ Mon May 23 11:40:41 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_vel8', 'model_saved_name': 'work_dir/ntu120/csub/base_vel8/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.velocity8.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon May 23 11:40:41 2022 ] # Parameters: 2333260
[ Mon May 23 11:40:41 2022 ] Training epoch: 1
[ Mon May 23 13:29:11 2022 ] using warm up, epoch: 5
[ Mon May 23 13:31:08 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_vel8', 'model_saved_name': 'work_dir/ntu120/csub/base_vel8/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.velocity8.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon May 23 13:31:08 2022 ] # Parameters: 2333260
[ Mon May 23 13:31:08 2022 ] Training epoch: 1
[ Mon May 23 13:33:46 2022 ] using warm up, epoch: 5
[ Mon May 23 13:34:53 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_vel8', 'model_saved_name': 'work_dir/ntu120/csub/base_vel8/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.velocity8.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon May 23 13:34:53 2022 ] # Parameters: 2783136
[ Mon May 23 13:34:53 2022 ] Training epoch: 1
[ Mon May 23 13:36:45 2022 ] using warm up, epoch: 5
[ Mon May 23 13:38:14 2022 ] using warm up, epoch: 5
[ Mon May 23 13:39:03 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_vel8', 'model_saved_name': 'work_dir/ntu120/csub/base_vel8/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.velocity8.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon May 23 13:39:03 2022 ] # Parameters: 2784480
[ Mon May 23 13:39:03 2022 ] Training epoch: 1
[ Mon May 23 13:55:14 2022 ] 	Mean training loss: 3.0521.  Mean training acc: 24.23%.
[ Mon May 23 13:55:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon May 23 13:55:14 2022 ] Eval epoch: 1
[ Mon May 23 13:59:11 2022 ] 	Mean test loss of 796 batches: 2.624047543984562.
[ Mon May 23 13:59:12 2022 ] 	Top1: 27.54%
[ Mon May 23 13:59:13 2022 ] 	Top5: 65.69%
[ Mon May 23 13:59:13 2022 ] Training epoch: 2
[ Mon May 23 14:14:42 2022 ] 	Mean training loss: 2.0251.  Mean training acc: 43.79%.
[ Mon May 23 14:14:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon May 23 14:14:42 2022 ] Eval epoch: 2
[ Mon May 23 14:18:43 2022 ] 	Mean test loss of 796 batches: 1.9818225940268244.
[ Mon May 23 14:18:43 2022 ] 	Top1: 44.27%
[ Mon May 23 14:18:44 2022 ] 	Top5: 79.28%
[ Mon May 23 14:18:44 2022 ] Training epoch: 3
[ Mon May 23 14:35:25 2022 ] using warm up, epoch: 5
[ Mon May 23 14:42:54 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_vel8', 'model_saved_name': 'work_dir/ntu120/csub/base_vel8/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.velocity8.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon May 23 14:42:54 2022 ] # Parameters: 2784480
[ Mon May 23 14:42:55 2022 ] Training epoch: 1
[ Mon May 23 15:03:16 2022 ] 	Mean training loss: 3.0521.  Mean training acc: 24.23%.
[ Mon May 23 15:03:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 15:03:17 2022 ] Eval epoch: 1
[ Mon May 23 15:08:44 2022 ] 	Mean test loss of 796 batches: 2.624047543984562.
[ Mon May 23 15:08:45 2022 ] 	Top1: 27.54%
[ Mon May 23 15:08:46 2022 ] 	Top5: 65.69%
[ Mon May 23 15:08:46 2022 ] Training epoch: 2
[ Mon May 23 15:29:04 2022 ] 	Mean training loss: 2.0251.  Mean training acc: 43.79%.
[ Mon May 23 15:29:04 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Mon May 23 15:29:04 2022 ] Eval epoch: 2
[ Mon May 23 15:35:57 2022 ] 	Mean test loss of 796 batches: 1.9818225940268244.
[ Mon May 23 15:36:01 2022 ] 	Top1: 44.27%
[ Mon May 23 15:36:05 2022 ] 	Top5: 79.28%
[ Mon May 23 15:36:06 2022 ] Training epoch: 3
[ Mon May 23 15:58:01 2022 ] 	Mean training loss: 1.5969.  Mean training acc: 54.03%.
[ Mon May 23 15:58:01 2022 ] 	Time consumption: [Data]07%, [Network]92%
[ Mon May 23 15:58:01 2022 ] Eval epoch: 3
[ Mon May 23 16:03:00 2022 ] 	Mean test loss of 796 batches: 1.5175706467886068.
[ Mon May 23 16:03:00 2022 ] 	Top1: 55.28%
[ Mon May 23 16:03:01 2022 ] 	Top5: 86.14%
[ Mon May 23 16:03:01 2022 ] Training epoch: 4
[ Mon May 23 16:23:00 2022 ] 	Mean training loss: 1.3802.  Mean training acc: 59.65%.
[ Mon May 23 16:23:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon May 23 16:23:00 2022 ] Eval epoch: 4
[ Mon May 23 16:28:10 2022 ] 	Mean test loss of 796 batches: 1.5360407868222377.
[ Mon May 23 16:28:11 2022 ] 	Top1: 54.18%
[ Mon May 23 16:28:11 2022 ] 	Top5: 86.16%
[ Mon May 23 16:28:11 2022 ] Training epoch: 5
[ Mon May 23 16:49:11 2022 ] 	Mean training loss: 1.2535.  Mean training acc: 63.11%.
[ Mon May 23 16:49:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon May 23 16:49:11 2022 ] Eval epoch: 5
[ Mon May 23 16:54:19 2022 ] 	Mean test loss of 796 batches: 1.4837077994592225.
[ Mon May 23 16:54:19 2022 ] 	Top1: 57.67%
[ Mon May 23 16:54:20 2022 ] 	Top5: 86.89%
[ Mon May 23 16:54:20 2022 ] Training epoch: 6
[ Mon May 23 17:13:55 2022 ] 	Mean training loss: 1.1122.  Mean training acc: 66.91%.
[ Mon May 23 17:13:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon May 23 17:13:55 2022 ] Eval epoch: 6
[ Mon May 23 17:19:04 2022 ] 	Mean test loss of 796 batches: 1.3942002499822397.
[ Mon May 23 17:19:04 2022 ] 	Top1: 60.70%
[ Mon May 23 17:19:05 2022 ] 	Top5: 87.36%
[ Mon May 23 17:19:05 2022 ] Training epoch: 7
[ Mon May 23 17:39:33 2022 ] 	Mean training loss: 1.0230.  Mean training acc: 69.37%.
[ Mon May 23 17:39:33 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 17:39:33 2022 ] Eval epoch: 7
[ Mon May 23 17:45:03 2022 ] 	Mean test loss of 796 batches: 1.2795280702224927.
[ Mon May 23 17:45:04 2022 ] 	Top1: 64.18%
[ Mon May 23 17:45:06 2022 ] 	Top5: 89.00%
[ Mon May 23 17:45:06 2022 ] Training epoch: 8
[ Mon May 23 18:04:09 2022 ] 	Mean training loss: 0.9524.  Mean training acc: 71.57%.
[ Mon May 23 18:04:09 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 18:04:09 2022 ] Eval epoch: 8
[ Mon May 23 18:09:15 2022 ] 	Mean test loss of 796 batches: 1.1915458507049623.
[ Mon May 23 18:09:16 2022 ] 	Top1: 65.30%
[ Mon May 23 18:09:17 2022 ] 	Top5: 90.18%
[ Mon May 23 18:09:17 2022 ] Training epoch: 9
[ Mon May 23 18:29:14 2022 ] 	Mean training loss: 0.9040.  Mean training acc: 72.85%.
[ Mon May 23 18:29:14 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 18:29:14 2022 ] Eval epoch: 9
[ Mon May 23 18:34:29 2022 ] 	Mean test loss of 796 batches: 1.0621836450531255.
[ Mon May 23 18:34:31 2022 ] 	Top1: 68.16%
[ Mon May 23 18:34:33 2022 ] 	Top5: 92.02%
[ Mon May 23 18:34:33 2022 ] Training epoch: 10
[ Mon May 23 18:53:54 2022 ] 	Mean training loss: 0.8763.  Mean training acc: 73.55%.
[ Mon May 23 18:53:54 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Mon May 23 18:53:54 2022 ] Eval epoch: 10
[ Mon May 23 18:58:43 2022 ] 	Mean test loss of 796 batches: 1.7687904085570842.
[ Mon May 23 18:58:44 2022 ] 	Top1: 52.41%
[ Mon May 23 18:58:45 2022 ] 	Top5: 83.68%
[ Mon May 23 18:58:46 2022 ] Training epoch: 11
[ Mon May 23 19:18:33 2022 ] 	Mean training loss: 0.8518.  Mean training acc: 74.37%.
[ Mon May 23 19:18:33 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Mon May 23 19:18:33 2022 ] Eval epoch: 11
[ Mon May 23 19:23:35 2022 ] 	Mean test loss of 796 batches: 1.198772409416024.
[ Mon May 23 19:23:36 2022 ] 	Top1: 65.34%
[ Mon May 23 19:23:38 2022 ] 	Top5: 91.68%
[ Mon May 23 19:23:38 2022 ] Training epoch: 12
[ Mon May 23 19:43:26 2022 ] 	Mean training loss: 0.8202.  Mean training acc: 75.25%.
[ Mon May 23 19:43:26 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 19:43:26 2022 ] Eval epoch: 12
[ Mon May 23 19:48:52 2022 ] 	Mean test loss of 796 batches: 1.0201173248752278.
[ Mon May 23 19:48:54 2022 ] 	Top1: 69.70%
[ Mon May 23 19:48:55 2022 ] 	Top5: 93.06%
[ Mon May 23 19:48:55 2022 ] Training epoch: 13
[ Mon May 23 20:08:18 2022 ] 	Mean training loss: 0.8089.  Mean training acc: 75.50%.
[ Mon May 23 20:08:18 2022 ] 	Time consumption: [Data]06%, [Network]93%
[ Mon May 23 20:08:18 2022 ] Eval epoch: 13
[ Mon May 23 20:13:26 2022 ] 	Mean test loss of 796 batches: 1.11816779913465.
[ Mon May 23 20:13:26 2022 ] 	Top1: 67.88%
[ Mon May 23 20:13:27 2022 ] 	Top5: 91.17%
[ Mon May 23 20:13:27 2022 ] Training epoch: 14
[ Mon May 23 20:33:05 2022 ] 	Mean training loss: 0.7949.  Mean training acc: 75.91%.
[ Mon May 23 20:33:05 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 20:33:05 2022 ] Eval epoch: 14
[ Mon May 23 20:38:04 2022 ] 	Mean test loss of 796 batches: 1.062269310424825.
[ Mon May 23 20:38:05 2022 ] 	Top1: 68.82%
[ Mon May 23 20:38:06 2022 ] 	Top5: 92.73%
[ Mon May 23 20:38:06 2022 ] Training epoch: 15
[ Mon May 23 20:57:13 2022 ] 	Mean training loss: 0.7860.  Mean training acc: 76.20%.
[ Mon May 23 20:57:13 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 20:57:13 2022 ] Eval epoch: 15
[ Mon May 23 21:02:19 2022 ] 	Mean test loss of 796 batches: 1.1003760017417183.
[ Mon May 23 21:02:20 2022 ] 	Top1: 67.72%
[ Mon May 23 21:02:20 2022 ] 	Top5: 91.78%
[ Mon May 23 21:02:20 2022 ] Training epoch: 16
[ Mon May 23 21:22:04 2022 ] 	Mean training loss: 0.7734.  Mean training acc: 76.76%.
[ Mon May 23 21:22:04 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 21:22:05 2022 ] Eval epoch: 16
[ Mon May 23 21:27:35 2022 ] 	Mean test loss of 796 batches: 1.0471223060359907.
[ Mon May 23 21:27:36 2022 ] 	Top1: 69.76%
[ Mon May 23 21:27:37 2022 ] 	Top5: 92.33%
[ Mon May 23 21:27:37 2022 ] Training epoch: 17
[ Mon May 23 21:47:32 2022 ] 	Mean training loss: 0.7619.  Mean training acc: 76.98%.
[ Mon May 23 21:47:32 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Mon May 23 21:47:32 2022 ] Eval epoch: 17
[ Mon May 23 21:52:47 2022 ] 	Mean test loss of 796 batches: 0.9766420416496507.
[ Mon May 23 21:52:48 2022 ] 	Top1: 70.50%
[ Mon May 23 21:52:50 2022 ] 	Top5: 93.53%
[ Mon May 23 21:52:50 2022 ] Training epoch: 18
[ Mon May 23 22:11:58 2022 ] 	Mean training loss: 0.7528.  Mean training acc: 77.14%.
[ Mon May 23 22:11:58 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 22:11:58 2022 ] Eval epoch: 18
[ Mon May 23 22:17:11 2022 ] 	Mean test loss of 796 batches: 0.9811636765286251.
[ Mon May 23 22:17:13 2022 ] 	Top1: 70.69%
[ Mon May 23 22:17:13 2022 ] 	Top5: 93.20%
[ Mon May 23 22:17:14 2022 ] Training epoch: 19
[ Mon May 23 22:37:37 2022 ] 	Mean training loss: 0.7455.  Mean training acc: 77.45%.
[ Mon May 23 22:37:37 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Mon May 23 22:37:37 2022 ] Eval epoch: 19
[ Mon May 23 22:42:53 2022 ] 	Mean test loss of 796 batches: 1.0511228029602138.
[ Mon May 23 22:42:54 2022 ] 	Top1: 69.26%
[ Mon May 23 22:42:54 2022 ] 	Top5: 92.43%
[ Mon May 23 22:42:55 2022 ] Training epoch: 20
[ Mon May 23 23:01:59 2022 ] 	Mean training loss: 0.7359.  Mean training acc: 77.63%.
[ Mon May 23 23:01:59 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 23:01:59 2022 ] Eval epoch: 20
[ Mon May 23 23:07:12 2022 ] 	Mean test loss of 796 batches: 0.9660091856541346.
[ Mon May 23 23:07:13 2022 ] 	Top1: 71.35%
[ Mon May 23 23:07:14 2022 ] 	Top5: 93.42%
[ Mon May 23 23:07:14 2022 ] Training epoch: 21
[ Mon May 23 23:28:09 2022 ] 	Mean training loss: 0.7318.  Mean training acc: 77.72%.
[ Mon May 23 23:28:09 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Mon May 23 23:28:09 2022 ] Eval epoch: 21
[ Mon May 23 23:33:31 2022 ] 	Mean test loss of 796 batches: 0.966264728962177.
[ Mon May 23 23:33:32 2022 ] 	Top1: 71.48%
[ Mon May 23 23:33:33 2022 ] 	Top5: 93.10%
[ Mon May 23 23:33:33 2022 ] Training epoch: 22
[ Mon May 23 23:52:54 2022 ] 	Mean training loss: 0.7217.  Mean training acc: 78.16%.
[ Mon May 23 23:52:54 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Mon May 23 23:52:54 2022 ] Eval epoch: 22
[ Mon May 23 23:58:08 2022 ] 	Mean test loss of 796 batches: 0.9784008100741173.
[ Mon May 23 23:58:09 2022 ] 	Top1: 71.29%
[ Mon May 23 23:58:10 2022 ] 	Top5: 92.98%
[ Mon May 23 23:58:10 2022 ] Training epoch: 23
[ Tue May 24 00:18:09 2022 ] 	Mean training loss: 0.7238.  Mean training acc: 78.08%.
[ Tue May 24 00:18:09 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 00:18:09 2022 ] Eval epoch: 23
[ Tue May 24 00:23:48 2022 ] 	Mean test loss of 796 batches: 1.0524108008898083.
[ Tue May 24 00:23:49 2022 ] 	Top1: 68.87%
[ Tue May 24 00:23:50 2022 ] 	Top5: 92.59%
[ Tue May 24 00:23:50 2022 ] Training epoch: 24
[ Tue May 24 00:43:06 2022 ] 	Mean training loss: 0.7174.  Mean training acc: 78.32%.
[ Tue May 24 00:43:06 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 00:43:06 2022 ] Eval epoch: 24
[ Tue May 24 00:49:47 2022 ] 	Mean test loss of 796 batches: 0.9302897489437806.
[ Tue May 24 00:49:48 2022 ] 	Top1: 72.52%
[ Tue May 24 00:49:49 2022 ] 	Top5: 93.36%
[ Tue May 24 00:49:50 2022 ] Training epoch: 25
[ Tue May 24 01:14:24 2022 ] 	Mean training loss: 0.7114.  Mean training acc: 78.59%.
[ Tue May 24 01:14:24 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 01:14:24 2022 ] Eval epoch: 25
[ Tue May 24 01:21:14 2022 ] 	Mean test loss of 796 batches: 1.0890716472687434.
[ Tue May 24 01:21:15 2022 ] 	Top1: 69.23%
[ Tue May 24 01:21:15 2022 ] 	Top5: 91.49%
[ Tue May 24 01:21:16 2022 ] Training epoch: 26
[ Tue May 24 01:46:04 2022 ] 	Mean training loss: 0.7115.  Mean training acc: 78.52%.
[ Tue May 24 01:46:04 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 01:46:04 2022 ] Eval epoch: 26
[ Tue May 24 01:52:42 2022 ] 	Mean test loss of 796 batches: 0.9871794503912255.
[ Tue May 24 01:52:43 2022 ] 	Top1: 70.83%
[ Tue May 24 01:52:44 2022 ] 	Top5: 93.17%
[ Tue May 24 01:52:44 2022 ] Training epoch: 27
[ Tue May 24 02:17:43 2022 ] 	Mean training loss: 0.7062.  Mean training acc: 78.60%.
[ Tue May 24 02:17:43 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 02:17:43 2022 ] Eval epoch: 27
[ Tue May 24 02:24:11 2022 ] 	Mean test loss of 796 batches: 0.9540402123975993.
[ Tue May 24 02:24:11 2022 ] 	Top1: 71.34%
[ Tue May 24 02:24:12 2022 ] 	Top5: 93.70%
[ Tue May 24 02:24:13 2022 ] Training epoch: 28
[ Tue May 24 02:49:26 2022 ] 	Mean training loss: 0.7098.  Mean training acc: 78.35%.
[ Tue May 24 02:49:26 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 02:49:26 2022 ] Eval epoch: 28
[ Tue May 24 02:55:44 2022 ] 	Mean test loss of 796 batches: 0.9700066825403041.
[ Tue May 24 02:55:45 2022 ] 	Top1: 72.26%
[ Tue May 24 02:55:46 2022 ] 	Top5: 93.84%
[ Tue May 24 02:55:46 2022 ] Training epoch: 29
[ Tue May 24 03:21:01 2022 ] 	Mean training loss: 0.7071.  Mean training acc: 78.52%.
[ Tue May 24 03:21:01 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 03:21:01 2022 ] Eval epoch: 29
[ Tue May 24 03:27:04 2022 ] 	Mean test loss of 796 batches: 1.1691177574608793.
[ Tue May 24 03:27:05 2022 ] 	Top1: 67.24%
[ Tue May 24 03:27:05 2022 ] 	Top5: 91.18%
[ Tue May 24 03:27:06 2022 ] Training epoch: 30
[ Tue May 24 03:52:10 2022 ] 	Mean training loss: 0.6996.  Mean training acc: 78.72%.
[ Tue May 24 03:52:10 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 03:52:10 2022 ] Eval epoch: 30
[ Tue May 24 03:58:36 2022 ] 	Mean test loss of 796 batches: 1.0586899917890977.
[ Tue May 24 03:58:37 2022 ] 	Top1: 69.39%
[ Tue May 24 03:58:38 2022 ] 	Top5: 91.72%
[ Tue May 24 03:58:38 2022 ] Training epoch: 31
[ Tue May 24 04:23:29 2022 ] 	Mean training loss: 0.6916.  Mean training acc: 79.00%.
[ Tue May 24 04:23:30 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 04:23:30 2022 ] Eval epoch: 31
[ Tue May 24 04:30:03 2022 ] 	Mean test loss of 796 batches: 1.2334793410708558.
[ Tue May 24 04:30:04 2022 ] 	Top1: 65.79%
[ Tue May 24 04:30:04 2022 ] 	Top5: 89.94%
[ Tue May 24 04:30:05 2022 ] Training epoch: 32
[ Tue May 24 04:54:27 2022 ] 	Mean training loss: 0.6918.  Mean training acc: 78.94%.
[ Tue May 24 04:54:27 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue May 24 04:54:27 2022 ] Eval epoch: 32
[ Tue May 24 05:01:21 2022 ] 	Mean test loss of 796 batches: 0.9225032014688056.
[ Tue May 24 05:01:22 2022 ] 	Top1: 72.59%
[ Tue May 24 05:01:22 2022 ] 	Top5: 94.06%
[ Tue May 24 05:01:23 2022 ] Training epoch: 33
[ Tue May 24 05:26:07 2022 ] 	Mean training loss: 0.6926.  Mean training acc: 78.89%.
[ Tue May 24 05:26:07 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue May 24 05:26:07 2022 ] Eval epoch: 33
[ Tue May 24 05:33:03 2022 ] 	Mean test loss of 796 batches: 0.9789567456098657.
[ Tue May 24 05:33:04 2022 ] 	Top1: 71.25%
[ Tue May 24 05:33:05 2022 ] 	Top5: 92.88%
[ Tue May 24 05:33:05 2022 ] Training epoch: 34
[ Tue May 24 05:57:34 2022 ] 	Mean training loss: 0.6864.  Mean training acc: 79.07%.
[ Tue May 24 05:57:34 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 05:57:34 2022 ] Eval epoch: 34
[ Tue May 24 06:04:05 2022 ] 	Mean test loss of 796 batches: 0.9893310448557289.
[ Tue May 24 06:04:06 2022 ] 	Top1: 71.02%
[ Tue May 24 06:04:07 2022 ] 	Top5: 93.09%
[ Tue May 24 06:04:07 2022 ] Training epoch: 35
[ Tue May 24 06:29:01 2022 ] 	Mean training loss: 0.6861.  Mean training acc: 79.06%.
[ Tue May 24 06:29:01 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 06:29:01 2022 ] Eval epoch: 35
[ Tue May 24 06:35:47 2022 ] 	Mean test loss of 796 batches: 1.1921207275821935.
[ Tue May 24 06:35:49 2022 ] 	Top1: 65.72%
[ Tue May 24 06:35:49 2022 ] 	Top5: 90.81%
[ Tue May 24 06:35:49 2022 ] Training epoch: 36
[ Tue May 24 07:00:12 2022 ] 	Mean training loss: 0.3818.  Mean training acc: 88.45%.
[ Tue May 24 07:00:12 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 07:00:13 2022 ] Eval epoch: 36
[ Tue May 24 07:06:29 2022 ] 	Mean test loss of 796 batches: 0.562506846133526.
[ Tue May 24 07:06:30 2022 ] 	Top1: 82.75%
[ Tue May 24 07:06:31 2022 ] 	Top5: 96.82%
[ Tue May 24 07:06:31 2022 ] Training epoch: 37
[ Tue May 24 07:31:06 2022 ] 	Mean training loss: 0.2999.  Mean training acc: 90.90%.
[ Tue May 24 07:31:06 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 07:31:07 2022 ] Eval epoch: 37
[ Tue May 24 07:37:48 2022 ] 	Mean test loss of 796 batches: 0.5350762645072823.
[ Tue May 24 07:37:49 2022 ] 	Top1: 83.81%
[ Tue May 24 07:37:49 2022 ] 	Top5: 97.05%
[ Tue May 24 07:37:49 2022 ] Training epoch: 38
[ Tue May 24 08:02:13 2022 ] 	Mean training loss: 0.2655.  Mean training acc: 91.95%.
[ Tue May 24 08:02:13 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue May 24 08:02:13 2022 ] Eval epoch: 38
[ Tue May 24 08:08:47 2022 ] 	Mean test loss of 796 batches: 0.5413495677911756.
[ Tue May 24 08:08:47 2022 ] 	Top1: 83.63%
[ Tue May 24 08:08:48 2022 ] 	Top5: 96.97%
[ Tue May 24 08:08:48 2022 ] Training epoch: 39
[ Tue May 24 08:33:19 2022 ] 	Mean training loss: 0.2412.  Mean training acc: 92.79%.
[ Tue May 24 08:33:19 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 08:33:19 2022 ] Eval epoch: 39
[ Tue May 24 08:40:27 2022 ] 	Mean test loss of 796 batches: 0.5426865488796229.
[ Tue May 24 08:40:28 2022 ] 	Top1: 83.62%
[ Tue May 24 08:40:28 2022 ] 	Top5: 97.10%
[ Tue May 24 08:40:29 2022 ] Training epoch: 40
[ Tue May 24 09:04:36 2022 ] 	Mean training loss: 0.2209.  Mean training acc: 93.42%.
[ Tue May 24 09:04:36 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 09:04:36 2022 ] Eval epoch: 40
[ Tue May 24 09:11:16 2022 ] 	Mean test loss of 796 batches: 0.5559682809939636.
[ Tue May 24 09:11:17 2022 ] 	Top1: 83.66%
[ Tue May 24 09:11:18 2022 ] 	Top5: 96.90%
[ Tue May 24 09:11:18 2022 ] Training epoch: 41
[ Tue May 24 09:35:37 2022 ] 	Mean training loss: 0.2051.  Mean training acc: 93.89%.
[ Tue May 24 09:35:37 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 09:35:37 2022 ] Eval epoch: 41
[ Tue May 24 09:42:55 2022 ] 	Mean test loss of 796 batches: 0.5637583771449088.
[ Tue May 24 09:42:56 2022 ] 	Top1: 83.42%
[ Tue May 24 09:42:56 2022 ] 	Top5: 96.96%
[ Tue May 24 09:42:57 2022 ] Training epoch: 42
[ Tue May 24 10:06:59 2022 ] 	Mean training loss: 0.1908.  Mean training acc: 94.53%.
[ Tue May 24 10:06:59 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue May 24 10:07:00 2022 ] Eval epoch: 42
[ Tue May 24 10:13:22 2022 ] 	Mean test loss of 796 batches: 0.5707449573209163.
[ Tue May 24 10:13:23 2022 ] 	Top1: 83.57%
[ Tue May 24 10:13:24 2022 ] 	Top5: 96.84%
[ Tue May 24 10:13:24 2022 ] Training epoch: 43
[ Tue May 24 10:37:05 2022 ] 	Mean training loss: 0.1771.  Mean training acc: 94.99%.
[ Tue May 24 10:37:05 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 10:37:05 2022 ] Eval epoch: 43
[ Tue May 24 10:43:52 2022 ] 	Mean test loss of 796 batches: 0.5792010951525153.
[ Tue May 24 10:43:53 2022 ] 	Top1: 83.23%
[ Tue May 24 10:43:53 2022 ] 	Top5: 96.89%
[ Tue May 24 10:43:53 2022 ] Training epoch: 44
[ Tue May 24 11:07:57 2022 ] 	Mean training loss: 0.1660.  Mean training acc: 95.30%.
[ Tue May 24 11:07:57 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 11:07:57 2022 ] Eval epoch: 44
[ Tue May 24 11:13:55 2022 ] 	Mean test loss of 796 batches: 0.5976234733889899.
[ Tue May 24 11:13:56 2022 ] 	Top1: 82.81%
[ Tue May 24 11:13:56 2022 ] 	Top5: 96.84%
[ Tue May 24 11:13:57 2022 ] Training epoch: 45
[ Tue May 24 11:35:03 2022 ] 	Mean training loss: 0.1543.  Mean training acc: 95.63%.
[ Tue May 24 11:35:04 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 11:35:04 2022 ] Eval epoch: 45
[ Tue May 24 11:39:47 2022 ] 	Mean test loss of 796 batches: 0.6108265957659363.
[ Tue May 24 11:39:48 2022 ] 	Top1: 82.54%
[ Tue May 24 11:39:48 2022 ] 	Top5: 96.68%
[ Tue May 24 11:39:48 2022 ] Training epoch: 46
[ Tue May 24 12:00:50 2022 ] 	Mean training loss: 0.1497.  Mean training acc: 95.87%.
[ Tue May 24 12:00:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue May 24 12:00:50 2022 ] Eval epoch: 46
[ Tue May 24 12:05:51 2022 ] 	Mean test loss of 796 batches: 0.6059895405948312.
[ Tue May 24 12:05:51 2022 ] 	Top1: 83.01%
[ Tue May 24 12:05:52 2022 ] 	Top5: 96.64%
[ Tue May 24 12:05:52 2022 ] Training epoch: 47
[ Tue May 24 12:24:40 2022 ] 	Mean training loss: 0.1430.  Mean training acc: 96.09%.
[ Tue May 24 12:24:40 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue May 24 12:24:40 2022 ] Eval epoch: 47
[ Tue May 24 12:29:49 2022 ] 	Mean test loss of 796 batches: 0.6275300716784731.
[ Tue May 24 12:29:50 2022 ] 	Top1: 82.20%
[ Tue May 24 12:29:50 2022 ] 	Top5: 96.39%
[ Tue May 24 12:29:51 2022 ] Training epoch: 48
[ Tue May 24 12:49:52 2022 ] 	Mean training loss: 0.1384.  Mean training acc: 96.32%.
[ Tue May 24 12:49:52 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue May 24 12:49:52 2022 ] Eval epoch: 48
[ Tue May 24 12:54:16 2022 ] 	Mean test loss of 796 batches: 0.6366239493740863.
[ Tue May 24 12:54:17 2022 ] 	Top1: 81.91%
[ Tue May 24 12:54:17 2022 ] 	Top5: 96.23%
[ Tue May 24 12:54:17 2022 ] Training epoch: 49
[ Tue May 24 13:07:30 2022 ] 	Mean training loss: 0.1390.  Mean training acc: 96.22%.
[ Tue May 24 13:07:30 2022 ] 	Time consumption: [Data]07%, [Network]93%
[ Tue May 24 13:07:30 2022 ] Eval epoch: 49
[ Tue May 24 13:11:28 2022 ] 	Mean test loss of 796 batches: 0.6591292526666543.
[ Tue May 24 13:11:29 2022 ] 	Top1: 81.86%
[ Tue May 24 13:11:30 2022 ] 	Top5: 96.29%
[ Tue May 24 13:11:30 2022 ] Training epoch: 50
[ Tue May 24 13:30:43 2022 ] 	Mean training loss: 0.1363.  Mean training acc: 96.37%.
[ Tue May 24 13:30:43 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 13:30:43 2022 ] Eval epoch: 50
[ Tue May 24 13:35:56 2022 ] 	Mean test loss of 796 batches: 0.6625207928594333.
[ Tue May 24 13:35:56 2022 ] 	Top1: 81.89%
[ Tue May 24 13:35:57 2022 ] 	Top5: 96.22%
[ Tue May 24 13:35:57 2022 ] Training epoch: 51
[ Tue May 24 13:56:03 2022 ] 	Mean training loss: 0.1316.  Mean training acc: 96.49%.
[ Tue May 24 13:56:03 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 13:56:03 2022 ] Eval epoch: 51
[ Tue May 24 14:01:03 2022 ] 	Mean test loss of 796 batches: 0.698115729740891.
[ Tue May 24 14:01:03 2022 ] 	Top1: 81.05%
[ Tue May 24 14:01:04 2022 ] 	Top5: 96.02%
[ Tue May 24 14:01:04 2022 ] Training epoch: 52
[ Tue May 24 14:21:43 2022 ] 	Mean training loss: 0.1369.  Mean training acc: 96.29%.
[ Tue May 24 14:21:43 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 14:21:43 2022 ] Eval epoch: 52
[ Tue May 24 14:26:52 2022 ] 	Mean test loss of 796 batches: 0.6619592510145064.
[ Tue May 24 14:26:53 2022 ] 	Top1: 81.72%
[ Tue May 24 14:26:53 2022 ] 	Top5: 96.17%
[ Tue May 24 14:26:53 2022 ] Training epoch: 53
[ Tue May 24 14:46:57 2022 ] 	Mean training loss: 0.1330.  Mean training acc: 96.38%.
[ Tue May 24 14:46:57 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 14:46:57 2022 ] Eval epoch: 53
[ Tue May 24 14:51:43 2022 ] 	Mean test loss of 796 batches: 0.6870115928857321.
[ Tue May 24 14:51:44 2022 ] 	Top1: 81.49%
[ Tue May 24 14:51:44 2022 ] 	Top5: 96.08%
[ Tue May 24 14:51:44 2022 ] Training epoch: 54
[ Tue May 24 15:12:39 2022 ] 	Mean training loss: 0.1348.  Mean training acc: 96.41%.
[ Tue May 24 15:12:39 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 15:12:40 2022 ] Eval epoch: 54
[ Tue May 24 15:18:58 2022 ] 	Mean test loss of 796 batches: 0.6761978741585459.
[ Tue May 24 15:18:59 2022 ] 	Top1: 81.58%
[ Tue May 24 15:19:00 2022 ] 	Top5: 95.93%
[ Tue May 24 15:19:00 2022 ] Training epoch: 55
[ Tue May 24 15:43:20 2022 ] 	Mean training loss: 0.1317.  Mean training acc: 96.47%.
[ Tue May 24 15:43:20 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue May 24 15:43:20 2022 ] Eval epoch: 55
[ Tue May 24 15:49:44 2022 ] 	Mean test loss of 796 batches: 0.6804039302988717.
[ Tue May 24 15:49:45 2022 ] 	Top1: 81.52%
[ Tue May 24 15:49:46 2022 ] 	Top5: 96.04%
[ Tue May 24 15:49:46 2022 ] Training epoch: 56
[ Tue May 24 16:14:16 2022 ] 	Mean training loss: 0.0692.  Mean training acc: 98.57%.
[ Tue May 24 16:14:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 16:14:16 2022 ] Eval epoch: 56
[ Tue May 24 16:20:51 2022 ] 	Mean test loss of 796 batches: 0.5930289489652344.
[ Tue May 24 16:20:52 2022 ] 	Top1: 83.78%
[ Tue May 24 16:20:53 2022 ] 	Top5: 96.76%
[ Tue May 24 16:20:53 2022 ] Training epoch: 57
[ Tue May 24 16:45:34 2022 ] 	Mean training loss: 0.0494.  Mean training acc: 99.10%.
[ Tue May 24 16:45:34 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 16:45:34 2022 ] Eval epoch: 57
[ Tue May 24 16:52:10 2022 ] 	Mean test loss of 796 batches: 0.5934402646131851.
[ Tue May 24 16:52:11 2022 ] 	Top1: 84.04%
[ Tue May 24 16:52:12 2022 ] 	Top5: 96.79%
[ Tue May 24 16:52:12 2022 ] Training epoch: 58
[ Tue May 24 17:14:04 2022 ] 	Mean training loss: 0.0432.  Mean training acc: 99.33%.
[ Tue May 24 17:14:04 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 17:14:04 2022 ] Eval epoch: 58
[ Tue May 24 17:17:50 2022 ] 	Mean test loss of 796 batches: 0.590175045392097.
[ Tue May 24 17:17:51 2022 ] 	Top1: 84.13%
[ Tue May 24 17:17:52 2022 ] 	Top5: 96.78%
[ Tue May 24 17:17:52 2022 ] Training epoch: 59
[ Tue May 24 17:38:56 2022 ] 	Mean training loss: 0.0412.  Mean training acc: 99.31%.
[ Tue May 24 17:38:56 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 17:38:57 2022 ] Eval epoch: 59
[ Tue May 24 17:44:26 2022 ] 	Mean test loss of 796 batches: 0.6077568066123892.
[ Tue May 24 17:44:27 2022 ] 	Top1: 83.61%
[ Tue May 24 17:44:28 2022 ] 	Top5: 96.70%
[ Tue May 24 17:44:28 2022 ] Training epoch: 60
[ Tue May 24 18:05:05 2022 ] 	Mean training loss: 0.0367.  Mean training acc: 99.44%.
[ Tue May 24 18:05:05 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue May 24 18:05:06 2022 ] Eval epoch: 60
[ Tue May 24 18:10:12 2022 ] 	Mean test loss of 796 batches: 0.5997965614119517.
[ Tue May 24 18:10:12 2022 ] 	Top1: 84.00%
[ Tue May 24 18:10:13 2022 ] 	Top5: 96.79%
[ Tue May 24 18:10:13 2022 ] Training epoch: 61
[ Tue May 24 18:31:30 2022 ] 	Mean training loss: 0.0335.  Mean training acc: 99.53%.
[ Tue May 24 18:31:30 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 18:31:30 2022 ] Eval epoch: 61
[ Tue May 24 18:36:44 2022 ] 	Mean test loss of 796 batches: 0.6153229848954396.
[ Tue May 24 18:36:44 2022 ] 	Top1: 83.59%
[ Tue May 24 18:36:45 2022 ] 	Top5: 96.69%
[ Tue May 24 18:36:45 2022 ] Training epoch: 62
[ Tue May 24 18:57:19 2022 ] 	Mean training loss: 0.0339.  Mean training acc: 99.50%.
[ Tue May 24 18:57:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue May 24 18:57:19 2022 ] Eval epoch: 62
[ Tue May 24 19:02:29 2022 ] 	Mean test loss of 796 batches: 0.5990143884254161.
[ Tue May 24 19:02:29 2022 ] 	Top1: 84.01%
[ Tue May 24 19:02:30 2022 ] 	Top5: 96.71%
[ Tue May 24 19:02:30 2022 ] Training epoch: 63
[ Tue May 24 19:19:23 2022 ] 	Mean training loss: 0.0311.  Mean training acc: 99.59%.
[ Tue May 24 19:19:23 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 19:19:23 2022 ] Eval epoch: 63
[ Tue May 24 19:23:21 2022 ] 	Mean test loss of 796 batches: 0.6046146177522951.
[ Tue May 24 19:23:21 2022 ] 	Top1: 83.95%
[ Tue May 24 19:23:22 2022 ] 	Top5: 96.61%
[ Tue May 24 19:23:22 2022 ] Training epoch: 64
[ Tue May 24 19:38:36 2022 ] 	Mean training loss: 0.0296.  Mean training acc: 99.65%.
[ Tue May 24 19:38:36 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue May 24 19:38:36 2022 ] Eval epoch: 64
[ Tue May 24 19:42:28 2022 ] 	Mean test loss of 796 batches: 0.5946407286197546.
[ Tue May 24 19:42:29 2022 ] 	Top1: 84.20%
[ Tue May 24 19:42:29 2022 ] 	Top5: 96.73%
[ Tue May 24 19:42:30 2022 ] Training epoch: 65
[ Tue May 24 19:58:19 2022 ] 	Mean training loss: 0.0299.  Mean training acc: 99.60%.
[ Tue May 24 19:58:19 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Tue May 24 19:58:19 2022 ] Eval epoch: 65
[ Tue May 24 20:02:21 2022 ] 	Mean test loss of 796 batches: 0.605865849977612.
[ Tue May 24 20:02:21 2022 ] 	Top1: 84.04%
[ Tue May 24 20:02:22 2022 ] 	Top5: 96.66%
[ Tue May 24 20:06:24 2022 ] Best accuracy: 0.841984328050433
[ Tue May 24 20:06:24 2022 ] Epoch number: 64
[ Tue May 24 20:06:24 2022 ] Model name: work_dir/ntu120/csub/base_vel8
[ Tue May 24 20:06:24 2022 ] Model total number of params: 2784480
[ Tue May 24 20:06:24 2022 ] Weight decay: 0.0004
[ Tue May 24 20:06:24 2022 ] Base LR: 0.1
[ Tue May 24 20:06:24 2022 ] Batch Size: 64
[ Tue May 24 20:06:24 2022 ] Test Batch Size: 64
[ Tue May 24 20:06:24 2022 ] seed: 1
