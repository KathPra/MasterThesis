[ Tue Nov  1 18:28:45 2022 ] using warm up, epoch: 5
[ Tue Nov  1 18:29:31 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod9b', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod9b/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module9b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Nov  1 18:29:31 2022 ] # Parameters: 2192050
[ Tue Nov  1 18:29:31 2022 ] Training epoch: 1
[ Tue Nov  1 18:34:28 2022 ] 	Mean training loss: 3.0932.  Mean training acc: 23.13%.
[ Tue Nov  1 18:34:28 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 18:34:28 2022 ] Eval epoch: 1
[ Tue Nov  1 18:36:00 2022 ] 	Mean test loss of 796 batches: 2.337980340174095.
[ Tue Nov  1 18:36:01 2022 ] 	Top1: 34.64%
[ Tue Nov  1 18:36:02 2022 ] 	Top5: 71.05%
[ Tue Nov  1 18:36:02 2022 ] Training epoch: 2
[ Tue Nov  1 18:43:23 2022 ] 	Mean training loss: 2.0308.  Mean training acc: 43.45%.
[ Tue Nov  1 18:43:23 2022 ] 	Time consumption: [Data]05%, [Network]93%
[ Tue Nov  1 18:43:23 2022 ] Eval epoch: 2
[ Tue Nov  1 18:45:04 2022 ] 	Mean test loss of 796 batches: 1.8055585696170078.
[ Tue Nov  1 18:45:05 2022 ] 	Top1: 47.66%
[ Tue Nov  1 18:45:06 2022 ] 	Top5: 80.65%
[ Tue Nov  1 18:45:06 2022 ] Training epoch: 3
[ Tue Nov  1 18:50:22 2022 ] 	Mean training loss: 1.6501.  Mean training acc: 52.56%.
[ Tue Nov  1 18:50:22 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 18:50:22 2022 ] Eval epoch: 3
[ Tue Nov  1 18:53:04 2022 ] 	Mean test loss of 796 batches: 1.7581657869132918.
[ Tue Nov  1 18:53:05 2022 ] 	Top1: 51.24%
[ Tue Nov  1 18:53:07 2022 ] 	Top5: 82.03%
[ Tue Nov  1 18:53:07 2022 ] Training epoch: 4
[ Tue Nov  1 19:00:07 2022 ] 	Mean training loss: 1.4347.  Mean training acc: 58.30%.
[ Tue Nov  1 19:00:07 2022 ] 	Time consumption: [Data]06%, [Network]92%
[ Tue Nov  1 19:00:07 2022 ] Eval epoch: 4
[ Tue Nov  1 19:02:30 2022 ] 	Mean test loss of 796 batches: 1.5867063652480666.
[ Tue Nov  1 19:02:30 2022 ] 	Top1: 54.89%
[ Tue Nov  1 19:02:31 2022 ] 	Top5: 85.33%
[ Tue Nov  1 19:02:31 2022 ] Training epoch: 5
[ Tue Nov  1 19:11:19 2022 ] 	Mean training loss: 1.3074.  Mean training acc: 61.48%.
[ Tue Nov  1 19:11:19 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue Nov  1 19:11:19 2022 ] Eval epoch: 5
[ Tue Nov  1 19:14:02 2022 ] 	Mean test loss of 796 batches: 1.7149683646670537.
[ Tue Nov  1 19:14:03 2022 ] 	Top1: 52.32%
[ Tue Nov  1 19:14:05 2022 ] 	Top5: 85.01%
[ Tue Nov  1 19:14:05 2022 ] Training epoch: 6
[ Tue Nov  1 19:23:14 2022 ] 	Mean training loss: 1.1799.  Mean training acc: 65.07%.
[ Tue Nov  1 19:23:14 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue Nov  1 19:23:14 2022 ] Eval epoch: 6
[ Tue Nov  1 19:25:43 2022 ] 	Mean test loss of 796 batches: 1.4774277029774296.
[ Tue Nov  1 19:25:44 2022 ] 	Top1: 56.88%
[ Tue Nov  1 19:25:45 2022 ] 	Top5: 86.86%
[ Tue Nov  1 19:25:45 2022 ] Training epoch: 7
[ Tue Nov  1 19:34:50 2022 ] 	Mean training loss: 1.1055.  Mean training acc: 66.95%.
[ Tue Nov  1 19:34:50 2022 ] 	Time consumption: [Data]04%, [Network]94%
[ Tue Nov  1 19:34:50 2022 ] Eval epoch: 7
[ Tue Nov  1 19:37:36 2022 ] 	Mean test loss of 796 batches: 1.5803877283355698.
[ Tue Nov  1 19:37:38 2022 ] 	Top1: 55.73%
[ Tue Nov  1 19:37:39 2022 ] 	Top5: 86.68%
[ Tue Nov  1 19:37:39 2022 ] Training epoch: 8
[ Tue Nov  1 19:46:42 2022 ] 	Mean training loss: 1.0513.  Mean training acc: 68.59%.
[ Tue Nov  1 19:46:42 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Tue Nov  1 19:46:42 2022 ] Eval epoch: 8
[ Tue Nov  1 19:48:06 2022 ] 	Mean test loss of 796 batches: 1.1674109225222213.
[ Tue Nov  1 19:48:07 2022 ] 	Top1: 64.78%
[ Tue Nov  1 19:48:08 2022 ] 	Top5: 90.98%
[ Tue Nov  1 19:48:08 2022 ] Training epoch: 9
[ Tue Nov  1 19:55:43 2022 ] 	Mean training loss: 1.0117.  Mean training acc: 69.58%.
[ Tue Nov  1 19:55:43 2022 ] 	Time consumption: [Data]05%, [Network]93%
[ Tue Nov  1 19:55:43 2022 ] Eval epoch: 9
[ Tue Nov  1 19:57:11 2022 ] 	Mean test loss of 796 batches: 1.309454144994218.
[ Tue Nov  1 19:57:13 2022 ] 	Top1: 63.25%
[ Tue Nov  1 19:57:14 2022 ] 	Top5: 88.84%
[ Tue Nov  1 19:57:15 2022 ] Training epoch: 10
[ Tue Nov  1 20:02:12 2022 ] 	Mean training loss: 0.9795.  Mean training acc: 70.13%.
[ Tue Nov  1 20:02:12 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 20:02:12 2022 ] Eval epoch: 10
[ Tue Nov  1 20:03:25 2022 ] 	Mean test loss of 796 batches: 1.213272199783493.
[ Tue Nov  1 20:03:27 2022 ] 	Top1: 64.80%
[ Tue Nov  1 20:03:28 2022 ] 	Top5: 90.62%
[ Tue Nov  1 20:03:28 2022 ] Training epoch: 11
[ Tue Nov  1 20:08:11 2022 ] 	Mean training loss: 0.9516.  Mean training acc: 71.32%.
[ Tue Nov  1 20:08:11 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 20:08:11 2022 ] Eval epoch: 11
[ Tue Nov  1 20:09:40 2022 ] 	Mean test loss of 796 batches: 1.14050472392958.
[ Tue Nov  1 20:09:41 2022 ] 	Top1: 66.84%
[ Tue Nov  1 20:09:42 2022 ] 	Top5: 91.12%
[ Tue Nov  1 20:09:43 2022 ] Training epoch: 12
[ Tue Nov  1 20:15:03 2022 ] 	Mean training loss: 0.9284.  Mean training acc: 72.00%.
[ Tue Nov  1 20:15:03 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 20:15:03 2022 ] Eval epoch: 12
[ Tue Nov  1 20:16:29 2022 ] 	Mean test loss of 796 batches: 1.3703844205069182.
[ Tue Nov  1 20:16:30 2022 ] 	Top1: 62.46%
[ Tue Nov  1 20:16:30 2022 ] 	Top5: 87.85%
[ Tue Nov  1 20:16:31 2022 ] Training epoch: 13
[ Tue Nov  1 20:20:53 2022 ] 	Mean training loss: 0.9118.  Mean training acc: 72.40%.
[ Tue Nov  1 20:20:53 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 20:20:53 2022 ] Eval epoch: 13
[ Tue Nov  1 20:22:09 2022 ] 	Mean test loss of 796 batches: 1.0940692845600932.
[ Tue Nov  1 20:22:10 2022 ] 	Top1: 68.47%
[ Tue Nov  1 20:22:12 2022 ] 	Top5: 91.90%
[ Tue Nov  1 20:22:12 2022 ] Training epoch: 14
[ Tue Nov  1 20:27:25 2022 ] 	Mean training loss: 0.9027.  Mean training acc: 72.67%.
[ Tue Nov  1 20:27:25 2022 ] 	Time consumption: [Data]06%, [Network]91%
[ Tue Nov  1 20:27:25 2022 ] Eval epoch: 14
[ Tue Nov  1 20:28:56 2022 ] 	Mean test loss of 796 batches: 1.2622440449107233.
[ Tue Nov  1 20:28:57 2022 ] 	Top1: 64.01%
[ Tue Nov  1 20:28:58 2022 ] 	Top5: 90.01%
[ Tue Nov  1 20:28:58 2022 ] Training epoch: 15
[ Tue Nov  1 20:33:54 2022 ] 	Mean training loss: 0.8937.  Mean training acc: 73.03%.
[ Tue Nov  1 20:33:54 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 20:33:54 2022 ] Eval epoch: 15
[ Tue Nov  1 20:35:13 2022 ] 	Mean test loss of 796 batches: 1.4805939148868148.
[ Tue Nov  1 20:35:14 2022 ] 	Top1: 60.53%
[ Tue Nov  1 20:35:15 2022 ] 	Top5: 89.10%
[ Tue Nov  1 20:35:15 2022 ] Training epoch: 16
[ Tue Nov  1 20:40:25 2022 ] 	Mean training loss: 0.8834.  Mean training acc: 73.18%.
[ Tue Nov  1 20:40:25 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 20:40:25 2022 ] Eval epoch: 16
[ Tue Nov  1 20:41:54 2022 ] 	Mean test loss of 796 batches: 1.5214532629104716.
[ Tue Nov  1 20:41:55 2022 ] 	Top1: 58.13%
[ Tue Nov  1 20:41:56 2022 ] 	Top5: 87.03%
[ Tue Nov  1 20:41:57 2022 ] Training epoch: 17
[ Tue Nov  1 20:47:10 2022 ] 	Mean training loss: 0.8666.  Mean training acc: 73.77%.
[ Tue Nov  1 20:47:10 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 20:47:10 2022 ] Eval epoch: 17
[ Tue Nov  1 20:48:24 2022 ] 	Mean test loss of 796 batches: 1.136267424041602.
[ Tue Nov  1 20:48:25 2022 ] 	Top1: 67.56%
[ Tue Nov  1 20:48:26 2022 ] 	Top5: 91.02%
[ Tue Nov  1 20:48:26 2022 ] Training epoch: 18
[ Tue Nov  1 20:53:19 2022 ] 	Mean training loss: 0.8596.  Mean training acc: 74.08%.
[ Tue Nov  1 20:53:19 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 20:53:19 2022 ] Eval epoch: 18
[ Tue Nov  1 20:54:46 2022 ] 	Mean test loss of 796 batches: 1.1521924056824129.
[ Tue Nov  1 20:54:47 2022 ] 	Top1: 66.33%
[ Tue Nov  1 20:54:48 2022 ] 	Top5: 91.17%
[ Tue Nov  1 20:54:48 2022 ] Training epoch: 19
[ Tue Nov  1 21:00:16 2022 ] 	Mean training loss: 0.8554.  Mean training acc: 74.12%.
[ Tue Nov  1 21:00:16 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 21:00:16 2022 ] Eval epoch: 19
[ Tue Nov  1 21:01:29 2022 ] 	Mean test loss of 796 batches: 1.0534610893558618.
[ Tue Nov  1 21:01:30 2022 ] 	Top1: 69.53%
[ Tue Nov  1 21:01:31 2022 ] 	Top5: 92.48%
[ Tue Nov  1 21:01:31 2022 ] Training epoch: 20
[ Tue Nov  1 21:05:58 2022 ] 	Mean training loss: 0.8452.  Mean training acc: 74.44%.
[ Tue Nov  1 21:05:58 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 21:05:58 2022 ] Eval epoch: 20
[ Tue Nov  1 21:07:25 2022 ] 	Mean test loss of 796 batches: 1.213804556084937.
[ Tue Nov  1 21:07:26 2022 ] 	Top1: 65.39%
[ Tue Nov  1 21:07:27 2022 ] 	Top5: 90.38%
[ Tue Nov  1 21:07:27 2022 ] Training epoch: 21
[ Tue Nov  1 21:12:57 2022 ] 	Mean training loss: 0.8415.  Mean training acc: 74.70%.
[ Tue Nov  1 21:12:57 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 21:12:57 2022 ] Eval epoch: 21
[ Tue Nov  1 21:14:25 2022 ] 	Mean test loss of 796 batches: 1.3004351960279834.
[ Tue Nov  1 21:14:26 2022 ] 	Top1: 64.68%
[ Tue Nov  1 21:14:27 2022 ] 	Top5: 90.00%
[ Tue Nov  1 21:14:27 2022 ] Training epoch: 22
[ Tue Nov  1 21:18:57 2022 ] 	Mean training loss: 0.8338.  Mean training acc: 74.73%.
[ Tue Nov  1 21:18:57 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 21:18:57 2022 ] Eval epoch: 22
[ Tue Nov  1 21:20:17 2022 ] 	Mean test loss of 796 batches: 1.046521947124795.
[ Tue Nov  1 21:20:18 2022 ] 	Top1: 68.87%
[ Tue Nov  1 21:20:19 2022 ] 	Top5: 92.37%
[ Tue Nov  1 21:20:19 2022 ] Training epoch: 23
[ Tue Nov  1 21:25:47 2022 ] 	Mean training loss: 0.8243.  Mean training acc: 74.90%.
[ Tue Nov  1 21:25:47 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 21:25:47 2022 ] Eval epoch: 23
[ Tue Nov  1 21:27:13 2022 ] 	Mean test loss of 796 batches: 1.1969074075245978.
[ Tue Nov  1 21:27:14 2022 ] 	Top1: 65.73%
[ Tue Nov  1 21:27:15 2022 ] 	Top5: 90.45%
[ Tue Nov  1 21:27:15 2022 ] Training epoch: 24
[ Tue Nov  1 21:32:03 2022 ] 	Mean training loss: 0.8297.  Mean training acc: 74.63%.
[ Tue Nov  1 21:32:03 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 21:32:03 2022 ] Eval epoch: 24
[ Tue Nov  1 21:33:16 2022 ] 	Mean test loss of 796 batches: 1.3781431783833096.
[ Tue Nov  1 21:33:17 2022 ] 	Top1: 61.38%
[ Tue Nov  1 21:33:18 2022 ] 	Top5: 87.38%
[ Tue Nov  1 21:33:18 2022 ] Training epoch: 25
[ Tue Nov  1 21:38:36 2022 ] 	Mean training loss: 0.8222.  Mean training acc: 74.92%.
[ Tue Nov  1 21:38:36 2022 ] 	Time consumption: [Data]06%, [Network]92%
[ Tue Nov  1 21:38:36 2022 ] Eval epoch: 25
[ Tue Nov  1 21:40:07 2022 ] 	Mean test loss of 796 batches: 1.2432337540328202.
[ Tue Nov  1 21:40:08 2022 ] 	Top1: 64.77%
[ Tue Nov  1 21:40:09 2022 ] 	Top5: 90.01%
[ Tue Nov  1 21:40:09 2022 ] Training epoch: 26
[ Tue Nov  1 21:45:07 2022 ] 	Mean training loss: 0.8180.  Mean training acc: 75.22%.
[ Tue Nov  1 21:45:07 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 21:45:07 2022 ] Eval epoch: 26
[ Tue Nov  1 21:46:22 2022 ] 	Mean test loss of 796 batches: 1.1373984615257637.
[ Tue Nov  1 21:46:23 2022 ] 	Top1: 67.69%
[ Tue Nov  1 21:46:25 2022 ] 	Top5: 90.31%
[ Tue Nov  1 21:46:25 2022 ] Training epoch: 27
[ Tue Nov  1 21:51:16 2022 ] 	Mean training loss: 0.8145.  Mean training acc: 75.19%.
[ Tue Nov  1 21:51:16 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 21:51:16 2022 ] Eval epoch: 27
[ Tue Nov  1 21:52:48 2022 ] 	Mean test loss of 796 batches: 1.461994457933771.
[ Tue Nov  1 21:52:49 2022 ] 	Top1: 61.23%
[ Tue Nov  1 21:52:50 2022 ] 	Top5: 85.74%
[ Tue Nov  1 21:52:50 2022 ] Training epoch: 28
[ Tue Nov  1 21:58:13 2022 ] 	Mean training loss: 0.8071.  Mean training acc: 75.46%.
[ Tue Nov  1 21:58:13 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 21:58:13 2022 ] Eval epoch: 28
[ Tue Nov  1 21:59:29 2022 ] 	Mean test loss of 796 batches: 1.186815876345239.
[ Tue Nov  1 21:59:30 2022 ] 	Top1: 66.25%
[ Tue Nov  1 21:59:31 2022 ] 	Top5: 91.17%
[ Tue Nov  1 21:59:31 2022 ] Training epoch: 29
[ Tue Nov  1 22:03:53 2022 ] 	Mean training loss: 0.8062.  Mean training acc: 75.43%.
[ Tue Nov  1 22:03:53 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 22:03:53 2022 ] Eval epoch: 29
[ Tue Nov  1 22:05:25 2022 ] 	Mean test loss of 796 batches: 1.088200226950286.
[ Tue Nov  1 22:05:26 2022 ] 	Top1: 68.34%
[ Tue Nov  1 22:05:28 2022 ] 	Top5: 91.87%
[ Tue Nov  1 22:05:28 2022 ] Training epoch: 30
[ Tue Nov  1 22:10:46 2022 ] 	Mean training loss: 0.8104.  Mean training acc: 75.42%.
[ Tue Nov  1 22:10:46 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:10:46 2022 ] Eval epoch: 30
[ Tue Nov  1 22:12:14 2022 ] 	Mean test loss of 796 batches: 1.6083076130130782.
[ Tue Nov  1 22:12:15 2022 ] 	Top1: 58.00%
[ Tue Nov  1 22:12:17 2022 ] 	Top5: 85.09%
[ Tue Nov  1 22:12:17 2022 ] Training epoch: 31
[ Tue Nov  1 22:17:00 2022 ] 	Mean training loss: 0.8041.  Mean training acc: 75.63%.
[ Tue Nov  1 22:17:00 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 22:17:00 2022 ] Eval epoch: 31
[ Tue Nov  1 22:18:17 2022 ] 	Mean test loss of 796 batches: 1.144197275253696.
[ Tue Nov  1 22:18:18 2022 ] 	Top1: 67.03%
[ Tue Nov  1 22:18:19 2022 ] 	Top5: 90.61%
[ Tue Nov  1 22:18:19 2022 ] Training epoch: 32
[ Tue Nov  1 22:23:38 2022 ] 	Mean training loss: 0.7981.  Mean training acc: 75.73%.
[ Tue Nov  1 22:23:38 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:23:38 2022 ] Eval epoch: 32
[ Tue Nov  1 22:25:10 2022 ] 	Mean test loss of 796 batches: 1.0439497367221506.
[ Tue Nov  1 22:25:11 2022 ] 	Top1: 68.72%
[ Tue Nov  1 22:25:12 2022 ] 	Top5: 92.33%
[ Tue Nov  1 22:25:13 2022 ] Training epoch: 33
[ Tue Nov  1 22:30:16 2022 ] 	Mean training loss: 0.7995.  Mean training acc: 75.66%.
[ Tue Nov  1 22:30:16 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:30:16 2022 ] Eval epoch: 33
[ Tue Nov  1 22:31:30 2022 ] 	Mean test loss of 796 batches: 1.0510261923673765.
[ Tue Nov  1 22:31:31 2022 ] 	Top1: 69.58%
[ Tue Nov  1 22:31:32 2022 ] 	Top5: 92.20%
[ Tue Nov  1 22:31:32 2022 ] Training epoch: 34
[ Tue Nov  1 22:36:47 2022 ] 	Mean training loss: 0.7979.  Mean training acc: 75.96%.
[ Tue Nov  1 22:36:47 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:36:47 2022 ] Eval epoch: 34
[ Tue Nov  1 22:38:15 2022 ] 	Mean test loss of 796 batches: 1.3173430465798281.
[ Tue Nov  1 22:38:16 2022 ] 	Top1: 64.08%
[ Tue Nov  1 22:38:17 2022 ] 	Top5: 89.59%
[ Tue Nov  1 22:38:17 2022 ] Training epoch: 35
[ Tue Nov  1 22:43:22 2022 ] 	Mean training loss: 0.7895.  Mean training acc: 76.01%.
[ Tue Nov  1 22:43:22 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Tue Nov  1 22:43:22 2022 ] Eval epoch: 35
[ Tue Nov  1 22:44:36 2022 ] 	Mean test loss of 796 batches: 1.0460579940047696.
[ Tue Nov  1 22:44:37 2022 ] 	Top1: 69.53%
[ Tue Nov  1 22:44:38 2022 ] 	Top5: 92.02%
[ Tue Nov  1 22:44:38 2022 ] Training epoch: 36
[ Tue Nov  1 22:49:32 2022 ] 	Mean training loss: 0.4616.  Mean training acc: 85.75%.
[ Tue Nov  1 22:49:32 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:49:32 2022 ] Eval epoch: 36
[ Tue Nov  1 22:51:03 2022 ] 	Mean test loss of 796 batches: 0.6182904380874418.
[ Tue Nov  1 22:51:04 2022 ] 	Top1: 80.85%
[ Tue Nov  1 22:51:05 2022 ] 	Top5: 96.42%
[ Tue Nov  1 22:51:06 2022 ] Training epoch: 37
[ Tue Nov  1 22:56:29 2022 ] 	Mean training loss: 0.3750.  Mean training acc: 88.34%.
[ Tue Nov  1 22:56:29 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 22:56:29 2022 ] Eval epoch: 37
[ Tue Nov  1 22:57:46 2022 ] 	Mean test loss of 796 batches: 0.5894635527970353.
[ Tue Nov  1 22:57:47 2022 ] 	Top1: 81.72%
[ Tue Nov  1 22:57:47 2022 ] 	Top5: 96.66%
[ Tue Nov  1 22:57:48 2022 ] Training epoch: 38
[ Tue Nov  1 23:02:31 2022 ] 	Mean training loss: 0.3356.  Mean training acc: 89.60%.
[ Tue Nov  1 23:02:31 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 23:02:31 2022 ] Eval epoch: 38
[ Tue Nov  1 23:04:03 2022 ] 	Mean test loss of 796 batches: 0.6028326935504549.
[ Tue Nov  1 23:04:05 2022 ] 	Top1: 81.74%
[ Tue Nov  1 23:04:06 2022 ] 	Top5: 96.48%
[ Tue Nov  1 23:04:06 2022 ] Training epoch: 39
[ Tue Nov  1 23:09:29 2022 ] 	Mean training loss: 0.3095.  Mean training acc: 90.37%.
[ Tue Nov  1 23:09:29 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:09:30 2022 ] Eval epoch: 39
[ Tue Nov  1 23:10:51 2022 ] 	Mean test loss of 796 batches: 0.60102298656413.
[ Tue Nov  1 23:10:53 2022 ] 	Top1: 82.02%
[ Tue Nov  1 23:10:54 2022 ] 	Top5: 96.59%
[ Tue Nov  1 23:10:54 2022 ] Training epoch: 40
[ Tue Nov  1 23:15:25 2022 ] 	Mean training loss: 0.2863.  Mean training acc: 90.99%.
[ Tue Nov  1 23:15:25 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Tue Nov  1 23:15:25 2022 ] Eval epoch: 40
[ Tue Nov  1 23:16:53 2022 ] 	Mean test loss of 796 batches: 0.5980257763897054.
[ Tue Nov  1 23:16:55 2022 ] 	Top1: 81.80%
[ Tue Nov  1 23:16:56 2022 ] 	Top5: 96.64%
[ Tue Nov  1 23:16:56 2022 ] Training epoch: 41
[ Tue Nov  1 23:22:20 2022 ] 	Mean training loss: 0.2662.  Mean training acc: 91.62%.
[ Tue Nov  1 23:22:20 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:22:21 2022 ] Eval epoch: 41
[ Tue Nov  1 23:23:47 2022 ] 	Mean test loss of 796 batches: 0.6599307142141926.
[ Tue Nov  1 23:23:48 2022 ] 	Top1: 80.70%
[ Tue Nov  1 23:23:49 2022 ] 	Top5: 96.13%
[ Tue Nov  1 23:23:49 2022 ] Training epoch: 42
[ Tue Nov  1 23:28:19 2022 ] 	Mean training loss: 0.2517.  Mean training acc: 92.07%.
[ Tue Nov  1 23:28:19 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:28:19 2022 ] Eval epoch: 42
[ Tue Nov  1 23:29:38 2022 ] 	Mean test loss of 796 batches: 0.6248519745884679.
[ Tue Nov  1 23:29:39 2022 ] 	Top1: 81.87%
[ Tue Nov  1 23:29:40 2022 ] 	Top5: 96.48%
[ Tue Nov  1 23:29:41 2022 ] Training epoch: 43
[ Tue Nov  1 23:34:54 2022 ] 	Mean training loss: 0.2409.  Mean training acc: 92.46%.
[ Tue Nov  1 23:34:54 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:34:54 2022 ] Eval epoch: 43
[ Tue Nov  1 23:36:22 2022 ] 	Mean test loss of 796 batches: 0.6481818294517658.
[ Tue Nov  1 23:36:23 2022 ] 	Top1: 81.26%
[ Tue Nov  1 23:36:25 2022 ] 	Top5: 96.25%
[ Tue Nov  1 23:36:25 2022 ] Training epoch: 44
[ Tue Nov  1 23:41:18 2022 ] 	Mean training loss: 0.2296.  Mean training acc: 92.81%.
[ Tue Nov  1 23:41:18 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:41:18 2022 ] Eval epoch: 44
[ Tue Nov  1 23:42:34 2022 ] 	Mean test loss of 796 batches: 0.6438685639681828.
[ Tue Nov  1 23:42:35 2022 ] 	Top1: 81.58%
[ Tue Nov  1 23:42:36 2022 ] 	Top5: 96.45%
[ Tue Nov  1 23:42:36 2022 ] Training epoch: 45
[ Tue Nov  1 23:47:45 2022 ] 	Mean training loss: 0.2248.  Mean training acc: 92.95%.
[ Tue Nov  1 23:47:45 2022 ] 	Time consumption: [Data]06%, [Network]92%
[ Tue Nov  1 23:47:45 2022 ] Eval epoch: 45
[ Tue Nov  1 23:49:13 2022 ] 	Mean test loss of 796 batches: 0.672270924742123.
[ Tue Nov  1 23:49:14 2022 ] 	Top1: 81.26%
[ Tue Nov  1 23:49:15 2022 ] 	Top5: 96.00%
[ Tue Nov  1 23:49:16 2022 ] Training epoch: 46
[ Tue Nov  1 23:54:19 2022 ] 	Mean training loss: 0.2207.  Mean training acc: 93.08%.
[ Tue Nov  1 23:54:19 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Tue Nov  1 23:54:19 2022 ] Eval epoch: 46
[ Tue Nov  1 23:55:33 2022 ] 	Mean test loss of 796 batches: 0.6881276660472454.
[ Tue Nov  1 23:55:34 2022 ] 	Top1: 80.59%
[ Tue Nov  1 23:55:35 2022 ] 	Top5: 95.98%
[ Tue Nov  1 23:55:35 2022 ] Training epoch: 47
[ Wed Nov  2 00:00:32 2022 ] 	Mean training loss: 0.2105.  Mean training acc: 93.41%.
[ Wed Nov  2 00:00:32 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:00:32 2022 ] Eval epoch: 47
[ Wed Nov  2 00:02:00 2022 ] 	Mean test loss of 796 batches: 0.6971039186376873.
[ Wed Nov  2 00:02:00 2022 ] 	Top1: 80.41%
[ Wed Nov  2 00:02:01 2022 ] 	Top5: 95.95%
[ Wed Nov  2 00:02:01 2022 ] Training epoch: 48
[ Wed Nov  2 00:07:18 2022 ] 	Mean training loss: 0.2056.  Mean training acc: 93.60%.
[ Wed Nov  2 00:07:18 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:07:18 2022 ] Eval epoch: 48
[ Wed Nov  2 00:08:32 2022 ] 	Mean test loss of 796 batches: 0.722046203022102.
[ Wed Nov  2 00:08:33 2022 ] 	Top1: 79.78%
[ Wed Nov  2 00:08:34 2022 ] 	Top5: 95.71%
[ Wed Nov  2 00:08:34 2022 ] Training epoch: 49
[ Wed Nov  2 00:13:19 2022 ] 	Mean training loss: 0.2062.  Mean training acc: 93.54%.
[ Wed Nov  2 00:13:19 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:13:19 2022 ] Eval epoch: 49
[ Wed Nov  2 00:14:48 2022 ] 	Mean test loss of 796 batches: 0.7468188117918133.
[ Wed Nov  2 00:14:49 2022 ] 	Top1: 79.86%
[ Wed Nov  2 00:14:50 2022 ] 	Top5: 95.53%
[ Wed Nov  2 00:14:50 2022 ] Training epoch: 50
[ Wed Nov  2 00:20:17 2022 ] 	Mean training loss: 0.2026.  Mean training acc: 93.73%.
[ Wed Nov  2 00:20:17 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:20:17 2022 ] Eval epoch: 50
[ Wed Nov  2 00:21:34 2022 ] 	Mean test loss of 796 batches: 0.7389878445403211.
[ Wed Nov  2 00:21:34 2022 ] 	Top1: 79.60%
[ Wed Nov  2 00:21:35 2022 ] 	Top5: 95.26%
[ Wed Nov  2 00:21:35 2022 ] Training epoch: 51
[ Wed Nov  2 00:26:19 2022 ] 	Mean training loss: 0.2017.  Mean training acc: 93.71%.
[ Wed Nov  2 00:26:19 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:26:19 2022 ] Eval epoch: 51
[ Wed Nov  2 00:27:47 2022 ] 	Mean test loss of 796 batches: 0.8141376858006171.
[ Wed Nov  2 00:27:48 2022 ] 	Top1: 78.68%
[ Wed Nov  2 00:27:49 2022 ] 	Top5: 94.76%
[ Wed Nov  2 00:27:49 2022 ] Training epoch: 52
[ Wed Nov  2 00:33:14 2022 ] 	Mean training loss: 0.2018.  Mean training acc: 93.82%.
[ Wed Nov  2 00:33:14 2022 ] 	Time consumption: [Data]06%, [Network]92%
[ Wed Nov  2 00:33:14 2022 ] Eval epoch: 52
[ Wed Nov  2 00:34:37 2022 ] 	Mean test loss of 796 batches: 0.7383319996110159.
[ Wed Nov  2 00:34:38 2022 ] 	Top1: 80.03%
[ Wed Nov  2 00:34:39 2022 ] 	Top5: 95.75%
[ Wed Nov  2 00:34:39 2022 ] Training epoch: 53
[ Wed Nov  2 00:39:13 2022 ] 	Mean training loss: 0.2018.  Mean training acc: 93.69%.
[ Wed Nov  2 00:39:13 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:39:14 2022 ] Eval epoch: 53
[ Wed Nov  2 00:40:43 2022 ] 	Mean test loss of 796 batches: 0.7441010424895352.
[ Wed Nov  2 00:40:44 2022 ] 	Top1: 79.76%
[ Wed Nov  2 00:40:45 2022 ] 	Top5: 95.59%
[ Wed Nov  2 00:40:45 2022 ] Training epoch: 54
[ Wed Nov  2 00:46:10 2022 ] 	Mean training loss: 0.2015.  Mean training acc: 93.74%.
[ Wed Nov  2 00:46:10 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:46:10 2022 ] Eval epoch: 54
[ Wed Nov  2 00:47:37 2022 ] 	Mean test loss of 796 batches: 0.8220058060976578.
[ Wed Nov  2 00:47:38 2022 ] 	Top1: 78.13%
[ Wed Nov  2 00:47:39 2022 ] 	Top5: 94.76%
[ Wed Nov  2 00:47:39 2022 ] Training epoch: 55
[ Wed Nov  2 00:52:06 2022 ] 	Mean training loss: 0.1982.  Mean training acc: 93.82%.
[ Wed Nov  2 00:52:06 2022 ] 	Time consumption: [Data]08%, [Network]89%
[ Wed Nov  2 00:52:06 2022 ] Eval epoch: 55
[ Wed Nov  2 00:53:35 2022 ] 	Mean test loss of 796 batches: 0.7442778398624467.
[ Wed Nov  2 00:53:36 2022 ] 	Top1: 80.19%
[ Wed Nov  2 00:53:37 2022 ] 	Top5: 95.88%
[ Wed Nov  2 00:53:37 2022 ] Training epoch: 56
[ Wed Nov  2 00:59:01 2022 ] 	Mean training loss: 0.1122.  Mean training acc: 96.95%.
[ Wed Nov  2 00:59:01 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 00:59:01 2022 ] Eval epoch: 56
[ Wed Nov  2 01:00:28 2022 ] 	Mean test loss of 796 batches: 0.6605974325217568.
[ Wed Nov  2 01:00:29 2022 ] 	Top1: 82.01%
[ Wed Nov  2 01:00:30 2022 ] 	Top5: 96.36%
[ Wed Nov  2 01:00:31 2022 ] Training epoch: 57
[ Wed Nov  2 01:05:04 2022 ] 	Mean training loss: 0.0841.  Mean training acc: 97.96%.
[ Wed Nov  2 01:05:04 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Nov  2 01:05:04 2022 ] Eval epoch: 57
[ Wed Nov  2 01:06:22 2022 ] 	Mean test loss of 796 batches: 0.6631121514786278.
[ Wed Nov  2 01:06:23 2022 ] 	Top1: 82.18%
[ Wed Nov  2 01:06:24 2022 ] 	Top5: 96.38%
[ Wed Nov  2 01:06:24 2022 ] Training epoch: 58
[ Wed Nov  2 01:11:50 2022 ] 	Mean training loss: 0.0734.  Mean training acc: 98.25%.
[ Wed Nov  2 01:11:50 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 01:11:50 2022 ] Eval epoch: 58
[ Wed Nov  2 01:13:19 2022 ] 	Mean test loss of 796 batches: 0.6715812418076336.
[ Wed Nov  2 01:13:21 2022 ] 	Top1: 82.27%
[ Wed Nov  2 01:13:21 2022 ] 	Top5: 96.36%
[ Wed Nov  2 01:13:22 2022 ] Training epoch: 59
[ Wed Nov  2 01:18:06 2022 ] 	Mean training loss: 0.0676.  Mean training acc: 98.44%.
[ Wed Nov  2 01:18:06 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Nov  2 01:18:06 2022 ] Eval epoch: 59
[ Wed Nov  2 01:19:17 2022 ] 	Mean test loss of 796 batches: 0.6750953695573025.
[ Wed Nov  2 01:19:18 2022 ] 	Top1: 82.17%
[ Wed Nov  2 01:19:19 2022 ] 	Top5: 96.35%
[ Wed Nov  2 01:19:19 2022 ] Training epoch: 60
[ Wed Nov  2 01:24:50 2022 ] 	Mean training loss: 0.0624.  Mean training acc: 98.60%.
[ Wed Nov  2 01:24:50 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 01:24:50 2022 ] Eval epoch: 60
[ Wed Nov  2 01:26:18 2022 ] 	Mean test loss of 796 batches: 0.6772307156908077.
[ Wed Nov  2 01:26:19 2022 ] 	Top1: 82.22%
[ Wed Nov  2 01:26:21 2022 ] 	Top5: 96.35%
[ Wed Nov  2 01:26:21 2022 ] Training epoch: 61
[ Wed Nov  2 01:31:14 2022 ] 	Mean training loss: 0.0593.  Mean training acc: 98.66%.
[ Wed Nov  2 01:31:14 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Wed Nov  2 01:31:14 2022 ] Eval epoch: 61
[ Wed Nov  2 01:32:28 2022 ] 	Mean test loss of 796 batches: 0.6830019818281933.
[ Wed Nov  2 01:32:29 2022 ] 	Top1: 82.12%
[ Wed Nov  2 01:32:30 2022 ] 	Top5: 96.20%
[ Wed Nov  2 01:32:30 2022 ] Training epoch: 62
[ Wed Nov  2 01:37:52 2022 ] 	Mean training loss: 0.0559.  Mean training acc: 98.73%.
[ Wed Nov  2 01:37:52 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 01:37:52 2022 ] Eval epoch: 62
[ Wed Nov  2 01:39:24 2022 ] 	Mean test loss of 796 batches: 0.6847128194649166.
[ Wed Nov  2 01:39:25 2022 ] 	Top1: 82.22%
[ Wed Nov  2 01:39:26 2022 ] 	Top5: 96.19%
[ Wed Nov  2 01:39:26 2022 ] Training epoch: 63
[ Wed Nov  2 01:44:27 2022 ] 	Mean training loss: 0.0531.  Mean training acc: 98.89%.
[ Wed Nov  2 01:44:27 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 01:44:27 2022 ] Eval epoch: 63
[ Wed Nov  2 01:45:43 2022 ] 	Mean test loss of 796 batches: 0.6785516884486804.
[ Wed Nov  2 01:45:45 2022 ] 	Top1: 82.40%
[ Wed Nov  2 01:45:46 2022 ] 	Top5: 96.34%
[ Wed Nov  2 01:45:46 2022 ] Training epoch: 64
[ Wed Nov  2 01:51:01 2022 ] 	Mean training loss: 0.0510.  Mean training acc: 98.93%.
[ Wed Nov  2 01:51:01 2022 ] 	Time consumption: [Data]07%, [Network]90%
[ Wed Nov  2 01:51:01 2022 ] Eval epoch: 64
[ Wed Nov  2 01:52:31 2022 ] 	Mean test loss of 796 batches: 0.6914183991123459.
[ Wed Nov  2 01:52:32 2022 ] 	Top1: 82.15%
[ Wed Nov  2 01:52:33 2022 ] 	Top5: 96.21%
[ Wed Nov  2 01:52:33 2022 ] Training epoch: 65
[ Wed Nov  2 01:57:41 2022 ] 	Mean training loss: 0.0495.  Mean training acc: 98.95%.
[ Wed Nov  2 01:57:41 2022 ] 	Time consumption: [Data]07%, [Network]91%
[ Wed Nov  2 01:57:41 2022 ] Eval epoch: 65
[ Wed Nov  2 01:58:55 2022 ] 	Mean test loss of 796 batches: 0.6837304622243772.
[ Wed Nov  2 01:58:56 2022 ] 	Top1: 82.34%
[ Wed Nov  2 01:58:57 2022 ] 	Top5: 96.31%
[ Wed Nov  2 02:00:14 2022 ] Best accuracy: 0.8239949724071565
[ Wed Nov  2 02:00:14 2022 ] Epoch number: 63
[ Wed Nov  2 02:00:14 2022 ] Model name: work_dir/ntu120/csub/sym_mod9b
[ Wed Nov  2 02:00:14 2022 ] Model total number of params: 2192050
[ Wed Nov  2 02:00:14 2022 ] Weight decay: 0.0004
[ Wed Nov  2 02:00:14 2022 ] Base LR: 0.1
[ Wed Nov  2 02:00:14 2022 ] Batch Size: 64
[ Wed Nov  2 02:00:14 2022 ] Test Batch Size: 64
[ Wed Nov  2 02:00:14 2022 ] seed: 1
