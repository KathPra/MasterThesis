[ Wed Jul  6 11:21:38 2022 ] using warm up, epoch: 5
[ Wed Jul  6 11:22:04 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod1', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod1/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 11:22:04 2022 ] # Parameters: 2195826
[ Wed Jul  6 11:22:04 2022 ] Training epoch: 1
[ Wed Jul  6 11:25:11 2022 ] 	Mean training loss: 3.0727.  Mean training acc: 23.52%.
[ Wed Jul  6 11:25:11 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:25:11 2022 ] Eval epoch: 1
[ Wed Jul  6 11:25:59 2022 ] 	Mean test loss of 796 batches: 2.374697610661013.
[ Wed Jul  6 11:26:00 2022 ] 	Top1: 34.89%
[ Wed Jul  6 11:26:00 2022 ] 	Top5: 69.44%
[ Wed Jul  6 11:26:00 2022 ] Training epoch: 2
[ Wed Jul  6 11:29:07 2022 ] 	Mean training loss: 2.0962.  Mean training acc: 41.41%.
[ Wed Jul  6 11:29:07 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:29:07 2022 ] Eval epoch: 2
[ Wed Jul  6 11:29:55 2022 ] 	Mean test loss of 796 batches: 1.8884571643181183.
[ Wed Jul  6 11:29:56 2022 ] 	Top1: 44.33%
[ Wed Jul  6 11:29:56 2022 ] 	Top5: 80.58%
[ Wed Jul  6 11:29:56 2022 ] Training epoch: 3
[ Wed Jul  6 11:33:03 2022 ] 	Mean training loss: 1.7053.  Mean training acc: 50.96%.
[ Wed Jul  6 11:33:03 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:33:03 2022 ] Eval epoch: 3
[ Wed Jul  6 11:33:51 2022 ] 	Mean test loss of 796 batches: 1.677876032477048.
[ Wed Jul  6 11:33:52 2022 ] 	Top1: 51.72%
[ Wed Jul  6 11:33:52 2022 ] 	Top5: 83.43%
[ Wed Jul  6 11:33:52 2022 ] Training epoch: 4
[ Wed Jul  6 11:37:00 2022 ] 	Mean training loss: 1.4714.  Mean training acc: 57.12%.
[ Wed Jul  6 11:37:00 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:37:00 2022 ] Eval epoch: 4
[ Wed Jul  6 11:37:48 2022 ] 	Mean test loss of 796 batches: 1.4784164005637768.
[ Wed Jul  6 11:37:48 2022 ] 	Top1: 57.96%
[ Wed Jul  6 11:37:49 2022 ] 	Top5: 87.01%
[ Wed Jul  6 11:37:49 2022 ] Training epoch: 5
[ Wed Jul  6 11:40:56 2022 ] 	Mean training loss: 1.3265.  Mean training acc: 60.87%.
[ Wed Jul  6 11:40:56 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:40:56 2022 ] Eval epoch: 5
[ Wed Jul  6 11:41:44 2022 ] 	Mean test loss of 796 batches: 1.326897792555579.
[ Wed Jul  6 11:41:44 2022 ] 	Top1: 61.24%
[ Wed Jul  6 11:41:45 2022 ] 	Top5: 89.09%
[ Wed Jul  6 11:41:45 2022 ] Training epoch: 6
[ Wed Jul  6 11:44:52 2022 ] 	Mean training loss: 1.1803.  Mean training acc: 64.75%.
[ Wed Jul  6 11:44:52 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:44:52 2022 ] Eval epoch: 6
[ Wed Jul  6 11:45:40 2022 ] 	Mean test loss of 796 batches: 1.405165762270815.
[ Wed Jul  6 11:45:41 2022 ] 	Top1: 57.82%
[ Wed Jul  6 11:45:41 2022 ] 	Top5: 87.83%
[ Wed Jul  6 11:45:41 2022 ] Training epoch: 7
[ Wed Jul  6 11:48:48 2022 ] 	Mean training loss: 1.0977.  Mean training acc: 67.01%.
[ Wed Jul  6 11:48:48 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:48:48 2022 ] Eval epoch: 7
[ Wed Jul  6 11:49:35 2022 ] 	Mean test loss of 796 batches: 1.239917004527758.
[ Wed Jul  6 11:49:35 2022 ] 	Top1: 62.33%
[ Wed Jul  6 11:49:35 2022 ] 	Top5: 89.53%
[ Wed Jul  6 11:49:36 2022 ] Training epoch: 8
[ Wed Jul  6 11:52:41 2022 ] 	Mean training loss: 1.0396.  Mean training acc: 68.71%.
[ Wed Jul  6 11:52:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 11:52:41 2022 ] Eval epoch: 8
[ Wed Jul  6 11:53:29 2022 ] 	Mean test loss of 796 batches: 1.2977173736496785.
[ Wed Jul  6 11:53:30 2022 ] 	Top1: 62.30%
[ Wed Jul  6 11:53:30 2022 ] 	Top5: 89.78%
[ Wed Jul  6 11:53:30 2022 ] Training epoch: 9
[ Wed Jul  6 11:56:37 2022 ] 	Mean training loss: 0.9961.  Mean training acc: 70.10%.
[ Wed Jul  6 11:56:37 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 11:56:37 2022 ] Eval epoch: 9
[ Wed Jul  6 11:57:25 2022 ] 	Mean test loss of 796 batches: 1.4724962195784004.
[ Wed Jul  6 11:57:25 2022 ] 	Top1: 59.07%
[ Wed Jul  6 11:57:26 2022 ] 	Top5: 87.70%
[ Wed Jul  6 11:57:26 2022 ] Training epoch: 10
[ Wed Jul  6 12:00:32 2022 ] 	Mean training loss: 0.9744.  Mean training acc: 70.46%.
[ Wed Jul  6 12:00:32 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:00:32 2022 ] Eval epoch: 10
[ Wed Jul  6 12:01:21 2022 ] 	Mean test loss of 796 batches: 1.2624989622576752.
[ Wed Jul  6 12:01:21 2022 ] 	Top1: 63.38%
[ Wed Jul  6 12:01:22 2022 ] 	Top5: 89.88%
[ Wed Jul  6 12:01:22 2022 ] Training epoch: 11
[ Wed Jul  6 12:04:28 2022 ] 	Mean training loss: 0.9442.  Mean training acc: 71.55%.
[ Wed Jul  6 12:04:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 12:04:28 2022 ] Eval epoch: 11
[ Wed Jul  6 12:05:16 2022 ] 	Mean test loss of 796 batches: 1.2646348529200457.
[ Wed Jul  6 12:05:16 2022 ] 	Top1: 63.04%
[ Wed Jul  6 12:05:16 2022 ] 	Top5: 89.50%
[ Wed Jul  6 12:05:16 2022 ] Training epoch: 12
[ Wed Jul  6 12:08:22 2022 ] 	Mean training loss: 0.9277.  Mean training acc: 72.23%.
[ Wed Jul  6 12:08:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 12:08:22 2022 ] Eval epoch: 12
[ Wed Jul  6 12:09:09 2022 ] 	Mean test loss of 796 batches: 1.3308046029964884.
[ Wed Jul  6 12:09:10 2022 ] 	Top1: 60.92%
[ Wed Jul  6 12:09:10 2022 ] 	Top5: 88.71%
[ Wed Jul  6 12:09:10 2022 ] Training epoch: 13
[ Wed Jul  6 12:12:17 2022 ] 	Mean training loss: 0.9057.  Mean training acc: 72.58%.
[ Wed Jul  6 12:12:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:12:17 2022 ] Eval epoch: 13
[ Wed Jul  6 12:13:04 2022 ] 	Mean test loss of 796 batches: 1.071371536121596.
[ Wed Jul  6 12:13:05 2022 ] 	Top1: 67.65%
[ Wed Jul  6 12:13:05 2022 ] 	Top5: 92.33%
[ Wed Jul  6 12:13:05 2022 ] Training epoch: 14
[ Wed Jul  6 12:16:11 2022 ] 	Mean training loss: 0.8912.  Mean training acc: 72.85%.
[ Wed Jul  6 12:16:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 12:16:11 2022 ] Eval epoch: 14
[ Wed Jul  6 12:16:59 2022 ] 	Mean test loss of 796 batches: 1.3214893959574963.
[ Wed Jul  6 12:16:59 2022 ] 	Top1: 62.31%
[ Wed Jul  6 12:17:00 2022 ] 	Top5: 88.94%
[ Wed Jul  6 12:17:00 2022 ] Training epoch: 15
[ Wed Jul  6 12:20:06 2022 ] 	Mean training loss: 0.8770.  Mean training acc: 73.57%.
[ Wed Jul  6 12:20:06 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:20:06 2022 ] Eval epoch: 15
[ Wed Jul  6 12:20:53 2022 ] 	Mean test loss of 796 batches: 1.3604535643179811.
[ Wed Jul  6 12:20:54 2022 ] 	Top1: 62.30%
[ Wed Jul  6 12:20:54 2022 ] 	Top5: 89.34%
[ Wed Jul  6 12:20:54 2022 ] Training epoch: 16
[ Wed Jul  6 12:24:00 2022 ] 	Mean training loss: 0.8752.  Mean training acc: 73.51%.
[ Wed Jul  6 12:24:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 12:24:00 2022 ] Eval epoch: 16
[ Wed Jul  6 12:24:48 2022 ] 	Mean test loss of 796 batches: 1.020239107310772.
[ Wed Jul  6 12:24:48 2022 ] 	Top1: 69.62%
[ Wed Jul  6 12:24:48 2022 ] 	Top5: 92.60%
[ Wed Jul  6 12:24:48 2022 ] Training epoch: 17
[ Wed Jul  6 12:27:55 2022 ] 	Mean training loss: 0.8602.  Mean training acc: 73.98%.
[ Wed Jul  6 12:27:55 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:27:55 2022 ] Eval epoch: 17
[ Wed Jul  6 12:28:43 2022 ] 	Mean test loss of 796 batches: 1.1710191633383833.
[ Wed Jul  6 12:28:43 2022 ] 	Top1: 66.39%
[ Wed Jul  6 12:28:44 2022 ] 	Top5: 90.54%
[ Wed Jul  6 12:28:44 2022 ] Training epoch: 18
[ Wed Jul  6 12:31:50 2022 ] 	Mean training loss: 0.8583.  Mean training acc: 74.03%.
[ Wed Jul  6 12:31:50 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:31:50 2022 ] Eval epoch: 18
[ Wed Jul  6 12:32:38 2022 ] 	Mean test loss of 796 batches: 1.318254669332624.
[ Wed Jul  6 12:32:38 2022 ] 	Top1: 62.91%
[ Wed Jul  6 12:32:38 2022 ] 	Top5: 88.75%
[ Wed Jul  6 12:32:38 2022 ] Training epoch: 19
[ Wed Jul  6 12:35:46 2022 ] 	Mean training loss: 0.8425.  Mean training acc: 74.56%.
[ Wed Jul  6 12:35:46 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 12:35:46 2022 ] Eval epoch: 19
[ Wed Jul  6 12:36:35 2022 ] 	Mean test loss of 796 batches: 1.1288086824755572.
[ Wed Jul  6 12:36:36 2022 ] 	Top1: 66.91%
[ Wed Jul  6 12:36:36 2022 ] 	Top5: 91.38%
[ Wed Jul  6 12:36:36 2022 ] Training epoch: 20
[ Wed Jul  6 12:39:45 2022 ] 	Mean training loss: 0.8409.  Mean training acc: 74.46%.
[ Wed Jul  6 12:39:45 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 12:39:45 2022 ] Eval epoch: 20
[ Wed Jul  6 12:40:34 2022 ] 	Mean test loss of 796 batches: 1.08094724196585.
[ Wed Jul  6 12:40:35 2022 ] 	Top1: 68.19%
[ Wed Jul  6 12:40:35 2022 ] 	Top5: 92.66%
[ Wed Jul  6 12:40:35 2022 ] Training epoch: 21
[ Wed Jul  6 12:43:44 2022 ] 	Mean training loss: 0.8338.  Mean training acc: 74.80%.
[ Wed Jul  6 12:43:44 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 12:43:44 2022 ] Eval epoch: 21
[ Wed Jul  6 12:44:34 2022 ] 	Mean test loss of 796 batches: 1.2272525100627136.
[ Wed Jul  6 12:44:34 2022 ] 	Top1: 65.58%
[ Wed Jul  6 12:44:35 2022 ] 	Top5: 91.19%
[ Wed Jul  6 12:44:35 2022 ] Training epoch: 22
[ Wed Jul  6 12:47:44 2022 ] 	Mean training loss: 0.8331.  Mean training acc: 74.60%.
[ Wed Jul  6 12:47:44 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 12:47:44 2022 ] Eval epoch: 22
[ Wed Jul  6 12:48:33 2022 ] 	Mean test loss of 796 batches: 1.3881227904977511.
[ Wed Jul  6 12:48:33 2022 ] 	Top1: 61.48%
[ Wed Jul  6 12:48:33 2022 ] 	Top5: 87.14%
[ Wed Jul  6 12:48:33 2022 ] Training epoch: 23
[ Wed Jul  6 12:51:41 2022 ] 	Mean training loss: 0.8299.  Mean training acc: 74.73%.
[ Wed Jul  6 12:51:41 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 12:51:41 2022 ] Eval epoch: 23
[ Wed Jul  6 12:52:29 2022 ] 	Mean test loss of 796 batches: 1.0043465612671483.
[ Wed Jul  6 12:52:30 2022 ] 	Top1: 70.67%
[ Wed Jul  6 12:52:30 2022 ] 	Top5: 92.96%
[ Wed Jul  6 12:52:30 2022 ] Training epoch: 24
[ Wed Jul  6 12:55:37 2022 ] 	Mean training loss: 0.8259.  Mean training acc: 74.80%.
[ Wed Jul  6 12:55:37 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:55:37 2022 ] Eval epoch: 24
[ Wed Jul  6 12:56:25 2022 ] 	Mean test loss of 796 batches: 1.1289225845555564.
[ Wed Jul  6 12:56:26 2022 ] 	Top1: 67.01%
[ Wed Jul  6 12:56:26 2022 ] 	Top5: 91.70%
[ Wed Jul  6 12:56:26 2022 ] Training epoch: 25
[ Wed Jul  6 12:59:33 2022 ] 	Mean training loss: 0.8246.  Mean training acc: 74.99%.
[ Wed Jul  6 12:59:33 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 12:59:33 2022 ] Eval epoch: 25
[ Wed Jul  6 13:00:21 2022 ] 	Mean test loss of 796 batches: 1.369886302955486.
[ Wed Jul  6 13:00:21 2022 ] 	Top1: 63.63%
[ Wed Jul  6 13:00:22 2022 ] 	Top5: 88.99%
[ Wed Jul  6 13:00:22 2022 ] Training epoch: 26
[ Wed Jul  6 13:03:28 2022 ] 	Mean training loss: 0.8178.  Mean training acc: 75.21%.
[ Wed Jul  6 13:03:28 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:03:28 2022 ] Eval epoch: 26
[ Wed Jul  6 13:04:16 2022 ] 	Mean test loss of 796 batches: 0.9849617686029055.
[ Wed Jul  6 13:04:17 2022 ] 	Top1: 70.48%
[ Wed Jul  6 13:04:17 2022 ] 	Top5: 92.90%
[ Wed Jul  6 13:04:17 2022 ] Training epoch: 27
[ Wed Jul  6 13:07:24 2022 ] 	Mean training loss: 0.8084.  Mean training acc: 75.33%.
[ Wed Jul  6 13:07:24 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:07:24 2022 ] Eval epoch: 27
[ Wed Jul  6 13:08:12 2022 ] 	Mean test loss of 796 batches: 1.125355845083244.
[ Wed Jul  6 13:08:13 2022 ] 	Top1: 66.91%
[ Wed Jul  6 13:08:13 2022 ] 	Top5: 91.68%
[ Wed Jul  6 13:08:13 2022 ] Training epoch: 28
[ Wed Jul  6 13:11:19 2022 ] 	Mean training loss: 0.8092.  Mean training acc: 75.32%.
[ Wed Jul  6 13:11:19 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:11:19 2022 ] Eval epoch: 28
[ Wed Jul  6 13:12:07 2022 ] 	Mean test loss of 796 batches: 1.2004301108457336.
[ Wed Jul  6 13:12:08 2022 ] 	Top1: 66.83%
[ Wed Jul  6 13:12:08 2022 ] 	Top5: 90.84%
[ Wed Jul  6 13:12:08 2022 ] Training epoch: 29
[ Wed Jul  6 13:15:14 2022 ] 	Mean training loss: 0.8074.  Mean training acc: 75.58%.
[ Wed Jul  6 13:15:14 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:15:14 2022 ] Eval epoch: 29
[ Wed Jul  6 13:16:02 2022 ] 	Mean test loss of 796 batches: 0.976927421388015.
[ Wed Jul  6 13:16:03 2022 ] 	Top1: 70.90%
[ Wed Jul  6 13:16:03 2022 ] 	Top5: 92.95%
[ Wed Jul  6 13:16:03 2022 ] Training epoch: 30
[ Wed Jul  6 13:19:10 2022 ] 	Mean training loss: 0.8062.  Mean training acc: 75.44%.
[ Wed Jul  6 13:19:10 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:19:10 2022 ] Eval epoch: 30
[ Wed Jul  6 13:19:58 2022 ] 	Mean test loss of 796 batches: 1.1066341166145837.
[ Wed Jul  6 13:19:59 2022 ] 	Top1: 67.73%
[ Wed Jul  6 13:19:59 2022 ] 	Top5: 92.19%
[ Wed Jul  6 13:19:59 2022 ] Training epoch: 31
[ Wed Jul  6 13:23:06 2022 ] 	Mean training loss: 0.7996.  Mean training acc: 75.65%.
[ Wed Jul  6 13:23:06 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:23:06 2022 ] Eval epoch: 31
[ Wed Jul  6 13:23:54 2022 ] 	Mean test loss of 796 batches: 0.9970510113404025.
[ Wed Jul  6 13:23:54 2022 ] 	Top1: 70.06%
[ Wed Jul  6 13:23:55 2022 ] 	Top5: 93.03%
[ Wed Jul  6 13:23:55 2022 ] Training epoch: 32
[ Wed Jul  6 13:27:01 2022 ] 	Mean training loss: 0.7953.  Mean training acc: 75.83%.
[ Wed Jul  6 13:27:01 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:27:01 2022 ] Eval epoch: 32
[ Wed Jul  6 13:27:49 2022 ] 	Mean test loss of 796 batches: 1.1007267147227748.
[ Wed Jul  6 13:27:49 2022 ] 	Top1: 68.14%
[ Wed Jul  6 13:27:50 2022 ] 	Top5: 92.42%
[ Wed Jul  6 13:27:50 2022 ] Training epoch: 33
[ Wed Jul  6 13:30:56 2022 ] 	Mean training loss: 0.7953.  Mean training acc: 75.86%.
[ Wed Jul  6 13:30:56 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:30:56 2022 ] Eval epoch: 33
[ Wed Jul  6 13:31:44 2022 ] 	Mean test loss of 796 batches: 1.0013706824887338.
[ Wed Jul  6 13:31:45 2022 ] 	Top1: 70.72%
[ Wed Jul  6 13:31:45 2022 ] 	Top5: 92.71%
[ Wed Jul  6 13:31:45 2022 ] Training epoch: 34
[ Wed Jul  6 13:34:52 2022 ] 	Mean training loss: 0.8011.  Mean training acc: 75.74%.
[ Wed Jul  6 13:34:52 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:34:52 2022 ] Eval epoch: 34
[ Wed Jul  6 13:35:40 2022 ] 	Mean test loss of 796 batches: 1.157281638502176.
[ Wed Jul  6 13:35:40 2022 ] 	Top1: 66.53%
[ Wed Jul  6 13:35:40 2022 ] 	Top5: 90.85%
[ Wed Jul  6 13:35:40 2022 ] Training epoch: 35
[ Wed Jul  6 13:38:47 2022 ] 	Mean training loss: 0.7908.  Mean training acc: 75.97%.
[ Wed Jul  6 13:38:47 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:38:47 2022 ] Eval epoch: 35
[ Wed Jul  6 13:39:34 2022 ] 	Mean test loss of 796 batches: 0.9944749903963439.
[ Wed Jul  6 13:39:35 2022 ] 	Top1: 70.69%
[ Wed Jul  6 13:39:35 2022 ] 	Top5: 92.94%
[ Wed Jul  6 13:39:35 2022 ] Training epoch: 36
[ Wed Jul  6 13:42:41 2022 ] 	Mean training loss: 0.4585.  Mean training acc: 85.78%.
[ Wed Jul  6 13:42:41 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:42:41 2022 ] Eval epoch: 36
[ Wed Jul  6 13:43:29 2022 ] 	Mean test loss of 796 batches: 0.6325375931384276.
[ Wed Jul  6 13:43:31 2022 ] 	Top1: 80.61%
[ Wed Jul  6 13:43:31 2022 ] 	Top5: 96.18%
[ Wed Jul  6 13:43:31 2022 ] Training epoch: 37
[ Wed Jul  6 13:46:38 2022 ] 	Mean training loss: 0.3712.  Mean training acc: 88.37%.
[ Wed Jul  6 13:46:38 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:46:38 2022 ] Eval epoch: 37
[ Wed Jul  6 13:47:25 2022 ] 	Mean test loss of 796 batches: 0.6075807112788585.
[ Wed Jul  6 13:47:25 2022 ] 	Top1: 81.56%
[ Wed Jul  6 13:47:26 2022 ] 	Top5: 96.47%
[ Wed Jul  6 13:47:26 2022 ] Training epoch: 38
[ Wed Jul  6 13:50:33 2022 ] 	Mean training loss: 0.3321.  Mean training acc: 89.63%.
[ Wed Jul  6 13:50:33 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:50:33 2022 ] Eval epoch: 38
[ Wed Jul  6 13:51:21 2022 ] 	Mean test loss of 796 batches: 0.6214295132694083.
[ Wed Jul  6 13:51:21 2022 ] 	Top1: 81.32%
[ Wed Jul  6 13:51:21 2022 ] 	Top5: 96.44%
[ Wed Jul  6 13:51:21 2022 ] Training epoch: 39
[ Wed Jul  6 13:54:27 2022 ] 	Mean training loss: 0.3103.  Mean training acc: 90.21%.
[ Wed Jul  6 13:54:27 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:54:27 2022 ] Eval epoch: 39
[ Wed Jul  6 13:55:15 2022 ] 	Mean test loss of 796 batches: 0.6396537690362589.
[ Wed Jul  6 13:55:15 2022 ] 	Top1: 81.13%
[ Wed Jul  6 13:55:16 2022 ] 	Top5: 96.38%
[ Wed Jul  6 13:55:16 2022 ] Training epoch: 40
[ Wed Jul  6 13:58:22 2022 ] 	Mean training loss: 0.2896.  Mean training acc: 90.83%.
[ Wed Jul  6 13:58:22 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 13:58:22 2022 ] Eval epoch: 40
[ Wed Jul  6 13:59:09 2022 ] 	Mean test loss of 796 batches: 0.6350973480235991.
[ Wed Jul  6 13:59:10 2022 ] 	Top1: 81.26%
[ Wed Jul  6 13:59:10 2022 ] 	Top5: 96.41%
[ Wed Jul  6 13:59:10 2022 ] Training epoch: 41
[ Wed Jul  6 14:02:16 2022 ] 	Mean training loss: 0.2692.  Mean training acc: 91.60%.
[ Wed Jul  6 14:02:16 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:02:16 2022 ] Eval epoch: 41
[ Wed Jul  6 14:03:04 2022 ] 	Mean test loss of 796 batches: 0.6405000628566547.
[ Wed Jul  6 14:03:04 2022 ] 	Top1: 81.33%
[ Wed Jul  6 14:03:04 2022 ] 	Top5: 96.38%
[ Wed Jul  6 14:03:04 2022 ] Training epoch: 42
[ Wed Jul  6 14:06:10 2022 ] 	Mean training loss: 0.2592.  Mean training acc: 91.77%.
[ Wed Jul  6 14:06:10 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:06:10 2022 ] Eval epoch: 42
[ Wed Jul  6 14:06:58 2022 ] 	Mean test loss of 796 batches: 0.6353197732388075.
[ Wed Jul  6 14:06:59 2022 ] 	Top1: 81.50%
[ Wed Jul  6 14:06:59 2022 ] 	Top5: 96.42%
[ Wed Jul  6 14:06:59 2022 ] Training epoch: 43
[ Wed Jul  6 14:10:06 2022 ] 	Mean training loss: 0.2460.  Mean training acc: 92.25%.
[ Wed Jul  6 14:10:06 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 14:10:06 2022 ] Eval epoch: 43
[ Wed Jul  6 14:10:54 2022 ] 	Mean test loss of 796 batches: 0.6715070041336456.
[ Wed Jul  6 14:10:54 2022 ] 	Top1: 81.02%
[ Wed Jul  6 14:10:55 2022 ] 	Top5: 96.25%
[ Wed Jul  6 14:10:55 2022 ] Training epoch: 44
[ Wed Jul  6 14:14:02 2022 ] 	Mean training loss: 0.2334.  Mean training acc: 92.62%.
[ Wed Jul  6 14:14:02 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:14:02 2022 ] Eval epoch: 44
[ Wed Jul  6 14:14:49 2022 ] 	Mean test loss of 796 batches: 0.6822460325827925.
[ Wed Jul  6 14:14:50 2022 ] 	Top1: 80.65%
[ Wed Jul  6 14:14:50 2022 ] 	Top5: 96.01%
[ Wed Jul  6 14:14:50 2022 ] Training epoch: 45
[ Wed Jul  6 14:17:56 2022 ] 	Mean training loss: 0.2281.  Mean training acc: 92.84%.
[ Wed Jul  6 14:17:56 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:17:56 2022 ] Eval epoch: 45
[ Wed Jul  6 14:18:44 2022 ] 	Mean test loss of 796 batches: 0.7121458234798969.
[ Wed Jul  6 14:18:44 2022 ] 	Top1: 80.38%
[ Wed Jul  6 14:18:45 2022 ] 	Top5: 95.80%
[ Wed Jul  6 14:18:45 2022 ] Training epoch: 46
[ Wed Jul  6 14:21:51 2022 ] 	Mean training loss: 0.2239.  Mean training acc: 93.01%.
[ Wed Jul  6 14:21:51 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:21:51 2022 ] Eval epoch: 46
[ Wed Jul  6 14:22:39 2022 ] 	Mean test loss of 796 batches: 0.7012469196158587.
[ Wed Jul  6 14:22:39 2022 ] 	Top1: 80.54%
[ Wed Jul  6 14:22:40 2022 ] 	Top5: 95.92%
[ Wed Jul  6 14:22:40 2022 ] Training epoch: 47
[ Wed Jul  6 14:25:47 2022 ] 	Mean training loss: 0.2160.  Mean training acc: 93.22%.
[ Wed Jul  6 14:25:47 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:25:47 2022 ] Eval epoch: 47
[ Wed Jul  6 14:26:34 2022 ] 	Mean test loss of 796 batches: 0.7595215597793684.
[ Wed Jul  6 14:26:35 2022 ] 	Top1: 79.32%
[ Wed Jul  6 14:26:35 2022 ] 	Top5: 95.47%
[ Wed Jul  6 14:26:35 2022 ] Training epoch: 48
[ Wed Jul  6 14:29:43 2022 ] 	Mean training loss: 0.2163.  Mean training acc: 93.14%.
[ Wed Jul  6 14:29:43 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 14:29:43 2022 ] Eval epoch: 48
[ Wed Jul  6 14:30:30 2022 ] 	Mean test loss of 796 batches: 0.7156096553598442.
[ Wed Jul  6 14:30:31 2022 ] 	Top1: 80.45%
[ Wed Jul  6 14:30:31 2022 ] 	Top5: 95.82%
[ Wed Jul  6 14:30:31 2022 ] Training epoch: 49
[ Wed Jul  6 14:33:38 2022 ] 	Mean training loss: 0.2115.  Mean training acc: 93.51%.
[ Wed Jul  6 14:33:38 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 14:33:38 2022 ] Eval epoch: 49
[ Wed Jul  6 14:34:27 2022 ] 	Mean test loss of 796 batches: 0.7182361860314955.
[ Wed Jul  6 14:34:28 2022 ] 	Top1: 80.03%
[ Wed Jul  6 14:34:28 2022 ] 	Top5: 95.86%
[ Wed Jul  6 14:34:28 2022 ] Training epoch: 50
[ Wed Jul  6 14:37:34 2022 ] 	Mean training loss: 0.2102.  Mean training acc: 93.48%.
[ Wed Jul  6 14:37:34 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:37:34 2022 ] Eval epoch: 50
[ Wed Jul  6 14:38:23 2022 ] 	Mean test loss of 796 batches: 0.7846317169579429.
[ Wed Jul  6 14:38:23 2022 ] 	Top1: 78.85%
[ Wed Jul  6 14:38:24 2022 ] 	Top5: 95.34%
[ Wed Jul  6 14:38:24 2022 ] Training epoch: 51
[ Wed Jul  6 14:41:31 2022 ] 	Mean training loss: 0.2040.  Mean training acc: 93.61%.
[ Wed Jul  6 14:41:31 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Jul  6 14:41:31 2022 ] Eval epoch: 51
[ Wed Jul  6 14:42:19 2022 ] 	Mean test loss of 796 batches: 0.794614613468024.
[ Wed Jul  6 14:42:19 2022 ] 	Top1: 79.47%
[ Wed Jul  6 14:42:19 2022 ] 	Top5: 95.73%
[ Wed Jul  6 14:42:19 2022 ] Training epoch: 52
[ Wed Jul  6 14:45:25 2022 ] 	Mean training loss: 0.2077.  Mean training acc: 93.47%.
[ Wed Jul  6 14:45:25 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:45:25 2022 ] Eval epoch: 52
[ Wed Jul  6 14:46:13 2022 ] 	Mean test loss of 796 batches: 0.7381926686058392.
[ Wed Jul  6 14:46:13 2022 ] 	Top1: 79.72%
[ Wed Jul  6 14:46:14 2022 ] 	Top5: 95.68%
[ Wed Jul  6 14:46:14 2022 ] Training epoch: 53
[ Wed Jul  6 14:49:20 2022 ] 	Mean training loss: 0.2066.  Mean training acc: 93.49%.
[ Wed Jul  6 14:49:20 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:49:20 2022 ] Eval epoch: 53
[ Wed Jul  6 14:50:07 2022 ] 	Mean test loss of 796 batches: 0.7366381647374163.
[ Wed Jul  6 14:50:08 2022 ] 	Top1: 79.63%
[ Wed Jul  6 14:50:08 2022 ] 	Top5: 95.66%
[ Wed Jul  6 14:50:08 2022 ] Training epoch: 54
[ Wed Jul  6 14:53:14 2022 ] 	Mean training loss: 0.2055.  Mean training acc: 93.62%.
[ Wed Jul  6 14:53:14 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:53:14 2022 ] Eval epoch: 54
[ Wed Jul  6 14:54:01 2022 ] 	Mean test loss of 796 batches: 0.8319981330771692.
[ Wed Jul  6 14:54:02 2022 ] 	Top1: 78.07%
[ Wed Jul  6 14:54:02 2022 ] 	Top5: 95.03%
[ Wed Jul  6 14:54:02 2022 ] Training epoch: 55
[ Wed Jul  6 14:57:08 2022 ] 	Mean training loss: 0.2021.  Mean training acc: 93.69%.
[ Wed Jul  6 14:57:08 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 14:57:08 2022 ] Eval epoch: 55
[ Wed Jul  6 14:57:56 2022 ] 	Mean test loss of 796 batches: 0.8010267576661392.
[ Wed Jul  6 14:57:56 2022 ] 	Top1: 79.21%
[ Wed Jul  6 14:57:57 2022 ] 	Top5: 95.24%
[ Wed Jul  6 14:57:57 2022 ] Training epoch: 56
[ Wed Jul  6 15:01:03 2022 ] 	Mean training loss: 0.1140.  Mean training acc: 96.71%.
[ Wed Jul  6 15:01:03 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:01:03 2022 ] Eval epoch: 56
[ Wed Jul  6 15:01:51 2022 ] 	Mean test loss of 796 batches: 0.6781800723676781.
[ Wed Jul  6 15:01:51 2022 ] 	Top1: 81.61%
[ Wed Jul  6 15:01:51 2022 ] 	Top5: 96.17%
[ Wed Jul  6 15:01:52 2022 ] Training epoch: 57
[ Wed Jul  6 15:04:58 2022 ] 	Mean training loss: 0.0885.  Mean training acc: 97.80%.
[ Wed Jul  6 15:04:58 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:04:58 2022 ] Eval epoch: 57
[ Wed Jul  6 15:05:45 2022 ] 	Mean test loss of 796 batches: 0.6839633178780201.
[ Wed Jul  6 15:05:46 2022 ] 	Top1: 81.89%
[ Wed Jul  6 15:05:46 2022 ] 	Top5: 96.16%
[ Wed Jul  6 15:05:46 2022 ] Training epoch: 58
[ Wed Jul  6 15:08:52 2022 ] 	Mean training loss: 0.0784.  Mean training acc: 98.08%.
[ Wed Jul  6 15:08:52 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:08:52 2022 ] Eval epoch: 58
[ Wed Jul  6 15:09:40 2022 ] 	Mean test loss of 796 batches: 0.6852707715667598.
[ Wed Jul  6 15:09:40 2022 ] 	Top1: 81.86%
[ Wed Jul  6 15:09:41 2022 ] 	Top5: 96.21%
[ Wed Jul  6 15:09:41 2022 ] Training epoch: 59
[ Wed Jul  6 15:12:47 2022 ] 	Mean training loss: 0.0714.  Mean training acc: 98.32%.
[ Wed Jul  6 15:12:47 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:12:47 2022 ] Eval epoch: 59
[ Wed Jul  6 15:13:35 2022 ] 	Mean test loss of 796 batches: 0.6896189757056497.
[ Wed Jul  6 15:13:35 2022 ] 	Top1: 81.85%
[ Wed Jul  6 15:13:35 2022 ] 	Top5: 96.20%
[ Wed Jul  6 15:13:36 2022 ] Training epoch: 60
[ Wed Jul  6 15:16:42 2022 ] 	Mean training loss: 0.0671.  Mean training acc: 98.37%.
[ Wed Jul  6 15:16:42 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:16:43 2022 ] Eval epoch: 60
[ Wed Jul  6 15:17:32 2022 ] 	Mean test loss of 796 batches: 0.684941040782548.
[ Wed Jul  6 15:17:32 2022 ] 	Top1: 82.08%
[ Wed Jul  6 15:17:32 2022 ] 	Top5: 96.21%
[ Wed Jul  6 15:17:33 2022 ] Training epoch: 61
[ Wed Jul  6 15:20:41 2022 ] 	Mean training loss: 0.0639.  Mean training acc: 98.50%.
[ Wed Jul  6 15:20:41 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 15:20:41 2022 ] Eval epoch: 61
[ Wed Jul  6 15:21:30 2022 ] 	Mean test loss of 796 batches: 0.696738543583258.
[ Wed Jul  6 15:21:31 2022 ] 	Top1: 81.91%
[ Wed Jul  6 15:21:31 2022 ] 	Top5: 96.11%
[ Wed Jul  6 15:21:31 2022 ] Training epoch: 62
[ Wed Jul  6 15:24:40 2022 ] 	Mean training loss: 0.0596.  Mean training acc: 98.66%.
[ Wed Jul  6 15:24:40 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 15:24:40 2022 ] Eval epoch: 62
[ Wed Jul  6 15:25:30 2022 ] 	Mean test loss of 796 batches: 0.6964776629497808.
[ Wed Jul  6 15:25:30 2022 ] 	Top1: 81.96%
[ Wed Jul  6 15:25:31 2022 ] 	Top5: 96.17%
[ Wed Jul  6 15:25:31 2022 ] Training epoch: 63
[ Wed Jul  6 15:28:40 2022 ] 	Mean training loss: 0.0581.  Mean training acc: 98.70%.
[ Wed Jul  6 15:28:40 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Wed Jul  6 15:28:40 2022 ] Eval epoch: 63
[ Wed Jul  6 15:29:29 2022 ] 	Mean test loss of 796 batches: 0.7001043221019395.
[ Wed Jul  6 15:29:30 2022 ] 	Top1: 82.01%
[ Wed Jul  6 15:29:30 2022 ] 	Top5: 96.10%
[ Wed Jul  6 15:29:30 2022 ] Training epoch: 64
[ Wed Jul  6 15:32:37 2022 ] 	Mean training loss: 0.0550.  Mean training acc: 98.81%.
[ Wed Jul  6 15:32:37 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:32:37 2022 ] Eval epoch: 64
[ Wed Jul  6 15:33:25 2022 ] 	Mean test loss of 796 batches: 0.6982609347098662.
[ Wed Jul  6 15:33:25 2022 ] 	Top1: 81.99%
[ Wed Jul  6 15:33:25 2022 ] 	Top5: 96.12%
[ Wed Jul  6 15:33:26 2022 ] Training epoch: 65
[ Wed Jul  6 15:36:32 2022 ] 	Mean training loss: 0.0526.  Mean training acc: 98.88%.
[ Wed Jul  6 15:36:32 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 15:36:32 2022 ] Eval epoch: 65
[ Wed Jul  6 15:37:20 2022 ] 	Mean test loss of 796 batches: 0.6979846272748619.
[ Wed Jul  6 15:37:20 2022 ] 	Top1: 82.04%
[ Wed Jul  6 15:37:21 2022 ] 	Top5: 96.23%
[ Wed Jul  6 15:38:10 2022 ] Best accuracy: 0.8207545317072212
[ Wed Jul  6 15:38:10 2022 ] Epoch number: 60
[ Wed Jul  6 15:38:10 2022 ] Model name: work_dir/ntu120/csub/sym_mod1
[ Wed Jul  6 15:38:10 2022 ] Model total number of params: 2195826
[ Wed Jul  6 15:38:10 2022 ] Weight decay: 0.0004
[ Wed Jul  6 15:38:10 2022 ] Base LR: 0.1
[ Wed Jul  6 15:38:10 2022 ] Batch Size: 64
[ Wed Jul  6 15:38:10 2022 ] Test Batch Size: 64
[ Wed Jul  6 15:38:10 2022 ] seed: 1
