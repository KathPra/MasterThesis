[ Wed Jul  6 17:15:12 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:15:30 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:15:30 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:15:30 2022 ] Training epoch: 1
[ Wed Jul  6 17:22:07 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:22:26 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:22:26 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:22:26 2022 ] Training epoch: 1
[ Wed Jul  6 17:22:49 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:23:08 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:23:08 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:23:08 2022 ] Training epoch: 1
[ Wed Jul  6 17:23:20 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:28:54 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:29:12 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [5], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:29:12 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:29:12 2022 ] Training epoch: 1
[ Wed Jul  6 17:29:37 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:30:10 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [0], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:30:10 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:30:10 2022 ] Training epoch: 1
[ Wed Jul  6 22:52:31 2022 ] using warm up, epoch: 5
[ Wed Jul  6 23:03:59 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2_BL', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [1], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 23:03:59 2022 ] # Parameters: 2200114
[ Wed Jul  6 23:03:59 2022 ] Training epoch: 1
[ Wed Jul  6 23:08:32 2022 ] 	Mean training loss: 3.0913.  Mean training acc: 22.73%.
[ Wed Jul  6 23:08:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 23:08:32 2022 ] Eval epoch: 1
[ Wed Jul  6 23:10:24 2022 ] 	Mean test loss of 796 batches: 2.5645654185033924.
[ Wed Jul  6 23:10:24 2022 ] 	Top1: 30.98%
[ Wed Jul  6 23:10:25 2022 ] 	Top5: 66.84%
[ Wed Jul  6 23:10:25 2022 ] Training epoch: 2
[ Wed Jul  6 23:14:59 2022 ] 	Mean training loss: 2.0149.  Mean training acc: 43.45%.
[ Wed Jul  6 23:14:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 23:14:59 2022 ] Eval epoch: 2
[ Wed Jul  6 23:17:03 2022 ] 	Mean test loss of 796 batches: 1.9347317308636767.
[ Wed Jul  6 23:17:03 2022 ] 	Top1: 44.50%
[ Wed Jul  6 23:17:03 2022 ] 	Top5: 80.15%
[ Wed Jul  6 23:17:03 2022 ] Training epoch: 3
[ Wed Jul  6 23:21:37 2022 ] 	Mean training loss: 1.5741.  Mean training acc: 54.45%.
[ Wed Jul  6 23:21:37 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 23:21:37 2022 ] Eval epoch: 3
[ Wed Jul  6 23:23:44 2022 ] 	Mean test loss of 796 batches: 1.8195706037944885.
[ Wed Jul  6 23:23:44 2022 ] 	Top1: 48.60%
[ Wed Jul  6 23:23:45 2022 ] 	Top5: 80.21%
[ Wed Jul  6 23:23:45 2022 ] Training epoch: 4
[ Wed Jul  6 23:28:37 2022 ] 	Mean training loss: 1.3447.  Mean training acc: 60.63%.
[ Wed Jul  6 23:28:40 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 23:28:40 2022 ] Eval epoch: 4
[ Wed Jul  6 23:30:53 2022 ] 	Mean test loss of 796 batches: 1.643793480929418.
[ Wed Jul  6 23:30:53 2022 ] 	Top1: 55.13%
[ Wed Jul  6 23:30:53 2022 ] 	Top5: 84.99%
[ Wed Jul  6 23:30:54 2022 ] Training epoch: 5
[ Wed Jul  6 23:35:30 2022 ] 	Mean training loss: 1.2183.  Mean training acc: 63.82%.
[ Wed Jul  6 23:35:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 23:35:30 2022 ] Eval epoch: 5
[ Wed Jul  6 23:37:22 2022 ] 	Mean test loss of 796 batches: 1.561229747443942.
[ Wed Jul  6 23:37:22 2022 ] 	Top1: 55.67%
[ Wed Jul  6 23:37:22 2022 ] 	Top5: 87.43%
[ Wed Jul  6 23:37:23 2022 ] Training epoch: 6
[ Wed Jul  6 23:42:07 2022 ] 	Mean training loss: 1.1039.  Mean training acc: 67.03%.
[ Wed Jul  6 23:42:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 23:42:07 2022 ] Eval epoch: 6
[ Wed Jul  6 23:44:03 2022 ] 	Mean test loss of 796 batches: 1.5945898594718482.
[ Wed Jul  6 23:44:04 2022 ] 	Top1: 56.79%
[ Wed Jul  6 23:44:04 2022 ] 	Top5: 85.18%
[ Wed Jul  6 23:44:04 2022 ] Training epoch: 7
[ Wed Jul  6 23:48:36 2022 ] 	Mean training loss: 1.0486.  Mean training acc: 68.55%.
[ Wed Jul  6 23:48:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 23:48:36 2022 ] Eval epoch: 7
[ Wed Jul  6 23:50:48 2022 ] 	Mean test loss of 796 batches: 1.3148386084928585.
[ Wed Jul  6 23:50:48 2022 ] 	Top1: 62.08%
[ Wed Jul  6 23:50:49 2022 ] 	Top5: 89.06%
[ Wed Jul  6 23:50:49 2022 ] Training epoch: 8
[ Wed Jul  6 23:55:38 2022 ] 	Mean training loss: 0.9895.  Mean training acc: 70.06%.
[ Wed Jul  6 23:55:38 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 23:55:38 2022 ] Eval epoch: 8
[ Wed Jul  6 23:57:44 2022 ] 	Mean test loss of 796 batches: 1.2875771986404856.
[ Wed Jul  6 23:57:45 2022 ] 	Top1: 64.00%
[ Wed Jul  6 23:57:45 2022 ] 	Top5: 90.11%
[ Wed Jul  6 23:57:45 2022 ] Training epoch: 9
[ Thu Jul  7 00:02:33 2022 ] 	Mean training loss: 0.9673.  Mean training acc: 70.89%.
[ Thu Jul  7 00:02:33 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul  7 00:02:33 2022 ] Eval epoch: 9
[ Thu Jul  7 00:04:43 2022 ] 	Mean test loss of 796 batches: 1.2330908429383034.
[ Thu Jul  7 00:04:43 2022 ] 	Top1: 64.35%
[ Thu Jul  7 00:04:44 2022 ] 	Top5: 90.43%
[ Thu Jul  7 00:04:44 2022 ] Training epoch: 10
[ Thu Jul  7 00:09:16 2022 ] 	Mean training loss: 0.9383.  Mean training acc: 71.79%.
[ Thu Jul  7 00:09:16 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 00:09:16 2022 ] Eval epoch: 10
[ Thu Jul  7 00:11:08 2022 ] 	Mean test loss of 796 batches: 1.428112354148273.
[ Thu Jul  7 00:11:08 2022 ] 	Top1: 59.68%
[ Thu Jul  7 00:11:09 2022 ] 	Top5: 88.34%
[ Thu Jul  7 00:11:09 2022 ] Training epoch: 11
[ Thu Jul  7 00:15:49 2022 ] 	Mean training loss: 0.9215.  Mean training acc: 72.24%.
[ Thu Jul  7 00:15:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 00:15:49 2022 ] Eval epoch: 11
[ Thu Jul  7 00:17:46 2022 ] 	Mean test loss of 796 batches: 1.5381171696973805.
[ Thu Jul  7 00:17:46 2022 ] 	Top1: 57.97%
[ Thu Jul  7 00:17:47 2022 ] 	Top5: 86.01%
[ Thu Jul  7 00:17:47 2022 ] Training epoch: 12
[ Thu Jul  7 00:22:28 2022 ] 	Mean training loss: 0.9053.  Mean training acc: 72.62%.
[ Thu Jul  7 00:22:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 00:22:28 2022 ] Eval epoch: 12
[ Thu Jul  7 00:24:42 2022 ] 	Mean test loss of 796 batches: 1.1846051744405348.
[ Thu Jul  7 00:24:42 2022 ] 	Top1: 65.51%
[ Thu Jul  7 00:24:43 2022 ] 	Top5: 90.29%
[ Thu Jul  7 00:24:43 2022 ] Training epoch: 13
[ Thu Jul  7 00:29:19 2022 ] 	Mean training loss: 0.8896.  Mean training acc: 73.10%.
[ Thu Jul  7 00:29:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 00:29:19 2022 ] Eval epoch: 13
[ Thu Jul  7 00:31:14 2022 ] 	Mean test loss of 796 batches: 1.1518125103122026.
[ Thu Jul  7 00:31:14 2022 ] 	Top1: 66.68%
[ Thu Jul  7 00:31:15 2022 ] 	Top5: 90.72%
[ Thu Jul  7 00:31:15 2022 ] Training epoch: 14
[ Thu Jul  7 00:35:40 2022 ] 	Mean training loss: 0.8843.  Mean training acc: 73.34%.
[ Thu Jul  7 00:35:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 00:35:40 2022 ] Eval epoch: 14
[ Thu Jul  7 00:37:32 2022 ] 	Mean test loss of 796 batches: 1.1638576546730708.
[ Thu Jul  7 00:37:33 2022 ] 	Top1: 66.82%
[ Thu Jul  7 00:37:33 2022 ] 	Top5: 90.49%
[ Thu Jul  7 00:37:33 2022 ] Training epoch: 15
[ Thu Jul  7 00:42:11 2022 ] 	Mean training loss: 0.8748.  Mean training acc: 73.45%.
[ Thu Jul  7 00:42:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 00:42:11 2022 ] Eval epoch: 15
[ Thu Jul  7 00:44:22 2022 ] 	Mean test loss of 796 batches: 1.5307874119461482.
[ Thu Jul  7 00:44:22 2022 ] 	Top1: 58.14%
[ Thu Jul  7 00:44:23 2022 ] 	Top5: 86.72%
[ Thu Jul  7 00:44:23 2022 ] Training epoch: 16
[ Thu Jul  7 00:49:01 2022 ] 	Mean training loss: 0.8676.  Mean training acc: 73.72%.
[ Thu Jul  7 00:49:01 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul  7 00:49:01 2022 ] Eval epoch: 16
[ Thu Jul  7 00:50:54 2022 ] 	Mean test loss of 796 batches: 1.0802186355369174.
[ Thu Jul  7 00:50:54 2022 ] 	Top1: 68.62%
[ Thu Jul  7 00:50:55 2022 ] 	Top5: 91.99%
[ Thu Jul  7 00:50:55 2022 ] Training epoch: 17
[ Thu Jul  7 00:55:22 2022 ] 	Mean training loss: 0.8560.  Mean training acc: 74.09%.
[ Thu Jul  7 00:55:22 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 00:55:22 2022 ] Eval epoch: 17
[ Thu Jul  7 00:57:13 2022 ] 	Mean test loss of 796 batches: 1.173783477077532.
[ Thu Jul  7 00:57:13 2022 ] 	Top1: 67.52%
[ Thu Jul  7 00:57:14 2022 ] 	Top5: 90.62%
[ Thu Jul  7 00:57:14 2022 ] Training epoch: 18
[ Thu Jul  7 01:01:54 2022 ] 	Mean training loss: 0.8465.  Mean training acc: 74.30%.
[ Thu Jul  7 01:01:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 01:01:54 2022 ] Eval epoch: 18
[ Thu Jul  7 01:04:06 2022 ] 	Mean test loss of 796 batches: 1.3133367924534496.
[ Thu Jul  7 01:04:06 2022 ] 	Top1: 64.02%
[ Thu Jul  7 01:04:07 2022 ] 	Top5: 88.18%
[ Thu Jul  7 01:04:07 2022 ] Training epoch: 19
[ Thu Jul  7 01:08:40 2022 ] 	Mean training loss: 0.8408.  Mean training acc: 74.68%.
[ Thu Jul  7 01:08:40 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 01:08:40 2022 ] Eval epoch: 19
[ Thu Jul  7 01:10:33 2022 ] 	Mean test loss of 796 batches: 1.1282483101565035.
[ Thu Jul  7 01:10:34 2022 ] 	Top1: 67.79%
[ Thu Jul  7 01:10:34 2022 ] 	Top5: 90.92%
[ Thu Jul  7 01:10:34 2022 ] Training epoch: 20
[ Thu Jul  7 01:15:21 2022 ] 	Mean training loss: 0.8323.  Mean training acc: 74.74%.
[ Thu Jul  7 01:15:21 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul  7 01:15:21 2022 ] Eval epoch: 20
[ Thu Jul  7 01:17:33 2022 ] 	Mean test loss of 796 batches: 1.1954891143656856.
[ Thu Jul  7 01:17:33 2022 ] 	Top1: 65.92%
[ Thu Jul  7 01:17:34 2022 ] 	Top5: 89.54%
[ Thu Jul  7 01:17:34 2022 ] Training epoch: 21
[ Thu Jul  7 01:22:02 2022 ] 	Mean training loss: 0.8352.  Mean training acc: 74.67%.
[ Thu Jul  7 01:22:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 01:22:02 2022 ] Eval epoch: 21
[ Thu Jul  7 01:23:48 2022 ] 	Mean test loss of 796 batches: 1.014518427826352.
[ Thu Jul  7 01:23:48 2022 ] 	Top1: 69.46%
[ Thu Jul  7 01:23:49 2022 ] 	Top5: 92.30%
[ Thu Jul  7 01:23:49 2022 ] Training epoch: 22
[ Thu Jul  7 01:28:32 2022 ] 	Mean training loss: 0.8212.  Mean training acc: 75.34%.
[ Thu Jul  7 01:28:32 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 01:28:32 2022 ] Eval epoch: 22
[ Thu Jul  7 01:30:14 2022 ] 	Mean test loss of 796 batches: 1.077058494839836.
[ Thu Jul  7 01:30:14 2022 ] 	Top1: 69.10%
[ Thu Jul  7 01:30:14 2022 ] 	Top5: 91.72%
[ Thu Jul  7 01:30:14 2022 ] Training epoch: 23
[ Thu Jul  7 01:34:30 2022 ] 	Mean training loss: 0.8181.  Mean training acc: 75.36%.
[ Thu Jul  7 01:34:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jul  7 01:34:30 2022 ] Eval epoch: 23
[ Thu Jul  7 01:36:08 2022 ] 	Mean test loss of 796 batches: 1.1449749980814492.
[ Thu Jul  7 01:36:08 2022 ] 	Top1: 66.96%
[ Thu Jul  7 01:36:08 2022 ] 	Top5: 90.88%
[ Thu Jul  7 01:36:08 2022 ] Training epoch: 24
[ Thu Jul  7 01:40:31 2022 ] 	Mean training loss: 0.8253.  Mean training acc: 75.08%.
[ Thu Jul  7 01:40:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 01:40:31 2022 ] Eval epoch: 24
[ Thu Jul  7 01:42:15 2022 ] 	Mean test loss of 796 batches: 1.1007756852923924.
[ Thu Jul  7 01:42:15 2022 ] 	Top1: 68.21%
[ Thu Jul  7 01:42:15 2022 ] 	Top5: 91.54%
[ Thu Jul  7 01:42:15 2022 ] Training epoch: 25
[ Thu Jul  7 01:46:46 2022 ] 	Mean training loss: 0.8175.  Mean training acc: 75.40%.
[ Thu Jul  7 01:46:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 01:46:46 2022 ] Eval epoch: 25
[ Thu Jul  7 01:48:49 2022 ] 	Mean test loss of 796 batches: 1.0566444738800802.
[ Thu Jul  7 01:48:49 2022 ] 	Top1: 68.90%
[ Thu Jul  7 01:48:50 2022 ] 	Top5: 92.40%
[ Thu Jul  7 01:48:50 2022 ] Training epoch: 26
[ Thu Jul  7 01:53:25 2022 ] 	Mean training loss: 0.8135.  Mean training acc: 75.21%.
[ Thu Jul  7 01:53:25 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 01:53:25 2022 ] Eval epoch: 26
[ Thu Jul  7 01:55:26 2022 ] 	Mean test loss of 796 batches: 1.0811024214978793.
[ Thu Jul  7 01:55:27 2022 ] 	Top1: 68.50%
[ Thu Jul  7 01:55:27 2022 ] 	Top5: 91.57%
[ Thu Jul  7 01:55:27 2022 ] Training epoch: 27
[ Thu Jul  7 02:00:00 2022 ] 	Mean training loss: 0.8093.  Mean training acc: 75.54%.
[ Thu Jul  7 02:00:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:00:00 2022 ] Eval epoch: 27
[ Thu Jul  7 02:01:49 2022 ] 	Mean test loss of 796 batches: 1.0361620106701575.
[ Thu Jul  7 02:01:50 2022 ] 	Top1: 69.46%
[ Thu Jul  7 02:01:50 2022 ] 	Top5: 92.56%
[ Thu Jul  7 02:01:50 2022 ] Training epoch: 28
[ Thu Jul  7 02:06:15 2022 ] 	Mean training loss: 0.8070.  Mean training acc: 75.66%.
[ Thu Jul  7 02:06:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 02:06:15 2022 ] Eval epoch: 28
[ Thu Jul  7 02:08:17 2022 ] 	Mean test loss of 796 batches: 0.9731281363784369.
[ Thu Jul  7 02:08:18 2022 ] 	Top1: 71.23%
[ Thu Jul  7 02:08:18 2022 ] 	Top5: 93.22%
[ Thu Jul  7 02:08:18 2022 ] Training epoch: 29
[ Thu Jul  7 02:12:50 2022 ] 	Mean training loss: 0.8110.  Mean training acc: 75.41%.
[ Thu Jul  7 02:12:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 02:12:50 2022 ] Eval epoch: 29
[ Thu Jul  7 02:14:38 2022 ] 	Mean test loss of 796 batches: 1.0040898576902983.
[ Thu Jul  7 02:14:39 2022 ] 	Top1: 70.64%
[ Thu Jul  7 02:14:39 2022 ] 	Top5: 92.77%
[ Thu Jul  7 02:14:39 2022 ] Training epoch: 30
[ Thu Jul  7 02:19:05 2022 ] 	Mean training loss: 0.7993.  Mean training acc: 75.81%.
[ Thu Jul  7 02:19:05 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:19:05 2022 ] Eval epoch: 30
[ Thu Jul  7 02:21:09 2022 ] 	Mean test loss of 796 batches: 0.9995219780684416.
[ Thu Jul  7 02:21:10 2022 ] 	Top1: 70.43%
[ Thu Jul  7 02:21:10 2022 ] 	Top5: 92.61%
[ Thu Jul  7 02:21:10 2022 ] Training epoch: 31
[ Thu Jul  7 02:25:33 2022 ] 	Mean training loss: 0.8115.  Mean training acc: 75.28%.
[ Thu Jul  7 02:25:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:25:33 2022 ] Eval epoch: 31
[ Thu Jul  7 02:27:24 2022 ] 	Mean test loss of 796 batches: 0.9633233898773266.
[ Thu Jul  7 02:27:25 2022 ] 	Top1: 70.62%
[ Thu Jul  7 02:27:25 2022 ] 	Top5: 93.26%
[ Thu Jul  7 02:27:25 2022 ] Training epoch: 32
[ Thu Jul  7 02:32:02 2022 ] 	Mean training loss: 0.8050.  Mean training acc: 75.58%.
[ Thu Jul  7 02:32:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 02:32:02 2022 ] Eval epoch: 32
[ Thu Jul  7 02:33:56 2022 ] 	Mean test loss of 796 batches: 0.9892958271967706.
[ Thu Jul  7 02:33:57 2022 ] 	Top1: 70.25%
[ Thu Jul  7 02:33:57 2022 ] 	Top5: 92.93%
[ Thu Jul  7 02:33:57 2022 ] Training epoch: 33
[ Thu Jul  7 02:38:19 2022 ] 	Mean training loss: 0.8002.  Mean training acc: 75.66%.
[ Thu Jul  7 02:38:19 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:38:19 2022 ] Eval epoch: 33
[ Thu Jul  7 02:40:21 2022 ] 	Mean test loss of 796 batches: 1.1629049476591786.
[ Thu Jul  7 02:40:21 2022 ] 	Top1: 66.54%
[ Thu Jul  7 02:40:21 2022 ] 	Top5: 91.09%
[ Thu Jul  7 02:40:22 2022 ] Training epoch: 34
[ Thu Jul  7 02:44:47 2022 ] 	Mean training loss: 0.8008.  Mean training acc: 75.75%.
[ Thu Jul  7 02:44:47 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:44:47 2022 ] Eval epoch: 34
[ Thu Jul  7 02:46:39 2022 ] 	Mean test loss of 796 batches: 1.0742075862596983.
[ Thu Jul  7 02:46:39 2022 ] 	Top1: 68.69%
[ Thu Jul  7 02:46:40 2022 ] 	Top5: 91.72%
[ Thu Jul  7 02:46:40 2022 ] Training epoch: 35
[ Thu Jul  7 02:51:05 2022 ] 	Mean training loss: 0.7976.  Mean training acc: 75.84%.
[ Thu Jul  7 02:51:05 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 02:51:05 2022 ] Eval epoch: 35
[ Thu Jul  7 02:53:08 2022 ] 	Mean test loss of 796 batches: 1.2359273578204102.
[ Thu Jul  7 02:53:08 2022 ] 	Top1: 67.07%
[ Thu Jul  7 02:53:09 2022 ] 	Top5: 89.91%
[ Thu Jul  7 02:53:09 2022 ] Training epoch: 36
[ Thu Jul  7 02:57:47 2022 ] 	Mean training loss: 0.4597.  Mean training acc: 86.04%.
[ Thu Jul  7 02:57:47 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul  7 02:57:47 2022 ] Eval epoch: 36
[ Thu Jul  7 02:59:49 2022 ] 	Mean test loss of 796 batches: 0.6030938366250177.
[ Thu Jul  7 02:59:50 2022 ] 	Top1: 81.35%
[ Thu Jul  7 02:59:50 2022 ] 	Top5: 96.58%
[ Thu Jul  7 02:59:50 2022 ] Training epoch: 37
[ Thu Jul  7 03:04:28 2022 ] 	Mean training loss: 0.3666.  Mean training acc: 88.67%.
[ Thu Jul  7 03:04:28 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul  7 03:04:28 2022 ] Eval epoch: 37
[ Thu Jul  7 03:06:27 2022 ] 	Mean test loss of 796 batches: 0.5957767970897444.
[ Thu Jul  7 03:06:27 2022 ] 	Top1: 82.07%
[ Thu Jul  7 03:06:27 2022 ] 	Top5: 96.55%
[ Thu Jul  7 03:06:28 2022 ] Training epoch: 38
[ Thu Jul  7 03:10:51 2022 ] 	Mean training loss: 0.3311.  Mean training acc: 89.67%.
[ Thu Jul  7 03:10:51 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:10:51 2022 ] Eval epoch: 38
[ Thu Jul  7 03:12:42 2022 ] 	Mean test loss of 796 batches: 0.584839846040286.
[ Thu Jul  7 03:12:43 2022 ] 	Top1: 82.07%
[ Thu Jul  7 03:12:43 2022 ] 	Top5: 96.66%
[ Thu Jul  7 03:12:43 2022 ] Training epoch: 39
[ Thu Jul  7 03:17:14 2022 ] 	Mean training loss: 0.3063.  Mean training acc: 90.32%.
[ Thu Jul  7 03:17:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:17:15 2022 ] Eval epoch: 39
[ Thu Jul  7 03:19:10 2022 ] 	Mean test loss of 796 batches: 0.5891982461396025.
[ Thu Jul  7 03:19:10 2022 ] 	Top1: 82.07%
[ Thu Jul  7 03:19:10 2022 ] 	Top5: 96.83%
[ Thu Jul  7 03:19:11 2022 ] Training epoch: 40
[ Thu Jul  7 03:23:32 2022 ] 	Mean training loss: 0.2863.  Mean training acc: 90.98%.
[ Thu Jul  7 03:23:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:23:32 2022 ] Eval epoch: 40
[ Thu Jul  7 03:25:30 2022 ] 	Mean test loss of 796 batches: 0.5955108019275281.
[ Thu Jul  7 03:25:31 2022 ] 	Top1: 82.33%
[ Thu Jul  7 03:25:32 2022 ] 	Top5: 96.60%
[ Thu Jul  7 03:25:32 2022 ] Training epoch: 41
[ Thu Jul  7 03:30:08 2022 ] 	Mean training loss: 0.2686.  Mean training acc: 91.60%.
[ Thu Jul  7 03:30:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 03:30:08 2022 ] Eval epoch: 41
[ Thu Jul  7 03:31:56 2022 ] 	Mean test loss of 796 batches: 0.6163386551092318.
[ Thu Jul  7 03:31:57 2022 ] 	Top1: 81.73%
[ Thu Jul  7 03:31:57 2022 ] 	Top5: 96.60%
[ Thu Jul  7 03:31:57 2022 ] Training epoch: 42
[ Thu Jul  7 03:36:24 2022 ] 	Mean training loss: 0.2498.  Mean training acc: 92.23%.
[ Thu Jul  7 03:36:24 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:36:24 2022 ] Eval epoch: 42
[ Thu Jul  7 03:38:26 2022 ] 	Mean test loss of 796 batches: 0.6246777408704836.
[ Thu Jul  7 03:38:27 2022 ] 	Top1: 81.70%
[ Thu Jul  7 03:38:28 2022 ] 	Top5: 96.54%
[ Thu Jul  7 03:38:28 2022 ] Training epoch: 43
[ Thu Jul  7 03:43:02 2022 ] 	Mean training loss: 0.2403.  Mean training acc: 92.58%.
[ Thu Jul  7 03:43:02 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:43:02 2022 ] Eval epoch: 43
[ Thu Jul  7 03:45:02 2022 ] 	Mean test loss of 796 batches: 0.6192378161297222.
[ Thu Jul  7 03:45:03 2022 ] 	Top1: 81.89%
[ Thu Jul  7 03:45:03 2022 ] 	Top5: 96.56%
[ Thu Jul  7 03:45:03 2022 ] Training epoch: 44
[ Thu Jul  7 03:49:34 2022 ] 	Mean training loss: 0.2275.  Mean training acc: 92.96%.
[ Thu Jul  7 03:49:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:49:34 2022 ] Eval epoch: 44
[ Thu Jul  7 03:51:34 2022 ] 	Mean test loss of 796 batches: 0.6344242775485144.
[ Thu Jul  7 03:51:34 2022 ] 	Top1: 81.97%
[ Thu Jul  7 03:51:35 2022 ] 	Top5: 96.47%
[ Thu Jul  7 03:51:35 2022 ] Training epoch: 45
[ Thu Jul  7 03:56:10 2022 ] 	Mean training loss: 0.2211.  Mean training acc: 93.25%.
[ Thu Jul  7 03:56:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 03:56:10 2022 ] Eval epoch: 45
[ Thu Jul  7 03:58:08 2022 ] 	Mean test loss of 796 batches: 0.6691876897710053.
[ Thu Jul  7 03:58:09 2022 ] 	Top1: 80.89%
[ Thu Jul  7 03:58:09 2022 ] 	Top5: 96.18%
[ Thu Jul  7 03:58:09 2022 ] Training epoch: 46
[ Thu Jul  7 04:02:46 2022 ] 	Mean training loss: 0.2144.  Mean training acc: 93.35%.
[ Thu Jul  7 04:02:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:02:46 2022 ] Eval epoch: 46
[ Thu Jul  7 04:04:47 2022 ] 	Mean test loss of 796 batches: 0.6353606158895558.
[ Thu Jul  7 04:04:48 2022 ] 	Top1: 81.88%
[ Thu Jul  7 04:04:48 2022 ] 	Top5: 96.53%
[ Thu Jul  7 04:04:48 2022 ] Training epoch: 47
[ Thu Jul  7 04:09:25 2022 ] 	Mean training loss: 0.2101.  Mean training acc: 93.51%.
[ Thu Jul  7 04:09:25 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 04:09:25 2022 ] Eval epoch: 47
[ Thu Jul  7 04:11:24 2022 ] 	Mean test loss of 796 batches: 0.736944351794582.
[ Thu Jul  7 04:11:25 2022 ] 	Top1: 79.82%
[ Thu Jul  7 04:11:25 2022 ] 	Top5: 95.68%
[ Thu Jul  7 04:11:25 2022 ] Training epoch: 48
[ Thu Jul  7 04:16:00 2022 ] 	Mean training loss: 0.2087.  Mean training acc: 93.59%.
[ Thu Jul  7 04:16:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:16:00 2022 ] Eval epoch: 48
[ Thu Jul  7 04:17:58 2022 ] 	Mean test loss of 796 batches: 0.7123410493303933.
[ Thu Jul  7 04:17:59 2022 ] 	Top1: 80.60%
[ Thu Jul  7 04:17:59 2022 ] 	Top5: 95.87%
[ Thu Jul  7 04:17:59 2022 ] Training epoch: 49
[ Thu Jul  7 04:22:30 2022 ] 	Mean training loss: 0.2084.  Mean training acc: 93.53%.
[ Thu Jul  7 04:22:30 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:22:30 2022 ] Eval epoch: 49
[ Thu Jul  7 04:24:19 2022 ] 	Mean test loss of 796 batches: 0.7277501714158447.
[ Thu Jul  7 04:24:20 2022 ] 	Top1: 80.50%
[ Thu Jul  7 04:24:20 2022 ] 	Top5: 95.96%
[ Thu Jul  7 04:24:20 2022 ] Training epoch: 50
[ Thu Jul  7 04:28:48 2022 ] 	Mean training loss: 0.2045.  Mean training acc: 93.69%.
[ Thu Jul  7 04:28:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:28:48 2022 ] Eval epoch: 50
[ Thu Jul  7 04:30:46 2022 ] 	Mean test loss of 796 batches: 0.7256095271426529.
[ Thu Jul  7 04:30:46 2022 ] 	Top1: 80.04%
[ Thu Jul  7 04:30:47 2022 ] 	Top5: 95.90%
[ Thu Jul  7 04:30:47 2022 ] Training epoch: 51
[ Thu Jul  7 04:35:25 2022 ] 	Mean training loss: 0.2032.  Mean training acc: 93.76%.
[ Thu Jul  7 04:35:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:35:25 2022 ] Eval epoch: 51
[ Thu Jul  7 04:37:24 2022 ] 	Mean test loss of 796 batches: 0.7454456514749096.
[ Thu Jul  7 04:37:25 2022 ] 	Top1: 80.50%
[ Thu Jul  7 04:37:25 2022 ] 	Top5: 95.50%
[ Thu Jul  7 04:37:25 2022 ] Training epoch: 52
[ Thu Jul  7 04:42:03 2022 ] 	Mean training loss: 0.2077.  Mean training acc: 93.54%.
[ Thu Jul  7 04:42:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 04:42:03 2022 ] Eval epoch: 52
[ Thu Jul  7 04:44:03 2022 ] 	Mean test loss of 796 batches: 0.7442889691952934.
[ Thu Jul  7 04:44:04 2022 ] 	Top1: 80.00%
[ Thu Jul  7 04:44:04 2022 ] 	Top5: 95.92%
[ Thu Jul  7 04:44:04 2022 ] Training epoch: 53
[ Thu Jul  7 04:48:42 2022 ] 	Mean training loss: 0.2016.  Mean training acc: 93.75%.
[ Thu Jul  7 04:48:42 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:48:42 2022 ] Eval epoch: 53
[ Thu Jul  7 04:50:43 2022 ] 	Mean test loss of 796 batches: 0.7364186468492051.
[ Thu Jul  7 04:50:43 2022 ] 	Top1: 80.01%
[ Thu Jul  7 04:50:44 2022 ] 	Top5: 95.83%
[ Thu Jul  7 04:50:44 2022 ] Training epoch: 54
[ Thu Jul  7 04:55:21 2022 ] 	Mean training loss: 0.2007.  Mean training acc: 93.85%.
[ Thu Jul  7 04:55:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 04:55:21 2022 ] Eval epoch: 54
[ Thu Jul  7 04:57:22 2022 ] 	Mean test loss of 796 batches: 0.7412970555225509.
[ Thu Jul  7 04:57:22 2022 ] 	Top1: 80.17%
[ Thu Jul  7 04:57:23 2022 ] 	Top5: 95.66%
[ Thu Jul  7 04:57:23 2022 ] Training epoch: 55
[ Thu Jul  7 05:02:00 2022 ] 	Mean training loss: 0.1990.  Mean training acc: 93.78%.
[ Thu Jul  7 05:02:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 05:02:00 2022 ] Eval epoch: 55
[ Thu Jul  7 05:03:59 2022 ] 	Mean test loss of 796 batches: 0.7977220022199142.
[ Thu Jul  7 05:03:59 2022 ] 	Top1: 79.01%
[ Thu Jul  7 05:04:00 2022 ] 	Top5: 95.20%
[ Thu Jul  7 05:04:00 2022 ] Training epoch: 56
[ Thu Jul  7 05:08:36 2022 ] 	Mean training loss: 0.1158.  Mean training acc: 96.77%.
[ Thu Jul  7 05:08:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:08:36 2022 ] Eval epoch: 56
[ Thu Jul  7 05:10:35 2022 ] 	Mean test loss of 796 batches: 0.6559518364880552.
[ Thu Jul  7 05:10:36 2022 ] 	Top1: 82.34%
[ Thu Jul  7 05:10:36 2022 ] 	Top5: 96.38%
[ Thu Jul  7 05:10:36 2022 ] Training epoch: 57
[ Thu Jul  7 05:15:13 2022 ] 	Mean training loss: 0.0873.  Mean training acc: 97.79%.
[ Thu Jul  7 05:15:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:15:13 2022 ] Eval epoch: 57
[ Thu Jul  7 05:17:14 2022 ] 	Mean test loss of 796 batches: 0.6631214614938851.
[ Thu Jul  7 05:17:14 2022 ] 	Top1: 82.32%
[ Thu Jul  7 05:17:15 2022 ] 	Top5: 96.29%
[ Thu Jul  7 05:17:15 2022 ] Training epoch: 58
[ Thu Jul  7 05:21:53 2022 ] 	Mean training loss: 0.0755.  Mean training acc: 98.14%.
[ Thu Jul  7 05:21:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 05:21:53 2022 ] Eval epoch: 58
[ Thu Jul  7 05:23:54 2022 ] 	Mean test loss of 796 batches: 0.6723314837819367.
[ Thu Jul  7 05:23:55 2022 ] 	Top1: 82.21%
[ Thu Jul  7 05:23:55 2022 ] 	Top5: 96.28%
[ Thu Jul  7 05:23:55 2022 ] Training epoch: 59
[ Thu Jul  7 05:28:31 2022 ] 	Mean training loss: 0.0681.  Mean training acc: 98.40%.
[ Thu Jul  7 05:28:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:28:31 2022 ] Eval epoch: 59
[ Thu Jul  7 05:30:23 2022 ] 	Mean test loss of 796 batches: 0.6751808345448881.
[ Thu Jul  7 05:30:23 2022 ] 	Top1: 82.19%
[ Thu Jul  7 05:30:23 2022 ] 	Top5: 96.30%
[ Thu Jul  7 05:30:23 2022 ] Training epoch: 60
[ Thu Jul  7 05:34:54 2022 ] 	Mean training loss: 0.0659.  Mean training acc: 98.42%.
[ Thu Jul  7 05:34:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:34:54 2022 ] Eval epoch: 60
[ Thu Jul  7 05:36:55 2022 ] 	Mean test loss of 796 batches: 0.6727923410266039.
[ Thu Jul  7 05:36:55 2022 ] 	Top1: 82.47%
[ Thu Jul  7 05:36:56 2022 ] 	Top5: 96.25%
[ Thu Jul  7 05:36:56 2022 ] Training epoch: 61
[ Thu Jul  7 05:41:33 2022 ] 	Mean training loss: 0.0619.  Mean training acc: 98.61%.
[ Thu Jul  7 05:41:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 05:41:33 2022 ] Eval epoch: 61
[ Thu Jul  7 05:43:34 2022 ] 	Mean test loss of 796 batches: 0.6814894095044489.
[ Thu Jul  7 05:43:35 2022 ] 	Top1: 82.24%
[ Thu Jul  7 05:43:35 2022 ] 	Top5: 96.12%
[ Thu Jul  7 05:43:35 2022 ] Training epoch: 62
[ Thu Jul  7 05:48:12 2022 ] 	Mean training loss: 0.0577.  Mean training acc: 98.73%.
[ Thu Jul  7 05:48:12 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:48:12 2022 ] Eval epoch: 62
[ Thu Jul  7 05:50:12 2022 ] 	Mean test loss of 796 batches: 0.6740650471356047.
[ Thu Jul  7 05:50:13 2022 ] 	Top1: 82.44%
[ Thu Jul  7 05:50:13 2022 ] 	Top5: 96.31%
[ Thu Jul  7 05:50:13 2022 ] Training epoch: 63
[ Thu Jul  7 05:54:49 2022 ] 	Mean training loss: 0.0552.  Mean training acc: 98.79%.
[ Thu Jul  7 05:54:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul  7 05:54:49 2022 ] Eval epoch: 63
[ Thu Jul  7 05:56:50 2022 ] 	Mean test loss of 796 batches: 0.6810727279689444.
[ Thu Jul  7 05:56:50 2022 ] 	Top1: 82.49%
[ Thu Jul  7 05:56:51 2022 ] 	Top5: 96.17%
[ Thu Jul  7 05:56:51 2022 ] Training epoch: 64
[ Thu Jul  7 06:01:29 2022 ] 	Mean training loss: 0.0542.  Mean training acc: 98.81%.
[ Thu Jul  7 06:01:29 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 06:01:29 2022 ] Eval epoch: 64
[ Thu Jul  7 06:03:29 2022 ] 	Mean test loss of 796 batches: 0.6810360665727949.
[ Thu Jul  7 06:03:30 2022 ] 	Top1: 82.44%
[ Thu Jul  7 06:03:30 2022 ] 	Top5: 96.20%
[ Thu Jul  7 06:03:30 2022 ] Training epoch: 65
[ Thu Jul  7 06:08:08 2022 ] 	Mean training loss: 0.0514.  Mean training acc: 98.91%.
[ Thu Jul  7 06:08:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul  7 06:08:09 2022 ] Eval epoch: 65
[ Thu Jul  7 06:10:09 2022 ] 	Mean test loss of 796 batches: 0.6888688079469917.
[ Thu Jul  7 06:10:10 2022 ] 	Top1: 82.31%
[ Thu Jul  7 06:10:10 2022 ] 	Top5: 96.17%
[ Thu Jul  7 06:12:13 2022 ] Best accuracy: 0.8249180070307743
[ Thu Jul  7 06:12:13 2022 ] Epoch number: 63
[ Thu Jul  7 06:12:13 2022 ] Model name: work_dir/ntu120/csub/sym_mod2_BL
[ Thu Jul  7 06:12:13 2022 ] Model total number of params: 2200114
[ Thu Jul  7 06:12:13 2022 ] Weight decay: 0.0004
[ Thu Jul  7 06:12:13 2022 ] Base LR: 0.1
[ Thu Jul  7 06:12:13 2022 ] Batch Size: 64
[ Thu Jul  7 06:12:13 2022 ] Test Batch Size: 64
[ Thu Jul  7 06:12:13 2022 ] seed: 1
