[ Tue Aug  2 16:25:05 2022 ] using warm up, epoch: 5
[ Tue Aug  2 16:25:24 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spher_harm1', 'model_saved_name': 'work_dir/ntu120/csub/spher_harm1/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spherical_harm1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Tue Aug  2 16:25:24 2022 ] # Parameters: 2180490
[ Tue Aug  2 16:25:24 2022 ] Training epoch: 1
[ Tue Aug  2 16:30:17 2022 ] 	Mean training loss: 3.1709.  Mean training acc: 21.64%.
[ Tue Aug  2 16:30:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 16:30:17 2022 ] Eval epoch: 1
[ Tue Aug  2 16:31:36 2022 ] 	Mean test loss of 796 batches: 2.6419814896942984.
[ Tue Aug  2 16:31:37 2022 ] 	Top1: 27.65%
[ Tue Aug  2 16:31:37 2022 ] 	Top5: 63.93%
[ Tue Aug  2 16:31:37 2022 ] Training epoch: 2
[ Tue Aug  2 16:36:29 2022 ] 	Mean training loss: 2.0620.  Mean training acc: 42.27%.
[ Tue Aug  2 16:36:29 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 16:36:29 2022 ] Eval epoch: 2
[ Tue Aug  2 16:37:49 2022 ] 	Mean test loss of 796 batches: 1.8975382713067472.
[ Tue Aug  2 16:37:49 2022 ] 	Top1: 44.50%
[ Tue Aug  2 16:37:50 2022 ] 	Top5: 80.08%
[ Tue Aug  2 16:37:50 2022 ] Training epoch: 3
[ Tue Aug  2 16:42:41 2022 ] 	Mean training loss: 1.6181.  Mean training acc: 53.30%.
[ Tue Aug  2 16:42:41 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 16:42:41 2022 ] Eval epoch: 3
[ Tue Aug  2 16:43:55 2022 ] 	Mean test loss of 796 batches: 1.5778599433114182.
[ Tue Aug  2 16:43:55 2022 ] 	Top1: 55.03%
[ Tue Aug  2 16:43:56 2022 ] 	Top5: 86.37%
[ Tue Aug  2 16:43:56 2022 ] Training epoch: 4
[ Tue Aug  2 16:48:49 2022 ] 	Mean training loss: 1.3868.  Mean training acc: 59.48%.
[ Tue Aug  2 16:48:49 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 16:48:49 2022 ] Eval epoch: 4
[ Tue Aug  2 16:50:07 2022 ] 	Mean test loss of 796 batches: 1.542875611452601.
[ Tue Aug  2 16:50:07 2022 ] 	Top1: 56.09%
[ Tue Aug  2 16:50:08 2022 ] 	Top5: 86.10%
[ Tue Aug  2 16:50:08 2022 ] Training epoch: 5
[ Tue Aug  2 16:54:56 2022 ] 	Mean training loss: 1.2496.  Mean training acc: 63.03%.
[ Tue Aug  2 16:54:56 2022 ] 	Time consumption: [Data]02%, [Network]96%
[ Tue Aug  2 16:54:56 2022 ] Eval epoch: 5
[ Tue Aug  2 16:56:16 2022 ] 	Mean test loss of 796 batches: 1.5253918909247797.
[ Tue Aug  2 16:56:16 2022 ] 	Top1: 56.99%
[ Tue Aug  2 16:56:17 2022 ] 	Top5: 87.32%
[ Tue Aug  2 16:56:17 2022 ] Training epoch: 6
[ Tue Aug  2 17:01:05 2022 ] 	Mean training loss: 1.1396.  Mean training acc: 66.03%.
[ Tue Aug  2 17:01:05 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 17:01:05 2022 ] Eval epoch: 6
[ Tue Aug  2 17:02:18 2022 ] 	Mean test loss of 796 batches: 1.2849731031599356.
[ Tue Aug  2 17:02:19 2022 ] 	Top1: 62.48%
[ Tue Aug  2 17:02:19 2022 ] 	Top5: 90.29%
[ Tue Aug  2 17:02:20 2022 ] Training epoch: 7
[ Tue Aug  2 17:07:11 2022 ] 	Mean training loss: 1.0613.  Mean training acc: 68.21%.
[ Tue Aug  2 17:07:11 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 17:07:11 2022 ] Eval epoch: 7
[ Tue Aug  2 17:08:30 2022 ] 	Mean test loss of 796 batches: 1.3955019204011514.
[ Tue Aug  2 17:08:31 2022 ] 	Top1: 59.90%
[ Tue Aug  2 17:08:32 2022 ] 	Top5: 87.93%
[ Tue Aug  2 17:08:32 2022 ] Training epoch: 8
[ Tue Aug  2 17:13:20 2022 ] 	Mean training loss: 1.0181.  Mean training acc: 69.36%.
[ Tue Aug  2 17:13:20 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 17:13:20 2022 ] Eval epoch: 8
[ Tue Aug  2 17:14:36 2022 ] 	Mean test loss of 796 batches: 1.284251229884337.
[ Tue Aug  2 17:14:36 2022 ] 	Top1: 63.19%
[ Tue Aug  2 17:14:37 2022 ] 	Top5: 89.73%
[ Tue Aug  2 17:14:37 2022 ] Training epoch: 9
[ Tue Aug  2 17:19:25 2022 ] 	Mean training loss: 0.9873.  Mean training acc: 70.30%.
[ Tue Aug  2 17:19:25 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 17:19:25 2022 ] Eval epoch: 9
[ Tue Aug  2 17:20:44 2022 ] 	Mean test loss of 796 batches: 1.2100600430638946.
[ Tue Aug  2 17:20:45 2022 ] 	Top1: 63.70%
[ Tue Aug  2 17:20:45 2022 ] 	Top5: 90.09%
[ Tue Aug  2 17:20:45 2022 ] Training epoch: 10
[ Tue Aug  2 17:25:27 2022 ] 	Mean training loss: 0.9572.  Mean training acc: 71.12%.
[ Tue Aug  2 17:25:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Aug  2 17:25:27 2022 ] Eval epoch: 10
[ Tue Aug  2 17:26:46 2022 ] 	Mean test loss of 796 batches: 1.1126497848399322.
[ Tue Aug  2 17:26:46 2022 ] 	Top1: 66.55%
[ Tue Aug  2 17:26:47 2022 ] 	Top5: 91.49%
[ Tue Aug  2 17:26:47 2022 ] Training epoch: 11
[ Tue Aug  2 17:31:43 2022 ] 	Mean training loss: 0.9346.  Mean training acc: 71.57%.
[ Tue Aug  2 17:31:43 2022 ] 	Time consumption: [Data]02%, [Network]92%
[ Tue Aug  2 17:31:43 2022 ] Eval epoch: 11
[ Tue Aug  2 17:32:46 2022 ] 	Mean test loss of 796 batches: 1.325504955259999.
[ Tue Aug  2 17:32:47 2022 ] 	Top1: 63.25%
[ Tue Aug  2 17:32:47 2022 ] 	Top5: 89.71%
[ Tue Aug  2 17:32:47 2022 ] Training epoch: 12
[ Tue Aug  2 17:37:24 2022 ] 	Mean training loss: 0.9257.  Mean training acc: 72.31%.
[ Tue Aug  2 17:37:24 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 17:37:24 2022 ] Eval epoch: 12
[ Tue Aug  2 17:38:35 2022 ] 	Mean test loss of 796 batches: 1.481699852188628.
[ Tue Aug  2 17:38:35 2022 ] 	Top1: 60.15%
[ Tue Aug  2 17:38:36 2022 ] 	Top5: 87.16%
[ Tue Aug  2 17:38:36 2022 ] Training epoch: 13
[ Tue Aug  2 17:43:13 2022 ] 	Mean training loss: 0.9066.  Mean training acc: 72.42%.
[ Tue Aug  2 17:43:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 17:43:13 2022 ] Eval epoch: 13
[ Tue Aug  2 17:44:21 2022 ] 	Mean test loss of 796 batches: 1.1212777376699088.
[ Tue Aug  2 17:44:22 2022 ] 	Top1: 66.82%
[ Tue Aug  2 17:44:22 2022 ] 	Top5: 91.01%
[ Tue Aug  2 17:44:22 2022 ] Training epoch: 14
[ Tue Aug  2 17:49:01 2022 ] 	Mean training loss: 0.8828.  Mean training acc: 73.27%.
[ Tue Aug  2 17:49:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 17:49:01 2022 ] Eval epoch: 14
[ Tue Aug  2 17:50:15 2022 ] 	Mean test loss of 796 batches: 1.072115098973315.
[ Tue Aug  2 17:50:15 2022 ] 	Top1: 69.03%
[ Tue Aug  2 17:50:15 2022 ] 	Top5: 92.00%
[ Tue Aug  2 17:50:15 2022 ] Training epoch: 15
[ Tue Aug  2 17:54:54 2022 ] 	Mean training loss: 0.8784.  Mean training acc: 73.46%.
[ Tue Aug  2 17:54:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 17:54:54 2022 ] Eval epoch: 15
[ Tue Aug  2 17:56:05 2022 ] 	Mean test loss of 796 batches: 1.1375517771396804.
[ Tue Aug  2 17:56:05 2022 ] 	Top1: 66.73%
[ Tue Aug  2 17:56:06 2022 ] 	Top5: 91.13%
[ Tue Aug  2 17:56:06 2022 ] Training epoch: 16
[ Tue Aug  2 18:00:45 2022 ] 	Mean training loss: 0.8656.  Mean training acc: 73.86%.
[ Tue Aug  2 18:00:45 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:00:45 2022 ] Eval epoch: 16
[ Tue Aug  2 18:01:58 2022 ] 	Mean test loss of 796 batches: 1.3286959383281032.
[ Tue Aug  2 18:01:58 2022 ] 	Top1: 62.82%
[ Tue Aug  2 18:01:59 2022 ] 	Top5: 89.76%
[ Tue Aug  2 18:01:59 2022 ] Training epoch: 17
[ Tue Aug  2 18:06:28 2022 ] 	Mean training loss: 0.8633.  Mean training acc: 73.98%.
[ Tue Aug  2 18:06:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:06:28 2022 ] Eval epoch: 17
[ Tue Aug  2 18:07:41 2022 ] 	Mean test loss of 796 batches: 1.1131039236358662.
[ Tue Aug  2 18:07:41 2022 ] 	Top1: 67.10%
[ Tue Aug  2 18:07:41 2022 ] 	Top5: 91.73%
[ Tue Aug  2 18:07:42 2022 ] Training epoch: 18
[ Tue Aug  2 18:12:21 2022 ] 	Mean training loss: 0.8513.  Mean training acc: 74.09%.
[ Tue Aug  2 18:12:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:12:21 2022 ] Eval epoch: 18
[ Tue Aug  2 18:13:35 2022 ] 	Mean test loss of 796 batches: 1.1134437129425643.
[ Tue Aug  2 18:13:35 2022 ] 	Top1: 67.35%
[ Tue Aug  2 18:13:36 2022 ] 	Top5: 91.75%
[ Tue Aug  2 18:13:36 2022 ] Training epoch: 19
[ Tue Aug  2 18:18:10 2022 ] 	Mean training loss: 0.8413.  Mean training acc: 74.50%.
[ Tue Aug  2 18:18:10 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:18:10 2022 ] Eval epoch: 19
[ Tue Aug  2 18:19:24 2022 ] 	Mean test loss of 796 batches: 1.038289621584679.
[ Tue Aug  2 18:19:25 2022 ] 	Top1: 69.77%
[ Tue Aug  2 18:19:25 2022 ] 	Top5: 92.47%
[ Tue Aug  2 18:19:25 2022 ] Training epoch: 20
[ Tue Aug  2 18:24:07 2022 ] 	Mean training loss: nan.  Mean training acc: 66.78%.
[ Tue Aug  2 18:24:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:24:07 2022 ] Eval epoch: 20
[ Tue Aug  2 18:25:19 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:25:19 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:25:19 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:25:19 2022 ] Training epoch: 21
[ Tue Aug  2 18:30:01 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:30:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:30:01 2022 ] Eval epoch: 21
[ Tue Aug  2 18:31:16 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:31:16 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:31:17 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:31:17 2022 ] Training epoch: 22
[ Tue Aug  2 18:35:54 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:35:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:35:54 2022 ] Eval epoch: 22
[ Tue Aug  2 18:37:02 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:37:02 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:37:03 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:37:03 2022 ] Training epoch: 23
[ Tue Aug  2 18:41:44 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:41:44 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:41:44 2022 ] Eval epoch: 23
[ Tue Aug  2 18:42:59 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:42:59 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:42:59 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:42:59 2022 ] Training epoch: 24
[ Tue Aug  2 18:47:41 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:47:41 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:47:41 2022 ] Eval epoch: 24
[ Tue Aug  2 18:48:53 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:48:53 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:48:53 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:48:53 2022 ] Training epoch: 25
[ Tue Aug  2 18:53:34 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:53:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:53:34 2022 ] Eval epoch: 25
[ Tue Aug  2 18:54:49 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 18:54:49 2022 ] 	Top1: 1.13%
[ Tue Aug  2 18:54:49 2022 ] 	Top5: 3.89%
[ Tue Aug  2 18:54:49 2022 ] Training epoch: 26
[ Tue Aug  2 18:59:26 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 18:59:27 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 18:59:27 2022 ] Eval epoch: 26
[ Tue Aug  2 19:00:41 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:00:41 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:00:42 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:00:42 2022 ] Training epoch: 27
[ Tue Aug  2 19:05:23 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:05:23 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:05:23 2022 ] Eval epoch: 27
[ Tue Aug  2 19:06:35 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:06:35 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:06:35 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:06:35 2022 ] Training epoch: 28
[ Tue Aug  2 19:11:18 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:11:18 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:11:18 2022 ] Eval epoch: 28
[ Tue Aug  2 19:12:33 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:12:33 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:12:33 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:12:33 2022 ] Training epoch: 29
[ Tue Aug  2 19:17:15 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:17:15 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:17:15 2022 ] Eval epoch: 29
[ Tue Aug  2 19:18:25 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:18:26 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:18:26 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:18:26 2022 ] Training epoch: 30
[ Tue Aug  2 19:23:06 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:23:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:23:06 2022 ] Eval epoch: 30
[ Tue Aug  2 19:24:17 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:24:17 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:24:17 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:24:17 2022 ] Training epoch: 31
[ Tue Aug  2 19:28:53 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:28:53 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:28:53 2022 ] Eval epoch: 31
[ Tue Aug  2 19:30:02 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:30:02 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:30:03 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:30:03 2022 ] Training epoch: 32
[ Tue Aug  2 19:34:38 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:34:38 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:34:38 2022 ] Eval epoch: 32
[ Tue Aug  2 19:35:51 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:35:51 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:35:51 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:35:51 2022 ] Training epoch: 33
[ Tue Aug  2 19:40:22 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:40:22 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:40:22 2022 ] Eval epoch: 33
[ Tue Aug  2 19:41:34 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:41:34 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:41:34 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:41:34 2022 ] Training epoch: 34
[ Tue Aug  2 19:46:15 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:46:15 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:46:15 2022 ] Eval epoch: 34
[ Tue Aug  2 19:47:28 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:47:28 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:47:29 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:47:29 2022 ] Training epoch: 35
[ Tue Aug  2 19:52:07 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:52:07 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:52:07 2022 ] Eval epoch: 35
[ Tue Aug  2 19:53:21 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:53:21 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:53:22 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:53:22 2022 ] Training epoch: 36
[ Tue Aug  2 19:58:02 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 19:58:02 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 19:58:02 2022 ] Eval epoch: 36
[ Tue Aug  2 19:59:13 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 19:59:13 2022 ] 	Top1: 1.13%
[ Tue Aug  2 19:59:13 2022 ] 	Top5: 3.89%
[ Tue Aug  2 19:59:13 2022 ] Training epoch: 37
[ Tue Aug  2 20:03:55 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:03:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:03:55 2022 ] Eval epoch: 37
[ Tue Aug  2 20:05:10 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:05:10 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:05:11 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:05:11 2022 ] Training epoch: 38
[ Tue Aug  2 20:09:53 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:09:53 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:09:53 2022 ] Eval epoch: 38
[ Tue Aug  2 20:11:03 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:11:04 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:11:04 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:11:04 2022 ] Training epoch: 39
[ Tue Aug  2 20:15:40 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:15:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:15:40 2022 ] Eval epoch: 39
[ Tue Aug  2 20:16:56 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:16:56 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:16:56 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:16:56 2022 ] Training epoch: 40
[ Tue Aug  2 20:21:33 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:21:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:21:33 2022 ] Eval epoch: 40
[ Tue Aug  2 20:22:47 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:22:47 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:22:47 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:22:47 2022 ] Training epoch: 41
[ Tue Aug  2 20:27:28 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:27:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:27:28 2022 ] Eval epoch: 41
[ Tue Aug  2 20:28:40 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:28:40 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:28:40 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:28:40 2022 ] Training epoch: 42
[ Tue Aug  2 20:33:20 2022 ] 	Mean training loss: nan.  Mean training acc: 1.05%.
[ Tue Aug  2 20:33:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:33:20 2022 ] Eval epoch: 42
[ Tue Aug  2 20:34:35 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:34:35 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:34:35 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:34:35 2022 ] Training epoch: 43
[ Tue Aug  2 20:39:15 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:39:15 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:39:15 2022 ] Eval epoch: 43
[ Tue Aug  2 20:40:26 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:40:27 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:40:27 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:40:27 2022 ] Training epoch: 44
[ Tue Aug  2 20:45:06 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:45:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:45:06 2022 ] Eval epoch: 44
[ Tue Aug  2 20:46:21 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:46:22 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:46:22 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:46:22 2022 ] Training epoch: 45
[ Tue Aug  2 20:51:01 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:51:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:51:01 2022 ] Eval epoch: 45
[ Tue Aug  2 20:52:12 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:52:12 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:52:12 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:52:12 2022 ] Training epoch: 46
[ Tue Aug  2 20:56:53 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 20:56:53 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 20:56:53 2022 ] Eval epoch: 46
[ Tue Aug  2 20:58:08 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 20:58:08 2022 ] 	Top1: 1.13%
[ Tue Aug  2 20:58:09 2022 ] 	Top5: 3.89%
[ Tue Aug  2 20:58:09 2022 ] Training epoch: 47
[ Tue Aug  2 21:02:43 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:02:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:02:43 2022 ] Eval epoch: 47
[ Tue Aug  2 21:03:57 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:03:57 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:03:57 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:03:58 2022 ] Training epoch: 48
[ Tue Aug  2 21:08:39 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:08:39 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:08:39 2022 ] Eval epoch: 48
[ Tue Aug  2 21:09:51 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:09:52 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:09:52 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:09:52 2022 ] Training epoch: 49
[ Tue Aug  2 21:14:32 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:14:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:14:32 2022 ] Eval epoch: 49
[ Tue Aug  2 21:15:47 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:15:48 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:15:48 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:15:48 2022 ] Training epoch: 50
[ Tue Aug  2 21:20:28 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:20:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:20:28 2022 ] Eval epoch: 50
[ Tue Aug  2 21:21:38 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:21:38 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:21:39 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:21:39 2022 ] Training epoch: 51
[ Tue Aug  2 21:26:21 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:26:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:26:21 2022 ] Eval epoch: 51
[ Tue Aug  2 21:27:36 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:27:36 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:27:36 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:27:36 2022 ] Training epoch: 52
[ Tue Aug  2 21:32:14 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:32:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:32:14 2022 ] Eval epoch: 52
[ Tue Aug  2 21:33:27 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:33:27 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:33:28 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:33:28 2022 ] Training epoch: 53
[ Tue Aug  2 21:38:09 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:38:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:38:09 2022 ] Eval epoch: 53
[ Tue Aug  2 21:39:24 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:39:24 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:39:24 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:39:24 2022 ] Training epoch: 54
[ Tue Aug  2 21:43:59 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:43:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:43:59 2022 ] Eval epoch: 54
[ Tue Aug  2 21:45:15 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:45:15 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:45:15 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:45:15 2022 ] Training epoch: 55
[ Tue Aug  2 21:49:56 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:49:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:49:56 2022 ] Eval epoch: 55
[ Tue Aug  2 21:51:06 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:51:06 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:51:06 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:51:06 2022 ] Training epoch: 56
[ Tue Aug  2 21:55:55 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 21:55:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 21:55:55 2022 ] Eval epoch: 56
[ Tue Aug  2 21:57:30 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 21:57:30 2022 ] 	Top1: 1.13%
[ Tue Aug  2 21:57:30 2022 ] 	Top5: 3.89%
[ Tue Aug  2 21:57:30 2022 ] Training epoch: 57
[ Tue Aug  2 22:03:19 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:03:19 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:03:19 2022 ] Eval epoch: 57
[ Tue Aug  2 22:04:51 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:04:51 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:04:51 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:04:51 2022 ] Training epoch: 58
[ Tue Aug  2 22:10:36 2022 ] 	Mean training loss: nan.  Mean training acc: 1.05%.
[ Tue Aug  2 22:10:36 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:10:36 2022 ] Eval epoch: 58
[ Tue Aug  2 22:11:50 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:11:50 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:11:50 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:11:50 2022 ] Training epoch: 59
[ Tue Aug  2 22:16:27 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:16:27 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:16:27 2022 ] Eval epoch: 59
[ Tue Aug  2 22:17:43 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:17:43 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:17:43 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:17:43 2022 ] Training epoch: 60
[ Tue Aug  2 22:22:25 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:22:25 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:22:25 2022 ] Eval epoch: 60
[ Tue Aug  2 22:23:34 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:23:34 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:23:35 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:23:35 2022 ] Training epoch: 61
[ Tue Aug  2 22:28:19 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:28:19 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Aug  2 22:28:19 2022 ] Eval epoch: 61
[ Tue Aug  2 22:29:34 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:29:34 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:29:34 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:29:34 2022 ] Training epoch: 62
[ Tue Aug  2 22:34:17 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:34:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:34:17 2022 ] Eval epoch: 62
[ Tue Aug  2 22:35:27 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:35:27 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:35:28 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:35:28 2022 ] Training epoch: 63
[ Tue Aug  2 22:40:09 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:40:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:40:09 2022 ] Eval epoch: 63
[ Tue Aug  2 22:41:25 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:41:26 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:41:26 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:41:26 2022 ] Training epoch: 64
[ Tue Aug  2 22:46:00 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:46:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:46:00 2022 ] Eval epoch: 64
[ Tue Aug  2 22:47:13 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:47:13 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:47:13 2022 ] 	Top5: 3.89%
[ Tue Aug  2 22:47:13 2022 ] Training epoch: 65
[ Tue Aug  2 22:51:49 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Tue Aug  2 22:51:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Aug  2 22:51:49 2022 ] Eval epoch: 65
[ Tue Aug  2 22:52:59 2022 ] 	Mean test loss of 796 batches: nan.
[ Tue Aug  2 22:52:59 2022 ] 	Top1: 1.13%
[ Tue Aug  2 22:52:59 2022 ] 	Top5: 3.89%
[ Wed Aug  3 09:50:06 2022 ] using warm up, epoch: 5
[ Wed Aug  3 09:52:01 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spher_harm1', 'model_saved_name': 'work_dir/ntu120/csub/spher_harm1/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spherical_harm1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Aug  3 09:52:01 2022 ] # Parameters: 2180490
[ Wed Aug  3 09:52:01 2022 ] Training epoch: 1
[ Wed Aug  3 09:55:03 2022 ] 	Mean training loss: 3.1741.  Mean training acc: 21.57%.
[ Wed Aug  3 09:55:03 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 09:55:03 2022 ] Eval epoch: 1
[ Wed Aug  3 09:55:50 2022 ] 	Mean test loss of 796 batches: 2.586507822550721.
[ Wed Aug  3 09:55:50 2022 ] 	Top1: 29.05%
[ Wed Aug  3 09:55:50 2022 ] 	Top5: 65.74%
[ Wed Aug  3 09:55:51 2022 ] Training epoch: 2
[ Wed Aug  3 09:58:54 2022 ] 	Mean training loss: 2.0648.  Mean training acc: 42.26%.
[ Wed Aug  3 09:58:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 09:58:54 2022 ] Eval epoch: 2
[ Wed Aug  3 09:59:41 2022 ] 	Mean test loss of 796 batches: 1.8843896369538715.
[ Wed Aug  3 09:59:41 2022 ] 	Top1: 44.97%
[ Wed Aug  3 09:59:41 2022 ] 	Top5: 80.02%
[ Wed Aug  3 09:59:41 2022 ] Training epoch: 3
[ Wed Aug  3 10:02:44 2022 ] 	Mean training loss: 1.6148.  Mean training acc: 53.28%.
[ Wed Aug  3 10:02:44 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 10:02:44 2022 ] Eval epoch: 3
[ Wed Aug  3 10:03:30 2022 ] 	Mean test loss of 796 batches: 1.5482244272926944.
[ Wed Aug  3 10:03:30 2022 ] 	Top1: 55.27%
[ Wed Aug  3 10:03:31 2022 ] 	Top5: 85.92%
[ Wed Aug  3 10:03:31 2022 ] Training epoch: 4
[ Wed Aug  3 10:06:33 2022 ] 	Mean training loss: 1.3868.  Mean training acc: 59.48%.
[ Wed Aug  3 10:06:33 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 10:06:33 2022 ] Eval epoch: 4
[ Wed Aug  3 10:07:18 2022 ] 	Mean test loss of 796 batches: 1.38640580783088.
[ Wed Aug  3 10:07:19 2022 ] 	Top1: 59.20%
[ Wed Aug  3 10:07:19 2022 ] 	Top5: 88.12%
[ Wed Aug  3 10:07:19 2022 ] Training epoch: 5
[ Wed Aug  3 10:10:22 2022 ] 	Mean training loss: 1.2575.  Mean training acc: 62.79%.
[ Wed Aug  3 10:10:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:10:22 2022 ] Eval epoch: 5
[ Wed Aug  3 10:11:08 2022 ] 	Mean test loss of 796 batches: 1.607654967574618.
[ Wed Aug  3 10:11:08 2022 ] 	Top1: 53.82%
[ Wed Aug  3 10:11:08 2022 ] 	Top5: 85.46%
[ Wed Aug  3 10:11:09 2022 ] Training epoch: 6
[ Wed Aug  3 10:14:11 2022 ] 	Mean training loss: 1.1511.  Mean training acc: 65.75%.
[ Wed Aug  3 10:14:11 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:14:11 2022 ] Eval epoch: 6
[ Wed Aug  3 10:14:57 2022 ] 	Mean test loss of 796 batches: 1.3661472937419785.
[ Wed Aug  3 10:14:57 2022 ] 	Top1: 60.45%
[ Wed Aug  3 10:14:58 2022 ] 	Top5: 89.58%
[ Wed Aug  3 10:14:58 2022 ] Training epoch: 7
[ Wed Aug  3 10:18:00 2022 ] 	Mean training loss: 1.0676.  Mean training acc: 68.11%.
[ Wed Aug  3 10:18:00 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:18:00 2022 ] Eval epoch: 7
[ Wed Aug  3 10:18:45 2022 ] 	Mean test loss of 796 batches: 1.4154172560303055.
[ Wed Aug  3 10:18:46 2022 ] 	Top1: 59.96%
[ Wed Aug  3 10:18:46 2022 ] 	Top5: 87.51%
[ Wed Aug  3 10:18:46 2022 ] Training epoch: 8
[ Wed Aug  3 10:21:48 2022 ] 	Mean training loss: 1.0273.  Mean training acc: 69.49%.
[ Wed Aug  3 10:21:48 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:21:48 2022 ] Eval epoch: 8
[ Wed Aug  3 10:22:34 2022 ] 	Mean test loss of 796 batches: 1.175385244976935.
[ Wed Aug  3 10:22:34 2022 ] 	Top1: 65.18%
[ Wed Aug  3 10:22:35 2022 ] 	Top5: 90.56%
[ Wed Aug  3 10:22:35 2022 ] Training epoch: 9
[ Wed Aug  3 10:25:37 2022 ] 	Mean training loss: 0.9916.  Mean training acc: 70.24%.
[ Wed Aug  3 10:25:37 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:25:37 2022 ] Eval epoch: 9
[ Wed Aug  3 10:26:22 2022 ] 	Mean test loss of 796 batches: 1.3566035816268107.
[ Wed Aug  3 10:26:23 2022 ] 	Top1: 61.05%
[ Wed Aug  3 10:26:23 2022 ] 	Top5: 88.65%
[ Wed Aug  3 10:26:23 2022 ] Training epoch: 10
[ Wed Aug  3 10:29:25 2022 ] 	Mean training loss: 0.9558.  Mean training acc: 71.23%.
[ Wed Aug  3 10:29:25 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:29:25 2022 ] Eval epoch: 10
[ Wed Aug  3 10:30:10 2022 ] 	Mean test loss of 796 batches: 1.2917826207888186.
[ Wed Aug  3 10:30:11 2022 ] 	Top1: 62.68%
[ Wed Aug  3 10:30:11 2022 ] 	Top5: 90.00%
[ Wed Aug  3 10:30:11 2022 ] Training epoch: 11
[ Wed Aug  3 10:33:14 2022 ] 	Mean training loss: 0.9375.  Mean training acc: 71.70%.
[ Wed Aug  3 10:33:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:33:14 2022 ] Eval epoch: 11
[ Wed Aug  3 10:34:00 2022 ] 	Mean test loss of 796 batches: 1.2592067040839987.
[ Wed Aug  3 10:34:00 2022 ] 	Top1: 64.09%
[ Wed Aug  3 10:34:00 2022 ] 	Top5: 90.22%
[ Wed Aug  3 10:34:00 2022 ] Training epoch: 12
[ Wed Aug  3 10:37:03 2022 ] 	Mean training loss: 0.9220.  Mean training acc: 72.28%.
[ Wed Aug  3 10:37:03 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 10:37:03 2022 ] Eval epoch: 12
[ Wed Aug  3 10:37:49 2022 ] 	Mean test loss of 796 batches: 1.206443184022628.
[ Wed Aug  3 10:37:49 2022 ] 	Top1: 65.27%
[ Wed Aug  3 10:37:50 2022 ] 	Top5: 90.28%
[ Wed Aug  3 10:37:50 2022 ] Training epoch: 13
[ Wed Aug  3 10:40:52 2022 ] 	Mean training loss: 0.9074.  Mean training acc: 72.75%.
[ Wed Aug  3 10:40:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:40:52 2022 ] Eval epoch: 13
[ Wed Aug  3 10:41:37 2022 ] 	Mean test loss of 796 batches: 1.2235084518266084.
[ Wed Aug  3 10:41:38 2022 ] 	Top1: 65.15%
[ Wed Aug  3 10:41:38 2022 ] 	Top5: 90.19%
[ Wed Aug  3 10:41:38 2022 ] Training epoch: 14
[ Wed Aug  3 10:44:40 2022 ] 	Mean training loss: 0.8887.  Mean training acc: 73.08%.
[ Wed Aug  3 10:44:40 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:44:40 2022 ] Eval epoch: 14
[ Wed Aug  3 10:45:25 2022 ] 	Mean test loss of 796 batches: 1.090385368421449.
[ Wed Aug  3 10:45:26 2022 ] 	Top1: 68.48%
[ Wed Aug  3 10:45:26 2022 ] 	Top5: 91.11%
[ Wed Aug  3 10:45:26 2022 ] Training epoch: 15
[ Wed Aug  3 10:48:28 2022 ] 	Mean training loss: 0.8767.  Mean training acc: 73.70%.
[ Wed Aug  3 10:48:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 10:48:28 2022 ] Eval epoch: 15
[ Wed Aug  3 10:49:14 2022 ] 	Mean test loss of 796 batches: 1.196124989595545.
[ Wed Aug  3 10:49:14 2022 ] 	Top1: 65.34%
[ Wed Aug  3 10:49:15 2022 ] 	Top5: 90.98%
[ Wed Aug  3 10:49:15 2022 ] Training epoch: 16
[ Wed Aug  3 10:52:17 2022 ] 	Mean training loss: 0.8693.  Mean training acc: 73.87%.
[ Wed Aug  3 10:52:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:52:17 2022 ] Eval epoch: 16
[ Wed Aug  3 10:53:03 2022 ] 	Mean test loss of 796 batches: 1.1713269301994362.
[ Wed Aug  3 10:53:04 2022 ] 	Top1: 66.54%
[ Wed Aug  3 10:53:04 2022 ] 	Top5: 89.84%
[ Wed Aug  3 10:53:04 2022 ] Training epoch: 17
[ Wed Aug  3 10:56:06 2022 ] 	Mean training loss: 0.8673.  Mean training acc: 73.75%.
[ Wed Aug  3 10:56:06 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:56:06 2022 ] Eval epoch: 17
[ Wed Aug  3 10:56:52 2022 ] 	Mean test loss of 796 batches: 1.1140523047078794.
[ Wed Aug  3 10:56:52 2022 ] 	Top1: 67.27%
[ Wed Aug  3 10:56:52 2022 ] 	Top5: 91.66%
[ Wed Aug  3 10:56:52 2022 ] Training epoch: 18
[ Wed Aug  3 10:59:54 2022 ] 	Mean training loss: 0.8501.  Mean training acc: 74.19%.
[ Wed Aug  3 10:59:54 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 10:59:54 2022 ] Eval epoch: 18
[ Wed Aug  3 11:00:40 2022 ] 	Mean test loss of 796 batches: 1.104374626922847.
[ Wed Aug  3 11:00:41 2022 ] 	Top1: 67.76%
[ Wed Aug  3 11:00:41 2022 ] 	Top5: 91.78%
[ Wed Aug  3 11:00:41 2022 ] Training epoch: 19
[ Wed Aug  3 11:03:44 2022 ] 	Mean training loss: 0.8444.  Mean training acc: 74.64%.
[ Wed Aug  3 11:03:44 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:03:44 2022 ] Eval epoch: 19
[ Wed Aug  3 11:04:30 2022 ] 	Mean test loss of 796 batches: 1.0222523756437565.
[ Wed Aug  3 11:04:30 2022 ] 	Top1: 69.37%
[ Wed Aug  3 11:04:31 2022 ] 	Top5: 92.50%
[ Wed Aug  3 11:04:31 2022 ] Training epoch: 20
[ Wed Aug  3 11:07:34 2022 ] 	Mean training loss: 0.8446.  Mean training acc: 74.41%.
[ Wed Aug  3 11:07:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 11:07:34 2022 ] Eval epoch: 20
[ Wed Aug  3 11:08:20 2022 ] 	Mean test loss of 796 batches: 1.316059656553532.
[ Wed Aug  3 11:08:21 2022 ] 	Top1: 62.98%
[ Wed Aug  3 11:08:21 2022 ] 	Top5: 88.31%
[ Wed Aug  3 11:08:21 2022 ] Training epoch: 21
[ Wed Aug  3 11:11:24 2022 ] 	Mean training loss: 0.8398.  Mean training acc: 74.88%.
[ Wed Aug  3 11:11:24 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:11:24 2022 ] Eval epoch: 21
[ Wed Aug  3 11:12:10 2022 ] 	Mean test loss of 796 batches: 1.1194690180633535.
[ Wed Aug  3 11:12:10 2022 ] 	Top1: 68.01%
[ Wed Aug  3 11:12:10 2022 ] 	Top5: 91.50%
[ Wed Aug  3 11:12:10 2022 ] Training epoch: 22
[ Wed Aug  3 11:15:10 2022 ] 	Mean training loss: nan.  Mean training acc: 21.81%.
[ Wed Aug  3 11:15:10 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:15:10 2022 ] Eval epoch: 22
[ Wed Aug  3 11:15:56 2022 ] 	Mean test loss of 796 batches: nan.
[ Wed Aug  3 11:15:56 2022 ] 	Top1: 1.13%
[ Wed Aug  3 11:15:56 2022 ] 	Top5: 3.89%
[ Wed Aug  3 11:15:56 2022 ] Training epoch: 23
[ Wed Aug  3 11:18:56 2022 ] 	Mean training loss: nan.  Mean training acc: 1.06%.
[ Wed Aug  3 11:18:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 11:18:56 2022 ] Eval epoch: 23
[ Wed Aug  3 11:48:58 2022 ] using warm up, epoch: 5
[ Wed Aug  3 11:49:12 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spher_harm1', 'model_saved_name': 'work_dir/ntu120/csub/spher_harm1/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spherical_harm1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Aug  3 11:49:12 2022 ] # Parameters: 2180490
[ Wed Aug  3 11:49:12 2022 ] Training epoch: 1
[ Wed Aug  3 11:52:14 2022 ] 	Mean training loss: 3.1741.  Mean training acc: 21.57%.
[ Wed Aug  3 11:52:14 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:52:14 2022 ] Eval epoch: 1
[ Wed Aug  3 11:52:59 2022 ] 	Mean test loss of 796 batches: 2.586507822550721.
[ Wed Aug  3 11:53:00 2022 ] 	Top1: 29.05%
[ Wed Aug  3 11:53:00 2022 ] 	Top5: 65.74%
[ Wed Aug  3 11:53:00 2022 ] Training epoch: 2
[ Wed Aug  3 11:56:02 2022 ] 	Mean training loss: 2.0648.  Mean training acc: 42.26%.
[ Wed Aug  3 11:56:02 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 11:56:02 2022 ] Eval epoch: 2
[ Wed Aug  3 11:56:50 2022 ] 	Mean test loss of 796 batches: 1.8843896369538715.
[ Wed Aug  3 11:56:50 2022 ] 	Top1: 44.97%
[ Wed Aug  3 11:56:51 2022 ] 	Top5: 80.02%
[ Wed Aug  3 11:56:51 2022 ] Training epoch: 3
[ Wed Aug  3 11:59:58 2022 ] 	Mean training loss: 1.6148.  Mean training acc: 53.28%.
[ Wed Aug  3 11:59:58 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 11:59:58 2022 ] Eval epoch: 3
[ Wed Aug  3 12:00:49 2022 ] 	Mean test loss of 796 batches: 1.5482244272926944.
[ Wed Aug  3 12:00:50 2022 ] 	Top1: 55.27%
[ Wed Aug  3 12:00:50 2022 ] 	Top5: 85.92%
[ Wed Aug  3 12:00:50 2022 ] Training epoch: 4
[ Wed Aug  3 12:03:57 2022 ] 	Mean training loss: 1.3868.  Mean training acc: 59.48%.
[ Wed Aug  3 12:03:57 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 12:03:57 2022 ] Eval epoch: 4
[ Wed Aug  3 12:04:47 2022 ] 	Mean test loss of 796 batches: 1.38640580783088.
[ Wed Aug  3 12:04:47 2022 ] 	Top1: 59.20%
[ Wed Aug  3 12:04:48 2022 ] 	Top5: 88.12%
[ Wed Aug  3 12:04:48 2022 ] Training epoch: 5
[ Wed Aug  3 12:07:56 2022 ] 	Mean training loss: 1.2575.  Mean training acc: 62.79%.
[ Wed Aug  3 12:07:56 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 12:07:56 2022 ] Eval epoch: 5
[ Wed Aug  3 12:08:45 2022 ] 	Mean test loss of 796 batches: 1.607654967574618.
[ Wed Aug  3 12:08:46 2022 ] 	Top1: 53.82%
[ Wed Aug  3 12:08:46 2022 ] 	Top5: 85.46%
[ Wed Aug  3 12:08:46 2022 ] Training epoch: 6
[ Wed Aug  3 12:11:54 2022 ] 	Mean training loss: 1.1511.  Mean training acc: 65.75%.
[ Wed Aug  3 12:11:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 12:11:54 2022 ] Eval epoch: 6
[ Wed Aug  3 12:12:44 2022 ] 	Mean test loss of 796 batches: 1.3661472937419785.
[ Wed Aug  3 12:12:44 2022 ] 	Top1: 60.45%
[ Wed Aug  3 12:12:44 2022 ] 	Top5: 89.58%
[ Wed Aug  3 12:12:45 2022 ] Training epoch: 7
[ Wed Aug  3 12:15:52 2022 ] 	Mean training loss: 1.0676.  Mean training acc: 68.11%.
[ Wed Aug  3 12:15:52 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 12:15:52 2022 ] Eval epoch: 7
[ Wed Aug  3 12:16:41 2022 ] 	Mean test loss of 796 batches: 1.4154172560303055.
[ Wed Aug  3 12:16:42 2022 ] 	Top1: 59.96%
[ Wed Aug  3 12:16:42 2022 ] 	Top5: 87.51%
[ Wed Aug  3 12:16:42 2022 ] Training epoch: 8
[ Wed Aug  3 12:20:33 2022 ] 	Mean training loss: 1.0273.  Mean training acc: 69.49%.
[ Wed Aug  3 12:20:33 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:20:33 2022 ] Eval epoch: 8
[ Wed Aug  3 12:21:22 2022 ] 	Mean test loss of 796 batches: 1.175385244976935.
[ Wed Aug  3 12:21:22 2022 ] 	Top1: 65.18%
[ Wed Aug  3 12:21:23 2022 ] 	Top5: 90.56%
[ Wed Aug  3 12:21:23 2022 ] Training epoch: 9
[ Wed Aug  3 12:24:25 2022 ] 	Mean training loss: 0.9916.  Mean training acc: 70.24%.
[ Wed Aug  3 12:24:25 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:24:25 2022 ] Eval epoch: 9
[ Wed Aug  3 12:25:10 2022 ] 	Mean test loss of 796 batches: 1.3566035816268107.
[ Wed Aug  3 12:25:11 2022 ] 	Top1: 61.05%
[ Wed Aug  3 12:25:11 2022 ] 	Top5: 88.65%
[ Wed Aug  3 12:25:11 2022 ] Training epoch: 10
[ Wed Aug  3 12:28:15 2022 ] 	Mean training loss: 0.9558.  Mean training acc: 71.23%.
[ Wed Aug  3 12:28:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:28:15 2022 ] Eval epoch: 10
[ Wed Aug  3 12:29:03 2022 ] 	Mean test loss of 796 batches: 1.2917826207888186.
[ Wed Aug  3 12:29:03 2022 ] 	Top1: 62.68%
[ Wed Aug  3 12:29:03 2022 ] 	Top5: 90.00%
[ Wed Aug  3 12:29:03 2022 ] Training epoch: 11
[ Wed Aug  3 12:32:07 2022 ] 	Mean training loss: 0.9375.  Mean training acc: 71.70%.
[ Wed Aug  3 12:32:07 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:32:07 2022 ] Eval epoch: 11
[ Wed Aug  3 12:32:54 2022 ] 	Mean test loss of 796 batches: 1.2592067040839987.
[ Wed Aug  3 12:32:55 2022 ] 	Top1: 64.09%
[ Wed Aug  3 12:32:55 2022 ] 	Top5: 90.22%
[ Wed Aug  3 12:32:55 2022 ] Training epoch: 12
[ Wed Aug  3 12:35:59 2022 ] 	Mean training loss: 0.9220.  Mean training acc: 72.28%.
[ Wed Aug  3 12:35:59 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:35:59 2022 ] Eval epoch: 12
[ Wed Aug  3 12:36:46 2022 ] 	Mean test loss of 796 batches: 1.206443184022628.
[ Wed Aug  3 12:36:46 2022 ] 	Top1: 65.27%
[ Wed Aug  3 12:36:46 2022 ] 	Top5: 90.28%
[ Wed Aug  3 12:36:47 2022 ] Training epoch: 13
[ Wed Aug  3 12:39:54 2022 ] 	Mean training loss: 0.9074.  Mean training acc: 72.75%.
[ Wed Aug  3 12:39:54 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:39:54 2022 ] Eval epoch: 13
[ Wed Aug  3 12:40:46 2022 ] 	Mean test loss of 796 batches: 1.2235084518266084.
[ Wed Aug  3 12:40:47 2022 ] 	Top1: 65.15%
[ Wed Aug  3 12:40:47 2022 ] 	Top5: 90.19%
[ Wed Aug  3 12:40:47 2022 ] Training epoch: 14
[ Wed Aug  3 12:44:19 2022 ] 	Mean training loss: 0.8887.  Mean training acc: 73.08%.
[ Wed Aug  3 12:44:19 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:44:19 2022 ] Eval epoch: 14
[ Wed Aug  3 12:45:11 2022 ] 	Mean test loss of 796 batches: 1.090385368421449.
[ Wed Aug  3 12:45:11 2022 ] 	Top1: 68.48%
[ Wed Aug  3 12:45:12 2022 ] 	Top5: 91.11%
[ Wed Aug  3 12:45:12 2022 ] Training epoch: 15
[ Wed Aug  3 12:48:43 2022 ] 	Mean training loss: 0.8767.  Mean training acc: 73.70%.
[ Wed Aug  3 12:48:43 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:48:43 2022 ] Eval epoch: 15
[ Wed Aug  3 12:49:37 2022 ] 	Mean test loss of 796 batches: 1.196124989595545.
[ Wed Aug  3 12:49:38 2022 ] 	Top1: 65.34%
[ Wed Aug  3 12:49:38 2022 ] 	Top5: 90.98%
[ Wed Aug  3 12:49:38 2022 ] Training epoch: 16
[ Wed Aug  3 12:53:07 2022 ] 	Mean training loss: 0.8693.  Mean training acc: 73.87%.
[ Wed Aug  3 12:53:08 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:53:08 2022 ] Eval epoch: 16
[ Wed Aug  3 12:54:00 2022 ] 	Mean test loss of 796 batches: 1.1713269301994362.
[ Wed Aug  3 12:54:00 2022 ] 	Top1: 66.54%
[ Wed Aug  3 12:54:01 2022 ] 	Top5: 89.84%
[ Wed Aug  3 12:54:01 2022 ] Training epoch: 17
[ Wed Aug  3 12:57:31 2022 ] 	Mean training loss: 0.8673.  Mean training acc: 73.75%.
[ Wed Aug  3 12:57:31 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 12:57:31 2022 ] Eval epoch: 17
[ Wed Aug  3 12:58:23 2022 ] 	Mean test loss of 796 batches: 1.1140523047078794.
[ Wed Aug  3 12:58:23 2022 ] 	Top1: 67.27%
[ Wed Aug  3 12:58:24 2022 ] 	Top5: 91.66%
[ Wed Aug  3 12:58:24 2022 ] Training epoch: 18
[ Wed Aug  3 13:01:55 2022 ] 	Mean training loss: 0.8501.  Mean training acc: 74.19%.
[ Wed Aug  3 13:01:55 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:01:55 2022 ] Eval epoch: 18
[ Wed Aug  3 13:02:48 2022 ] 	Mean test loss of 796 batches: 1.104374626922847.
[ Wed Aug  3 13:02:48 2022 ] 	Top1: 67.76%
[ Wed Aug  3 13:02:48 2022 ] 	Top5: 91.78%
[ Wed Aug  3 13:02:49 2022 ] Training epoch: 19
[ Wed Aug  3 13:06:17 2022 ] 	Mean training loss: 0.8444.  Mean training acc: 74.64%.
[ Wed Aug  3 13:06:17 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:06:17 2022 ] Eval epoch: 19
[ Wed Aug  3 13:07:09 2022 ] 	Mean test loss of 796 batches: 1.0222523756437565.
[ Wed Aug  3 13:07:10 2022 ] 	Top1: 69.37%
[ Wed Aug  3 13:07:10 2022 ] 	Top5: 92.50%
[ Wed Aug  3 13:07:10 2022 ] Training epoch: 20
[ Wed Aug  3 13:10:19 2022 ] 	Mean training loss: 0.8446.  Mean training acc: 74.41%.
[ Wed Aug  3 13:10:19 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:10:19 2022 ] Eval epoch: 20
[ Wed Aug  3 13:11:04 2022 ] 	Mean test loss of 796 batches: 1.316059656553532.
[ Wed Aug  3 13:11:05 2022 ] 	Top1: 62.98%
[ Wed Aug  3 13:11:05 2022 ] 	Top5: 88.31%
[ Wed Aug  3 13:11:05 2022 ] Training epoch: 21
[ Wed Aug  3 13:14:08 2022 ] 	Mean training loss: 0.8398.  Mean training acc: 74.88%.
[ Wed Aug  3 13:14:08 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Aug  3 13:14:08 2022 ] Eval epoch: 21
[ Wed Aug  3 13:14:54 2022 ] 	Mean test loss of 796 batches: 1.1194690180633535.
[ Wed Aug  3 13:14:54 2022 ] 	Top1: 68.01%
[ Wed Aug  3 13:14:55 2022 ] 	Top5: 91.50%
[ Wed Aug  3 13:14:55 2022 ] Training epoch: 22
[ Wed Aug  3 13:32:10 2022 ] using warm up, epoch: 5
[ Wed Aug  3 13:32:49 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spher_harm1', 'model_saved_name': 'work_dir/ntu120/csub/spher_harm1/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spherical_harm1.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [2], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Aug  3 13:32:49 2022 ] # Parameters: 2180490
[ Wed Aug  3 13:32:49 2022 ] Training epoch: 1
[ Wed Aug  3 13:35:54 2022 ] 	Mean training loss: 3.1741.  Mean training acc: 21.57%.
[ Wed Aug  3 13:35:54 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 13:35:54 2022 ] Eval epoch: 1
[ Wed Aug  3 13:36:43 2022 ] 	Mean test loss of 796 batches: 2.586507822550721.
[ Wed Aug  3 13:36:43 2022 ] 	Top1: 29.05%
[ Wed Aug  3 13:36:44 2022 ] 	Top5: 65.74%
[ Wed Aug  3 13:36:44 2022 ] Training epoch: 2
[ Wed Aug  3 13:39:48 2022 ] 	Mean training loss: 2.0648.  Mean training acc: 42.26%.
[ Wed Aug  3 13:39:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 13:39:48 2022 ] Eval epoch: 2
[ Wed Aug  3 13:40:36 2022 ] 	Mean test loss of 796 batches: 1.8843896369538715.
[ Wed Aug  3 13:40:36 2022 ] 	Top1: 44.97%
[ Wed Aug  3 13:40:37 2022 ] 	Top5: 80.02%
[ Wed Aug  3 13:40:37 2022 ] Training epoch: 3
[ Wed Aug  3 13:43:42 2022 ] 	Mean training loss: 1.6148.  Mean training acc: 53.28%.
[ Wed Aug  3 13:43:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 13:43:43 2022 ] Eval epoch: 3
[ Wed Aug  3 13:44:39 2022 ] 	Mean test loss of 796 batches: 1.5482244272926944.
[ Wed Aug  3 13:44:39 2022 ] 	Top1: 55.27%
[ Wed Aug  3 13:44:40 2022 ] 	Top5: 85.92%
[ Wed Aug  3 13:44:40 2022 ] Training epoch: 4
[ Wed Aug  3 13:48:37 2022 ] 	Mean training loss: 1.3868.  Mean training acc: 59.48%.
[ Wed Aug  3 13:48:37 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Aug  3 13:48:37 2022 ] Eval epoch: 4
[ Wed Aug  3 13:49:24 2022 ] 	Mean test loss of 796 batches: 1.38640580783088.
[ Wed Aug  3 13:49:25 2022 ] 	Top1: 59.20%
[ Wed Aug  3 13:49:25 2022 ] 	Top5: 88.12%
[ Wed Aug  3 13:49:25 2022 ] Training epoch: 5
[ Wed Aug  3 13:52:28 2022 ] 	Mean training loss: 1.2575.  Mean training acc: 62.79%.
[ Wed Aug  3 13:52:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 13:52:28 2022 ] Eval epoch: 5
[ Wed Aug  3 13:53:15 2022 ] 	Mean test loss of 796 batches: 1.607654967574618.
[ Wed Aug  3 13:53:15 2022 ] 	Top1: 53.82%
[ Wed Aug  3 13:53:16 2022 ] 	Top5: 85.46%
[ Wed Aug  3 13:53:16 2022 ] Training epoch: 6
[ Wed Aug  3 13:56:19 2022 ] 	Mean training loss: 1.1511.  Mean training acc: 65.75%.
[ Wed Aug  3 13:56:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 13:56:19 2022 ] Eval epoch: 6
[ Wed Aug  3 13:57:05 2022 ] 	Mean test loss of 796 batches: 1.3661472937419785.
[ Wed Aug  3 13:57:06 2022 ] 	Top1: 60.45%
[ Wed Aug  3 13:57:06 2022 ] 	Top5: 89.58%
[ Wed Aug  3 13:57:06 2022 ] Training epoch: 7
[ Wed Aug  3 14:00:10 2022 ] 	Mean training loss: 1.0676.  Mean training acc: 68.11%.
[ Wed Aug  3 14:00:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:00:10 2022 ] Eval epoch: 7
[ Wed Aug  3 14:00:57 2022 ] 	Mean test loss of 796 batches: 1.4154172560303055.
[ Wed Aug  3 14:00:58 2022 ] 	Top1: 59.96%
[ Wed Aug  3 14:00:58 2022 ] 	Top5: 87.51%
[ Wed Aug  3 14:00:58 2022 ] Training epoch: 8
[ Wed Aug  3 14:04:02 2022 ] 	Mean training loss: 1.0273.  Mean training acc: 69.49%.
[ Wed Aug  3 14:04:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:04:02 2022 ] Eval epoch: 8
[ Wed Aug  3 14:04:49 2022 ] 	Mean test loss of 796 batches: 1.175385244976935.
[ Wed Aug  3 14:04:49 2022 ] 	Top1: 65.18%
[ Wed Aug  3 14:04:50 2022 ] 	Top5: 90.56%
[ Wed Aug  3 14:04:50 2022 ] Training epoch: 9
[ Wed Aug  3 14:07:54 2022 ] 	Mean training loss: 0.9916.  Mean training acc: 70.24%.
[ Wed Aug  3 14:07:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:07:54 2022 ] Eval epoch: 9
[ Wed Aug  3 14:08:41 2022 ] 	Mean test loss of 796 batches: 1.3566035816268107.
[ Wed Aug  3 14:08:42 2022 ] 	Top1: 61.05%
[ Wed Aug  3 14:08:42 2022 ] 	Top5: 88.65%
[ Wed Aug  3 14:08:42 2022 ] Training epoch: 10
[ Wed Aug  3 14:11:50 2022 ] 	Mean training loss: 0.9558.  Mean training acc: 71.23%.
[ Wed Aug  3 14:11:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:11:50 2022 ] Eval epoch: 10
[ Wed Aug  3 14:12:38 2022 ] 	Mean test loss of 796 batches: 1.2917826207888186.
[ Wed Aug  3 14:12:39 2022 ] 	Top1: 62.68%
[ Wed Aug  3 14:12:39 2022 ] 	Top5: 90.00%
[ Wed Aug  3 14:12:39 2022 ] Training epoch: 11
[ Wed Aug  3 14:15:46 2022 ] 	Mean training loss: 0.9375.  Mean training acc: 71.70%.
[ Wed Aug  3 14:15:46 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:15:46 2022 ] Eval epoch: 11
[ Wed Aug  3 14:16:35 2022 ] 	Mean test loss of 796 batches: 1.2592067040839987.
[ Wed Aug  3 14:16:35 2022 ] 	Top1: 64.09%
[ Wed Aug  3 14:16:35 2022 ] 	Top5: 90.22%
[ Wed Aug  3 14:16:35 2022 ] Training epoch: 12
[ Wed Aug  3 14:19:42 2022 ] 	Mean training loss: 0.9220.  Mean training acc: 72.28%.
[ Wed Aug  3 14:19:42 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:19:42 2022 ] Eval epoch: 12
[ Wed Aug  3 14:20:30 2022 ] 	Mean test loss of 796 batches: 1.206443184022628.
[ Wed Aug  3 14:20:30 2022 ] 	Top1: 65.27%
[ Wed Aug  3 14:20:31 2022 ] 	Top5: 90.28%
[ Wed Aug  3 14:20:31 2022 ] Training epoch: 13
[ Wed Aug  3 14:23:36 2022 ] 	Mean training loss: 0.9074.  Mean training acc: 72.75%.
[ Wed Aug  3 14:23:36 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:23:36 2022 ] Eval epoch: 13
[ Wed Aug  3 14:24:23 2022 ] 	Mean test loss of 796 batches: 1.2235084518266084.
[ Wed Aug  3 14:24:24 2022 ] 	Top1: 65.15%
[ Wed Aug  3 14:24:24 2022 ] 	Top5: 90.19%
[ Wed Aug  3 14:24:24 2022 ] Training epoch: 14
[ Wed Aug  3 14:27:31 2022 ] 	Mean training loss: 0.8887.  Mean training acc: 73.08%.
[ Wed Aug  3 14:27:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:27:31 2022 ] Eval epoch: 14
[ Wed Aug  3 14:28:19 2022 ] 	Mean test loss of 796 batches: 1.090385368421449.
[ Wed Aug  3 14:28:19 2022 ] 	Top1: 68.48%
[ Wed Aug  3 14:28:20 2022 ] 	Top5: 91.11%
[ Wed Aug  3 14:28:20 2022 ] Training epoch: 15
[ Wed Aug  3 14:31:28 2022 ] 	Mean training loss: 0.8767.  Mean training acc: 73.70%.
[ Wed Aug  3 14:31:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:31:28 2022 ] Eval epoch: 15
[ Wed Aug  3 14:32:17 2022 ] 	Mean test loss of 796 batches: 1.196124989595545.
[ Wed Aug  3 14:32:18 2022 ] 	Top1: 65.34%
[ Wed Aug  3 14:32:18 2022 ] 	Top5: 90.98%
[ Wed Aug  3 14:32:18 2022 ] Training epoch: 16
[ Wed Aug  3 14:35:26 2022 ] 	Mean training loss: 0.8693.  Mean training acc: 73.87%.
[ Wed Aug  3 14:35:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:35:26 2022 ] Eval epoch: 16
[ Wed Aug  3 14:36:15 2022 ] 	Mean test loss of 796 batches: 1.1713269301994362.
[ Wed Aug  3 14:36:16 2022 ] 	Top1: 66.54%
[ Wed Aug  3 14:36:16 2022 ] 	Top5: 89.84%
[ Wed Aug  3 14:36:16 2022 ] Training epoch: 17
[ Wed Aug  3 14:39:27 2022 ] 	Mean training loss: 0.8673.  Mean training acc: 73.75%.
[ Wed Aug  3 14:39:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:39:27 2022 ] Eval epoch: 17
[ Wed Aug  3 14:40:18 2022 ] 	Mean test loss of 796 batches: 1.1140523047078794.
[ Wed Aug  3 14:40:18 2022 ] 	Top1: 67.27%
[ Wed Aug  3 14:40:18 2022 ] 	Top5: 91.66%
[ Wed Aug  3 14:40:18 2022 ] Training epoch: 18
[ Wed Aug  3 14:43:27 2022 ] 	Mean training loss: 0.8501.  Mean training acc: 74.19%.
[ Wed Aug  3 14:43:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Aug  3 14:43:27 2022 ] Eval epoch: 18
[ Wed Aug  3 14:44:16 2022 ] 	Mean test loss of 796 batches: 1.104374626922847.
[ Wed Aug  3 14:44:16 2022 ] 	Top1: 67.76%
[ Wed Aug  3 14:44:17 2022 ] 	Top5: 91.78%
[ Wed Aug  3 14:44:17 2022 ] Training epoch: 19
[ Wed Aug  3 14:47:30 2022 ] 	Mean training loss: 0.8444.  Mean training acc: 74.64%.
[ Wed Aug  3 14:47:30 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Aug  3 14:47:30 2022 ] Eval epoch: 19
[ Wed Aug  3 14:48:26 2022 ] 	Mean test loss of 796 batches: 1.0222523756437565.
[ Wed Aug  3 14:48:27 2022 ] 	Top1: 69.37%
[ Wed Aug  3 14:48:27 2022 ] 	Top5: 92.50%
[ Wed Aug  3 14:48:27 2022 ] Training epoch: 20
[ Wed Aug  3 14:51:43 2022 ] 	Mean training loss: 0.8446.  Mean training acc: 74.41%.
[ Wed Aug  3 14:51:43 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Aug  3 14:51:43 2022 ] Eval epoch: 20
[ Wed Aug  3 14:52:39 2022 ] 	Mean test loss of 796 batches: 1.316059656553532.
[ Wed Aug  3 14:52:39 2022 ] 	Top1: 62.98%
[ Wed Aug  3 14:52:40 2022 ] 	Top5: 88.31%
[ Wed Aug  3 14:52:40 2022 ] Training epoch: 21
[ Wed Aug  3 14:55:55 2022 ] 	Mean training loss: 0.8398.  Mean training acc: 74.88%.
[ Wed Aug  3 14:55:55 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Wed Aug  3 14:55:55 2022 ] Eval epoch: 21
[ Wed Aug  3 14:56:51 2022 ] 	Mean test loss of 796 batches: 1.1194690180633535.
[ Wed Aug  3 14:56:52 2022 ] 	Top1: 68.01%
[ Wed Aug  3 14:56:52 2022 ] 	Top5: 91.50%
[ Wed Aug  3 14:56:52 2022 ] Training epoch: 22
