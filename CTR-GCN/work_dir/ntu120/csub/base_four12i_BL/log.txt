[ Wed Jun 29 00:01:52 2022 ] using warm up, epoch: 5
[ Wed Jun 29 00:02:07 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four12i_BL', 'model_saved_name': 'work_dir/ntu120/csub/base_four12i_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier12i_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jun 29 00:02:07 2022 ] # Parameters: 2100194
[ Wed Jun 29 00:02:07 2022 ] Training epoch: 1
[ Wed Jun 29 00:05:03 2022 ] 	Mean training loss: 3.0746.  Mean training acc: 23.76%.
[ Wed Jun 29 00:05:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:05:03 2022 ] Eval epoch: 1
[ Wed Jun 29 00:05:47 2022 ] 	Mean test loss of 796 batches: 2.333548490276289.
[ Wed Jun 29 00:05:47 2022 ] 	Top1: 35.44%
[ Wed Jun 29 00:05:47 2022 ] 	Top5: 70.00%
[ Wed Jun 29 00:05:48 2022 ] Training epoch: 2
[ Wed Jun 29 00:08:52 2022 ] 	Mean training loss: 1.9679.  Mean training acc: 45.02%.
[ Wed Jun 29 00:08:52 2022 ] 	Time consumption: [Data]02%, [Network]92%
[ Wed Jun 29 00:08:52 2022 ] Eval epoch: 2
[ Wed Jun 29 00:09:35 2022 ] 	Mean test loss of 796 batches: 1.7170667576430432.
[ Wed Jun 29 00:09:35 2022 ] 	Top1: 49.32%
[ Wed Jun 29 00:09:36 2022 ] 	Top5: 83.23%
[ Wed Jun 29 00:09:36 2022 ] Training epoch: 3
[ Wed Jun 29 00:12:29 2022 ] 	Mean training loss: 1.6023.  Mean training acc: 54.12%.
[ Wed Jun 29 00:12:29 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:12:29 2022 ] Eval epoch: 3
[ Wed Jun 29 00:13:13 2022 ] 	Mean test loss of 796 batches: 1.5975998480565583.
[ Wed Jun 29 00:13:13 2022 ] 	Top1: 54.16%
[ Wed Jun 29 00:13:13 2022 ] 	Top5: 84.20%
[ Wed Jun 29 00:13:13 2022 ] Training epoch: 4
[ Wed Jun 29 00:16:08 2022 ] 	Mean training loss: 1.4189.  Mean training acc: 58.80%.
[ Wed Jun 29 00:16:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:16:08 2022 ] Eval epoch: 4
[ Wed Jun 29 00:16:52 2022 ] 	Mean test loss of 796 batches: 1.48302867072611.
[ Wed Jun 29 00:16:52 2022 ] 	Top1: 56.77%
[ Wed Jun 29 00:16:53 2022 ] 	Top5: 85.78%
[ Wed Jun 29 00:16:53 2022 ] Training epoch: 5
[ Wed Jun 29 00:19:48 2022 ] 	Mean training loss: 1.2834.  Mean training acc: 62.56%.
[ Wed Jun 29 00:19:48 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jun 29 00:19:48 2022 ] Eval epoch: 5
[ Wed Jun 29 00:20:31 2022 ] 	Mean test loss of 796 batches: 1.6575166595042052.
[ Wed Jun 29 00:20:32 2022 ] 	Top1: 52.18%
[ Wed Jun 29 00:20:32 2022 ] 	Top5: 85.34%
[ Wed Jun 29 00:20:32 2022 ] Training epoch: 6
[ Wed Jun 29 00:23:26 2022 ] 	Mean training loss: 1.1301.  Mean training acc: 66.53%.
[ Wed Jun 29 00:23:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:23:26 2022 ] Eval epoch: 6
[ Wed Jun 29 00:24:09 2022 ] 	Mean test loss of 796 batches: 1.3397423121048577.
[ Wed Jun 29 00:24:09 2022 ] 	Top1: 61.35%
[ Wed Jun 29 00:24:10 2022 ] 	Top5: 87.98%
[ Wed Jun 29 00:24:10 2022 ] Training epoch: 7
[ Wed Jun 29 00:27:03 2022 ] 	Mean training loss: 1.0333.  Mean training acc: 69.28%.
[ Wed Jun 29 00:27:04 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:27:04 2022 ] Eval epoch: 7
[ Wed Jun 29 00:27:47 2022 ] 	Mean test loss of 796 batches: 1.3449476619611433.
[ Wed Jun 29 00:27:47 2022 ] 	Top1: 61.48%
[ Wed Jun 29 00:27:47 2022 ] 	Top5: 88.17%
[ Wed Jun 29 00:27:47 2022 ] Training epoch: 8
[ Wed Jun 29 00:30:42 2022 ] 	Mean training loss: 0.9701.  Mean training acc: 71.14%.
[ Wed Jun 29 00:30:42 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:30:42 2022 ] Eval epoch: 8
[ Wed Jun 29 00:31:26 2022 ] 	Mean test loss of 796 batches: 1.1384906049200039.
[ Wed Jun 29 00:31:26 2022 ] 	Top1: 66.04%
[ Wed Jun 29 00:31:26 2022 ] 	Top5: 91.44%
[ Wed Jun 29 00:31:27 2022 ] Training epoch: 9
[ Wed Jun 29 00:34:22 2022 ] 	Mean training loss: 0.9183.  Mean training acc: 72.62%.
[ Wed Jun 29 00:34:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:34:22 2022 ] Eval epoch: 9
[ Wed Jun 29 00:35:05 2022 ] 	Mean test loss of 796 batches: 1.1687091420867934.
[ Wed Jun 29 00:35:05 2022 ] 	Top1: 66.01%
[ Wed Jun 29 00:35:05 2022 ] 	Top5: 90.41%
[ Wed Jun 29 00:35:05 2022 ] Training epoch: 10
[ Wed Jun 29 00:37:59 2022 ] 	Mean training loss: 0.8876.  Mean training acc: 73.51%.
[ Wed Jun 29 00:37:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:37:59 2022 ] Eval epoch: 10
[ Wed Jun 29 00:38:42 2022 ] 	Mean test loss of 796 batches: 1.1224092451396899.
[ Wed Jun 29 00:38:43 2022 ] 	Top1: 66.74%
[ Wed Jun 29 00:38:43 2022 ] 	Top5: 91.27%
[ Wed Jun 29 00:38:43 2022 ] Training epoch: 11
[ Wed Jun 29 00:41:37 2022 ] 	Mean training loss: 0.8610.  Mean training acc: 74.29%.
[ Wed Jun 29 00:41:37 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:41:37 2022 ] Eval epoch: 11
[ Wed Jun 29 00:42:20 2022 ] 	Mean test loss of 796 batches: 1.153449256852943.
[ Wed Jun 29 00:42:20 2022 ] 	Top1: 66.06%
[ Wed Jun 29 00:42:20 2022 ] 	Top5: 90.84%
[ Wed Jun 29 00:42:20 2022 ] Training epoch: 12
[ Wed Jun 29 00:45:15 2022 ] 	Mean training loss: 0.8391.  Mean training acc: 74.83%.
[ Wed Jun 29 00:45:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:45:15 2022 ] Eval epoch: 12
[ Wed Jun 29 00:45:58 2022 ] 	Mean test loss of 796 batches: 1.7786631048025199.
[ Wed Jun 29 00:45:58 2022 ] 	Top1: 53.70%
[ Wed Jun 29 00:45:59 2022 ] 	Top5: 82.80%
[ Wed Jun 29 00:45:59 2022 ] Training epoch: 13
[ Wed Jun 29 00:48:53 2022 ] 	Mean training loss: 0.8280.  Mean training acc: 74.96%.
[ Wed Jun 29 00:48:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:48:53 2022 ] Eval epoch: 13
[ Wed Jun 29 00:49:36 2022 ] 	Mean test loss of 796 batches: 1.1364667216063145.
[ Wed Jun 29 00:49:36 2022 ] 	Top1: 67.35%
[ Wed Jun 29 00:49:37 2022 ] 	Top5: 91.04%
[ Wed Jun 29 00:49:37 2022 ] Training epoch: 14
[ Wed Jun 29 00:52:30 2022 ] 	Mean training loss: 0.8097.  Mean training acc: 75.73%.
[ Wed Jun 29 00:52:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:52:30 2022 ] Eval epoch: 14
[ Wed Jun 29 00:53:14 2022 ] 	Mean test loss of 796 batches: 1.1673945728783033.
[ Wed Jun 29 00:53:14 2022 ] 	Top1: 66.66%
[ Wed Jun 29 00:53:14 2022 ] 	Top5: 91.72%
[ Wed Jun 29 00:53:14 2022 ] Training epoch: 15
[ Wed Jun 29 00:56:08 2022 ] 	Mean training loss: 0.7952.  Mean training acc: 76.10%.
[ Wed Jun 29 00:56:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:56:08 2022 ] Eval epoch: 15
[ Wed Jun 29 00:56:51 2022 ] 	Mean test loss of 796 batches: 1.0868026760205551.
[ Wed Jun 29 00:56:52 2022 ] 	Top1: 68.07%
[ Wed Jun 29 00:56:52 2022 ] 	Top5: 91.60%
[ Wed Jun 29 00:56:52 2022 ] Training epoch: 16
[ Wed Jun 29 00:59:46 2022 ] 	Mean training loss: 0.7903.  Mean training acc: 76.25%.
[ Wed Jun 29 00:59:46 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 00:59:46 2022 ] Eval epoch: 16
[ Wed Jun 29 01:00:29 2022 ] 	Mean test loss of 796 batches: 1.1111406789128504.
[ Wed Jun 29 01:00:29 2022 ] 	Top1: 67.89%
[ Wed Jun 29 01:00:29 2022 ] 	Top5: 91.47%
[ Wed Jun 29 01:00:29 2022 ] Training epoch: 17
[ Wed Jun 29 01:03:23 2022 ] 	Mean training loss: 0.7746.  Mean training acc: 76.70%.
[ Wed Jun 29 01:03:23 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:03:23 2022 ] Eval epoch: 17
[ Wed Jun 29 01:04:07 2022 ] 	Mean test loss of 796 batches: 1.0598387249076187.
[ Wed Jun 29 01:04:07 2022 ] 	Top1: 69.10%
[ Wed Jun 29 01:04:07 2022 ] 	Top5: 92.47%
[ Wed Jun 29 01:04:07 2022 ] Training epoch: 18
[ Wed Jun 29 01:07:01 2022 ] 	Mean training loss: 0.7769.  Mean training acc: 76.58%.
[ Wed Jun 29 01:07:01 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:07:01 2022 ] Eval epoch: 18
[ Wed Jun 29 01:07:44 2022 ] 	Mean test loss of 796 batches: 0.9720055850681348.
[ Wed Jun 29 01:07:44 2022 ] 	Top1: 71.16%
[ Wed Jun 29 01:07:45 2022 ] 	Top5: 93.02%
[ Wed Jun 29 01:07:45 2022 ] Training epoch: 19
[ Wed Jun 29 01:10:38 2022 ] 	Mean training loss: 0.7640.  Mean training acc: 77.01%.
[ Wed Jun 29 01:10:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:10:38 2022 ] Eval epoch: 19
[ Wed Jun 29 01:11:21 2022 ] 	Mean test loss of 796 batches: 0.9251721001525021.
[ Wed Jun 29 01:11:22 2022 ] 	Top1: 72.77%
[ Wed Jun 29 01:11:22 2022 ] 	Top5: 93.17%
[ Wed Jun 29 01:11:22 2022 ] Training epoch: 20
[ Wed Jun 29 01:14:16 2022 ] 	Mean training loss: 0.7568.  Mean training acc: 77.25%.
[ Wed Jun 29 01:14:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:14:16 2022 ] Eval epoch: 20
[ Wed Jun 29 01:15:00 2022 ] 	Mean test loss of 796 batches: 1.3055716326563203.
[ Wed Jun 29 01:15:00 2022 ] 	Top1: 64.61%
[ Wed Jun 29 01:15:01 2022 ] 	Top5: 89.11%
[ Wed Jun 29 01:15:01 2022 ] Training epoch: 21
[ Wed Jun 29 01:17:55 2022 ] 	Mean training loss: 0.7588.  Mean training acc: 76.85%.
[ Wed Jun 29 01:17:55 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:17:55 2022 ] Eval epoch: 21
[ Wed Jun 29 01:18:39 2022 ] 	Mean test loss of 796 batches: 1.3018725392357189.
[ Wed Jun 29 01:18:39 2022 ] 	Top1: 64.05%
[ Wed Jun 29 01:18:39 2022 ] 	Top5: 89.57%
[ Wed Jun 29 01:18:40 2022 ] Training epoch: 22
[ Wed Jun 29 01:21:33 2022 ] 	Mean training loss: 0.7456.  Mean training acc: 77.52%.
[ Wed Jun 29 01:21:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:21:33 2022 ] Eval epoch: 22
[ Wed Jun 29 01:22:16 2022 ] 	Mean test loss of 796 batches: 1.2109791001857226.
[ Wed Jun 29 01:22:16 2022 ] 	Top1: 66.50%
[ Wed Jun 29 01:22:17 2022 ] 	Top5: 89.53%
[ Wed Jun 29 01:22:17 2022 ] Training epoch: 23
[ Wed Jun 29 01:25:10 2022 ] 	Mean training loss: 0.7475.  Mean training acc: 77.46%.
[ Wed Jun 29 01:25:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:25:10 2022 ] Eval epoch: 23
[ Wed Jun 29 01:25:54 2022 ] 	Mean test loss of 796 batches: 1.1310407009406305.
[ Wed Jun 29 01:25:54 2022 ] 	Top1: 67.85%
[ Wed Jun 29 01:25:54 2022 ] 	Top5: 90.95%
[ Wed Jun 29 01:25:54 2022 ] Training epoch: 24
[ Wed Jun 29 01:28:49 2022 ] 	Mean training loss: 0.7406.  Mean training acc: 77.71%.
[ Wed Jun 29 01:28:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:28:49 2022 ] Eval epoch: 24
[ Wed Jun 29 01:29:33 2022 ] 	Mean test loss of 796 batches: 0.9730458826051286.
[ Wed Jun 29 01:29:33 2022 ] 	Top1: 71.82%
[ Wed Jun 29 01:29:34 2022 ] 	Top5: 93.10%
[ Wed Jun 29 01:29:34 2022 ] Training epoch: 25
[ Wed Jun 29 01:32:28 2022 ] 	Mean training loss: 0.7396.  Mean training acc: 77.67%.
[ Wed Jun 29 01:32:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:32:28 2022 ] Eval epoch: 25
[ Wed Jun 29 01:33:13 2022 ] 	Mean test loss of 796 batches: 0.8704723451080634.
[ Wed Jun 29 01:33:13 2022 ] 	Top1: 74.07%
[ Wed Jun 29 01:33:13 2022 ] 	Top5: 94.12%
[ Wed Jun 29 01:33:13 2022 ] Training epoch: 26
[ Wed Jun 29 01:36:08 2022 ] 	Mean training loss: 0.7313.  Mean training acc: 78.00%.
[ Wed Jun 29 01:36:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:36:08 2022 ] Eval epoch: 26
[ Wed Jun 29 01:36:51 2022 ] 	Mean test loss of 796 batches: 0.9849509559384543.
[ Wed Jun 29 01:36:51 2022 ] 	Top1: 71.10%
[ Wed Jun 29 01:36:51 2022 ] 	Top5: 92.88%
[ Wed Jun 29 01:36:51 2022 ] Training epoch: 27
[ Wed Jun 29 01:39:45 2022 ] 	Mean training loss: 0.7282.  Mean training acc: 78.25%.
[ Wed Jun 29 01:39:45 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 01:39:45 2022 ] Eval epoch: 27
[ Wed Jun 29 01:40:28 2022 ] 	Mean test loss of 796 batches: 1.7976208465482721.
[ Wed Jun 29 01:40:28 2022 ] 	Top1: 56.03%
[ Wed Jun 29 01:40:28 2022 ] 	Top5: 81.56%
[ Wed Jun 29 01:40:28 2022 ] Training epoch: 28
[ Wed Jun 29 01:43:22 2022 ] 	Mean training loss: 0.7286.  Mean training acc: 78.15%.
[ Wed Jun 29 01:43:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:43:22 2022 ] Eval epoch: 28
[ Wed Jun 29 01:44:05 2022 ] 	Mean test loss of 796 batches: 1.0497378403292827.
[ Wed Jun 29 01:44:06 2022 ] 	Top1: 69.15%
[ Wed Jun 29 01:44:06 2022 ] 	Top5: 92.08%
[ Wed Jun 29 01:44:06 2022 ] Training epoch: 29
[ Wed Jun 29 01:47:00 2022 ] 	Mean training loss: 0.7286.  Mean training acc: 77.93%.
[ Wed Jun 29 01:47:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 01:47:00 2022 ] Eval epoch: 29
[ Wed Jun 29 01:47:43 2022 ] 	Mean test loss of 796 batches: 1.3095214512929245.
[ Wed Jun 29 01:47:44 2022 ] 	Top1: 63.69%
[ Wed Jun 29 01:47:44 2022 ] 	Top5: 88.99%
[ Wed Jun 29 01:47:44 2022 ] Training epoch: 30
[ Wed Jun 29 01:50:39 2022 ] 	Mean training loss: 0.7227.  Mean training acc: 78.38%.
[ Wed Jun 29 01:50:39 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:50:39 2022 ] Eval epoch: 30
[ Wed Jun 29 01:51:23 2022 ] 	Mean test loss of 796 batches: 1.0027910589647653.
[ Wed Jun 29 01:51:24 2022 ] 	Top1: 70.97%
[ Wed Jun 29 01:51:24 2022 ] 	Top5: 92.61%
[ Wed Jun 29 01:51:24 2022 ] Training epoch: 31
[ Wed Jun 29 01:54:18 2022 ] 	Mean training loss: 0.7202.  Mean training acc: 78.33%.
[ Wed Jun 29 01:54:18 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:54:18 2022 ] Eval epoch: 31
[ Wed Jun 29 01:55:01 2022 ] 	Mean test loss of 796 batches: 1.244559029650748.
[ Wed Jun 29 01:55:02 2022 ] 	Top1: 66.23%
[ Wed Jun 29 01:55:02 2022 ] 	Top5: 90.26%
[ Wed Jun 29 01:55:02 2022 ] Training epoch: 32
[ Wed Jun 29 01:57:56 2022 ] 	Mean training loss: 0.7212.  Mean training acc: 78.40%.
[ Wed Jun 29 01:57:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 01:57:56 2022 ] Eval epoch: 32
[ Wed Jun 29 01:58:39 2022 ] 	Mean test loss of 796 batches: 1.187722027189468.
[ Wed Jun 29 01:58:40 2022 ] 	Top1: 66.85%
[ Wed Jun 29 01:58:40 2022 ] 	Top5: 90.05%
[ Wed Jun 29 01:58:40 2022 ] Training epoch: 33
[ Wed Jun 29 02:01:34 2022 ] 	Mean training loss: 0.7182.  Mean training acc: 78.29%.
[ Wed Jun 29 02:01:34 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:01:34 2022 ] Eval epoch: 33
[ Wed Jun 29 02:02:17 2022 ] 	Mean test loss of 796 batches: 0.9387490869167462.
[ Wed Jun 29 02:02:17 2022 ] 	Top1: 72.82%
[ Wed Jun 29 02:02:18 2022 ] 	Top5: 93.11%
[ Wed Jun 29 02:02:18 2022 ] Training epoch: 34
[ Wed Jun 29 02:05:11 2022 ] 	Mean training loss: 0.7222.  Mean training acc: 78.16%.
[ Wed Jun 29 02:05:11 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 02:05:11 2022 ] Eval epoch: 34
[ Wed Jun 29 02:05:55 2022 ] 	Mean test loss of 796 batches: 0.9543587752248175.
[ Wed Jun 29 02:05:55 2022 ] 	Top1: 71.78%
[ Wed Jun 29 02:05:55 2022 ] 	Top5: 93.19%
[ Wed Jun 29 02:05:55 2022 ] Training epoch: 35
[ Wed Jun 29 02:08:49 2022 ] 	Mean training loss: 0.7092.  Mean training acc: 78.63%.
[ Wed Jun 29 02:08:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:08:49 2022 ] Eval epoch: 35
[ Wed Jun 29 02:09:32 2022 ] 	Mean test loss of 796 batches: 0.992672397956327.
[ Wed Jun 29 02:09:38 2022 ] 	Top1: 71.24%
[ Wed Jun 29 02:09:38 2022 ] 	Top5: 92.85%
[ Wed Jun 29 02:09:38 2022 ] Training epoch: 36
[ Wed Jun 29 02:12:31 2022 ] 	Mean training loss: 0.4125.  Mean training acc: 87.55%.
[ Wed Jun 29 02:12:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:12:31 2022 ] Eval epoch: 36
[ Wed Jun 29 02:13:15 2022 ] 	Mean test loss of 796 batches: 0.5672981241184413.
[ Wed Jun 29 02:13:15 2022 ] 	Top1: 82.51%
[ Wed Jun 29 02:13:15 2022 ] 	Top5: 96.71%
[ Wed Jun 29 02:13:15 2022 ] Training epoch: 37
[ Wed Jun 29 02:16:09 2022 ] 	Mean training loss: 0.3283.  Mean training acc: 90.20%.
[ Wed Jun 29 02:16:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:16:09 2022 ] Eval epoch: 37
[ Wed Jun 29 02:16:53 2022 ] 	Mean test loss of 796 batches: 0.5451118609301708.
[ Wed Jun 29 02:16:53 2022 ] 	Top1: 83.22%
[ Wed Jun 29 02:16:53 2022 ] 	Top5: 96.96%
[ Wed Jun 29 02:16:53 2022 ] Training epoch: 38
[ Wed Jun 29 02:19:47 2022 ] 	Mean training loss: 0.2954.  Mean training acc: 91.23%.
[ Wed Jun 29 02:19:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:19:47 2022 ] Eval epoch: 38
[ Wed Jun 29 02:20:29 2022 ] 	Mean test loss of 796 batches: 0.5471570265933348.
[ Wed Jun 29 02:20:30 2022 ] 	Top1: 83.40%
[ Wed Jun 29 02:20:30 2022 ] 	Top5: 96.89%
[ Wed Jun 29 02:20:30 2022 ] Training epoch: 39
[ Wed Jun 29 02:23:24 2022 ] 	Mean training loss: 0.2709.  Mean training acc: 92.03%.
[ Wed Jun 29 02:23:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:23:24 2022 ] Eval epoch: 39
[ Wed Jun 29 02:24:06 2022 ] 	Mean test loss of 796 batches: 0.5694318771006623.
[ Wed Jun 29 02:24:07 2022 ] 	Top1: 82.92%
[ Wed Jun 29 02:24:07 2022 ] 	Top5: 96.75%
[ Wed Jun 29 02:24:07 2022 ] Training epoch: 40
[ Wed Jun 29 02:27:00 2022 ] 	Mean training loss: 0.2495.  Mean training acc: 92.59%.
[ Wed Jun 29 02:27:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:27:00 2022 ] Eval epoch: 40
[ Wed Jun 29 02:27:43 2022 ] 	Mean test loss of 796 batches: 0.5513248461668365.
[ Wed Jun 29 02:27:44 2022 ] 	Top1: 83.40%
[ Wed Jun 29 02:27:44 2022 ] 	Top5: 96.92%
[ Wed Jun 29 02:27:44 2022 ] Training epoch: 41
[ Wed Jun 29 02:30:38 2022 ] 	Mean training loss: 0.2347.  Mean training acc: 93.17%.
[ Wed Jun 29 02:30:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:30:38 2022 ] Eval epoch: 41
[ Wed Jun 29 02:31:21 2022 ] 	Mean test loss of 796 batches: 0.5840950704568145.
[ Wed Jun 29 02:31:21 2022 ] 	Top1: 82.47%
[ Wed Jun 29 02:31:21 2022 ] 	Top5: 96.61%
[ Wed Jun 29 02:31:21 2022 ] Training epoch: 42
[ Wed Jun 29 02:34:15 2022 ] 	Mean training loss: 0.2145.  Mean training acc: 93.89%.
[ Wed Jun 29 02:34:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:34:15 2022 ] Eval epoch: 42
[ Wed Jun 29 02:34:58 2022 ] 	Mean test loss of 796 batches: 0.554215833516651.
[ Wed Jun 29 02:34:59 2022 ] 	Top1: 83.66%
[ Wed Jun 29 02:34:59 2022 ] 	Top5: 96.94%
[ Wed Jun 29 02:34:59 2022 ] Training epoch: 43
[ Wed Jun 29 02:37:53 2022 ] 	Mean training loss: 0.2073.  Mean training acc: 94.04%.
[ Wed Jun 29 02:37:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:37:53 2022 ] Eval epoch: 43
[ Wed Jun 29 02:38:36 2022 ] 	Mean test loss of 796 batches: 0.5910589243636359.
[ Wed Jun 29 02:38:36 2022 ] 	Top1: 82.88%
[ Wed Jun 29 02:38:37 2022 ] 	Top5: 96.60%
[ Wed Jun 29 02:38:37 2022 ] Training epoch: 44
[ Wed Jun 29 02:41:30 2022 ] 	Mean training loss: 0.1963.  Mean training acc: 94.51%.
[ Wed Jun 29 02:41:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:41:30 2022 ] Eval epoch: 44
[ Wed Jun 29 02:42:13 2022 ] 	Mean test loss of 796 batches: 0.6022202995179886.
[ Wed Jun 29 02:42:13 2022 ] 	Top1: 82.42%
[ Wed Jun 29 02:42:14 2022 ] 	Top5: 96.60%
[ Wed Jun 29 02:42:14 2022 ] Training epoch: 45
[ Wed Jun 29 02:45:08 2022 ] 	Mean training loss: 0.1828.  Mean training acc: 94.89%.
[ Wed Jun 29 02:45:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:45:08 2022 ] Eval epoch: 45
[ Wed Jun 29 02:45:51 2022 ] 	Mean test loss of 796 batches: 0.5834775576321174.
[ Wed Jun 29 02:45:51 2022 ] 	Top1: 83.08%
[ Wed Jun 29 02:45:52 2022 ] 	Top5: 96.74%
[ Wed Jun 29 02:45:52 2022 ] Training epoch: 46
[ Wed Jun 29 02:48:45 2022 ] 	Mean training loss: 0.1796.  Mean training acc: 94.97%.
[ Wed Jun 29 02:48:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:48:45 2022 ] Eval epoch: 46
[ Wed Jun 29 02:49:29 2022 ] 	Mean test loss of 796 batches: 0.5793590641968963.
[ Wed Jun 29 02:49:29 2022 ] 	Top1: 83.05%
[ Wed Jun 29 02:49:29 2022 ] 	Top5: 96.79%
[ Wed Jun 29 02:49:29 2022 ] Training epoch: 47
[ Wed Jun 29 02:52:23 2022 ] 	Mean training loss: 0.1779.  Mean training acc: 95.07%.
[ Wed Jun 29 02:52:23 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:52:23 2022 ] Eval epoch: 47
[ Wed Jun 29 02:53:06 2022 ] 	Mean test loss of 796 batches: 0.6166252105136463.
[ Wed Jun 29 02:53:07 2022 ] 	Top1: 82.50%
[ Wed Jun 29 02:53:07 2022 ] 	Top5: 96.54%
[ Wed Jun 29 02:53:07 2022 ] Training epoch: 48
[ Wed Jun 29 02:56:00 2022 ] 	Mean training loss: 0.1720.  Mean training acc: 95.24%.
[ Wed Jun 29 02:56:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jun 29 02:56:00 2022 ] Eval epoch: 48
[ Wed Jun 29 02:56:43 2022 ] 	Mean test loss of 796 batches: 0.6533348127057654.
[ Wed Jun 29 02:56:43 2022 ] 	Top1: 81.56%
[ Wed Jun 29 02:56:44 2022 ] 	Top5: 96.09%
[ Wed Jun 29 02:56:44 2022 ] Training epoch: 49
[ Wed Jun 29 02:59:37 2022 ] 	Mean training loss: 0.1657.  Mean training acc: 95.48%.
[ Wed Jun 29 02:59:37 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 02:59:37 2022 ] Eval epoch: 49
[ Wed Jun 29 03:00:20 2022 ] 	Mean test loss of 796 batches: 0.652486107344903.
[ Wed Jun 29 03:00:21 2022 ] 	Top1: 81.79%
[ Wed Jun 29 03:00:21 2022 ] 	Top5: 96.14%
[ Wed Jun 29 03:00:21 2022 ] Training epoch: 50
[ Wed Jun 29 03:03:15 2022 ] 	Mean training loss: 0.1657.  Mean training acc: 95.46%.
[ Wed Jun 29 03:03:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:03:15 2022 ] Eval epoch: 50
[ Wed Jun 29 03:03:58 2022 ] 	Mean test loss of 796 batches: 0.6582763935041488.
[ Wed Jun 29 03:03:59 2022 ] 	Top1: 81.18%
[ Wed Jun 29 03:03:59 2022 ] 	Top5: 96.01%
[ Wed Jun 29 03:03:59 2022 ] Training epoch: 51
[ Wed Jun 29 03:06:53 2022 ] 	Mean training loss: 0.1633.  Mean training acc: 95.54%.
[ Wed Jun 29 03:06:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:06:53 2022 ] Eval epoch: 51
[ Wed Jun 29 03:07:36 2022 ] 	Mean test loss of 796 batches: 0.6460246721460442.
[ Wed Jun 29 03:07:36 2022 ] 	Top1: 81.94%
[ Wed Jun 29 03:07:36 2022 ] 	Top5: 96.26%
[ Wed Jun 29 03:07:37 2022 ] Training epoch: 52
[ Wed Jun 29 03:10:30 2022 ] 	Mean training loss: 0.1650.  Mean training acc: 95.46%.
[ Wed Jun 29 03:10:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:10:30 2022 ] Eval epoch: 52
[ Wed Jun 29 03:11:13 2022 ] 	Mean test loss of 796 batches: 0.6673571069130496.
[ Wed Jun 29 03:11:14 2022 ] 	Top1: 81.52%
[ Wed Jun 29 03:11:14 2022 ] 	Top5: 96.17%
[ Wed Jun 29 03:11:14 2022 ] Training epoch: 53
[ Wed Jun 29 03:14:08 2022 ] 	Mean training loss: 0.1630.  Mean training acc: 95.51%.
[ Wed Jun 29 03:14:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:14:08 2022 ] Eval epoch: 53
[ Wed Jun 29 03:14:51 2022 ] 	Mean test loss of 796 batches: 0.6527495856897615.
[ Wed Jun 29 03:14:51 2022 ] 	Top1: 81.86%
[ Wed Jun 29 03:14:51 2022 ] 	Top5: 96.09%
[ Wed Jun 29 03:14:51 2022 ] Training epoch: 54
[ Wed Jun 29 03:17:45 2022 ] 	Mean training loss: 0.1623.  Mean training acc: 95.63%.
[ Wed Jun 29 03:17:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:17:45 2022 ] Eval epoch: 54
[ Wed Jun 29 03:18:28 2022 ] 	Mean test loss of 796 batches: 0.7012483576808742.
[ Wed Jun 29 03:18:29 2022 ] 	Top1: 80.60%
[ Wed Jun 29 03:18:29 2022 ] 	Top5: 95.85%
[ Wed Jun 29 03:18:29 2022 ] Training epoch: 55
[ Wed Jun 29 03:21:23 2022 ] 	Mean training loss: 0.1529.  Mean training acc: 95.82%.
[ Wed Jun 29 03:21:23 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:21:23 2022 ] Eval epoch: 55
[ Wed Jun 29 03:22:05 2022 ] 	Mean test loss of 796 batches: 0.6377177591898933.
[ Wed Jun 29 03:22:06 2022 ] 	Top1: 82.22%
[ Wed Jun 29 03:22:06 2022 ] 	Top5: 96.32%
[ Wed Jun 29 03:22:06 2022 ] Training epoch: 56
[ Wed Jun 29 03:25:00 2022 ] 	Mean training loss: 0.0888.  Mean training acc: 98.02%.
[ Wed Jun 29 03:25:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:25:00 2022 ] Eval epoch: 56
[ Wed Jun 29 03:25:43 2022 ] 	Mean test loss of 796 batches: 0.5863108548555692.
[ Wed Jun 29 03:25:43 2022 ] 	Top1: 83.76%
[ Wed Jun 29 03:25:44 2022 ] 	Top5: 96.75%
[ Wed Jun 29 03:25:44 2022 ] Training epoch: 57
[ Wed Jun 29 03:28:38 2022 ] 	Mean training loss: 0.0652.  Mean training acc: 98.72%.
[ Wed Jun 29 03:28:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:28:38 2022 ] Eval epoch: 57
[ Wed Jun 29 03:29:21 2022 ] 	Mean test loss of 796 batches: 0.5901943759234557.
[ Wed Jun 29 03:29:21 2022 ] 	Top1: 83.82%
[ Wed Jun 29 03:29:21 2022 ] 	Top5: 96.70%
[ Wed Jun 29 03:29:21 2022 ] Training epoch: 58
[ Wed Jun 29 03:32:15 2022 ] 	Mean training loss: 0.0579.  Mean training acc: 98.98%.
[ Wed Jun 29 03:32:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:32:15 2022 ] Eval epoch: 58
[ Wed Jun 29 03:32:58 2022 ] 	Mean test loss of 796 batches: 0.5899821332276766.
[ Wed Jun 29 03:32:58 2022 ] 	Top1: 83.87%
[ Wed Jun 29 03:32:58 2022 ] 	Top5: 96.68%
[ Wed Jun 29 03:32:58 2022 ] Training epoch: 59
[ Wed Jun 29 03:35:52 2022 ] 	Mean training loss: 0.0523.  Mean training acc: 99.11%.
[ Wed Jun 29 03:35:52 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:35:52 2022 ] Eval epoch: 59
[ Wed Jun 29 03:36:35 2022 ] 	Mean test loss of 796 batches: 0.588462576139063.
[ Wed Jun 29 03:36:35 2022 ] 	Top1: 84.07%
[ Wed Jun 29 03:36:36 2022 ] 	Top5: 96.71%
[ Wed Jun 29 03:36:36 2022 ] Training epoch: 60
[ Wed Jun 29 03:39:30 2022 ] 	Mean training loss: 0.0504.  Mean training acc: 99.16%.
[ Wed Jun 29 03:39:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:39:30 2022 ] Eval epoch: 60
[ Wed Jun 29 03:40:13 2022 ] 	Mean test loss of 796 batches: 0.5911789525524905.
[ Wed Jun 29 03:40:13 2022 ] 	Top1: 83.98%
[ Wed Jun 29 03:40:14 2022 ] 	Top5: 96.66%
[ Wed Jun 29 03:40:14 2022 ] Training epoch: 61
[ Wed Jun 29 03:43:07 2022 ] 	Mean training loss: 0.0480.  Mean training acc: 99.24%.
[ Wed Jun 29 03:43:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:43:07 2022 ] Eval epoch: 61
[ Wed Jun 29 03:43:50 2022 ] 	Mean test loss of 796 batches: 0.5937240595119683.
[ Wed Jun 29 03:43:51 2022 ] 	Top1: 83.93%
[ Wed Jun 29 03:43:51 2022 ] 	Top5: 96.59%
[ Wed Jun 29 03:43:51 2022 ] Training epoch: 62
[ Wed Jun 29 03:46:45 2022 ] 	Mean training loss: 0.0476.  Mean training acc: 99.19%.
[ Wed Jun 29 03:46:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:46:45 2022 ] Eval epoch: 62
[ Wed Jun 29 03:47:28 2022 ] 	Mean test loss of 796 batches: 0.5969151887275166.
[ Wed Jun 29 03:47:28 2022 ] 	Top1: 83.98%
[ Wed Jun 29 03:47:29 2022 ] 	Top5: 96.61%
[ Wed Jun 29 03:47:29 2022 ] Training epoch: 63
[ Wed Jun 29 03:50:22 2022 ] 	Mean training loss: 0.0437.  Mean training acc: 99.33%.
[ Wed Jun 29 03:50:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:50:22 2022 ] Eval epoch: 63
[ Wed Jun 29 03:51:06 2022 ] 	Mean test loss of 796 batches: 0.5936784310331896.
[ Wed Jun 29 03:51:06 2022 ] 	Top1: 84.09%
[ Wed Jun 29 03:51:06 2022 ] 	Top5: 96.63%
[ Wed Jun 29 03:51:06 2022 ] Training epoch: 64
[ Wed Jun 29 03:54:00 2022 ] 	Mean training loss: 0.0421.  Mean training acc: 99.38%.
[ Wed Jun 29 03:54:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:54:00 2022 ] Eval epoch: 64
[ Wed Jun 29 03:54:43 2022 ] 	Mean test loss of 796 batches: 0.5936875572268987.
[ Wed Jun 29 03:54:43 2022 ] 	Top1: 84.13%
[ Wed Jun 29 03:54:43 2022 ] 	Top5: 96.61%
[ Wed Jun 29 03:54:44 2022 ] Training epoch: 65
[ Wed Jun 29 03:57:37 2022 ] 	Mean training loss: 0.0413.  Mean training acc: 99.40%.
[ Wed Jun 29 03:57:37 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jun 29 03:57:37 2022 ] Eval epoch: 65
[ Wed Jun 29 03:58:21 2022 ] 	Mean test loss of 796 batches: 0.5967112732442779.
[ Wed Jun 29 03:58:21 2022 ] 	Top1: 84.17%
[ Wed Jun 29 03:58:21 2022 ] 	Top5: 96.55%
[ Wed Jun 29 03:59:06 2022 ] Best accuracy: 0.8416504644631669
[ Wed Jun 29 03:59:06 2022 ] Epoch number: 65
[ Wed Jun 29 03:59:06 2022 ] Model name: work_dir/ntu120/csub/base_four12i_BL
[ Wed Jun 29 03:59:06 2022 ] Model total number of params: 2100194
[ Wed Jun 29 03:59:06 2022 ] Weight decay: 0.0004
[ Wed Jun 29 03:59:06 2022 ] Base LR: 0.1
[ Wed Jun 29 03:59:06 2022 ] Batch Size: 64
[ Wed Jun 29 03:59:06 2022 ] Test Batch Size: 64
[ Wed Jun 29 03:59:06 2022 ] seed: 1
