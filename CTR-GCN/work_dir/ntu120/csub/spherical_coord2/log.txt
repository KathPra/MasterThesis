[ Wed Oct  5 12:34:20 2022 ] using warm up, epoch: 5
[ Wed Oct  5 12:34:36 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spherical_coord2', 'model_saved_name': 'work_dir/ntu120/csub/spherical_coord2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spher_coord2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Oct  5 12:34:36 2022 ] # Parameters: 2108322
[ Wed Oct  5 12:34:36 2022 ] Training epoch: 1
[ Wed Oct  5 12:41:42 2022 ] 	Mean training loss: 2.9414.  Mean training acc: 26.33%.
[ Wed Oct  5 12:41:42 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 12:41:42 2022 ] Eval epoch: 1
[ Wed Oct  5 12:43:28 2022 ] 	Mean test loss of 796 batches: 2.1020252795974215.
[ Wed Oct  5 12:43:29 2022 ] 	Top1: 39.86%
[ Wed Oct  5 12:43:29 2022 ] 	Top5: 75.75%
[ Wed Oct  5 12:43:29 2022 ] Training epoch: 2
[ Wed Oct  5 12:50:35 2022 ] 	Mean training loss: 1.8935.  Mean training acc: 46.47%.
[ Wed Oct  5 12:50:35 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 12:50:35 2022 ] Eval epoch: 2
[ Wed Oct  5 12:52:23 2022 ] 	Mean test loss of 796 batches: 1.9564892276747143.
[ Wed Oct  5 12:52:24 2022 ] 	Top1: 43.81%
[ Wed Oct  5 12:52:24 2022 ] 	Top5: 77.00%
[ Wed Oct  5 12:52:24 2022 ] Training epoch: 3
[ Wed Oct  5 12:59:31 2022 ] 	Mean training loss: 1.5758.  Mean training acc: 54.54%.
[ Wed Oct  5 12:59:31 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 12:59:31 2022 ] Eval epoch: 3
[ Wed Oct  5 13:01:19 2022 ] 	Mean test loss of 796 batches: 1.8462923494116146.
[ Wed Oct  5 13:01:19 2022 ] 	Top1: 47.76%
[ Wed Oct  5 13:01:19 2022 ] 	Top5: 81.38%
[ Wed Oct  5 13:01:19 2022 ] Training epoch: 4
[ Wed Oct  5 13:08:26 2022 ] 	Mean training loss: 1.3983.  Mean training acc: 59.31%.
[ Wed Oct  5 13:08:26 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:08:26 2022 ] Eval epoch: 4
[ Wed Oct  5 13:10:13 2022 ] 	Mean test loss of 796 batches: 1.4147835916759979.
[ Wed Oct  5 13:10:14 2022 ] 	Top1: 59.12%
[ Wed Oct  5 13:10:14 2022 ] 	Top5: 87.47%
[ Wed Oct  5 13:10:14 2022 ] Training epoch: 5
[ Wed Oct  5 13:17:21 2022 ] 	Mean training loss: 1.2745.  Mean training acc: 62.58%.
[ Wed Oct  5 13:17:21 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:17:21 2022 ] Eval epoch: 5
[ Wed Oct  5 13:19:08 2022 ] 	Mean test loss of 796 batches: 1.5272433965200156.
[ Wed Oct  5 13:19:09 2022 ] 	Top1: 56.35%
[ Wed Oct  5 13:19:09 2022 ] 	Top5: 85.13%
[ Wed Oct  5 13:19:09 2022 ] Training epoch: 6
[ Wed Oct  5 13:26:13 2022 ] 	Mean training loss: 1.1261.  Mean training acc: 66.47%.
[ Wed Oct  5 13:26:13 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:26:13 2022 ] Eval epoch: 6
[ Wed Oct  5 13:28:01 2022 ] 	Mean test loss of 796 batches: 1.4195791885032127.
[ Wed Oct  5 13:28:02 2022 ] 	Top1: 60.58%
[ Wed Oct  5 13:28:02 2022 ] 	Top5: 86.57%
[ Wed Oct  5 13:28:02 2022 ] Training epoch: 7
[ Wed Oct  5 13:35:10 2022 ] 	Mean training loss: 1.0363.  Mean training acc: 69.28%.
[ Wed Oct  5 13:35:10 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:35:10 2022 ] Eval epoch: 7
[ Wed Oct  5 13:36:57 2022 ] 	Mean test loss of 796 batches: 1.453088290652438.
[ Wed Oct  5 13:36:58 2022 ] 	Top1: 59.09%
[ Wed Oct  5 13:36:58 2022 ] 	Top5: 87.21%
[ Wed Oct  5 13:36:58 2022 ] Training epoch: 8
[ Wed Oct  5 13:44:09 2022 ] 	Mean training loss: 0.9774.  Mean training acc: 70.88%.
[ Wed Oct  5 13:44:09 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:44:09 2022 ] Eval epoch: 8
[ Wed Oct  5 13:45:59 2022 ] 	Mean test loss of 796 batches: 1.269858579390013.
[ Wed Oct  5 13:45:59 2022 ] 	Top1: 63.13%
[ Wed Oct  5 13:45:59 2022 ] 	Top5: 90.29%
[ Wed Oct  5 13:45:59 2022 ] Training epoch: 9
[ Wed Oct  5 13:53:10 2022 ] 	Mean training loss: 0.9355.  Mean training acc: 71.86%.
[ Wed Oct  5 13:53:10 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 13:53:10 2022 ] Eval epoch: 9
[ Wed Oct  5 13:54:58 2022 ] 	Mean test loss of 796 batches: 1.2103747352208925.
[ Wed Oct  5 13:54:58 2022 ] 	Top1: 63.81%
[ Wed Oct  5 13:54:59 2022 ] 	Top5: 90.60%
[ Wed Oct  5 13:54:59 2022 ] Training epoch: 10
[ Wed Oct  5 14:02:08 2022 ] 	Mean training loss: 0.8951.  Mean training acc: 73.08%.
[ Wed Oct  5 14:02:08 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:02:08 2022 ] Eval epoch: 10
[ Wed Oct  5 14:03:58 2022 ] 	Mean test loss of 796 batches: 1.3081169669053063.
[ Wed Oct  5 14:03:58 2022 ] 	Top1: 63.39%
[ Wed Oct  5 14:03:59 2022 ] 	Top5: 89.71%
[ Wed Oct  5 14:03:59 2022 ] Training epoch: 11
[ Wed Oct  5 14:11:06 2022 ] 	Mean training loss: 0.8673.  Mean training acc: 74.13%.
[ Wed Oct  5 14:11:06 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:11:06 2022 ] Eval epoch: 11
[ Wed Oct  5 14:12:51 2022 ] 	Mean test loss of 796 batches: 1.8278752949519372.
[ Wed Oct  5 14:12:51 2022 ] 	Top1: 53.20%
[ Wed Oct  5 14:12:51 2022 ] 	Top5: 83.96%
[ Wed Oct  5 14:12:51 2022 ] Training epoch: 12
[ Wed Oct  5 14:19:53 2022 ] 	Mean training loss: 0.8471.  Mean training acc: 74.48%.
[ Wed Oct  5 14:19:54 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:19:54 2022 ] Eval epoch: 12
[ Wed Oct  5 14:21:38 2022 ] 	Mean test loss of 796 batches: 1.3612229499460464.
[ Wed Oct  5 14:21:38 2022 ] 	Top1: 61.74%
[ Wed Oct  5 14:21:38 2022 ] 	Top5: 88.92%
[ Wed Oct  5 14:21:38 2022 ] Training epoch: 13
[ Wed Oct  5 14:28:34 2022 ] 	Mean training loss: 0.8270.  Mean training acc: 75.03%.
[ Wed Oct  5 14:28:34 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:28:34 2022 ] Eval epoch: 13
[ Wed Oct  5 14:30:13 2022 ] 	Mean test loss of 796 batches: 1.2263521637074912.
[ Wed Oct  5 14:30:13 2022 ] 	Top1: 65.11%
[ Wed Oct  5 14:30:13 2022 ] 	Top5: 90.49%
[ Wed Oct  5 14:30:13 2022 ] Training epoch: 14
[ Wed Oct  5 14:37:03 2022 ] 	Mean training loss: 0.8145.  Mean training acc: 75.40%.
[ Wed Oct  5 14:37:03 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:37:03 2022 ] Eval epoch: 14
[ Wed Oct  5 14:38:47 2022 ] 	Mean test loss of 796 batches: 1.310651568087501.
[ Wed Oct  5 14:38:47 2022 ] 	Top1: 61.37%
[ Wed Oct  5 14:38:48 2022 ] 	Top5: 90.30%
[ Wed Oct  5 14:38:48 2022 ] Training epoch: 15
[ Wed Oct  5 14:45:40 2022 ] 	Mean training loss: 0.7989.  Mean training acc: 75.96%.
[ Wed Oct  5 14:45:40 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:45:40 2022 ] Eval epoch: 15
[ Wed Oct  5 14:47:20 2022 ] 	Mean test loss of 796 batches: 1.0884876748050876.
[ Wed Oct  5 14:47:20 2022 ] 	Top1: 67.93%
[ Wed Oct  5 14:47:21 2022 ] 	Top5: 91.84%
[ Wed Oct  5 14:47:21 2022 ] Training epoch: 16
[ Wed Oct  5 14:54:17 2022 ] 	Mean training loss: 0.7845.  Mean training acc: 76.27%.
[ Wed Oct  5 14:54:17 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 14:54:17 2022 ] Eval epoch: 16
[ Wed Oct  5 14:55:57 2022 ] 	Mean test loss of 796 batches: 1.3554150343091045.
[ Wed Oct  5 14:55:58 2022 ] 	Top1: 61.76%
[ Wed Oct  5 14:55:58 2022 ] 	Top5: 89.42%
[ Wed Oct  5 14:55:58 2022 ] Training epoch: 17
[ Wed Oct  5 15:02:55 2022 ] 	Mean training loss: 0.7792.  Mean training acc: 76.49%.
[ Wed Oct  5 15:02:55 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:02:55 2022 ] Eval epoch: 17
[ Wed Oct  5 15:04:35 2022 ] 	Mean test loss of 796 batches: 1.5232209162646202.
[ Wed Oct  5 15:04:36 2022 ] 	Top1: 58.66%
[ Wed Oct  5 15:04:36 2022 ] 	Top5: 85.96%
[ Wed Oct  5 15:04:36 2022 ] Training epoch: 18
[ Wed Oct  5 15:11:30 2022 ] 	Mean training loss: 0.7650.  Mean training acc: 76.93%.
[ Wed Oct  5 15:11:30 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:11:30 2022 ] Eval epoch: 18
[ Wed Oct  5 15:13:09 2022 ] 	Mean test loss of 796 batches: 1.0446220241000306.
[ Wed Oct  5 15:13:10 2022 ] 	Top1: 69.22%
[ Wed Oct  5 15:13:10 2022 ] 	Top5: 92.98%
[ Wed Oct  5 15:13:10 2022 ] Training epoch: 19
[ Wed Oct  5 15:20:05 2022 ] 	Mean training loss: 0.7595.  Mean training acc: 76.92%.
[ Wed Oct  5 15:20:05 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:20:05 2022 ] Eval epoch: 19
[ Wed Oct  5 15:21:47 2022 ] 	Mean test loss of 796 batches: 1.0661175526940643.
[ Wed Oct  5 15:21:48 2022 ] 	Top1: 68.66%
[ Wed Oct  5 15:21:48 2022 ] 	Top5: 91.99%
[ Wed Oct  5 15:21:48 2022 ] Training epoch: 20
[ Wed Oct  5 15:28:48 2022 ] 	Mean training loss: 0.7533.  Mean training acc: 77.12%.
[ Wed Oct  5 15:28:48 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:28:48 2022 ] Eval epoch: 20
[ Wed Oct  5 15:30:29 2022 ] 	Mean test loss of 796 batches: 1.09415349832282.
[ Wed Oct  5 15:30:30 2022 ] 	Top1: 68.21%
[ Wed Oct  5 15:30:30 2022 ] 	Top5: 91.33%
[ Wed Oct  5 15:30:30 2022 ] Training epoch: 21
[ Wed Oct  5 15:37:27 2022 ] 	Mean training loss: 0.7450.  Mean training acc: 77.58%.
[ Wed Oct  5 15:37:27 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:37:27 2022 ] Eval epoch: 21
[ Wed Oct  5 15:39:09 2022 ] 	Mean test loss of 796 batches: 1.0719564358642952.
[ Wed Oct  5 15:39:10 2022 ] 	Top1: 68.78%
[ Wed Oct  5 15:39:10 2022 ] 	Top5: 92.48%
[ Wed Oct  5 15:39:10 2022 ] Training epoch: 22
[ Wed Oct  5 15:46:05 2022 ] 	Mean training loss: 0.7420.  Mean training acc: 77.58%.
[ Wed Oct  5 15:46:05 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:46:05 2022 ] Eval epoch: 22
[ Wed Oct  5 15:47:46 2022 ] 	Mean test loss of 796 batches: 0.9710261299082982.
[ Wed Oct  5 15:47:46 2022 ] 	Top1: 71.11%
[ Wed Oct  5 15:47:47 2022 ] 	Top5: 93.56%
[ Wed Oct  5 15:47:47 2022 ] Training epoch: 23
[ Wed Oct  5 15:54:43 2022 ] 	Mean training loss: 0.7321.  Mean training acc: 77.97%.
[ Wed Oct  5 15:54:43 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 15:54:43 2022 ] Eval epoch: 23
[ Wed Oct  5 15:56:24 2022 ] 	Mean test loss of 796 batches: 1.0822285275213683.
[ Wed Oct  5 15:56:24 2022 ] 	Top1: 68.64%
[ Wed Oct  5 15:56:25 2022 ] 	Top5: 92.51%
[ Wed Oct  5 15:56:25 2022 ] Training epoch: 24
[ Wed Oct  5 16:03:19 2022 ] 	Mean training loss: 0.7333.  Mean training acc: 77.68%.
[ Wed Oct  5 16:03:19 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:03:19 2022 ] Eval epoch: 24
[ Wed Oct  5 16:04:58 2022 ] 	Mean test loss of 796 batches: 1.0947565389937493.
[ Wed Oct  5 16:04:58 2022 ] 	Top1: 67.39%
[ Wed Oct  5 16:04:59 2022 ] 	Top5: 92.57%
[ Wed Oct  5 16:04:59 2022 ] Training epoch: 25
[ Wed Oct  5 16:11:50 2022 ] 	Mean training loss: 0.7273.  Mean training acc: 77.98%.
[ Wed Oct  5 16:11:50 2022 ] 	Time consumption: [Data]01%, [Network]99%
[ Wed Oct  5 16:11:50 2022 ] Eval epoch: 25
[ Wed Oct  5 16:13:35 2022 ] 	Mean test loss of 796 batches: 1.125423202600012.
[ Wed Oct  5 16:13:35 2022 ] 	Top1: 66.60%
[ Wed Oct  5 16:13:36 2022 ] 	Top5: 92.15%
[ Wed Oct  5 16:13:36 2022 ] Training epoch: 26
[ Wed Oct  5 16:20:33 2022 ] 	Mean training loss: 0.7227.  Mean training acc: 78.09%.
[ Wed Oct  5 16:20:33 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:20:33 2022 ] Eval epoch: 26
[ Wed Oct  5 16:22:18 2022 ] 	Mean test loss of 796 batches: 1.099190243674283.
[ Wed Oct  5 16:22:18 2022 ] 	Top1: 67.89%
[ Wed Oct  5 16:22:18 2022 ] 	Top5: 91.82%
[ Wed Oct  5 16:22:18 2022 ] Training epoch: 27
[ Wed Oct  5 16:29:19 2022 ] 	Mean training loss: 0.7196.  Mean training acc: 78.32%.
[ Wed Oct  5 16:29:19 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:29:19 2022 ] Eval epoch: 27
[ Wed Oct  5 16:31:03 2022 ] 	Mean test loss of 796 batches: 1.1578556809143805.
[ Wed Oct  5 16:31:04 2022 ] 	Top1: 66.50%
[ Wed Oct  5 16:31:04 2022 ] 	Top5: 91.01%
[ Wed Oct  5 16:31:04 2022 ] Training epoch: 28
[ Wed Oct  5 16:38:04 2022 ] 	Mean training loss: 0.7176.  Mean training acc: 78.34%.
[ Wed Oct  5 16:38:04 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:38:04 2022 ] Eval epoch: 28
[ Wed Oct  5 16:39:52 2022 ] 	Mean test loss of 796 batches: 0.9809389874039582.
[ Wed Oct  5 16:39:52 2022 ] 	Top1: 71.40%
[ Wed Oct  5 16:39:52 2022 ] 	Top5: 93.25%
[ Wed Oct  5 16:39:53 2022 ] Training epoch: 29
[ Wed Oct  5 16:46:53 2022 ] 	Mean training loss: 0.7140.  Mean training acc: 78.32%.
[ Wed Oct  5 16:46:53 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:46:53 2022 ] Eval epoch: 29
[ Wed Oct  5 16:48:39 2022 ] 	Mean test loss of 796 batches: 1.0938086637749744.
[ Wed Oct  5 16:48:40 2022 ] 	Top1: 69.75%
[ Wed Oct  5 16:48:40 2022 ] 	Top5: 91.41%
[ Wed Oct  5 16:48:40 2022 ] Training epoch: 30
[ Wed Oct  5 16:55:41 2022 ] 	Mean training loss: 0.7120.  Mean training acc: 78.39%.
[ Wed Oct  5 16:55:41 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 16:55:41 2022 ] Eval epoch: 30
[ Wed Oct  5 16:57:26 2022 ] 	Mean test loss of 796 batches: 1.0512308861367667.
[ Wed Oct  5 16:57:26 2022 ] 	Top1: 69.00%
[ Wed Oct  5 16:57:26 2022 ] 	Top5: 92.65%
[ Wed Oct  5 16:57:26 2022 ] Training epoch: 31
[ Wed Oct  5 17:04:27 2022 ] 	Mean training loss: 0.7089.  Mean training acc: 78.62%.
[ Wed Oct  5 17:04:27 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:04:27 2022 ] Eval epoch: 31
[ Wed Oct  5 17:06:12 2022 ] 	Mean test loss of 796 batches: 1.1156708275403209.
[ Wed Oct  5 17:06:12 2022 ] 	Top1: 68.26%
[ Wed Oct  5 17:06:13 2022 ] 	Top5: 92.15%
[ Wed Oct  5 17:06:13 2022 ] Training epoch: 32
[ Wed Oct  5 17:13:12 2022 ] 	Mean training loss: 0.7050.  Mean training acc: 78.78%.
[ Wed Oct  5 17:13:12 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:13:12 2022 ] Eval epoch: 32
[ Wed Oct  5 17:14:57 2022 ] 	Mean test loss of 796 batches: 1.594350495455253.
[ Wed Oct  5 17:14:57 2022 ] 	Top1: 58.38%
[ Wed Oct  5 17:14:58 2022 ] 	Top5: 87.79%
[ Wed Oct  5 17:14:58 2022 ] Training epoch: 33
[ Wed Oct  5 17:21:54 2022 ] 	Mean training loss: 0.7033.  Mean training acc: 78.78%.
[ Wed Oct  5 17:21:54 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:21:54 2022 ] Eval epoch: 33
[ Wed Oct  5 17:23:39 2022 ] 	Mean test loss of 796 batches: 1.5921717170045604.
[ Wed Oct  5 17:23:39 2022 ] 	Top1: 57.60%
[ Wed Oct  5 17:23:40 2022 ] 	Top5: 87.32%
[ Wed Oct  5 17:23:40 2022 ] Training epoch: 34
[ Wed Oct  5 17:30:37 2022 ] 	Mean training loss: 0.7036.  Mean training acc: 78.70%.
[ Wed Oct  5 17:30:37 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:30:37 2022 ] Eval epoch: 34
[ Wed Oct  5 17:32:22 2022 ] 	Mean test loss of 796 batches: 1.1065936675061232.
[ Wed Oct  5 17:32:22 2022 ] 	Top1: 68.83%
[ Wed Oct  5 17:32:22 2022 ] 	Top5: 91.66%
[ Wed Oct  5 17:32:23 2022 ] Training epoch: 35
[ Wed Oct  5 17:39:22 2022 ] 	Mean training loss: 0.6974.  Mean training acc: 78.89%.
[ Wed Oct  5 17:39:22 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:39:22 2022 ] Eval epoch: 35
[ Wed Oct  5 17:41:05 2022 ] 	Mean test loss of 796 batches: 1.0580365283030961.
[ Wed Oct  5 17:41:05 2022 ] 	Top1: 69.04%
[ Wed Oct  5 17:41:06 2022 ] 	Top5: 92.41%
[ Wed Oct  5 17:41:06 2022 ] Training epoch: 36
[ Wed Oct  5 17:48:04 2022 ] 	Mean training loss: 0.4051.  Mean training acc: 87.82%.
[ Wed Oct  5 17:48:04 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:48:04 2022 ] Eval epoch: 36
[ Wed Oct  5 17:49:47 2022 ] 	Mean test loss of 796 batches: 0.5543037688631058.
[ Wed Oct  5 17:49:47 2022 ] 	Top1: 82.76%
[ Wed Oct  5 17:49:48 2022 ] 	Top5: 96.91%
[ Wed Oct  5 17:49:48 2022 ] Training epoch: 37
[ Wed Oct  5 17:56:43 2022 ] 	Mean training loss: 0.3241.  Mean training acc: 90.17%.
[ Wed Oct  5 17:56:43 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 17:56:43 2022 ] Eval epoch: 37
[ Wed Oct  5 17:58:26 2022 ] 	Mean test loss of 796 batches: 0.5306665915059834.
[ Wed Oct  5 17:58:27 2022 ] 	Top1: 83.58%
[ Wed Oct  5 17:58:27 2022 ] 	Top5: 97.16%
[ Wed Oct  5 17:58:27 2022 ] Training epoch: 38
[ Wed Oct  5 18:05:24 2022 ] 	Mean training loss: 0.2889.  Mean training acc: 91.29%.
[ Wed Oct  5 18:05:24 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:05:24 2022 ] Eval epoch: 38
[ Wed Oct  5 18:07:08 2022 ] 	Mean test loss of 796 batches: 0.5317537752611927.
[ Wed Oct  5 18:07:08 2022 ] 	Top1: 83.78%
[ Wed Oct  5 18:07:08 2022 ] 	Top5: 97.15%
[ Wed Oct  5 18:07:08 2022 ] Training epoch: 39
[ Wed Oct  5 18:14:06 2022 ] 	Mean training loss: 0.2667.  Mean training acc: 92.15%.
[ Wed Oct  5 18:14:06 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:14:06 2022 ] Eval epoch: 39
[ Wed Oct  5 18:15:47 2022 ] 	Mean test loss of 796 batches: 0.5453681653487173.
[ Wed Oct  5 18:15:48 2022 ] 	Top1: 83.41%
[ Wed Oct  5 18:15:48 2022 ] 	Top5: 97.04%
[ Wed Oct  5 18:15:48 2022 ] Training epoch: 40
[ Wed Oct  5 18:22:44 2022 ] 	Mean training loss: 0.2450.  Mean training acc: 92.79%.
[ Wed Oct  5 18:22:44 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:22:44 2022 ] Eval epoch: 40
[ Wed Oct  5 18:24:27 2022 ] 	Mean test loss of 796 batches: 0.5434754145748202.
[ Wed Oct  5 18:24:27 2022 ] 	Top1: 83.62%
[ Wed Oct  5 18:24:27 2022 ] 	Top5: 97.02%
[ Wed Oct  5 18:24:27 2022 ] Training epoch: 41
[ Wed Oct  5 18:31:24 2022 ] 	Mean training loss: 0.2288.  Mean training acc: 93.37%.
[ Wed Oct  5 18:31:24 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:31:24 2022 ] Eval epoch: 41
[ Wed Oct  5 18:33:06 2022 ] 	Mean test loss of 796 batches: 0.5473211294030724.
[ Wed Oct  5 18:33:07 2022 ] 	Top1: 83.52%
[ Wed Oct  5 18:33:07 2022 ] 	Top5: 97.04%
[ Wed Oct  5 18:33:07 2022 ] Training epoch: 42
[ Wed Oct  5 18:40:02 2022 ] 	Mean training loss: 0.2141.  Mean training acc: 93.75%.
[ Wed Oct  5 18:40:03 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:40:03 2022 ] Eval epoch: 42
[ Wed Oct  5 18:41:46 2022 ] 	Mean test loss of 796 batches: 0.567782306098309.
[ Wed Oct  5 18:41:46 2022 ] 	Top1: 83.19%
[ Wed Oct  5 18:41:47 2022 ] 	Top5: 96.88%
[ Wed Oct  5 18:41:47 2022 ] Training epoch: 43
[ Wed Oct  5 18:48:43 2022 ] 	Mean training loss: 0.2045.  Mean training acc: 94.12%.
[ Wed Oct  5 18:48:43 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:48:43 2022 ] Eval epoch: 43
[ Wed Oct  5 18:50:26 2022 ] 	Mean test loss of 796 batches: 0.5755507010339418.
[ Wed Oct  5 18:50:27 2022 ] 	Top1: 82.93%
[ Wed Oct  5 18:50:27 2022 ] 	Top5: 96.72%
[ Wed Oct  5 18:50:27 2022 ] Training epoch: 44
[ Wed Oct  5 18:57:25 2022 ] 	Mean training loss: 0.1940.  Mean training acc: 94.56%.
[ Wed Oct  5 18:57:25 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 18:57:25 2022 ] Eval epoch: 44
[ Wed Oct  5 18:59:08 2022 ] 	Mean test loss of 796 batches: 0.5870669266517887.
[ Wed Oct  5 18:59:09 2022 ] 	Top1: 82.99%
[ Wed Oct  5 18:59:09 2022 ] 	Top5: 96.63%
[ Wed Oct  5 18:59:09 2022 ] Training epoch: 45
[ Wed Oct  5 19:06:06 2022 ] 	Mean training loss: 0.1905.  Mean training acc: 94.63%.
[ Wed Oct  5 19:06:06 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:06:06 2022 ] Eval epoch: 45
[ Wed Oct  5 19:07:48 2022 ] 	Mean test loss of 796 batches: 0.5782798099654478.
[ Wed Oct  5 19:07:48 2022 ] 	Top1: 83.22%
[ Wed Oct  5 19:07:49 2022 ] 	Top5: 96.81%
[ Wed Oct  5 19:07:49 2022 ] Training epoch: 46
[ Wed Oct  5 19:14:46 2022 ] 	Mean training loss: 0.1816.  Mean training acc: 94.84%.
[ Wed Oct  5 19:14:47 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:14:47 2022 ] Eval epoch: 46
[ Wed Oct  5 19:16:32 2022 ] 	Mean test loss of 796 batches: 0.5859710091453552.
[ Wed Oct  5 19:16:32 2022 ] 	Top1: 82.99%
[ Wed Oct  5 19:16:32 2022 ] 	Top5: 96.80%
[ Wed Oct  5 19:16:32 2022 ] Training epoch: 47
[ Wed Oct  5 19:23:34 2022 ] 	Mean training loss: 0.1730.  Mean training acc: 95.18%.
[ Wed Oct  5 19:23:34 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:23:34 2022 ] Eval epoch: 47
[ Wed Oct  5 19:25:19 2022 ] 	Mean test loss of 796 batches: 0.6311328876903982.
[ Wed Oct  5 19:25:19 2022 ] 	Top1: 82.03%
[ Wed Oct  5 19:25:19 2022 ] 	Top5: 96.36%
[ Wed Oct  5 19:25:19 2022 ] Training epoch: 48
[ Wed Oct  5 19:32:21 2022 ] 	Mean training loss: 0.1676.  Mean training acc: 95.38%.
[ Wed Oct  5 19:32:21 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:32:21 2022 ] Eval epoch: 48
[ Wed Oct  5 19:34:07 2022 ] 	Mean test loss of 796 batches: 0.6642621642998864.
[ Wed Oct  5 19:34:07 2022 ] 	Top1: 81.59%
[ Wed Oct  5 19:34:07 2022 ] 	Top5: 95.89%
[ Wed Oct  5 19:34:07 2022 ] Training epoch: 49
[ Wed Oct  5 19:41:09 2022 ] 	Mean training loss: 0.1651.  Mean training acc: 95.53%.
[ Wed Oct  5 19:41:09 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:41:09 2022 ] Eval epoch: 49
[ Wed Oct  5 19:42:53 2022 ] 	Mean test loss of 796 batches: 0.6228108774290313.
[ Wed Oct  5 19:42:54 2022 ] 	Top1: 82.63%
[ Wed Oct  5 19:42:54 2022 ] 	Top5: 96.36%
[ Wed Oct  5 19:42:54 2022 ] Training epoch: 50
[ Wed Oct  5 19:49:53 2022 ] 	Mean training loss: 0.1678.  Mean training acc: 95.41%.
[ Wed Oct  5 19:49:53 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:49:53 2022 ] Eval epoch: 50
[ Wed Oct  5 19:51:36 2022 ] 	Mean test loss of 796 batches: 0.6517057096463951.
[ Wed Oct  5 19:51:36 2022 ] 	Top1: 81.93%
[ Wed Oct  5 19:51:36 2022 ] 	Top5: 96.25%
[ Wed Oct  5 19:51:36 2022 ] Training epoch: 51
[ Wed Oct  5 19:58:35 2022 ] 	Mean training loss: 0.1662.  Mean training acc: 95.42%.
[ Wed Oct  5 19:58:36 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 19:58:36 2022 ] Eval epoch: 51
[ Wed Oct  5 20:00:20 2022 ] 	Mean test loss of 796 batches: 0.6846569755474976.
[ Wed Oct  5 20:00:20 2022 ] 	Top1: 81.17%
[ Wed Oct  5 20:00:21 2022 ] 	Top5: 96.02%
[ Wed Oct  5 20:00:21 2022 ] Training epoch: 52
[ Wed Oct  5 20:07:19 2022 ] 	Mean training loss: 0.1659.  Mean training acc: 95.37%.
[ Wed Oct  5 20:07:19 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:07:19 2022 ] Eval epoch: 52
[ Wed Oct  5 20:09:03 2022 ] 	Mean test loss of 796 batches: 0.6549300613939463.
[ Wed Oct  5 20:09:03 2022 ] 	Top1: 81.59%
[ Wed Oct  5 20:09:03 2022 ] 	Top5: 96.20%
[ Wed Oct  5 20:09:03 2022 ] Training epoch: 53
[ Wed Oct  5 20:16:00 2022 ] 	Mean training loss: 0.1596.  Mean training acc: 95.69%.
[ Wed Oct  5 20:16:00 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:16:00 2022 ] Eval epoch: 53
[ Wed Oct  5 20:17:46 2022 ] 	Mean test loss of 796 batches: 0.6562896426767111.
[ Wed Oct  5 20:17:46 2022 ] 	Top1: 81.47%
[ Wed Oct  5 20:17:47 2022 ] 	Top5: 96.21%
[ Wed Oct  5 20:17:47 2022 ] Training epoch: 54
[ Wed Oct  5 20:24:47 2022 ] 	Mean training loss: 0.1623.  Mean training acc: 95.60%.
[ Wed Oct  5 20:24:47 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:24:47 2022 ] Eval epoch: 54
[ Wed Oct  5 20:26:31 2022 ] 	Mean test loss of 796 batches: 0.6622014092421861.
[ Wed Oct  5 20:26:32 2022 ] 	Top1: 81.59%
[ Wed Oct  5 20:26:32 2022 ] 	Top5: 96.17%
[ Wed Oct  5 20:26:32 2022 ] Training epoch: 55
[ Wed Oct  5 20:33:32 2022 ] 	Mean training loss: 0.1598.  Mean training acc: 95.59%.
[ Wed Oct  5 20:33:32 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:33:32 2022 ] Eval epoch: 55
[ Wed Oct  5 20:35:15 2022 ] 	Mean test loss of 796 batches: 0.6598988128966422.
[ Wed Oct  5 20:35:16 2022 ] 	Top1: 82.02%
[ Wed Oct  5 20:35:16 2022 ] 	Top5: 96.05%
[ Wed Oct  5 20:35:16 2022 ] Training epoch: 56
[ Wed Oct  5 20:42:16 2022 ] 	Mean training loss: 0.0926.  Mean training acc: 97.92%.
[ Wed Oct  5 20:42:16 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:42:16 2022 ] Eval epoch: 56
[ Wed Oct  5 20:44:01 2022 ] 	Mean test loss of 796 batches: 0.5725571001229349.
[ Wed Oct  5 20:44:01 2022 ] 	Top1: 84.04%
[ Wed Oct  5 20:44:02 2022 ] 	Top5: 96.79%
[ Wed Oct  5 20:44:02 2022 ] Training epoch: 57
[ Wed Oct  5 20:51:02 2022 ] 	Mean training loss: 0.0692.  Mean training acc: 98.58%.
[ Wed Oct  5 20:51:02 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:51:02 2022 ] Eval epoch: 57
[ Wed Oct  5 20:52:46 2022 ] 	Mean test loss of 796 batches: 0.57101612432799.
[ Wed Oct  5 20:52:47 2022 ] 	Top1: 84.21%
[ Wed Oct  5 20:52:47 2022 ] 	Top5: 96.84%
[ Wed Oct  5 20:52:47 2022 ] Training epoch: 58
[ Wed Oct  5 20:59:48 2022 ] 	Mean training loss: 0.0605.  Mean training acc: 98.88%.
[ Wed Oct  5 20:59:48 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 20:59:48 2022 ] Eval epoch: 58
[ Wed Oct  5 21:01:31 2022 ] 	Mean test loss of 796 batches: 0.5739159618303105.
[ Wed Oct  5 21:01:32 2022 ] 	Top1: 84.08%
[ Wed Oct  5 21:01:32 2022 ] 	Top5: 96.80%
[ Wed Oct  5 21:01:32 2022 ] Training epoch: 59
[ Wed Oct  5 21:08:35 2022 ] 	Mean training loss: 0.0561.  Mean training acc: 99.00%.
[ Wed Oct  5 21:08:35 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Wed Oct  5 21:08:35 2022 ] Eval epoch: 59
[ Wed Oct  5 21:10:17 2022 ] 	Mean test loss of 796 batches: 0.5779865224326226.
[ Wed Oct  5 21:10:17 2022 ] 	Top1: 84.20%
[ Wed Oct  5 21:10:18 2022 ] 	Top5: 96.75%
[ Wed Oct  5 21:10:18 2022 ] Training epoch: 60
[ Wed Oct  5 21:14:20 2022 ] 	Mean training loss: 0.0538.  Mean training acc: 99.08%.
[ Wed Oct  5 21:14:20 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Oct  5 21:14:20 2022 ] Eval epoch: 60
[ Wed Oct  5 21:15:03 2022 ] 	Mean test loss of 796 batches: 0.5772542529201238.
[ Wed Oct  5 21:15:04 2022 ] 	Top1: 84.23%
[ Wed Oct  5 21:15:04 2022 ] 	Top5: 96.78%
[ Wed Oct  5 21:15:04 2022 ] Training epoch: 61
[ Wed Oct  5 21:18:00 2022 ] 	Mean training loss: 0.0508.  Mean training acc: 99.11%.
[ Wed Oct  5 21:18:00 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 21:18:00 2022 ] Eval epoch: 61
[ Wed Oct  5 21:18:44 2022 ] 	Mean test loss of 796 batches: 0.5720911998648065.
[ Wed Oct  5 21:18:44 2022 ] 	Top1: 84.31%
[ Wed Oct  5 21:18:45 2022 ] 	Top5: 96.84%
[ Wed Oct  5 21:18:45 2022 ] Training epoch: 62
[ Wed Oct  5 21:21:40 2022 ] 	Mean training loss: 0.0484.  Mean training acc: 99.20%.
[ Wed Oct  5 21:21:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 21:21:41 2022 ] Eval epoch: 62
[ Wed Oct  5 21:22:25 2022 ] 	Mean test loss of 796 batches: 0.5837286680295651.
[ Wed Oct  5 21:22:25 2022 ] 	Top1: 84.16%
[ Wed Oct  5 21:22:25 2022 ] 	Top5: 96.80%
[ Wed Oct  5 21:22:25 2022 ] Training epoch: 63
[ Wed Oct  5 21:25:21 2022 ] 	Mean training loss: 0.0461.  Mean training acc: 99.27%.
[ Wed Oct  5 21:25:21 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Wed Oct  5 21:25:21 2022 ] Eval epoch: 63
[ Wed Oct  5 21:26:05 2022 ] 	Mean test loss of 796 batches: 0.5859239772710968.
[ Wed Oct  5 21:26:06 2022 ] 	Top1: 84.10%
[ Wed Oct  5 21:26:06 2022 ] 	Top5: 96.68%
[ Wed Oct  5 21:26:06 2022 ] Training epoch: 64
[ Wed Oct  5 21:29:02 2022 ] 	Mean training loss: 0.0443.  Mean training acc: 99.31%.
[ Wed Oct  5 21:29:02 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 21:29:02 2022 ] Eval epoch: 64
[ Wed Oct  5 21:29:46 2022 ] 	Mean test loss of 796 batches: 0.5849844323092107.
[ Wed Oct  5 21:29:46 2022 ] 	Top1: 84.13%
[ Wed Oct  5 21:29:47 2022 ] 	Top5: 96.74%
[ Wed Oct  5 21:29:47 2022 ] Training epoch: 65
[ Wed Oct  5 21:32:43 2022 ] 	Mean training loss: 0.0429.  Mean training acc: 99.33%.
[ Wed Oct  5 21:32:43 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Oct  5 21:32:43 2022 ] Eval epoch: 65
[ Wed Oct  5 21:33:26 2022 ] 	Mean test loss of 796 batches: 0.5802240516620703.
[ Wed Oct  5 21:33:27 2022 ] 	Top1: 84.27%
[ Wed Oct  5 21:33:27 2022 ] 	Top5: 96.76%
[ Wed Oct  5 21:34:12 2022 ] Best accuracy: 0.8430644749504115
[ Wed Oct  5 21:34:12 2022 ] Epoch number: 61
[ Wed Oct  5 21:34:12 2022 ] Model name: work_dir/ntu120/csub/spherical_coord2
[ Wed Oct  5 21:34:12 2022 ] Model total number of params: 2108322
[ Wed Oct  5 21:34:12 2022 ] Weight decay: 0.0004
[ Wed Oct  5 21:34:12 2022 ] Base LR: 0.1
[ Wed Oct  5 21:34:12 2022 ] Batch Size: 64
[ Wed Oct  5 21:34:12 2022 ] Test Batch Size: 64
[ Wed Oct  5 21:34:12 2022 ] seed: 1
[ Thu Oct 27 15:05:31 2022 ] Load weights from work_dir/ntu120/csub/spherical_coord2/runs-65-63960.pt.
[ Thu Oct 27 15:05:38 2022 ] using warm up, epoch: 5
[ Thu Oct 27 15:06:03 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spherical_coord2', 'model_saved_name': 'work_dir/ntu120/csub/spherical_coord2/runs', 'config': 'config/nturgbd120-cross-subject/default_long.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spher_coord2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/ntu120/csub/spherical_coord2/runs-65-63960.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 90, 100], 'device': [5], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 65, 'num_epoch': 110, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Oct 27 15:06:03 2022 ] # Parameters: 2108322
[ Thu Oct 27 15:06:03 2022 ] Training epoch: 66
[ Thu Oct 27 15:06:21 2022 ] Load weights from work_dir/ntu120/csub/spherical_coord2/runs-65-63960.pt.
[ Thu Oct 27 15:06:26 2022 ] using warm up, epoch: 5
[ Thu Oct 27 15:06:53 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/spherical_coord2', 'model_saved_name': 'work_dir/ntu120/csub/spherical_coord2/runs', 'config': 'config/nturgbd120-cross-subject/default_long.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.spher_coord2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/ntu120/csub/spherical_coord2/runs-65-63960.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 90, 100], 'device': [5], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 65, 'num_epoch': 110, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Oct 27 15:06:53 2022 ] # Parameters: 2108322
[ Thu Oct 27 15:06:53 2022 ] Training epoch: 66
[ Thu Oct 27 15:09:57 2022 ] 	Mean training loss: 0.0400.  Mean training acc: 99.41%.
[ Thu Oct 27 15:09:57 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 15:09:57 2022 ] Eval epoch: 66
[ Thu Oct 27 15:10:56 2022 ] 	Mean test loss of 796 batches: 0.5826059633739592.
[ Thu Oct 27 15:10:57 2022 ] 	Top1: 84.29%
[ Thu Oct 27 15:10:58 2022 ] 	Top5: 96.70%
[ Thu Oct 27 15:10:58 2022 ] Training epoch: 67
[ Thu Oct 27 15:14:02 2022 ] 	Mean training loss: 0.0394.  Mean training acc: 99.45%.
[ Thu Oct 27 15:14:02 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 15:14:02 2022 ] Eval epoch: 67
[ Thu Oct 27 15:14:58 2022 ] 	Mean test loss of 796 batches: 0.584475781293539.
[ Thu Oct 27 15:14:59 2022 ] 	Top1: 84.30%
[ Thu Oct 27 15:15:00 2022 ] 	Top5: 96.74%
[ Thu Oct 27 15:15:00 2022 ] Training epoch: 68
[ Thu Oct 27 15:18:04 2022 ] 	Mean training loss: 0.0397.  Mean training acc: 99.45%.
[ Thu Oct 27 15:18:04 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:18:04 2022 ] Eval epoch: 68
[ Thu Oct 27 15:18:59 2022 ] 	Mean test loss of 796 batches: 0.5823111027834853.
[ Thu Oct 27 15:19:00 2022 ] 	Top1: 84.28%
[ Thu Oct 27 15:19:01 2022 ] 	Top5: 96.78%
[ Thu Oct 27 15:19:02 2022 ] Training epoch: 69
[ Thu Oct 27 15:22:04 2022 ] 	Mean training loss: 0.0381.  Mean training acc: 99.48%.
[ Thu Oct 27 15:22:04 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:22:05 2022 ] Eval epoch: 69
[ Thu Oct 27 15:23:03 2022 ] 	Mean test loss of 796 batches: 0.5920944780172153.
[ Thu Oct 27 15:23:03 2022 ] 	Top1: 84.13%
[ Thu Oct 27 15:23:04 2022 ] 	Top5: 96.67%
[ Thu Oct 27 15:23:04 2022 ] Training epoch: 70
[ Thu Oct 27 15:26:06 2022 ] 	Mean training loss: 0.0373.  Mean training acc: 99.47%.
[ Thu Oct 27 15:26:06 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 15:26:06 2022 ] Eval epoch: 70
[ Thu Oct 27 15:27:02 2022 ] 	Mean test loss of 796 batches: 0.585183061273235.
[ Thu Oct 27 15:27:03 2022 ] 	Top1: 84.26%
[ Thu Oct 27 15:27:04 2022 ] 	Top5: 96.75%
[ Thu Oct 27 15:27:04 2022 ] Training epoch: 71
[ Thu Oct 27 15:30:08 2022 ] 	Mean training loss: 0.0363.  Mean training acc: 99.50%.
[ Thu Oct 27 15:30:08 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:30:08 2022 ] Eval epoch: 71
[ Thu Oct 27 15:31:04 2022 ] 	Mean test loss of 796 batches: 0.5974573724594285.
[ Thu Oct 27 15:31:05 2022 ] 	Top1: 84.03%
[ Thu Oct 27 15:31:06 2022 ] 	Top5: 96.54%
[ Thu Oct 27 15:31:06 2022 ] Training epoch: 72
[ Thu Oct 27 15:34:07 2022 ] 	Mean training loss: 0.0356.  Mean training acc: 99.55%.
[ Thu Oct 27 15:34:07 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 15:34:07 2022 ] Eval epoch: 72
[ Thu Oct 27 15:35:02 2022 ] 	Mean test loss of 796 batches: 0.586271618375901.
[ Thu Oct 27 15:35:03 2022 ] 	Top1: 84.14%
[ Thu Oct 27 15:35:04 2022 ] 	Top5: 96.69%
[ Thu Oct 27 15:35:04 2022 ] Training epoch: 73
[ Thu Oct 27 15:38:10 2022 ] 	Mean training loss: 0.0350.  Mean training acc: 99.56%.
[ Thu Oct 27 15:38:10 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:38:10 2022 ] Eval epoch: 73
[ Thu Oct 27 15:39:06 2022 ] 	Mean test loss of 796 batches: 0.5857994481406394.
[ Thu Oct 27 15:39:07 2022 ] 	Top1: 84.28%
[ Thu Oct 27 15:39:08 2022 ] 	Top5: 96.72%
[ Thu Oct 27 15:39:08 2022 ] Training epoch: 74
[ Thu Oct 27 15:42:12 2022 ] 	Mean training loss: 0.0348.  Mean training acc: 99.53%.
[ Thu Oct 27 15:42:12 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 15:42:12 2022 ] Eval epoch: 74
[ Thu Oct 27 15:43:07 2022 ] 	Mean test loss of 796 batches: 0.5905468788339602.
[ Thu Oct 27 15:43:08 2022 ] 	Top1: 84.13%
[ Thu Oct 27 15:43:09 2022 ] 	Top5: 96.62%
[ Thu Oct 27 15:43:09 2022 ] Training epoch: 75
[ Thu Oct 27 15:46:12 2022 ] 	Mean training loss: 0.0342.  Mean training acc: 99.59%.
[ Thu Oct 27 15:46:12 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:46:12 2022 ] Eval epoch: 75
[ Thu Oct 27 15:47:06 2022 ] 	Mean test loss of 796 batches: 0.5981266953345931.
[ Thu Oct 27 15:47:07 2022 ] 	Top1: 83.98%
[ Thu Oct 27 15:47:08 2022 ] 	Top5: 96.64%
[ Thu Oct 27 15:47:08 2022 ] Training epoch: 76
[ Thu Oct 27 15:50:11 2022 ] 	Mean training loss: 0.0334.  Mean training acc: 99.58%.
[ Thu Oct 27 15:50:11 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 15:50:11 2022 ] Eval epoch: 76
[ Thu Oct 27 15:51:13 2022 ] 	Mean test loss of 796 batches: 0.5846154172389988.
[ Thu Oct 27 15:51:14 2022 ] 	Top1: 84.32%
[ Thu Oct 27 15:51:15 2022 ] 	Top5: 96.68%
[ Thu Oct 27 15:51:15 2022 ] Training epoch: 77
[ Thu Oct 27 15:54:22 2022 ] 	Mean training loss: 0.0319.  Mean training acc: 99.64%.
[ Thu Oct 27 15:54:22 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 15:54:22 2022 ] Eval epoch: 77
[ Thu Oct 27 15:55:26 2022 ] 	Mean test loss of 796 batches: 0.594368435180367.
[ Thu Oct 27 15:55:27 2022 ] 	Top1: 84.22%
[ Thu Oct 27 15:55:28 2022 ] 	Top5: 96.60%
[ Thu Oct 27 15:55:29 2022 ] Training epoch: 78
[ Thu Oct 27 15:58:34 2022 ] 	Mean training loss: 0.0314.  Mean training acc: 99.64%.
[ Thu Oct 27 15:58:34 2022 ] 	Time consumption: [Data]10%, [Network]90%
[ Thu Oct 27 15:58:34 2022 ] Eval epoch: 78
[ Thu Oct 27 15:59:31 2022 ] 	Mean test loss of 796 batches: 0.5929000226350211.
[ Thu Oct 27 15:59:32 2022 ] 	Top1: 84.16%
[ Thu Oct 27 15:59:33 2022 ] 	Top5: 96.58%
[ Thu Oct 27 15:59:33 2022 ] Training epoch: 79
[ Thu Oct 27 16:02:41 2022 ] 	Mean training loss: 0.0319.  Mean training acc: 99.64%.
[ Thu Oct 27 16:02:41 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 16:02:44 2022 ] Eval epoch: 79
[ Thu Oct 27 16:03:43 2022 ] 	Mean test loss of 796 batches: 0.5933999888758039.
[ Thu Oct 27 16:03:44 2022 ] 	Top1: 84.06%
[ Thu Oct 27 16:03:46 2022 ] 	Top5: 96.67%
[ Thu Oct 27 16:03:46 2022 ] Training epoch: 80
[ Thu Oct 27 16:06:52 2022 ] 	Mean training loss: 0.0307.  Mean training acc: 99.65%.
[ Thu Oct 27 16:06:52 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 16:06:52 2022 ] Eval epoch: 80
[ Thu Oct 27 16:07:49 2022 ] 	Mean test loss of 796 batches: 0.5937940934953753.
[ Thu Oct 27 16:07:50 2022 ] 	Top1: 84.16%
[ Thu Oct 27 16:07:51 2022 ] 	Top5: 96.57%
[ Thu Oct 27 16:07:51 2022 ] Training epoch: 81
[ Thu Oct 27 16:10:56 2022 ] 	Mean training loss: 0.0314.  Mean training acc: 99.64%.
[ Thu Oct 27 16:10:56 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 16:10:56 2022 ] Eval epoch: 81
[ Thu Oct 27 16:11:55 2022 ] 	Mean test loss of 796 batches: 0.5964352044314333.
[ Thu Oct 27 16:11:56 2022 ] 	Top1: 84.06%
[ Thu Oct 27 16:11:57 2022 ] 	Top5: 96.67%
[ Thu Oct 27 16:11:57 2022 ] Training epoch: 82
[ Thu Oct 27 16:15:03 2022 ] 	Mean training loss: 0.0307.  Mean training acc: 99.63%.
[ Thu Oct 27 16:15:03 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 16:15:03 2022 ] Eval epoch: 82
[ Thu Oct 27 16:16:03 2022 ] 	Mean test loss of 796 batches: 0.5895856709860677.
[ Thu Oct 27 16:16:05 2022 ] 	Top1: 84.20%
[ Thu Oct 27 16:16:05 2022 ] 	Top5: 96.67%
[ Thu Oct 27 16:16:05 2022 ] Training epoch: 83
[ Thu Oct 27 16:19:47 2022 ] 	Mean training loss: 0.0310.  Mean training acc: 99.67%.
[ Thu Oct 27 16:19:47 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 16:19:47 2022 ] Eval epoch: 83
[ Thu Oct 27 16:21:20 2022 ] 	Mean test loss of 796 batches: 0.5894200782333712.
[ Thu Oct 27 16:21:21 2022 ] 	Top1: 84.35%
[ Thu Oct 27 16:21:22 2022 ] 	Top5: 96.62%
[ Thu Oct 27 16:21:22 2022 ] Training epoch: 84
[ Thu Oct 27 16:26:05 2022 ] 	Mean training loss: 0.0302.  Mean training acc: 99.63%.
[ Thu Oct 27 16:26:05 2022 ] 	Time consumption: [Data]07%, [Network]92%
[ Thu Oct 27 16:26:05 2022 ] Eval epoch: 84
[ Thu Oct 27 16:27:05 2022 ] 	Mean test loss of 796 batches: 0.5959799009861996.
[ Thu Oct 27 16:27:06 2022 ] 	Top1: 84.07%
[ Thu Oct 27 16:27:07 2022 ] 	Top5: 96.61%
[ Thu Oct 27 16:27:07 2022 ] Training epoch: 85
[ Thu Oct 27 16:30:13 2022 ] 	Mean training loss: 0.0301.  Mean training acc: 99.68%.
[ Thu Oct 27 16:30:13 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 16:30:13 2022 ] Eval epoch: 85
[ Thu Oct 27 16:31:09 2022 ] 	Mean test loss of 796 batches: 0.5923053561873621.
[ Thu Oct 27 16:31:10 2022 ] 	Top1: 84.19%
[ Thu Oct 27 16:31:11 2022 ] 	Top5: 96.55%
[ Thu Oct 27 16:31:11 2022 ] Training epoch: 86
[ Thu Oct 27 16:34:14 2022 ] 	Mean training loss: 0.0290.  Mean training acc: 99.67%.
[ Thu Oct 27 16:34:14 2022 ] 	Time consumption: [Data]08%, [Network]92%
[ Thu Oct 27 16:34:14 2022 ] Eval epoch: 86
[ Thu Oct 27 16:35:09 2022 ] 	Mean test loss of 796 batches: 0.5892932280411373.
[ Thu Oct 27 16:35:10 2022 ] 	Top1: 84.21%
[ Thu Oct 27 16:35:11 2022 ] 	Top5: 96.68%
[ Thu Oct 27 16:35:11 2022 ] Training epoch: 87
[ Thu Oct 27 16:38:19 2022 ] 	Mean training loss: 0.0295.  Mean training acc: 99.68%.
[ Thu Oct 27 16:38:19 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 16:38:19 2022 ] Eval epoch: 87
[ Thu Oct 27 16:39:14 2022 ] 	Mean test loss of 796 batches: 0.5965303429496012.
[ Thu Oct 27 16:39:15 2022 ] 	Top1: 84.10%
[ Thu Oct 27 16:39:15 2022 ] 	Top5: 96.59%
[ Thu Oct 27 16:39:16 2022 ] Training epoch: 88
[ Thu Oct 27 16:42:20 2022 ] 	Mean training loss: 0.0288.  Mean training acc: 99.66%.
[ Thu Oct 27 16:42:20 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 16:42:20 2022 ] Eval epoch: 88
[ Thu Oct 27 16:43:16 2022 ] 	Mean test loss of 796 batches: 0.5910000422192578.
[ Thu Oct 27 16:43:17 2022 ] 	Top1: 84.17%
[ Thu Oct 27 16:43:18 2022 ] 	Top5: 96.66%
[ Thu Oct 27 16:43:18 2022 ] Training epoch: 89
[ Thu Oct 27 16:46:23 2022 ] 	Mean training loss: 0.0274.  Mean training acc: 99.74%.
[ Thu Oct 27 16:46:23 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 16:46:23 2022 ] Eval epoch: 89
[ Thu Oct 27 16:47:20 2022 ] 	Mean test loss of 796 batches: 0.6009328437117326.
[ Thu Oct 27 16:47:21 2022 ] 	Top1: 83.98%
[ Thu Oct 27 16:47:22 2022 ] 	Top5: 96.58%
[ Thu Oct 27 16:47:22 2022 ] Training epoch: 90
[ Thu Oct 27 16:50:30 2022 ] 	Mean training loss: 0.0283.  Mean training acc: 99.71%.
[ Thu Oct 27 16:50:30 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 16:50:30 2022 ] Eval epoch: 90
[ Thu Oct 27 16:51:27 2022 ] 	Mean test loss of 796 batches: 0.5990447120076448.
[ Thu Oct 27 16:51:28 2022 ] 	Top1: 84.02%
[ Thu Oct 27 16:51:29 2022 ] 	Top5: 96.60%
[ Thu Oct 27 16:51:29 2022 ] Training epoch: 91
[ Thu Oct 27 16:54:35 2022 ] 	Mean training loss: 0.0274.  Mean training acc: 99.72%.
[ Thu Oct 27 16:54:35 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 16:54:35 2022 ] Eval epoch: 91
[ Thu Oct 27 16:55:32 2022 ] 	Mean test loss of 796 batches: 0.5964318248536906.
[ Thu Oct 27 16:55:34 2022 ] 	Top1: 84.05%
[ Thu Oct 27 16:55:35 2022 ] 	Top5: 96.64%
[ Thu Oct 27 16:55:35 2022 ] Training epoch: 92
[ Thu Oct 27 16:58:42 2022 ] 	Mean training loss: 0.0261.  Mean training acc: 99.76%.
[ Thu Oct 27 16:58:42 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 16:58:42 2022 ] Eval epoch: 92
[ Thu Oct 27 16:59:37 2022 ] 	Mean test loss of 796 batches: 0.5919949346193903.
[ Thu Oct 27 16:59:38 2022 ] 	Top1: 84.26%
[ Thu Oct 27 16:59:39 2022 ] 	Top5: 96.61%
[ Thu Oct 27 16:59:39 2022 ] Training epoch: 93
[ Thu Oct 27 17:02:45 2022 ] 	Mean training loss: 0.0254.  Mean training acc: 99.76%.
[ Thu Oct 27 17:02:45 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 17:02:45 2022 ] Eval epoch: 93
[ Thu Oct 27 17:03:45 2022 ] 	Mean test loss of 796 batches: 0.5926467826234261.
[ Thu Oct 27 17:03:45 2022 ] 	Top1: 84.09%
[ Thu Oct 27 17:03:46 2022 ] 	Top5: 96.64%
[ Thu Oct 27 17:03:47 2022 ] Training epoch: 94
[ Thu Oct 27 17:06:51 2022 ] 	Mean training loss: 0.0253.  Mean training acc: 99.79%.
[ Thu Oct 27 17:06:51 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:06:51 2022 ] Eval epoch: 94
[ Thu Oct 27 17:07:46 2022 ] 	Mean test loss of 796 batches: 0.5914423788158251.
[ Thu Oct 27 17:07:47 2022 ] 	Top1: 84.21%
[ Thu Oct 27 17:07:48 2022 ] 	Top5: 96.68%
[ Thu Oct 27 17:07:48 2022 ] Training epoch: 95
[ Thu Oct 27 17:10:53 2022 ] 	Mean training loss: 0.0246.  Mean training acc: 99.78%.
[ Thu Oct 27 17:10:53 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:10:53 2022 ] Eval epoch: 95
[ Thu Oct 27 17:11:49 2022 ] 	Mean test loss of 796 batches: 0.5893874815571585.
[ Thu Oct 27 17:11:50 2022 ] 	Top1: 84.23%
[ Thu Oct 27 17:11:51 2022 ] 	Top5: 96.68%
[ Thu Oct 27 17:11:51 2022 ] Training epoch: 96
[ Thu Oct 27 17:15:00 2022 ] 	Mean training loss: 0.0246.  Mean training acc: 99.78%.
[ Thu Oct 27 17:15:00 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:15:00 2022 ] Eval epoch: 96
[ Thu Oct 27 17:15:56 2022 ] 	Mean test loss of 796 batches: 0.5910411696932536.
[ Thu Oct 27 17:15:57 2022 ] 	Top1: 84.31%
[ Thu Oct 27 17:15:58 2022 ] 	Top5: 96.69%
[ Thu Oct 27 17:15:58 2022 ] Training epoch: 97
[ Thu Oct 27 17:19:02 2022 ] 	Mean training loss: 0.0247.  Mean training acc: 99.79%.
[ Thu Oct 27 17:19:02 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:19:02 2022 ] Eval epoch: 97
[ Thu Oct 27 17:19:58 2022 ] 	Mean test loss of 796 batches: 0.5919806242372897.
[ Thu Oct 27 17:19:59 2022 ] 	Top1: 84.17%
[ Thu Oct 27 17:20:01 2022 ] 	Top5: 96.68%
[ Thu Oct 27 17:20:01 2022 ] Training epoch: 98
[ Thu Oct 27 17:23:07 2022 ] 	Mean training loss: 0.0251.  Mean training acc: 99.77%.
[ Thu Oct 27 17:23:07 2022 ] 	Time consumption: [Data]10%, [Network]90%
[ Thu Oct 27 17:23:07 2022 ] Eval epoch: 98
[ Thu Oct 27 17:24:03 2022 ] 	Mean test loss of 796 batches: 0.5943466048902977.
[ Thu Oct 27 17:24:04 2022 ] 	Top1: 84.16%
[ Thu Oct 27 17:24:04 2022 ] 	Top5: 96.67%
[ Thu Oct 27 17:24:04 2022 ] Training epoch: 99
[ Thu Oct 27 17:27:11 2022 ] 	Mean training loss: 0.0241.  Mean training acc: 99.81%.
[ Thu Oct 27 17:27:11 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 17:27:11 2022 ] Eval epoch: 99
[ Thu Oct 27 17:28:06 2022 ] 	Mean test loss of 796 batches: 0.5935512074695235.
[ Thu Oct 27 17:28:07 2022 ] 	Top1: 84.24%
[ Thu Oct 27 17:28:08 2022 ] 	Top5: 96.66%
[ Thu Oct 27 17:28:08 2022 ] Training epoch: 100
[ Thu Oct 27 17:31:15 2022 ] 	Mean training loss: 0.0234.  Mean training acc: 99.80%.
[ Thu Oct 27 17:31:15 2022 ] 	Time consumption: [Data]10%, [Network]90%
[ Thu Oct 27 17:31:15 2022 ] Eval epoch: 100
[ Thu Oct 27 17:32:11 2022 ] 	Mean test loss of 796 batches: 0.5889655111577531.
[ Thu Oct 27 17:32:12 2022 ] 	Top1: 84.19%
[ Thu Oct 27 17:32:13 2022 ] 	Top5: 96.73%
[ Thu Oct 27 17:32:13 2022 ] Training epoch: 101
[ Thu Oct 27 17:35:19 2022 ] 	Mean training loss: 0.0249.  Mean training acc: 99.78%.
[ Thu Oct 27 17:35:19 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 17:35:19 2022 ] Eval epoch: 101
[ Thu Oct 27 17:36:15 2022 ] 	Mean test loss of 796 batches: 0.59233453276628.
[ Thu Oct 27 17:36:16 2022 ] 	Top1: 84.12%
[ Thu Oct 27 17:36:17 2022 ] 	Top5: 96.69%
[ Thu Oct 27 17:36:18 2022 ] Training epoch: 102
[ Thu Oct 27 17:39:22 2022 ] 	Mean training loss: 0.0244.  Mean training acc: 99.81%.
[ Thu Oct 27 17:39:22 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:39:22 2022 ] Eval epoch: 102
[ Thu Oct 27 17:40:19 2022 ] 	Mean test loss of 796 batches: 0.5881671675892743.
[ Thu Oct 27 17:40:20 2022 ] 	Top1: 84.33%
[ Thu Oct 27 17:40:22 2022 ] 	Top5: 96.71%
[ Thu Oct 27 17:40:22 2022 ] Training epoch: 103
[ Thu Oct 27 17:43:36 2022 ] 	Mean training loss: 0.0245.  Mean training acc: 99.77%.
[ Thu Oct 27 17:43:36 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 17:43:36 2022 ] Eval epoch: 103
[ Thu Oct 27 17:44:37 2022 ] 	Mean test loss of 796 batches: 0.5912358968088113.
[ Thu Oct 27 17:44:38 2022 ] 	Top1: 84.21%
[ Thu Oct 27 17:44:40 2022 ] 	Top5: 96.65%
[ Thu Oct 27 17:44:40 2022 ] Training epoch: 104
[ Thu Oct 27 17:47:59 2022 ] 	Mean training loss: 0.0236.  Mean training acc: 99.82%.
[ Thu Oct 27 17:47:59 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:47:59 2022 ] Eval epoch: 104
[ Thu Oct 27 17:49:00 2022 ] 	Mean test loss of 796 batches: 0.5916592552579341.
[ Thu Oct 27 17:49:02 2022 ] 	Top1: 84.12%
[ Thu Oct 27 17:49:04 2022 ] 	Top5: 96.66%
[ Thu Oct 27 17:49:04 2022 ] Training epoch: 105
[ Thu Oct 27 17:52:25 2022 ] 	Mean training loss: 0.0236.  Mean training acc: 99.82%.
[ Thu Oct 27 17:52:25 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:52:25 2022 ] Eval epoch: 105
[ Thu Oct 27 17:53:24 2022 ] 	Mean test loss of 796 batches: 0.5990852722687525.
[ Thu Oct 27 17:53:25 2022 ] 	Top1: 84.04%
[ Thu Oct 27 17:53:26 2022 ] 	Top5: 96.61%
[ Thu Oct 27 17:53:27 2022 ] Training epoch: 106
[ Thu Oct 27 17:56:41 2022 ] 	Mean training loss: 0.0230.  Mean training acc: 99.82%.
[ Thu Oct 27 17:56:41 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 17:56:41 2022 ] Eval epoch: 106
[ Thu Oct 27 17:57:42 2022 ] 	Mean test loss of 796 batches: 0.5941214060958419.
[ Thu Oct 27 17:57:43 2022 ] 	Top1: 84.14%
[ Thu Oct 27 17:57:44 2022 ] 	Top5: 96.65%
[ Thu Oct 27 17:57:44 2022 ] Training epoch: 107
[ Thu Oct 27 18:00:59 2022 ] 	Mean training loss: 0.0232.  Mean training acc: 99.82%.
[ Thu Oct 27 18:00:59 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 18:00:59 2022 ] Eval epoch: 107
[ Thu Oct 27 18:01:59 2022 ] 	Mean test loss of 796 batches: 0.5926308631616172.
[ Thu Oct 27 18:02:01 2022 ] 	Top1: 84.13%
[ Thu Oct 27 18:02:02 2022 ] 	Top5: 96.65%
[ Thu Oct 27 18:02:03 2022 ] Training epoch: 108
[ Thu Oct 27 18:05:21 2022 ] 	Mean training loss: 0.0226.  Mean training acc: 99.85%.
[ Thu Oct 27 18:05:21 2022 ] 	Time consumption: [Data]08%, [Network]91%
[ Thu Oct 27 18:05:21 2022 ] Eval epoch: 108
[ Thu Oct 27 18:06:24 2022 ] 	Mean test loss of 796 batches: 0.5861843898681802.
[ Thu Oct 27 18:06:25 2022 ] 	Top1: 84.32%
[ Thu Oct 27 18:06:26 2022 ] 	Top5: 96.69%
[ Thu Oct 27 18:06:26 2022 ] Training epoch: 109
[ Thu Oct 27 18:09:46 2022 ] 	Mean training loss: 0.0225.  Mean training acc: 99.83%.
[ Thu Oct 27 18:09:46 2022 ] 	Time consumption: [Data]09%, [Network]91%
[ Thu Oct 27 18:09:46 2022 ] Eval epoch: 109
[ Thu Oct 27 18:10:45 2022 ] 	Mean test loss of 796 batches: 0.5907206623581.
[ Thu Oct 27 18:10:46 2022 ] 	Top1: 84.24%
[ Thu Oct 27 18:10:47 2022 ] 	Top5: 96.67%
[ Thu Oct 27 18:10:47 2022 ] Training epoch: 110
[ Thu Oct 27 18:13:53 2022 ] 	Mean training loss: 0.0226.  Mean training acc: 99.82%.
[ Thu Oct 27 18:13:53 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 18:13:53 2022 ] Eval epoch: 110
[ Thu Oct 27 18:14:58 2022 ] 	Mean test loss of 796 batches: 0.5894861918378004.
[ Thu Oct 27 18:14:59 2022 ] 	Top1: 84.23%
[ Thu Oct 27 18:15:00 2022 ] 	Top5: 96.63%
[ Thu Oct 27 18:16:06 2022 ] Best accuracy: 0.8435161727449478
[ Thu Oct 27 18:16:06 2022 ] Epoch number: 83
[ Thu Oct 27 18:16:06 2022 ] Model name: work_dir/ntu120/csub/spherical_coord2
[ Thu Oct 27 18:16:06 2022 ] Model total number of params: 2108322
[ Thu Oct 27 18:16:06 2022 ] Weight decay: 0.0004
[ Thu Oct 27 18:16:06 2022 ] Base LR: 0.1
[ Thu Oct 27 18:16:06 2022 ] Batch Size: 64
[ Thu Oct 27 18:16:06 2022 ] Test Batch Size: 64
[ Thu Oct 27 18:16:06 2022 ] seed: 1
