[ Thu Jul 14 17:59:41 2022 ] using warm up, epoch: 5
[ Thu Jul 14 18:00:00 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod4', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod4/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module4.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Jul 14 18:00:00 2022 ] # Parameters: 2200114
[ Thu Jul 14 18:00:00 2022 ] Training epoch: 1
[ Thu Jul 14 18:03:09 2022 ] 	Mean training loss: 3.0905.  Mean training acc: 23.06%.
[ Thu Jul 14 18:03:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul 14 18:03:09 2022 ] Eval epoch: 1
[ Thu Jul 14 18:03:57 2022 ] 	Mean test loss of 796 batches: 2.5927421131625246.
[ Thu Jul 14 18:03:57 2022 ] 	Top1: 29.60%
[ Thu Jul 14 18:03:57 2022 ] 	Top5: 66.23%
[ Thu Jul 14 18:03:58 2022 ] Training epoch: 2
[ Thu Jul 14 18:07:06 2022 ] 	Mean training loss: 2.0755.  Mean training acc: 42.08%.
[ Thu Jul 14 18:07:06 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 18:07:06 2022 ] Eval epoch: 2
[ Thu Jul 14 18:07:57 2022 ] 	Mean test loss of 796 batches: 1.8702871108324683.
[ Thu Jul 14 18:07:58 2022 ] 	Top1: 46.55%
[ Thu Jul 14 18:07:58 2022 ] 	Top5: 80.41%
[ Thu Jul 14 18:07:58 2022 ] Training epoch: 3
[ Thu Jul 14 18:11:09 2022 ] 	Mean training loss: 1.6835.  Mean training acc: 51.48%.
[ Thu Jul 14 18:11:09 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 18:11:09 2022 ] Eval epoch: 3
[ Thu Jul 14 18:11:59 2022 ] 	Mean test loss of 796 batches: 1.7850360542386021.
[ Thu Jul 14 18:12:00 2022 ] 	Top1: 47.83%
[ Thu Jul 14 18:12:00 2022 ] 	Top5: 81.73%
[ Thu Jul 14 18:12:00 2022 ] Training epoch: 4
[ Thu Jul 14 18:15:11 2022 ] 	Mean training loss: 1.4567.  Mean training acc: 57.44%.
[ Thu Jul 14 18:15:11 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:15:11 2022 ] Eval epoch: 4
[ Thu Jul 14 18:16:00 2022 ] 	Mean test loss of 796 batches: 1.506466858425931.
[ Thu Jul 14 18:16:00 2022 ] 	Top1: 55.40%
[ Thu Jul 14 18:16:01 2022 ] 	Top5: 86.14%
[ Thu Jul 14 18:16:01 2022 ] Training epoch: 5
[ Thu Jul 14 18:19:10 2022 ] 	Mean training loss: 1.3083.  Mean training acc: 61.41%.
[ Thu Jul 14 18:19:10 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 18:19:10 2022 ] Eval epoch: 5
[ Thu Jul 14 18:20:00 2022 ] 	Mean test loss of 796 batches: 1.6045006975606457.
[ Thu Jul 14 18:20:01 2022 ] 	Top1: 55.05%
[ Thu Jul 14 18:20:01 2022 ] 	Top5: 85.21%
[ Thu Jul 14 18:20:01 2022 ] Training epoch: 6
[ Thu Jul 14 18:23:11 2022 ] 	Mean training loss: 1.1616.  Mean training acc: 65.36%.
[ Thu Jul 14 18:23:11 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 18:23:11 2022 ] Eval epoch: 6
[ Thu Jul 14 18:24:01 2022 ] 	Mean test loss of 796 batches: 1.3132735593384834.
[ Thu Jul 14 18:24:02 2022 ] 	Top1: 60.86%
[ Thu Jul 14 18:24:02 2022 ] 	Top5: 89.60%
[ Thu Jul 14 18:24:02 2022 ] Training epoch: 7
[ Thu Jul 14 18:27:12 2022 ] 	Mean training loss: 1.0873.  Mean training acc: 67.57%.
[ Thu Jul 14 18:27:12 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 18:27:12 2022 ] Eval epoch: 7
[ Thu Jul 14 18:28:04 2022 ] 	Mean test loss of 796 batches: 1.4250859293206852.
[ Thu Jul 14 18:28:05 2022 ] 	Top1: 59.19%
[ Thu Jul 14 18:28:05 2022 ] 	Top5: 87.97%
[ Thu Jul 14 18:28:05 2022 ] Training epoch: 8
[ Thu Jul 14 18:31:16 2022 ] 	Mean training loss: 1.0379.  Mean training acc: 68.95%.
[ Thu Jul 14 18:31:16 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:31:16 2022 ] Eval epoch: 8
[ Thu Jul 14 18:32:08 2022 ] 	Mean test loss of 796 batches: 1.2585165857070655.
[ Thu Jul 14 18:32:09 2022 ] 	Top1: 64.30%
[ Thu Jul 14 18:32:09 2022 ] 	Top5: 88.63%
[ Thu Jul 14 18:32:09 2022 ] Training epoch: 9
[ Thu Jul 14 18:35:21 2022 ] 	Mean training loss: 0.9959.  Mean training acc: 70.21%.
[ Thu Jul 14 18:35:21 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:35:21 2022 ] Eval epoch: 9
[ Thu Jul 14 18:36:13 2022 ] 	Mean test loss of 796 batches: 1.5278992185640574.
[ Thu Jul 14 18:36:13 2022 ] 	Top1: 58.76%
[ Thu Jul 14 18:36:14 2022 ] 	Top5: 87.20%
[ Thu Jul 14 18:36:14 2022 ] Training epoch: 10
[ Thu Jul 14 18:39:25 2022 ] 	Mean training loss: 0.9632.  Mean training acc: 70.95%.
[ Thu Jul 14 18:39:25 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:39:25 2022 ] Eval epoch: 10
[ Thu Jul 14 18:40:16 2022 ] 	Mean test loss of 796 batches: 1.1798566075126131.
[ Thu Jul 14 18:40:16 2022 ] 	Top1: 65.26%
[ Thu Jul 14 18:40:16 2022 ] 	Top5: 90.72%
[ Thu Jul 14 18:40:17 2022 ] Training epoch: 11
[ Thu Jul 14 18:43:28 2022 ] 	Mean training loss: 0.9400.  Mean training acc: 71.66%.
[ Thu Jul 14 18:43:28 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:43:28 2022 ] Eval epoch: 11
[ Thu Jul 14 18:44:19 2022 ] 	Mean test loss of 796 batches: 1.1787967473343388.
[ Thu Jul 14 18:44:19 2022 ] 	Top1: 64.70%
[ Thu Jul 14 18:44:20 2022 ] 	Top5: 90.74%
[ Thu Jul 14 18:44:20 2022 ] Training epoch: 12
[ Thu Jul 14 18:47:31 2022 ] 	Mean training loss: 0.9197.  Mean training acc: 72.07%.
[ Thu Jul 14 18:47:31 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:47:31 2022 ] Eval epoch: 12
[ Thu Jul 14 18:48:20 2022 ] 	Mean test loss of 796 batches: 1.1535313008867916.
[ Thu Jul 14 18:48:20 2022 ] 	Top1: 65.78%
[ Thu Jul 14 18:48:20 2022 ] 	Top5: 91.22%
[ Thu Jul 14 18:48:21 2022 ] Training epoch: 13
[ Thu Jul 14 18:51:31 2022 ] 	Mean training loss: 0.9052.  Mean training acc: 72.65%.
[ Thu Jul 14 18:51:31 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:51:31 2022 ] Eval epoch: 13
[ Thu Jul 14 18:52:21 2022 ] 	Mean test loss of 796 batches: 1.1188882316401856.
[ Thu Jul 14 18:52:21 2022 ] 	Top1: 67.53%
[ Thu Jul 14 18:52:22 2022 ] 	Top5: 91.50%
[ Thu Jul 14 18:52:22 2022 ] Training epoch: 14
[ Thu Jul 14 18:55:33 2022 ] 	Mean training loss: 0.8875.  Mean training acc: 73.15%.
[ Thu Jul 14 18:55:33 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 18:55:33 2022 ] Eval epoch: 14
[ Thu Jul 14 18:56:25 2022 ] 	Mean test loss of 796 batches: 1.1399516464028525.
[ Thu Jul 14 18:56:25 2022 ] 	Top1: 67.18%
[ Thu Jul 14 18:56:26 2022 ] 	Top5: 90.62%
[ Thu Jul 14 18:56:26 2022 ] Training epoch: 15
[ Thu Jul 14 18:59:37 2022 ] 	Mean training loss: 0.8785.  Mean training acc: 73.50%.
[ Thu Jul 14 18:59:37 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 18:59:37 2022 ] Eval epoch: 15
[ Thu Jul 14 19:00:29 2022 ] 	Mean test loss of 796 batches: 1.0646549506702614.
[ Thu Jul 14 19:00:29 2022 ] 	Top1: 68.39%
[ Thu Jul 14 19:00:30 2022 ] 	Top5: 91.71%
[ Thu Jul 14 19:00:30 2022 ] Training epoch: 16
[ Thu Jul 14 19:03:42 2022 ] 	Mean training loss: 0.8625.  Mean training acc: 74.01%.
[ Thu Jul 14 19:03:42 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 19:03:42 2022 ] Eval epoch: 16
[ Thu Jul 14 19:04:33 2022 ] 	Mean test loss of 796 batches: 1.075241678324177.
[ Thu Jul 14 19:04:33 2022 ] 	Top1: 68.22%
[ Thu Jul 14 19:04:34 2022 ] 	Top5: 91.71%
[ Thu Jul 14 19:04:34 2022 ] Training epoch: 17
[ Thu Jul 14 19:07:44 2022 ] 	Mean training loss: 0.8562.  Mean training acc: 73.96%.
[ Thu Jul 14 19:07:44 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 19:07:44 2022 ] Eval epoch: 17
[ Thu Jul 14 19:08:36 2022 ] 	Mean test loss of 796 batches: 1.1172784653740313.
[ Thu Jul 14 19:08:36 2022 ] 	Top1: 66.70%
[ Thu Jul 14 19:08:37 2022 ] 	Top5: 91.82%
[ Thu Jul 14 19:08:37 2022 ] Training epoch: 18
[ Thu Jul 14 19:11:48 2022 ] 	Mean training loss: 0.8449.  Mean training acc: 74.28%.
[ Thu Jul 14 19:11:48 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 19:11:48 2022 ] Eval epoch: 18
[ Thu Jul 14 19:12:37 2022 ] 	Mean test loss of 796 batches: 1.1731686582367624.
[ Thu Jul 14 19:12:37 2022 ] 	Top1: 66.58%
[ Thu Jul 14 19:12:38 2022 ] 	Top5: 91.23%
[ Thu Jul 14 19:12:38 2022 ] Training epoch: 19
[ Thu Jul 14 19:15:47 2022 ] 	Mean training loss: 0.8373.  Mean training acc: 74.72%.
[ Thu Jul 14 19:15:47 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:15:47 2022 ] Eval epoch: 19
[ Thu Jul 14 19:16:36 2022 ] 	Mean test loss of 796 batches: 1.0446841324768474.
[ Thu Jul 14 19:16:36 2022 ] 	Top1: 69.53%
[ Thu Jul 14 19:16:37 2022 ] 	Top5: 92.26%
[ Thu Jul 14 19:16:37 2022 ] Training epoch: 20
[ Thu Jul 14 19:19:46 2022 ] 	Mean training loss: 0.8387.  Mean training acc: 74.90%.
[ Thu Jul 14 19:19:46 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:19:46 2022 ] Eval epoch: 20
[ Thu Jul 14 19:20:34 2022 ] 	Mean test loss of 796 batches: 1.1262895970338553.
[ Thu Jul 14 19:20:35 2022 ] 	Top1: 67.35%
[ Thu Jul 14 19:20:35 2022 ] 	Top5: 91.75%
[ Thu Jul 14 19:20:35 2022 ] Training epoch: 21
[ Thu Jul 14 19:23:44 2022 ] 	Mean training loss: 0.8321.  Mean training acc: 74.82%.
[ Thu Jul 14 19:23:44 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:23:44 2022 ] Eval epoch: 21
[ Thu Jul 14 19:24:50 2022 ] 	Mean test loss of 796 batches: 1.0586239197970035.
[ Thu Jul 14 19:24:50 2022 ] 	Top1: 68.84%
[ Thu Jul 14 19:24:51 2022 ] 	Top5: 91.56%
[ Thu Jul 14 19:24:51 2022 ] Training epoch: 22
[ Thu Jul 14 19:29:26 2022 ] 	Mean training loss: 0.8221.  Mean training acc: 75.06%.
[ Thu Jul 14 19:29:26 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:29:26 2022 ] Eval epoch: 22
[ Thu Jul 14 19:30:37 2022 ] 	Mean test loss of 796 batches: 1.0914804498903716.
[ Thu Jul 14 19:30:38 2022 ] 	Top1: 68.01%
[ Thu Jul 14 19:30:38 2022 ] 	Top5: 91.88%
[ Thu Jul 14 19:30:38 2022 ] Training epoch: 23
[ Thu Jul 14 19:35:10 2022 ] 	Mean training loss: 0.8241.  Mean training acc: 74.90%.
[ Thu Jul 14 19:35:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul 14 19:35:10 2022 ] Eval epoch: 23
[ Thu Jul 14 19:36:18 2022 ] 	Mean test loss of 796 batches: 0.997745192867128.
[ Thu Jul 14 19:36:19 2022 ] 	Top1: 69.93%
[ Thu Jul 14 19:36:19 2022 ] 	Top5: 93.08%
[ Thu Jul 14 19:36:19 2022 ] Training epoch: 24
[ Thu Jul 14 19:41:04 2022 ] 	Mean training loss: 0.8159.  Mean training acc: 75.24%.
[ Thu Jul 14 19:41:04 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:41:04 2022 ] Eval epoch: 24
[ Thu Jul 14 19:42:14 2022 ] 	Mean test loss of 796 batches: 1.1390685976375288.
[ Thu Jul 14 19:42:15 2022 ] 	Top1: 68.07%
[ Thu Jul 14 19:42:15 2022 ] 	Top5: 91.72%
[ Thu Jul 14 19:42:15 2022 ] Training epoch: 25
[ Thu Jul 14 19:47:11 2022 ] 	Mean training loss: 0.8074.  Mean training acc: 75.41%.
[ Thu Jul 14 19:47:11 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:47:11 2022 ] Eval epoch: 25
[ Thu Jul 14 19:48:25 2022 ] 	Mean test loss of 796 batches: 1.0294985786904043.
[ Thu Jul 14 19:48:25 2022 ] 	Top1: 70.00%
[ Thu Jul 14 19:48:26 2022 ] 	Top5: 92.28%
[ Thu Jul 14 19:48:26 2022 ] Training epoch: 26
[ Thu Jul 14 19:53:26 2022 ] 	Mean training loss: 0.8097.  Mean training acc: 75.24%.
[ Thu Jul 14 19:53:26 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:53:26 2022 ] Eval epoch: 26
[ Thu Jul 14 19:54:43 2022 ] 	Mean test loss of 796 batches: 1.1359576826269304.
[ Thu Jul 14 19:54:43 2022 ] 	Top1: 66.61%
[ Thu Jul 14 19:54:44 2022 ] 	Top5: 91.57%
[ Thu Jul 14 19:54:44 2022 ] Training epoch: 27
[ Thu Jul 14 19:59:39 2022 ] 	Mean training loss: 0.8061.  Mean training acc: 75.48%.
[ Thu Jul 14 19:59:39 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 19:59:39 2022 ] Eval epoch: 27
[ Thu Jul 14 20:01:01 2022 ] 	Mean test loss of 796 batches: 1.035319479715884.
[ Thu Jul 14 20:01:01 2022 ] 	Top1: 69.97%
[ Thu Jul 14 20:01:02 2022 ] 	Top5: 92.13%
[ Thu Jul 14 20:01:02 2022 ] Training epoch: 28
[ Thu Jul 14 20:06:14 2022 ] 	Mean training loss: 0.8055.  Mean training acc: 75.48%.
[ Thu Jul 14 20:06:15 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 20:06:15 2022 ] Eval epoch: 28
[ Thu Jul 14 20:07:28 2022 ] 	Mean test loss of 796 batches: 1.0080391775124038.
[ Thu Jul 14 20:07:29 2022 ] 	Top1: 70.15%
[ Thu Jul 14 20:07:29 2022 ] 	Top5: 92.67%
[ Thu Jul 14 20:07:29 2022 ] Training epoch: 29
[ Thu Jul 14 20:12:35 2022 ] 	Mean training loss: 0.8104.  Mean training acc: 75.37%.
[ Thu Jul 14 20:12:35 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 20:12:35 2022 ] Eval epoch: 29
[ Thu Jul 14 20:13:56 2022 ] 	Mean test loss of 796 batches: 1.0268735355842653.
[ Thu Jul 14 20:13:57 2022 ] 	Top1: 69.96%
[ Thu Jul 14 20:13:57 2022 ] 	Top5: 92.22%
[ Thu Jul 14 20:13:57 2022 ] Training epoch: 30
[ Thu Jul 14 20:18:59 2022 ] 	Mean training loss: 0.7926.  Mean training acc: 75.88%.
[ Thu Jul 14 20:18:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 20:18:59 2022 ] Eval epoch: 30
[ Thu Jul 14 20:20:22 2022 ] 	Mean test loss of 796 batches: 1.1947994530575359.
[ Thu Jul 14 20:20:22 2022 ] 	Top1: 66.47%
[ Thu Jul 14 20:20:23 2022 ] 	Top5: 91.05%
[ Thu Jul 14 20:20:23 2022 ] Training epoch: 31
[ Thu Jul 14 20:25:31 2022 ] 	Mean training loss: 0.7933.  Mean training acc: 75.73%.
[ Thu Jul 14 20:25:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 20:25:31 2022 ] Eval epoch: 31
[ Thu Jul 14 20:26:44 2022 ] 	Mean test loss of 796 batches: 1.1022082840902123.
[ Thu Jul 14 20:26:45 2022 ] 	Top1: 69.46%
[ Thu Jul 14 20:26:45 2022 ] 	Top5: 91.68%
[ Thu Jul 14 20:26:45 2022 ] Training epoch: 32
[ Thu Jul 14 20:32:01 2022 ] 	Mean training loss: 0.7979.  Mean training acc: 75.77%.
[ Thu Jul 14 20:32:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 20:32:01 2022 ] Eval epoch: 32
[ Thu Jul 14 20:33:21 2022 ] 	Mean test loss of 796 batches: 1.0503745842444239.
[ Thu Jul 14 20:33:22 2022 ] 	Top1: 69.06%
[ Thu Jul 14 20:33:22 2022 ] 	Top5: 91.82%
[ Thu Jul 14 20:33:22 2022 ] Training epoch: 33
[ Thu Jul 14 20:38:37 2022 ] 	Mean training loss: 0.7929.  Mean training acc: 75.79%.
[ Thu Jul 14 20:38:37 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 20:38:37 2022 ] Eval epoch: 33
[ Thu Jul 14 20:40:03 2022 ] 	Mean test loss of 796 batches: 1.2240579046271554.
[ Thu Jul 14 20:40:03 2022 ] 	Top1: 65.09%
[ Thu Jul 14 20:40:03 2022 ] 	Top5: 91.29%
[ Thu Jul 14 20:40:04 2022 ] Training epoch: 34
[ Thu Jul 14 20:45:17 2022 ] 	Mean training loss: 0.7887.  Mean training acc: 76.03%.
[ Thu Jul 14 20:45:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 20:45:17 2022 ] Eval epoch: 34
[ Thu Jul 14 20:46:37 2022 ] 	Mean test loss of 796 batches: 1.0783303813943312.
[ Thu Jul 14 20:46:37 2022 ] 	Top1: 68.60%
[ Thu Jul 14 20:46:38 2022 ] 	Top5: 92.59%
[ Thu Jul 14 20:46:38 2022 ] Training epoch: 35
[ Thu Jul 14 20:51:58 2022 ] 	Mean training loss: 0.7879.  Mean training acc: 75.95%.
[ Thu Jul 14 20:51:58 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 20:51:58 2022 ] Eval epoch: 35
[ Thu Jul 14 20:53:25 2022 ] 	Mean test loss of 796 batches: 1.149402890822396.
[ Thu Jul 14 20:53:25 2022 ] 	Top1: 66.31%
[ Thu Jul 14 20:53:25 2022 ] 	Top5: 91.16%
[ Thu Jul 14 20:53:25 2022 ] Training epoch: 36
[ Thu Jul 14 20:58:50 2022 ] 	Mean training loss: 0.4493.  Mean training acc: 86.06%.
[ Thu Jul 14 20:58:50 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 20:58:50 2022 ] Eval epoch: 36
[ Thu Jul 14 21:00:19 2022 ] 	Mean test loss of 796 batches: 0.6050791264834565.
[ Thu Jul 14 21:00:19 2022 ] 	Top1: 81.32%
[ Thu Jul 14 21:00:20 2022 ] 	Top5: 96.44%
[ Thu Jul 14 21:00:20 2022 ] Training epoch: 37
[ Thu Jul 14 21:05:41 2022 ] 	Mean training loss: 0.3622.  Mean training acc: 88.51%.
[ Thu Jul 14 21:05:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Thu Jul 14 21:05:41 2022 ] Eval epoch: 37
[ Thu Jul 14 21:07:06 2022 ] 	Mean test loss of 796 batches: 0.6077798336706869.
[ Thu Jul 14 21:07:07 2022 ] 	Top1: 81.45%
[ Thu Jul 14 21:07:07 2022 ] 	Top5: 96.47%
[ Thu Jul 14 21:07:07 2022 ] Training epoch: 38
[ Thu Jul 14 21:12:29 2022 ] 	Mean training loss: 0.3254.  Mean training acc: 89.79%.
[ Thu Jul 14 21:12:29 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 21:12:29 2022 ] Eval epoch: 38
[ Thu Jul 14 21:13:47 2022 ] 	Mean test loss of 796 batches: 0.5908318653693376.
[ Thu Jul 14 21:13:47 2022 ] 	Top1: 82.02%
[ Thu Jul 14 21:13:48 2022 ] 	Top5: 96.70%
[ Thu Jul 14 21:13:48 2022 ] Training epoch: 39
[ Thu Jul 14 21:19:06 2022 ] 	Mean training loss: 0.3005.  Mean training acc: 90.48%.
[ Thu Jul 14 21:19:06 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 21:19:06 2022 ] Eval epoch: 39
[ Thu Jul 14 21:20:31 2022 ] 	Mean test loss of 796 batches: 0.6066786992602312.
[ Thu Jul 14 21:20:31 2022 ] 	Top1: 81.76%
[ Thu Jul 14 21:20:32 2022 ] 	Top5: 96.57%
[ Thu Jul 14 21:20:32 2022 ] Training epoch: 40
[ Thu Jul 14 21:26:00 2022 ] 	Mean training loss: 0.2781.  Mean training acc: 91.39%.
[ Thu Jul 14 21:26:00 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 21:26:00 2022 ] Eval epoch: 40
[ Thu Jul 14 21:27:30 2022 ] 	Mean test loss of 796 batches: 0.5944342142130112.
[ Thu Jul 14 21:27:30 2022 ] 	Top1: 82.21%
[ Thu Jul 14 21:27:31 2022 ] 	Top5: 96.68%
[ Thu Jul 14 21:27:31 2022 ] Training epoch: 41
[ Thu Jul 14 21:32:59 2022 ] 	Mean training loss: 0.2630.  Mean training acc: 91.73%.
[ Thu Jul 14 21:32:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 21:32:59 2022 ] Eval epoch: 41
[ Thu Jul 14 21:34:28 2022 ] 	Mean test loss of 796 batches: 0.6140233276402531.
[ Thu Jul 14 21:34:28 2022 ] 	Top1: 82.06%
[ Thu Jul 14 21:34:28 2022 ] 	Top5: 96.45%
[ Thu Jul 14 21:34:28 2022 ] Training epoch: 42
[ Thu Jul 14 21:39:50 2022 ] 	Mean training loss: 0.2486.  Mean training acc: 92.23%.
[ Thu Jul 14 21:39:50 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 21:39:50 2022 ] Eval epoch: 42
[ Thu Jul 14 21:41:15 2022 ] 	Mean test loss of 796 batches: 0.6309281701980224.
[ Thu Jul 14 21:41:16 2022 ] 	Top1: 81.82%
[ Thu Jul 14 21:41:16 2022 ] 	Top5: 96.48%
[ Thu Jul 14 21:41:16 2022 ] Training epoch: 43
[ Thu Jul 14 21:46:28 2022 ] 	Mean training loss: 0.2361.  Mean training acc: 92.68%.
[ Thu Jul 14 21:46:28 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 21:46:28 2022 ] Eval epoch: 43
[ Thu Jul 14 21:47:53 2022 ] 	Mean test loss of 796 batches: 0.6642549738531286.
[ Thu Jul 14 21:47:53 2022 ] 	Top1: 81.28%
[ Thu Jul 14 21:47:54 2022 ] 	Top5: 96.24%
[ Thu Jul 14 21:47:54 2022 ] Training epoch: 44
[ Thu Jul 14 21:53:17 2022 ] 	Mean training loss: 0.2239.  Mean training acc: 92.94%.
[ Thu Jul 14 21:53:17 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 21:53:17 2022 ] Eval epoch: 44
[ Thu Jul 14 21:54:41 2022 ] 	Mean test loss of 796 batches: 0.673802231073417.
[ Thu Jul 14 21:54:41 2022 ] 	Top1: 81.02%
[ Thu Jul 14 21:54:41 2022 ] 	Top5: 96.13%
[ Thu Jul 14 21:54:42 2022 ] Training epoch: 45
[ Thu Jul 14 22:00:13 2022 ] 	Mean training loss: 0.2191.  Mean training acc: 93.13%.
[ Thu Jul 14 22:00:13 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jul 14 22:00:13 2022 ] Eval epoch: 45
[ Thu Jul 14 22:01:40 2022 ] 	Mean test loss of 796 batches: 0.6670564617446844.
[ Thu Jul 14 22:01:41 2022 ] 	Top1: 81.44%
[ Thu Jul 14 22:01:41 2022 ] 	Top5: 96.16%
[ Thu Jul 14 22:01:41 2022 ] Training epoch: 46
[ Thu Jul 14 22:05:06 2022 ] 	Mean training loss: 0.2138.  Mean training acc: 93.41%.
[ Thu Jul 14 22:05:06 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:05:06 2022 ] Eval epoch: 46
[ Thu Jul 14 22:05:56 2022 ] 	Mean test loss of 796 batches: 0.6684807294034328.
[ Thu Jul 14 22:05:57 2022 ] 	Top1: 81.13%
[ Thu Jul 14 22:05:57 2022 ] 	Top5: 96.25%
[ Thu Jul 14 22:05:58 2022 ] Training epoch: 47
[ Thu Jul 14 22:09:09 2022 ] 	Mean training loss: 0.2086.  Mean training acc: 93.56%.
[ Thu Jul 14 22:09:09 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:09:10 2022 ] Eval epoch: 47
[ Thu Jul 14 22:10:02 2022 ] 	Mean test loss of 796 batches: 0.6863076835964343.
[ Thu Jul 14 22:10:02 2022 ] 	Top1: 80.88%
[ Thu Jul 14 22:10:03 2022 ] 	Top5: 96.01%
[ Thu Jul 14 22:10:03 2022 ] Training epoch: 48
[ Thu Jul 14 22:13:15 2022 ] 	Mean training loss: 0.2054.  Mean training acc: 93.65%.
[ Thu Jul 14 22:13:15 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:13:15 2022 ] Eval epoch: 48
[ Thu Jul 14 22:14:06 2022 ] 	Mean test loss of 796 batches: 0.6899333226414931.
[ Thu Jul 14 22:14:06 2022 ] 	Top1: 80.89%
[ Thu Jul 14 22:14:07 2022 ] 	Top5: 96.04%
[ Thu Jul 14 22:14:07 2022 ] Training epoch: 49
[ Thu Jul 14 22:17:18 2022 ] 	Mean training loss: 0.2006.  Mean training acc: 93.78%.
[ Thu Jul 14 22:17:18 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:17:18 2022 ] Eval epoch: 49
[ Thu Jul 14 22:18:09 2022 ] 	Mean test loss of 796 batches: 0.713673853661734.
[ Thu Jul 14 22:18:10 2022 ] 	Top1: 80.69%
[ Thu Jul 14 22:18:10 2022 ] 	Top5: 95.96%
[ Thu Jul 14 22:18:10 2022 ] Training epoch: 50
[ Thu Jul 14 22:21:21 2022 ] 	Mean training loss: 0.1982.  Mean training acc: 93.76%.
[ Thu Jul 14 22:21:21 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:21:21 2022 ] Eval epoch: 50
[ Thu Jul 14 22:22:10 2022 ] 	Mean test loss of 796 batches: 0.7150451968325742.
[ Thu Jul 14 22:22:10 2022 ] 	Top1: 80.28%
[ Thu Jul 14 22:22:11 2022 ] 	Top5: 95.96%
[ Thu Jul 14 22:22:11 2022 ] Training epoch: 51
[ Thu Jul 14 22:25:20 2022 ] 	Mean training loss: 0.1977.  Mean training acc: 93.88%.
[ Thu Jul 14 22:25:20 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 22:25:20 2022 ] Eval epoch: 51
[ Thu Jul 14 22:26:11 2022 ] 	Mean test loss of 796 batches: 0.7243140514041461.
[ Thu Jul 14 22:26:11 2022 ] 	Top1: 80.09%
[ Thu Jul 14 22:26:11 2022 ] 	Top5: 95.78%
[ Thu Jul 14 22:26:11 2022 ] Training epoch: 52
[ Thu Jul 14 22:29:23 2022 ] 	Mean training loss: 0.1976.  Mean training acc: 93.85%.
[ Thu Jul 14 22:29:23 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:29:23 2022 ] Eval epoch: 52
[ Thu Jul 14 22:30:13 2022 ] 	Mean test loss of 796 batches: 0.7704088182548932.
[ Thu Jul 14 22:30:13 2022 ] 	Top1: 79.44%
[ Thu Jul 14 22:30:14 2022 ] 	Top5: 95.39%
[ Thu Jul 14 22:30:14 2022 ] Training epoch: 53
[ Thu Jul 14 22:33:23 2022 ] 	Mean training loss: 0.1973.  Mean training acc: 93.85%.
[ Thu Jul 14 22:33:23 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 22:33:24 2022 ] Eval epoch: 53
[ Thu Jul 14 22:34:14 2022 ] 	Mean test loss of 796 batches: 0.7570587288700605.
[ Thu Jul 14 22:34:14 2022 ] 	Top1: 79.60%
[ Thu Jul 14 22:34:15 2022 ] 	Top5: 95.61%
[ Thu Jul 14 22:34:15 2022 ] Training epoch: 54
[ Thu Jul 14 22:37:29 2022 ] 	Mean training loss: 0.1957.  Mean training acc: 94.00%.
[ Thu Jul 14 22:37:29 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Thu Jul 14 22:37:29 2022 ] Eval epoch: 54
[ Thu Jul 14 22:38:20 2022 ] 	Mean test loss of 796 batches: 0.7506330471635614.
[ Thu Jul 14 22:38:20 2022 ] 	Top1: 80.06%
[ Thu Jul 14 22:38:21 2022 ] 	Top5: 95.67%
[ Thu Jul 14 22:38:21 2022 ] Training epoch: 55
[ Thu Jul 14 22:41:34 2022 ] 	Mean training loss: 0.1932.  Mean training acc: 93.98%.
[ Thu Jul 14 22:41:34 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:41:34 2022 ] Eval epoch: 55
[ Thu Jul 14 22:42:25 2022 ] 	Mean test loss of 796 batches: 0.7837993253078592.
[ Thu Jul 14 22:42:26 2022 ] 	Top1: 79.22%
[ Thu Jul 14 22:42:26 2022 ] 	Top5: 94.92%
[ Thu Jul 14 22:42:26 2022 ] Training epoch: 56
[ Thu Jul 14 22:45:35 2022 ] 	Mean training loss: 0.1138.  Mean training acc: 96.91%.
[ Thu Jul 14 22:45:35 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 22:45:35 2022 ] Eval epoch: 56
[ Thu Jul 14 22:46:23 2022 ] 	Mean test loss of 796 batches: 0.6572207064840512.
[ Thu Jul 14 22:46:24 2022 ] 	Top1: 82.32%
[ Thu Jul 14 22:46:24 2022 ] 	Top5: 96.42%
[ Thu Jul 14 22:46:24 2022 ] Training epoch: 57
[ Thu Jul 14 22:49:35 2022 ] 	Mean training loss: 0.0830.  Mean training acc: 97.99%.
[ Thu Jul 14 22:49:35 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Thu Jul 14 22:49:35 2022 ] Eval epoch: 57
[ Thu Jul 14 22:50:25 2022 ] 	Mean test loss of 796 batches: 0.6664466831468083.
[ Thu Jul 14 22:50:25 2022 ] 	Top1: 82.22%
[ Thu Jul 14 22:50:26 2022 ] 	Top5: 96.25%
[ Thu Jul 14 22:50:26 2022 ] Training epoch: 58
[ Thu Jul 14 22:53:36 2022 ] 	Mean training loss: 0.0743.  Mean training acc: 98.24%.
[ Thu Jul 14 22:53:36 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 22:53:36 2022 ] Eval epoch: 58
[ Thu Jul 14 22:54:27 2022 ] 	Mean test loss of 796 batches: 0.6571205055350484.
[ Thu Jul 14 22:54:27 2022 ] 	Top1: 82.52%
[ Thu Jul 14 22:54:28 2022 ] 	Top5: 96.38%
[ Thu Jul 14 22:54:28 2022 ] Training epoch: 59
[ Thu Jul 14 22:57:39 2022 ] 	Mean training loss: 0.0677.  Mean training acc: 98.39%.
[ Thu Jul 14 22:57:39 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 22:57:39 2022 ] Eval epoch: 59
[ Thu Jul 14 22:58:31 2022 ] 	Mean test loss of 796 batches: 0.6687747234263313.
[ Thu Jul 14 22:58:32 2022 ] 	Top1: 82.43%
[ Thu Jul 14 22:58:33 2022 ] 	Top5: 96.28%
[ Thu Jul 14 22:58:33 2022 ] Training epoch: 60
[ Thu Jul 14 23:01:45 2022 ] 	Mean training loss: 0.0632.  Mean training acc: 98.52%.
[ Thu Jul 14 23:01:45 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 23:01:46 2022 ] Eval epoch: 60
[ Thu Jul 14 23:02:36 2022 ] 	Mean test loss of 796 batches: 0.6689765553678101.
[ Thu Jul 14 23:02:36 2022 ] 	Top1: 82.52%
[ Thu Jul 14 23:02:37 2022 ] 	Top5: 96.33%
[ Thu Jul 14 23:02:37 2022 ] Training epoch: 61
[ Thu Jul 14 23:05:49 2022 ] 	Mean training loss: 0.0592.  Mean training acc: 98.64%.
[ Thu Jul 14 23:05:49 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 23:05:49 2022 ] Eval epoch: 61
[ Thu Jul 14 23:06:39 2022 ] 	Mean test loss of 796 batches: 0.6721325690984427.
[ Thu Jul 14 23:06:40 2022 ] 	Top1: 82.53%
[ Thu Jul 14 23:06:40 2022 ] 	Top5: 96.33%
[ Thu Jul 14 23:06:40 2022 ] Training epoch: 62
[ Thu Jul 14 23:09:51 2022 ] 	Mean training loss: 0.0564.  Mean training acc: 98.75%.
[ Thu Jul 14 23:09:51 2022 ] 	Time consumption: [Data]04%, [Network]96%
[ Thu Jul 14 23:09:51 2022 ] Eval epoch: 62
[ Thu Jul 14 23:10:40 2022 ] 	Mean test loss of 796 batches: 0.6781337250810322.
[ Thu Jul 14 23:10:41 2022 ] 	Top1: 82.45%
[ Thu Jul 14 23:10:41 2022 ] 	Top5: 96.28%
[ Thu Jul 14 23:10:41 2022 ] Training epoch: 63
[ Thu Jul 14 23:13:53 2022 ] 	Mean training loss: 0.0541.  Mean training acc: 98.79%.
[ Thu Jul 14 23:13:53 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 23:13:53 2022 ] Eval epoch: 63
[ Thu Jul 14 23:14:42 2022 ] 	Mean test loss of 796 batches: 0.6903637286893387.
[ Thu Jul 14 23:14:43 2022 ] 	Top1: 82.34%
[ Thu Jul 14 23:14:43 2022 ] 	Top5: 96.16%
[ Thu Jul 14 23:14:43 2022 ] Training epoch: 64
[ Thu Jul 14 23:17:54 2022 ] 	Mean training loss: 0.0512.  Mean training acc: 98.90%.
[ Thu Jul 14 23:17:54 2022 ] 	Time consumption: [Data]04%, [Network]95%
[ Thu Jul 14 23:17:55 2022 ] Eval epoch: 64
[ Thu Jul 14 23:18:46 2022 ] 	Mean test loss of 796 batches: 0.6892686490924215.
[ Thu Jul 14 23:18:46 2022 ] 	Top1: 82.41%
[ Thu Jul 14 23:18:47 2022 ] 	Top5: 96.17%
[ Thu Jul 14 23:18:47 2022 ] Training epoch: 65
[ Thu Jul 14 23:22:02 2022 ] 	Mean training loss: 0.0493.  Mean training acc: 98.98%.
[ Thu Jul 14 23:22:02 2022 ] 	Time consumption: [Data]05%, [Network]94%
[ Thu Jul 14 23:22:02 2022 ] Eval epoch: 65
[ Thu Jul 14 23:22:55 2022 ] 	Mean test loss of 796 batches: 0.6894205139116876.
[ Thu Jul 14 23:22:56 2022 ] 	Top1: 82.39%
[ Thu Jul 14 23:22:56 2022 ] 	Top5: 96.12%
[ Thu Jul 14 23:23:52 2022 ] Best accuracy: 0.8252715096525854
[ Thu Jul 14 23:23:52 2022 ] Epoch number: 61
[ Thu Jul 14 23:23:52 2022 ] Model name: work_dir/ntu120/csub/sym_mod4
[ Thu Jul 14 23:23:52 2022 ] Model total number of params: 2200114
[ Thu Jul 14 23:23:52 2022 ] Weight decay: 0.0004
[ Thu Jul 14 23:23:52 2022 ] Base LR: 0.1
[ Thu Jul 14 23:23:52 2022 ] Batch Size: 64
[ Thu Jul 14 23:23:52 2022 ] Test Batch Size: 64
[ Thu Jul 14 23:23:52 2022 ] seed: 1
