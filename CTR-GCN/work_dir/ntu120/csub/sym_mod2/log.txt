[ Wed Jul  6 16:50:39 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:50:55 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:50:55 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:50:55 2022 ] Training epoch: 1
[ Wed Jul  6 16:52:18 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:52:34 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:52:34 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:52:34 2022 ] Training epoch: 1
[ Wed Jul  6 16:54:03 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:54:19 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:54:19 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:54:19 2022 ] Training epoch: 1
[ Wed Jul  6 16:54:46 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:55:01 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:55:01 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:55:01 2022 ] Training epoch: 1
[ Wed Jul  6 16:55:36 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:55:52 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:55:52 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:55:52 2022 ] Training epoch: 1
[ Wed Jul  6 16:58:21 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:58:35 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:58:35 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:58:35 2022 ] Training epoch: 1
[ Wed Jul  6 16:59:20 2022 ] using warm up, epoch: 5
[ Wed Jul  6 16:59:35 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 16:59:35 2022 ] # Parameters: 2200114
[ Wed Jul  6 16:59:35 2022 ] Training epoch: 1
[ Wed Jul  6 17:00:23 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:00:38 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:00:38 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:00:38 2022 ] Training epoch: 1
[ Wed Jul  6 17:00:58 2022 ] using warm up, epoch: 5
[ Wed Jul  6 17:01:13 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/sym_mod2', 'model_saved_name': 'work_dir/ntu120/csub/sym_mod2/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.sym_module2.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Wed Jul  6 17:01:13 2022 ] # Parameters: 2200114
[ Wed Jul  6 17:01:13 2022 ] Training epoch: 1
[ Wed Jul  6 17:04:20 2022 ] 	Mean training loss: 3.0955.  Mean training acc: 23.02%.
[ Wed Jul  6 17:04:20 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:04:20 2022 ] Eval epoch: 1
[ Wed Jul  6 17:05:07 2022 ] 	Mean test loss of 796 batches: 2.5466575206224644.
[ Wed Jul  6 17:05:08 2022 ] 	Top1: 30.82%
[ Wed Jul  6 17:05:08 2022 ] 	Top5: 66.75%
[ Wed Jul  6 17:05:08 2022 ] Training epoch: 2
[ Wed Jul  6 17:08:16 2022 ] 	Mean training loss: 2.0589.  Mean training acc: 42.33%.
[ Wed Jul  6 17:08:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:08:16 2022 ] Eval epoch: 2
[ Wed Jul  6 17:09:03 2022 ] 	Mean test loss of 796 batches: 1.8074885614253768.
[ Wed Jul  6 17:09:03 2022 ] 	Top1: 47.92%
[ Wed Jul  6 17:09:04 2022 ] 	Top5: 81.80%
[ Wed Jul  6 17:09:04 2022 ] Training epoch: 3
[ Wed Jul  6 17:12:11 2022 ] 	Mean training loss: 1.6408.  Mean training acc: 52.75%.
[ Wed Jul  6 17:12:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:12:11 2022 ] Eval epoch: 3
[ Wed Jul  6 17:12:59 2022 ] 	Mean test loss of 796 batches: 2.008037273758021.
[ Wed Jul  6 17:12:59 2022 ] 	Top1: 43.41%
[ Wed Jul  6 17:13:00 2022 ] 	Top5: 80.29%
[ Wed Jul  6 17:13:00 2022 ] Training epoch: 4
[ Wed Jul  6 17:16:08 2022 ] 	Mean training loss: 1.4098.  Mean training acc: 58.60%.
[ Wed Jul  6 17:16:08 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 17:16:08 2022 ] Eval epoch: 4
[ Wed Jul  6 17:16:57 2022 ] 	Mean test loss of 796 batches: 1.5056555891905599.
[ Wed Jul  6 17:16:58 2022 ] 	Top1: 55.18%
[ Wed Jul  6 17:16:58 2022 ] 	Top5: 86.77%
[ Wed Jul  6 17:16:58 2022 ] Training epoch: 5
[ Wed Jul  6 17:20:06 2022 ] 	Mean training loss: 1.2774.  Mean training acc: 62.29%.
[ Wed Jul  6 17:20:06 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:20:06 2022 ] Eval epoch: 5
[ Wed Jul  6 17:20:54 2022 ] 	Mean test loss of 796 batches: 1.8341988099729596.
[ Wed Jul  6 17:20:55 2022 ] 	Top1: 51.46%
[ Wed Jul  6 17:20:55 2022 ] 	Top5: 83.24%
[ Wed Jul  6 17:20:55 2022 ] Training epoch: 6
[ Wed Jul  6 17:24:04 2022 ] 	Mean training loss: 1.1407.  Mean training acc: 66.10%.
[ Wed Jul  6 17:24:04 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 17:24:04 2022 ] Eval epoch: 6
[ Wed Jul  6 17:24:52 2022 ] 	Mean test loss of 796 batches: 1.3990291907409926.
[ Wed Jul  6 17:24:52 2022 ] 	Top1: 59.27%
[ Wed Jul  6 17:24:53 2022 ] 	Top5: 89.52%
[ Wed Jul  6 17:24:53 2022 ] Training epoch: 7
[ Wed Jul  6 17:28:01 2022 ] 	Mean training loss: 1.0694.  Mean training acc: 68.13%.
[ Wed Jul  6 17:28:01 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 17:28:01 2022 ] Eval epoch: 7
[ Wed Jul  6 17:28:49 2022 ] 	Mean test loss of 796 batches: 1.3259598140665634.
[ Wed Jul  6 17:28:50 2022 ] 	Top1: 61.53%
[ Wed Jul  6 17:28:50 2022 ] 	Top5: 88.76%
[ Wed Jul  6 17:28:50 2022 ] Training epoch: 8
[ Wed Jul  6 17:31:59 2022 ] 	Mean training loss: 1.0199.  Mean training acc: 69.34%.
[ Wed Jul  6 17:31:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:31:59 2022 ] Eval epoch: 8
[ Wed Jul  6 17:32:46 2022 ] 	Mean test loss of 796 batches: 1.2280605967020868.
[ Wed Jul  6 17:33:12 2022 ] 	Top1: 64.18%
[ Wed Jul  6 17:33:12 2022 ] 	Top5: 88.91%
[ Wed Jul  6 17:33:12 2022 ] Training epoch: 9
[ Wed Jul  6 17:36:19 2022 ] 	Mean training loss: 0.9831.  Mean training acc: 70.47%.
[ Wed Jul  6 17:36:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:36:19 2022 ] Eval epoch: 9
[ Wed Jul  6 17:37:07 2022 ] 	Mean test loss of 796 batches: 1.1938300896903977.
[ Wed Jul  6 17:37:07 2022 ] 	Top1: 64.50%
[ Wed Jul  6 17:37:08 2022 ] 	Top5: 90.48%
[ Wed Jul  6 17:37:08 2022 ] Training epoch: 10
[ Wed Jul  6 17:40:15 2022 ] 	Mean training loss: 0.9565.  Mean training acc: 71.26%.
[ Wed Jul  6 17:40:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:40:15 2022 ] Eval epoch: 10
[ Wed Jul  6 17:41:02 2022 ] 	Mean test loss of 796 batches: 1.2692576554327755.
[ Wed Jul  6 17:41:02 2022 ] 	Top1: 63.31%
[ Wed Jul  6 17:41:03 2022 ] 	Top5: 90.14%
[ Wed Jul  6 17:41:03 2022 ] Training epoch: 11
[ Wed Jul  6 17:44:09 2022 ] 	Mean training loss: 0.9338.  Mean training acc: 71.93%.
[ Wed Jul  6 17:44:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 17:44:09 2022 ] Eval epoch: 11
[ Wed Jul  6 17:44:57 2022 ] 	Mean test loss of 796 batches: 1.206712882610122.
[ Wed Jul  6 17:44:57 2022 ] 	Top1: 64.09%
[ Wed Jul  6 17:44:58 2022 ] 	Top5: 91.27%
[ Wed Jul  6 17:44:58 2022 ] Training epoch: 12
[ Wed Jul  6 17:48:05 2022 ] 	Mean training loss: 0.9157.  Mean training acc: 72.26%.
[ Wed Jul  6 17:48:05 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:48:05 2022 ] Eval epoch: 12
[ Wed Jul  6 17:48:52 2022 ] 	Mean test loss of 796 batches: 1.2263156576971312.
[ Wed Jul  6 17:48:52 2022 ] 	Top1: 63.14%
[ Wed Jul  6 17:48:53 2022 ] 	Top5: 90.42%
[ Wed Jul  6 17:48:53 2022 ] Training epoch: 13
[ Wed Jul  6 17:52:00 2022 ] 	Mean training loss: 0.9063.  Mean training acc: 72.58%.
[ Wed Jul  6 17:52:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:52:00 2022 ] Eval epoch: 13
[ Wed Jul  6 17:52:46 2022 ] 	Mean test loss of 796 batches: 1.1752913182779172.
[ Wed Jul  6 17:52:47 2022 ] 	Top1: 65.28%
[ Wed Jul  6 17:52:47 2022 ] 	Top5: 90.74%
[ Wed Jul  6 17:52:47 2022 ] Training epoch: 14
[ Wed Jul  6 17:55:54 2022 ] 	Mean training loss: 0.8862.  Mean training acc: 73.13%.
[ Wed Jul  6 17:55:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 17:55:54 2022 ] Eval epoch: 14
[ Wed Jul  6 17:56:41 2022 ] 	Mean test loss of 796 batches: 1.2527895986509683.
[ Wed Jul  6 17:56:41 2022 ] 	Top1: 64.09%
[ Wed Jul  6 17:56:42 2022 ] 	Top5: 89.91%
[ Wed Jul  6 17:56:42 2022 ] Training epoch: 15
[ Wed Jul  6 17:59:48 2022 ] 	Mean training loss: 0.8762.  Mean training acc: 73.53%.
[ Wed Jul  6 17:59:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 17:59:48 2022 ] Eval epoch: 15
[ Wed Jul  6 18:00:35 2022 ] 	Mean test loss of 796 batches: 1.1199867510840522.
[ Wed Jul  6 18:00:35 2022 ] 	Top1: 67.09%
[ Wed Jul  6 18:00:36 2022 ] 	Top5: 91.27%
[ Wed Jul  6 18:00:36 2022 ] Training epoch: 16
[ Wed Jul  6 18:03:43 2022 ] 	Mean training loss: 0.8672.  Mean training acc: 73.69%.
[ Wed Jul  6 18:03:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:03:43 2022 ] Eval epoch: 16
[ Wed Jul  6 18:04:30 2022 ] 	Mean test loss of 796 batches: 1.1824351876749466.
[ Wed Jul  6 18:04:30 2022 ] 	Top1: 65.90%
[ Wed Jul  6 18:04:31 2022 ] 	Top5: 90.92%
[ Wed Jul  6 18:04:31 2022 ] Training epoch: 17
[ Wed Jul  6 18:07:38 2022 ] 	Mean training loss: 0.8628.  Mean training acc: 73.87%.
[ Wed Jul  6 18:07:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:07:38 2022 ] Eval epoch: 17
[ Wed Jul  6 18:08:25 2022 ] 	Mean test loss of 796 batches: 1.2480857151761726.
[ Wed Jul  6 18:08:25 2022 ] 	Top1: 63.57%
[ Wed Jul  6 18:08:26 2022 ] 	Top5: 90.24%
[ Wed Jul  6 18:08:26 2022 ] Training epoch: 18
[ Wed Jul  6 18:11:32 2022 ] 	Mean training loss: 0.8551.  Mean training acc: 73.96%.
[ Wed Jul  6 18:11:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:11:32 2022 ] Eval epoch: 18
[ Wed Jul  6 18:12:19 2022 ] 	Mean test loss of 796 batches: 1.1228996219871632.
[ Wed Jul  6 18:12:19 2022 ] 	Top1: 67.52%
[ Wed Jul  6 18:12:19 2022 ] 	Top5: 91.82%
[ Wed Jul  6 18:12:19 2022 ] Training epoch: 19
[ Wed Jul  6 18:15:26 2022 ] 	Mean training loss: 0.8446.  Mean training acc: 74.54%.
[ Wed Jul  6 18:15:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:15:26 2022 ] Eval epoch: 19
[ Wed Jul  6 18:16:13 2022 ] 	Mean test loss of 796 batches: 1.1473657501926973.
[ Wed Jul  6 18:16:13 2022 ] 	Top1: 66.66%
[ Wed Jul  6 18:16:14 2022 ] 	Top5: 91.35%
[ Wed Jul  6 18:16:14 2022 ] Training epoch: 20
[ Wed Jul  6 18:19:20 2022 ] 	Mean training loss: 0.8430.  Mean training acc: 74.51%.
[ Wed Jul  6 18:19:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:19:20 2022 ] Eval epoch: 20
[ Wed Jul  6 18:20:07 2022 ] 	Mean test loss of 796 batches: 1.376046490541954.
[ Wed Jul  6 18:20:07 2022 ] 	Top1: 61.13%
[ Wed Jul  6 18:20:07 2022 ] 	Top5: 88.64%
[ Wed Jul  6 18:20:08 2022 ] Training epoch: 21
[ Wed Jul  6 18:23:14 2022 ] 	Mean training loss: 0.8406.  Mean training acc: 74.54%.
[ Wed Jul  6 18:23:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:23:14 2022 ] Eval epoch: 21
[ Wed Jul  6 18:24:02 2022 ] 	Mean test loss of 796 batches: 1.0826938847950356.
[ Wed Jul  6 18:24:03 2022 ] 	Top1: 68.06%
[ Wed Jul  6 18:24:03 2022 ] 	Top5: 91.83%
[ Wed Jul  6 18:24:03 2022 ] Training epoch: 22
[ Wed Jul  6 18:27:10 2022 ] 	Mean training loss: 0.8296.  Mean training acc: 74.75%.
[ Wed Jul  6 18:27:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:27:10 2022 ] Eval epoch: 22
[ Wed Jul  6 18:27:57 2022 ] 	Mean test loss of 796 batches: 1.0459307236737343.
[ Wed Jul  6 18:27:58 2022 ] 	Top1: 68.68%
[ Wed Jul  6 18:27:58 2022 ] 	Top5: 92.34%
[ Wed Jul  6 18:27:58 2022 ] Training epoch: 23
[ Wed Jul  6 18:31:05 2022 ] 	Mean training loss: 0.8321.  Mean training acc: 74.63%.
[ Wed Jul  6 18:31:05 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:31:05 2022 ] Eval epoch: 23
[ Wed Jul  6 18:31:51 2022 ] 	Mean test loss of 796 batches: 1.0372348609357025.
[ Wed Jul  6 18:31:52 2022 ] 	Top1: 69.02%
[ Wed Jul  6 18:31:52 2022 ] 	Top5: 92.53%
[ Wed Jul  6 18:31:52 2022 ] Training epoch: 24
[ Wed Jul  6 18:34:59 2022 ] 	Mean training loss: 0.8222.  Mean training acc: 75.08%.
[ Wed Jul  6 18:34:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:34:59 2022 ] Eval epoch: 24
[ Wed Jul  6 18:35:45 2022 ] 	Mean test loss of 796 batches: 1.2087944580157797.
[ Wed Jul  6 18:35:54 2022 ] 	Top1: 65.73%
[ Wed Jul  6 18:35:55 2022 ] 	Top5: 90.37%
[ Wed Jul  6 18:35:55 2022 ] Training epoch: 25
[ Wed Jul  6 18:39:01 2022 ] 	Mean training loss: 0.8217.  Mean training acc: 74.97%.
[ Wed Jul  6 18:39:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:39:01 2022 ] Eval epoch: 25
[ Wed Jul  6 18:39:48 2022 ] 	Mean test loss of 796 batches: 1.1435477277966002.
[ Wed Jul  6 18:39:48 2022 ] 	Top1: 66.69%
[ Wed Jul  6 18:39:48 2022 ] 	Top5: 91.00%
[ Wed Jul  6 18:39:48 2022 ] Training epoch: 26
[ Wed Jul  6 18:42:55 2022 ] 	Mean training loss: 0.8205.  Mean training acc: 75.05%.
[ Wed Jul  6 18:42:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:42:55 2022 ] Eval epoch: 26
[ Wed Jul  6 18:43:42 2022 ] 	Mean test loss of 796 batches: 1.033495512103016.
[ Wed Jul  6 18:43:42 2022 ] 	Top1: 69.66%
[ Wed Jul  6 18:43:42 2022 ] 	Top5: 91.94%
[ Wed Jul  6 18:43:42 2022 ] Training epoch: 27
[ Wed Jul  6 18:46:49 2022 ] 	Mean training loss: 0.8111.  Mean training acc: 75.36%.
[ Wed Jul  6 18:46:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:46:49 2022 ] Eval epoch: 27
[ Wed Jul  6 18:47:36 2022 ] 	Mean test loss of 796 batches: 1.098545037696709.
[ Wed Jul  6 18:47:36 2022 ] 	Top1: 68.65%
[ Wed Jul  6 18:47:36 2022 ] 	Top5: 91.38%
[ Wed Jul  6 18:47:36 2022 ] Training epoch: 28
[ Wed Jul  6 18:50:43 2022 ] 	Mean training loss: 0.8152.  Mean training acc: 75.20%.
[ Wed Jul  6 18:50:43 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:50:43 2022 ] Eval epoch: 28
[ Wed Jul  6 18:51:30 2022 ] 	Mean test loss of 796 batches: 1.0273557249924645.
[ Wed Jul  6 18:51:30 2022 ] 	Top1: 69.36%
[ Wed Jul  6 18:51:30 2022 ] 	Top5: 92.15%
[ Wed Jul  6 18:51:30 2022 ] Training epoch: 29
[ Wed Jul  6 18:54:37 2022 ] 	Mean training loss: 0.8133.  Mean training acc: 75.27%.
[ Wed Jul  6 18:54:37 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 18:54:37 2022 ] Eval epoch: 29
[ Wed Jul  6 18:55:24 2022 ] 	Mean test loss of 796 batches: 1.0583991651334355.
[ Wed Jul  6 18:55:24 2022 ] 	Top1: 68.92%
[ Wed Jul  6 18:55:24 2022 ] 	Top5: 92.29%
[ Wed Jul  6 18:55:24 2022 ] Training epoch: 30
[ Wed Jul  6 18:58:31 2022 ] 	Mean training loss: 0.8081.  Mean training acc: 75.33%.
[ Wed Jul  6 18:58:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 18:58:31 2022 ] Eval epoch: 30
[ Wed Jul  6 18:59:18 2022 ] 	Mean test loss of 796 batches: 1.0797183465718025.
[ Wed Jul  6 18:59:18 2022 ] 	Top1: 68.36%
[ Wed Jul  6 18:59:19 2022 ] 	Top5: 92.35%
[ Wed Jul  6 18:59:19 2022 ] Training epoch: 31
[ Wed Jul  6 19:02:26 2022 ] 	Mean training loss: 0.8050.  Mean training acc: 75.52%.
[ Wed Jul  6 19:02:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:02:26 2022 ] Eval epoch: 31
[ Wed Jul  6 19:03:12 2022 ] 	Mean test loss of 796 batches: 1.0755434824369061.
[ Wed Jul  6 19:03:13 2022 ] 	Top1: 68.17%
[ Wed Jul  6 19:03:13 2022 ] 	Top5: 91.87%
[ Wed Jul  6 19:03:13 2022 ] Training epoch: 32
[ Wed Jul  6 19:06:20 2022 ] 	Mean training loss: 0.8005.  Mean training acc: 75.67%.
[ Wed Jul  6 19:06:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:06:20 2022 ] Eval epoch: 32
[ Wed Jul  6 19:07:06 2022 ] 	Mean test loss of 796 batches: 1.1695605428449471.
[ Wed Jul  6 19:07:07 2022 ] 	Top1: 66.36%
[ Wed Jul  6 19:07:07 2022 ] 	Top5: 90.88%
[ Wed Jul  6 19:07:07 2022 ] Training epoch: 33
[ Wed Jul  6 19:10:14 2022 ] 	Mean training loss: 0.7953.  Mean training acc: 75.67%.
[ Wed Jul  6 19:10:14 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:10:14 2022 ] Eval epoch: 33
[ Wed Jul  6 19:11:00 2022 ] 	Mean test loss of 796 batches: 1.1526663327149709.
[ Wed Jul  6 19:11:01 2022 ] 	Top1: 66.69%
[ Wed Jul  6 19:11:01 2022 ] 	Top5: 91.13%
[ Wed Jul  6 19:11:01 2022 ] Training epoch: 34
[ Wed Jul  6 19:14:08 2022 ] 	Mean training loss: 0.7909.  Mean training acc: 75.99%.
[ Wed Jul  6 19:14:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:14:08 2022 ] Eval epoch: 34
[ Wed Jul  6 19:14:54 2022 ] 	Mean test loss of 796 batches: 1.0798443538609461.
[ Wed Jul  6 19:14:54 2022 ] 	Top1: 68.35%
[ Wed Jul  6 19:14:55 2022 ] 	Top5: 91.46%
[ Wed Jul  6 19:14:55 2022 ] Training epoch: 35
[ Wed Jul  6 19:18:01 2022 ] 	Mean training loss: 0.7914.  Mean training acc: 75.87%.
[ Wed Jul  6 19:18:01 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:18:01 2022 ] Eval epoch: 35
[ Wed Jul  6 19:18:48 2022 ] 	Mean test loss of 796 batches: 1.1625590729878177.
[ Wed Jul  6 19:18:49 2022 ] 	Top1: 66.11%
[ Wed Jul  6 19:18:49 2022 ] 	Top5: 91.25%
[ Wed Jul  6 19:18:49 2022 ] Training epoch: 36
[ Wed Jul  6 19:21:55 2022 ] 	Mean training loss: 0.4598.  Mean training acc: 85.79%.
[ Wed Jul  6 19:21:55 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:21:55 2022 ] Eval epoch: 36
[ Wed Jul  6 19:22:42 2022 ] 	Mean test loss of 796 batches: 0.616614871719225.
[ Wed Jul  6 19:22:43 2022 ] 	Top1: 80.93%
[ Wed Jul  6 19:22:43 2022 ] 	Top5: 96.40%
[ Wed Jul  6 19:22:43 2022 ] Training epoch: 37
[ Wed Jul  6 19:25:49 2022 ] 	Mean training loss: 0.3711.  Mean training acc: 88.42%.
[ Wed Jul  6 19:25:50 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:25:50 2022 ] Eval epoch: 37
[ Wed Jul  6 19:26:37 2022 ] 	Mean test loss of 796 batches: 0.5998807782634868.
[ Wed Jul  6 19:26:37 2022 ] 	Top1: 81.73%
[ Wed Jul  6 19:26:37 2022 ] 	Top5: 96.52%
[ Wed Jul  6 19:26:37 2022 ] Training epoch: 38
[ Wed Jul  6 19:29:44 2022 ] 	Mean training loss: 0.3325.  Mean training acc: 89.52%.
[ Wed Jul  6 19:29:44 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 19:29:44 2022 ] Eval epoch: 38
[ Wed Jul  6 19:30:30 2022 ] 	Mean test loss of 796 batches: 0.6062849177393931.
[ Wed Jul  6 19:30:30 2022 ] 	Top1: 81.59%
[ Wed Jul  6 19:30:31 2022 ] 	Top5: 96.61%
[ Wed Jul  6 19:30:31 2022 ] Training epoch: 39
[ Wed Jul  6 19:33:38 2022 ] 	Mean training loss: 0.3074.  Mean training acc: 90.34%.
[ Wed Jul  6 19:33:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:33:38 2022 ] Eval epoch: 39
[ Wed Jul  6 19:34:24 2022 ] 	Mean test loss of 796 batches: 0.5998948265672029.
[ Wed Jul  6 19:34:24 2022 ] 	Top1: 81.94%
[ Wed Jul  6 19:34:24 2022 ] 	Top5: 96.67%
[ Wed Jul  6 19:34:24 2022 ] Training epoch: 40
[ Wed Jul  6 19:37:33 2022 ] 	Mean training loss: 0.2846.  Mean training acc: 91.02%.
[ Wed Jul  6 19:37:33 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 19:37:33 2022 ] Eval epoch: 40
[ Wed Jul  6 19:38:22 2022 ] 	Mean test loss of 796 batches: 0.6288593852396437.
[ Wed Jul  6 19:38:23 2022 ] 	Top1: 81.37%
[ Wed Jul  6 19:38:23 2022 ] 	Top5: 96.37%
[ Wed Jul  6 19:38:23 2022 ] Training epoch: 41
[ Wed Jul  6 19:41:31 2022 ] 	Mean training loss: 0.2684.  Mean training acc: 91.65%.
[ Wed Jul  6 19:41:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:41:31 2022 ] Eval epoch: 41
[ Wed Jul  6 19:42:20 2022 ] 	Mean test loss of 796 batches: 0.6190453679137045.
[ Wed Jul  6 19:42:20 2022 ] 	Top1: 81.82%
[ Wed Jul  6 19:42:20 2022 ] 	Top5: 96.51%
[ Wed Jul  6 19:42:20 2022 ] Training epoch: 42
[ Wed Jul  6 19:45:27 2022 ] 	Mean training loss: 0.2533.  Mean training acc: 92.09%.
[ Wed Jul  6 19:45:27 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:45:27 2022 ] Eval epoch: 42
[ Wed Jul  6 19:46:14 2022 ] 	Mean test loss of 796 batches: 0.6383850320275105.
[ Wed Jul  6 19:46:14 2022 ] 	Top1: 81.45%
[ Wed Jul  6 19:46:14 2022 ] 	Top5: 96.40%
[ Wed Jul  6 19:46:14 2022 ] Training epoch: 43
[ Wed Jul  6 19:49:21 2022 ] 	Mean training loss: 0.2392.  Mean training acc: 92.62%.
[ Wed Jul  6 19:49:21 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:49:21 2022 ] Eval epoch: 43
[ Wed Jul  6 19:50:07 2022 ] 	Mean test loss of 796 batches: 0.6687207157307085.
[ Wed Jul  6 19:50:08 2022 ] 	Top1: 81.13%
[ Wed Jul  6 19:50:08 2022 ] 	Top5: 96.03%
[ Wed Jul  6 19:50:08 2022 ] Training epoch: 44
[ Wed Jul  6 19:53:17 2022 ] 	Mean training loss: 0.2316.  Mean training acc: 92.71%.
[ Wed Jul  6 19:53:17 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 19:53:17 2022 ] Eval epoch: 44
[ Wed Jul  6 19:54:06 2022 ] 	Mean test loss of 796 batches: 0.7119664966442327.
[ Wed Jul  6 19:54:07 2022 ] 	Top1: 80.28%
[ Wed Jul  6 19:54:07 2022 ] 	Top5: 96.04%
[ Wed Jul  6 19:54:07 2022 ] Training epoch: 45
[ Wed Jul  6 19:57:14 2022 ] 	Mean training loss: 0.2248.  Mean training acc: 92.94%.
[ Wed Jul  6 19:57:14 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 19:57:14 2022 ] Eval epoch: 45
[ Wed Jul  6 19:58:02 2022 ] 	Mean test loss of 796 batches: 0.6668860846241216.
[ Wed Jul  6 19:58:03 2022 ] 	Top1: 81.16%
[ Wed Jul  6 19:58:03 2022 ] 	Top5: 96.20%
[ Wed Jul  6 19:58:03 2022 ] Training epoch: 46
[ Wed Jul  6 20:01:12 2022 ] 	Mean training loss: 0.2164.  Mean training acc: 93.25%.
[ Wed Jul  6 20:01:12 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:01:12 2022 ] Eval epoch: 46
[ Wed Jul  6 20:02:01 2022 ] 	Mean test loss of 796 batches: 0.674225703555735.
[ Wed Jul  6 20:02:02 2022 ] 	Top1: 80.82%
[ Wed Jul  6 20:02:02 2022 ] 	Top5: 96.14%
[ Wed Jul  6 20:02:02 2022 ] Training epoch: 47
[ Wed Jul  6 20:05:12 2022 ] 	Mean training loss: 0.2119.  Mean training acc: 93.49%.
[ Wed Jul  6 20:05:12 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:05:12 2022 ] Eval epoch: 47
[ Wed Jul  6 20:06:02 2022 ] 	Mean test loss of 796 batches: 0.6845290618270037.
[ Wed Jul  6 20:06:02 2022 ] 	Top1: 80.89%
[ Wed Jul  6 20:06:03 2022 ] 	Top5: 96.16%
[ Wed Jul  6 20:06:03 2022 ] Training epoch: 48
[ Wed Jul  6 20:09:08 2022 ] 	Mean training loss: 0.2098.  Mean training acc: 93.41%.
[ Wed Jul  6 20:09:08 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 20:09:08 2022 ] Eval epoch: 48
[ Wed Jul  6 20:09:58 2022 ] 	Mean test loss of 796 batches: 0.75749157799698.
[ Wed Jul  6 20:09:59 2022 ] 	Top1: 79.13%
[ Wed Jul  6 20:09:59 2022 ] 	Top5: 95.55%
[ Wed Jul  6 20:09:59 2022 ] Training epoch: 49
[ Wed Jul  6 20:13:06 2022 ] 	Mean training loss: 0.2040.  Mean training acc: 93.45%.
[ Wed Jul  6 20:13:06 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Wed Jul  6 20:13:06 2022 ] Eval epoch: 49
[ Wed Jul  6 20:13:54 2022 ] 	Mean test loss of 796 batches: 0.6996770784839164.
[ Wed Jul  6 20:13:55 2022 ] 	Top1: 80.45%
[ Wed Jul  6 20:13:55 2022 ] 	Top5: 96.01%
[ Wed Jul  6 20:13:55 2022 ] Training epoch: 50
[ Wed Jul  6 20:17:05 2022 ] 	Mean training loss: 0.2039.  Mean training acc: 93.60%.
[ Wed Jul  6 20:17:05 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:17:05 2022 ] Eval epoch: 50
[ Wed Jul  6 20:17:54 2022 ] 	Mean test loss of 796 batches: 0.7461318420199443.
[ Wed Jul  6 20:17:54 2022 ] 	Top1: 79.54%
[ Wed Jul  6 20:17:55 2022 ] 	Top5: 95.54%
[ Wed Jul  6 20:17:55 2022 ] Training epoch: 51
[ Wed Jul  6 20:21:02 2022 ] 	Mean training loss: 0.2022.  Mean training acc: 93.68%.
[ Wed Jul  6 20:21:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 20:21:03 2022 ] Eval epoch: 51
[ Wed Jul  6 20:21:49 2022 ] 	Mean test loss of 796 batches: 0.7728061073333324.
[ Wed Jul  6 20:21:49 2022 ] 	Top1: 79.16%
[ Wed Jul  6 20:21:50 2022 ] 	Top5: 95.29%
[ Wed Jul  6 20:21:50 2022 ] Training epoch: 52
[ Wed Jul  6 20:24:58 2022 ] 	Mean training loss: 0.2021.  Mean training acc: 93.66%.
[ Wed Jul  6 20:24:59 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:24:59 2022 ] Eval epoch: 52
[ Wed Jul  6 20:25:47 2022 ] 	Mean test loss of 796 batches: 0.7359730624055593.
[ Wed Jul  6 20:25:48 2022 ] 	Top1: 80.02%
[ Wed Jul  6 20:25:48 2022 ] 	Top5: 95.80%
[ Wed Jul  6 20:25:48 2022 ] Training epoch: 53
[ Wed Jul  6 20:28:58 2022 ] 	Mean training loss: 0.2013.  Mean training acc: 93.75%.
[ Wed Jul  6 20:28:58 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:28:58 2022 ] Eval epoch: 53
[ Wed Jul  6 20:29:49 2022 ] 	Mean test loss of 796 batches: 0.7961329298103275.
[ Wed Jul  6 20:29:50 2022 ] 	Top1: 78.80%
[ Wed Jul  6 20:29:50 2022 ] 	Top5: 95.23%
[ Wed Jul  6 20:29:50 2022 ] Training epoch: 54
[ Wed Jul  6 20:32:59 2022 ] 	Mean training loss: 0.1980.  Mean training acc: 93.84%.
[ Wed Jul  6 20:32:59 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:32:59 2022 ] Eval epoch: 54
[ Wed Jul  6 20:33:50 2022 ] 	Mean test loss of 796 batches: 0.7902181937111232.
[ Wed Jul  6 20:33:50 2022 ] 	Top1: 79.02%
[ Wed Jul  6 20:33:50 2022 ] 	Top5: 95.29%
[ Wed Jul  6 20:33:50 2022 ] Training epoch: 55
[ Wed Jul  6 20:36:57 2022 ] 	Mean training loss: 0.1963.  Mean training acc: 93.93%.
[ Wed Jul  6 20:36:57 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 20:36:57 2022 ] Eval epoch: 55
[ Wed Jul  6 20:37:44 2022 ] 	Mean test loss of 796 batches: 0.782675270927162.
[ Wed Jul  6 20:37:45 2022 ] 	Top1: 79.18%
[ Wed Jul  6 20:37:45 2022 ] 	Top5: 95.16%
[ Wed Jul  6 20:37:46 2022 ] Training epoch: 56
[ Wed Jul  6 20:40:55 2022 ] 	Mean training loss: 0.1145.  Mean training acc: 96.85%.
[ Wed Jul  6 20:40:55 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:40:55 2022 ] Eval epoch: 56
[ Wed Jul  6 20:41:45 2022 ] 	Mean test loss of 796 batches: 0.6696429362698416.
[ Wed Jul  6 20:41:45 2022 ] 	Top1: 81.94%
[ Wed Jul  6 20:41:46 2022 ] 	Top5: 96.20%
[ Wed Jul  6 20:41:46 2022 ] Training epoch: 57
[ Wed Jul  6 20:44:54 2022 ] 	Mean training loss: 0.0850.  Mean training acc: 97.91%.
[ Wed Jul  6 20:44:54 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:44:54 2022 ] Eval epoch: 57
[ Wed Jul  6 20:45:42 2022 ] 	Mean test loss of 796 batches: 0.6728707346503608.
[ Wed Jul  6 20:45:42 2022 ] 	Top1: 82.09%
[ Wed Jul  6 20:45:43 2022 ] 	Top5: 96.13%
[ Wed Jul  6 20:45:43 2022 ] Training epoch: 58
[ Wed Jul  6 20:48:52 2022 ] 	Mean training loss: 0.0765.  Mean training acc: 98.16%.
[ Wed Jul  6 20:48:52 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:48:52 2022 ] Eval epoch: 58
[ Wed Jul  6 20:49:39 2022 ] 	Mean test loss of 796 batches: 0.6703605384439529.
[ Wed Jul  6 20:49:39 2022 ] 	Top1: 82.09%
[ Wed Jul  6 20:49:40 2022 ] 	Top5: 96.23%
[ Wed Jul  6 20:49:40 2022 ] Training epoch: 59
[ Wed Jul  6 20:52:48 2022 ] 	Mean training loss: 0.0689.  Mean training acc: 98.36%.
[ Wed Jul  6 20:52:48 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 20:52:48 2022 ] Eval epoch: 59
[ Wed Jul  6 20:53:36 2022 ] 	Mean test loss of 796 batches: 0.680423357968579.
[ Wed Jul  6 20:53:37 2022 ] 	Top1: 81.98%
[ Wed Jul  6 20:53:37 2022 ] 	Top5: 96.13%
[ Wed Jul  6 20:53:37 2022 ] Training epoch: 60
[ Wed Jul  6 20:56:44 2022 ] 	Mean training loss: 0.0649.  Mean training acc: 98.53%.
[ Wed Jul  6 20:56:44 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 20:56:44 2022 ] Eval epoch: 60
[ Wed Jul  6 20:57:32 2022 ] 	Mean test loss of 796 batches: 0.686532926113911.
[ Wed Jul  6 20:57:33 2022 ] 	Top1: 82.09%
[ Wed Jul  6 20:57:33 2022 ] 	Top5: 96.28%
[ Wed Jul  6 20:57:33 2022 ] Training epoch: 61
[ Wed Jul  6 21:00:42 2022 ] 	Mean training loss: 0.0587.  Mean training acc: 98.74%.
[ Wed Jul  6 21:00:42 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 21:00:42 2022 ] Eval epoch: 61
[ Wed Jul  6 21:01:31 2022 ] 	Mean test loss of 796 batches: 0.6868986777175012.
[ Wed Jul  6 21:01:31 2022 ] 	Top1: 82.12%
[ Wed Jul  6 21:01:32 2022 ] 	Top5: 96.23%
[ Wed Jul  6 21:01:32 2022 ] Training epoch: 62
[ Wed Jul  6 21:04:39 2022 ] 	Mean training loss: 0.0568.  Mean training acc: 98.71%.
[ Wed Jul  6 21:04:39 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Wed Jul  6 21:04:39 2022 ] Eval epoch: 62
[ Wed Jul  6 21:05:25 2022 ] 	Mean test loss of 796 batches: 0.6931740543126461.
[ Wed Jul  6 21:05:26 2022 ] 	Top1: 82.00%
[ Wed Jul  6 21:05:26 2022 ] 	Top5: 96.06%
[ Wed Jul  6 21:05:26 2022 ] Training epoch: 63
[ Wed Jul  6 21:08:35 2022 ] 	Mean training loss: 0.0539.  Mean training acc: 98.82%.
[ Wed Jul  6 21:08:35 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 21:08:35 2022 ] Eval epoch: 63
[ Wed Jul  6 21:09:24 2022 ] 	Mean test loss of 796 batches: 0.696266040748837.
[ Wed Jul  6 21:09:25 2022 ] 	Top1: 82.10%
[ Wed Jul  6 21:09:25 2022 ] 	Top5: 96.10%
[ Wed Jul  6 21:09:26 2022 ] Training epoch: 64
[ Wed Jul  6 21:12:34 2022 ] 	Mean training loss: 0.0521.  Mean training acc: 98.81%.
[ Wed Jul  6 21:12:34 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 21:12:34 2022 ] Eval epoch: 64
[ Wed Jul  6 21:13:25 2022 ] 	Mean test loss of 796 batches: 0.6929898823063877.
[ Wed Jul  6 21:13:26 2022 ] 	Top1: 82.06%
[ Wed Jul  6 21:13:26 2022 ] 	Top5: 96.12%
[ Wed Jul  6 21:13:26 2022 ] Training epoch: 65
[ Wed Jul  6 21:16:34 2022 ] 	Mean training loss: 0.0499.  Mean training acc: 98.98%.
[ Wed Jul  6 21:16:34 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Wed Jul  6 21:16:34 2022 ] Eval epoch: 65
[ Wed Jul  6 21:17:21 2022 ] 	Mean test loss of 796 batches: 0.7003149394994256.
[ Wed Jul  6 21:17:21 2022 ] 	Top1: 82.01%
[ Wed Jul  6 21:17:21 2022 ] 	Top5: 96.07%
[ Wed Jul  6 21:18:11 2022 ] Best accuracy: 0.8212258685363027
[ Wed Jul  6 21:18:11 2022 ] Epoch number: 61
[ Wed Jul  6 21:18:11 2022 ] Model name: work_dir/ntu120/csub/sym_mod2
[ Wed Jul  6 21:18:11 2022 ] Model total number of params: 2200114
[ Wed Jul  6 21:18:11 2022 ] Weight decay: 0.0004
[ Wed Jul  6 21:18:11 2022 ] Base LR: 0.1
[ Wed Jul  6 21:18:11 2022 ] Batch Size: 64
[ Wed Jul  6 21:18:11 2022 ] Test Batch Size: 64
[ Wed Jul  6 21:18:11 2022 ] seed: 1
