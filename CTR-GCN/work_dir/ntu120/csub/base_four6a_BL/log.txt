[ Thu Jun 30 10:33:56 2022 ] using warm up, epoch: 5
[ Thu Jun 30 10:39:33 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/base_four6a_BL', 'model_saved_name': 'work_dir/ntu120/csub/base_four6a_BL/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.fourier6a_BL.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [7], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Jun 30 10:39:33 2022 ] # Parameters: 2128482
[ Thu Jun 30 10:39:33 2022 ] Training epoch: 1
[ Thu Jun 30 10:46:26 2022 ] 	Mean training loss: 3.1514.  Mean training acc: 22.54%.
[ Thu Jun 30 10:46:26 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 10:46:26 2022 ] Eval epoch: 1
[ Thu Jun 30 10:49:18 2022 ] 	Mean test loss of 796 batches: 2.4545759681481214.
[ Thu Jun 30 10:49:19 2022 ] 	Top1: 32.81%
[ Thu Jun 30 10:49:19 2022 ] 	Top5: 66.54%
[ Thu Jun 30 10:49:19 2022 ] Training epoch: 2
[ Thu Jun 30 10:58:24 2022 ] 	Mean training loss: 2.0189.  Mean training acc: 44.08%.
[ Thu Jun 30 10:58:24 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 10:58:24 2022 ] Eval epoch: 2
[ Thu Jun 30 11:01:16 2022 ] 	Mean test loss of 796 batches: 1.7819055380234168.
[ Thu Jun 30 11:01:16 2022 ] 	Top1: 47.87%
[ Thu Jun 30 11:01:17 2022 ] 	Top5: 81.10%
[ Thu Jun 30 11:01:17 2022 ] Training epoch: 3
[ Thu Jun 30 11:10:18 2022 ] 	Mean training loss: 1.6039.  Mean training acc: 54.15%.
[ Thu Jun 30 11:10:18 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 11:10:18 2022 ] Eval epoch: 3
[ Thu Jun 30 11:13:09 2022 ] 	Mean test loss of 796 batches: 1.6559900160710417.
[ Thu Jun 30 11:13:09 2022 ] 	Top1: 52.43%
[ Thu Jun 30 11:13:09 2022 ] 	Top5: 83.27%
[ Thu Jun 30 11:13:09 2022 ] Training epoch: 4
[ Thu Jun 30 11:22:13 2022 ] 	Mean training loss: 1.4216.  Mean training acc: 58.80%.
[ Thu Jun 30 11:22:13 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 11:22:13 2022 ] Eval epoch: 4
[ Thu Jun 30 11:25:02 2022 ] 	Mean test loss of 796 batches: 1.6626572153676096.
[ Thu Jun 30 11:25:02 2022 ] 	Top1: 51.82%
[ Thu Jun 30 11:25:03 2022 ] 	Top5: 83.19%
[ Thu Jun 30 11:25:03 2022 ] Training epoch: 5
[ Thu Jun 30 11:34:22 2022 ] 	Mean training loss: 1.2821.  Mean training acc: 62.58%.
[ Thu Jun 30 11:34:22 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 11:34:22 2022 ] Eval epoch: 5
[ Thu Jun 30 11:37:21 2022 ] 	Mean test loss of 796 batches: 1.5009992111418116.
[ Thu Jun 30 11:37:21 2022 ] 	Top1: 56.60%
[ Thu Jun 30 11:37:22 2022 ] 	Top5: 86.61%
[ Thu Jun 30 11:37:22 2022 ] Training epoch: 6
[ Thu Jun 30 11:46:40 2022 ] 	Mean training loss: 1.1396.  Mean training acc: 66.40%.
[ Thu Jun 30 11:46:40 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 11:46:40 2022 ] Eval epoch: 6
[ Thu Jun 30 11:49:49 2022 ] 	Mean test loss of 796 batches: 1.6583041430418215.
[ Thu Jun 30 11:49:49 2022 ] 	Top1: 55.30%
[ Thu Jun 30 11:49:50 2022 ] 	Top5: 84.64%
[ Thu Jun 30 11:49:50 2022 ] Training epoch: 7
[ Thu Jun 30 11:59:11 2022 ] 	Mean training loss: 1.0437.  Mean training acc: 69.05%.
[ Thu Jun 30 11:59:11 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 11:59:11 2022 ] Eval epoch: 7
[ Thu Jun 30 12:02:06 2022 ] 	Mean test loss of 796 batches: 2.431174679766947.
[ Thu Jun 30 12:02:06 2022 ] 	Top1: 45.74%
[ Thu Jun 30 12:02:06 2022 ] 	Top5: 75.77%
[ Thu Jun 30 12:02:06 2022 ] Training epoch: 8
[ Thu Jun 30 12:11:14 2022 ] 	Mean training loss: 0.9815.  Mean training acc: 70.69%.
[ Thu Jun 30 12:11:14 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 12:11:14 2022 ] Eval epoch: 8
[ Thu Jun 30 12:14:08 2022 ] 	Mean test loss of 796 batches: 1.3091632700969826.
[ Thu Jun 30 12:14:09 2022 ] 	Top1: 62.80%
[ Thu Jun 30 12:14:09 2022 ] 	Top5: 88.59%
[ Thu Jun 30 12:14:09 2022 ] Training epoch: 9
[ Thu Jun 30 12:23:38 2022 ] 	Mean training loss: 0.9394.  Mean training acc: 71.85%.
[ Thu Jun 30 12:23:38 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 12:23:38 2022 ] Eval epoch: 9
[ Thu Jun 30 12:26:41 2022 ] 	Mean test loss of 796 batches: 1.1907655808269677.
[ Thu Jun 30 12:26:42 2022 ] 	Top1: 64.67%
[ Thu Jun 30 12:26:42 2022 ] 	Top5: 90.72%
[ Thu Jun 30 12:26:42 2022 ] Training epoch: 10
[ Thu Jun 30 12:36:16 2022 ] 	Mean training loss: 0.9009.  Mean training acc: 73.07%.
[ Thu Jun 30 12:36:16 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 12:36:16 2022 ] Eval epoch: 10
[ Thu Jun 30 12:39:10 2022 ] 	Mean test loss of 796 batches: 1.1779000714945433.
[ Thu Jun 30 12:39:10 2022 ] 	Top1: 66.45%
[ Thu Jun 30 12:39:11 2022 ] 	Top5: 90.45%
[ Thu Jun 30 12:39:11 2022 ] Training epoch: 11
[ Thu Jun 30 12:48:38 2022 ] 	Mean training loss: 0.8790.  Mean training acc: 73.57%.
[ Thu Jun 30 12:48:38 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 12:48:38 2022 ] Eval epoch: 11
[ Thu Jun 30 12:51:31 2022 ] 	Mean test loss of 796 batches: 1.1502873495445778.
[ Thu Jun 30 12:51:31 2022 ] 	Top1: 66.78%
[ Thu Jun 30 12:51:32 2022 ] 	Top5: 90.71%
[ Thu Jun 30 12:51:32 2022 ] Training epoch: 12
[ Thu Jun 30 13:00:58 2022 ] 	Mean training loss: 0.8546.  Mean training acc: 74.37%.
[ Thu Jun 30 13:00:58 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 13:00:58 2022 ] Eval epoch: 12
[ Thu Jun 30 13:03:47 2022 ] 	Mean test loss of 796 batches: 1.2826222006849308.
[ Thu Jun 30 13:03:47 2022 ] 	Top1: 63.55%
[ Thu Jun 30 13:03:47 2022 ] 	Top5: 89.11%
[ Thu Jun 30 13:03:47 2022 ] Training epoch: 13
[ Thu Jun 30 13:13:36 2022 ] 	Mean training loss: 0.8402.  Mean training acc: 74.86%.
[ Thu Jun 30 13:13:36 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 13:13:36 2022 ] Eval epoch: 13
[ Thu Jun 30 13:16:43 2022 ] 	Mean test loss of 796 batches: 1.2337947233612814.
[ Thu Jun 30 13:16:44 2022 ] 	Top1: 64.00%
[ Thu Jun 30 13:16:44 2022 ] 	Top5: 90.46%
[ Thu Jun 30 13:16:44 2022 ] Training epoch: 14
[ Thu Jun 30 13:25:56 2022 ] 	Mean training loss: 0.8139.  Mean training acc: 75.51%.
[ Thu Jun 30 13:25:56 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 13:25:56 2022 ] Eval epoch: 14
[ Thu Jun 30 13:28:52 2022 ] 	Mean test loss of 796 batches: 1.0649700535451947.
[ Thu Jun 30 13:28:53 2022 ] 	Top1: 69.27%
[ Thu Jun 30 13:28:53 2022 ] 	Top5: 91.51%
[ Thu Jun 30 13:28:53 2022 ] Training epoch: 15
[ Thu Jun 30 13:38:32 2022 ] 	Mean training loss: 0.8045.  Mean training acc: 75.77%.
[ Thu Jun 30 13:38:32 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 13:38:32 2022 ] Eval epoch: 15
[ Thu Jun 30 13:41:31 2022 ] 	Mean test loss of 796 batches: 1.2464786400672179.
[ Thu Jun 30 13:41:31 2022 ] 	Top1: 64.07%
[ Thu Jun 30 13:41:31 2022 ] 	Top5: 90.49%
[ Thu Jun 30 13:41:31 2022 ] Training epoch: 16
[ Thu Jun 30 13:50:53 2022 ] 	Mean training loss: 0.7933.  Mean training acc: 76.16%.
[ Thu Jun 30 13:50:53 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 13:50:53 2022 ] Eval epoch: 16
[ Thu Jun 30 13:53:49 2022 ] 	Mean test loss of 796 batches: 1.12305365019857.
[ Thu Jun 30 13:53:49 2022 ] 	Top1: 67.29%
[ Thu Jun 30 13:53:49 2022 ] 	Top5: 91.78%
[ Thu Jun 30 13:53:49 2022 ] Training epoch: 17
[ Thu Jun 30 14:03:30 2022 ] 	Mean training loss: 0.7824.  Mean training acc: 76.42%.
[ Thu Jun 30 14:03:30 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 14:03:30 2022 ] Eval epoch: 17
[ Thu Jun 30 14:07:02 2022 ] 	Mean test loss of 796 batches: 1.0594093568585625.
[ Thu Jun 30 14:07:02 2022 ] 	Top1: 69.11%
[ Thu Jun 30 14:07:03 2022 ] 	Top5: 91.77%
[ Thu Jun 30 14:07:03 2022 ] Training epoch: 18
[ Thu Jun 30 14:17:01 2022 ] 	Mean training loss: 0.7800.  Mean training acc: 76.34%.
[ Thu Jun 30 14:17:01 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 14:17:01 2022 ] Eval epoch: 18
[ Thu Jun 30 14:20:28 2022 ] 	Mean test loss of 796 batches: 1.249520493324977.
[ Thu Jun 30 14:20:29 2022 ] 	Top1: 65.32%
[ Thu Jun 30 14:20:29 2022 ] 	Top5: 89.76%
[ Thu Jun 30 14:20:29 2022 ] Training epoch: 19
[ Thu Jun 30 14:30:05 2022 ] 	Mean training loss: 0.7680.  Mean training acc: 76.82%.
[ Thu Jun 30 14:30:05 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 14:30:05 2022 ] Eval epoch: 19
[ Thu Jun 30 14:33:33 2022 ] 	Mean test loss of 796 batches: 1.2550362789975338.
[ Thu Jun 30 14:33:34 2022 ] 	Top1: 65.68%
[ Thu Jun 30 14:33:34 2022 ] 	Top5: 89.26%
[ Thu Jun 30 14:33:34 2022 ] Training epoch: 20
[ Thu Jun 30 14:43:18 2022 ] 	Mean training loss: 0.7687.  Mean training acc: 76.88%.
[ Thu Jun 30 14:43:18 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 14:43:18 2022 ] Eval epoch: 20
[ Thu Jun 30 14:46:49 2022 ] 	Mean test loss of 796 batches: 1.3072850294598384.
[ Thu Jun 30 14:46:50 2022 ] 	Top1: 63.63%
[ Thu Jun 30 14:46:50 2022 ] 	Top5: 90.05%
[ Thu Jun 30 14:46:51 2022 ] Training epoch: 21
[ Thu Jun 30 14:56:29 2022 ] 	Mean training loss: 0.7640.  Mean training acc: 77.06%.
[ Thu Jun 30 14:56:31 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 14:56:31 2022 ] Eval epoch: 21
[ Thu Jun 30 15:00:07 2022 ] 	Mean test loss of 796 batches: 1.4634941552002825.
[ Thu Jun 30 15:00:07 2022 ] 	Top1: 60.85%
[ Thu Jun 30 15:00:08 2022 ] 	Top5: 87.57%
[ Thu Jun 30 15:00:08 2022 ] Training epoch: 22
[ Thu Jun 30 15:10:15 2022 ] 	Mean training loss: 0.7542.  Mean training acc: 77.36%.
[ Thu Jun 30 15:10:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 15:10:15 2022 ] Eval epoch: 22
[ Thu Jun 30 15:13:55 2022 ] 	Mean test loss of 796 batches: 1.0409869657614124.
[ Thu Jun 30 15:13:55 2022 ] 	Top1: 70.13%
[ Thu Jun 30 15:13:56 2022 ] 	Top5: 92.04%
[ Thu Jun 30 15:13:56 2022 ] Training epoch: 23
[ Thu Jun 30 15:23:52 2022 ] 	Mean training loss: 0.7516.  Mean training acc: 77.50%.
[ Thu Jun 30 15:23:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 15:23:52 2022 ] Eval epoch: 23
[ Thu Jun 30 15:27:28 2022 ] 	Mean test loss of 796 batches: 1.287756454031072.
[ Thu Jun 30 15:27:28 2022 ] 	Top1: 64.35%
[ Thu Jun 30 15:27:29 2022 ] 	Top5: 88.34%
[ Thu Jun 30 15:27:29 2022 ] Training epoch: 24
[ Thu Jun 30 15:37:04 2022 ] 	Mean training loss: 0.7499.  Mean training acc: 77.49%.
[ Thu Jun 30 15:37:04 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 15:37:04 2022 ] Eval epoch: 24
[ Thu Jun 30 15:40:35 2022 ] 	Mean test loss of 796 batches: 0.9676797312857518.
[ Thu Jun 30 15:40:36 2022 ] 	Top1: 71.28%
[ Thu Jun 30 15:40:37 2022 ] 	Top5: 93.15%
[ Thu Jun 30 15:40:37 2022 ] Training epoch: 25
[ Thu Jun 30 15:50:49 2022 ] 	Mean training loss: 0.7504.  Mean training acc: 77.32%.
[ Thu Jun 30 15:50:49 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 15:50:49 2022 ] Eval epoch: 25
[ Thu Jun 30 15:54:09 2022 ] 	Mean test loss of 796 batches: 1.0874501468997504.
[ Thu Jun 30 15:54:11 2022 ] 	Top1: 68.78%
[ Thu Jun 30 15:54:11 2022 ] 	Top5: 91.71%
[ Thu Jun 30 15:54:11 2022 ] Training epoch: 26
[ Thu Jun 30 16:03:42 2022 ] 	Mean training loss: 0.7440.  Mean training acc: 77.60%.
[ Thu Jun 30 16:03:42 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 16:03:42 2022 ] Eval epoch: 26
[ Thu Jun 30 16:07:13 2022 ] 	Mean test loss of 796 batches: 1.003206703493643.
[ Thu Jun 30 16:07:13 2022 ] 	Top1: 70.70%
[ Thu Jun 30 16:07:14 2022 ] 	Top5: 93.04%
[ Thu Jun 30 16:07:14 2022 ] Training epoch: 27
[ Thu Jun 30 16:17:03 2022 ] 	Mean training loss: 0.7447.  Mean training acc: 77.73%.
[ Thu Jun 30 16:17:03 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 16:17:03 2022 ] Eval epoch: 27
[ Thu Jun 30 16:20:30 2022 ] 	Mean test loss of 796 batches: 1.0978312824089922.
[ Thu Jun 30 16:20:31 2022 ] 	Top1: 68.54%
[ Thu Jun 30 16:20:31 2022 ] 	Top5: 91.24%
[ Thu Jun 30 16:20:31 2022 ] Training epoch: 28
[ Thu Jun 30 16:30:22 2022 ] 	Mean training loss: 0.7389.  Mean training acc: 77.76%.
[ Thu Jun 30 16:30:22 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 16:30:22 2022 ] Eval epoch: 28
[ Thu Jun 30 16:33:50 2022 ] 	Mean test loss of 796 batches: 1.076699859308238.
[ Thu Jun 30 16:33:51 2022 ] 	Top1: 68.75%
[ Thu Jun 30 16:33:52 2022 ] 	Top5: 91.31%
[ Thu Jun 30 16:33:52 2022 ] Training epoch: 29
[ Thu Jun 30 16:43:40 2022 ] 	Mean training loss: 0.7434.  Mean training acc: 77.55%.
[ Thu Jun 30 16:43:40 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 16:43:40 2022 ] Eval epoch: 29
[ Thu Jun 30 16:47:11 2022 ] 	Mean test loss of 796 batches: 1.0449326480153818.
[ Thu Jun 30 16:47:12 2022 ] 	Top1: 69.56%
[ Thu Jun 30 16:47:13 2022 ] 	Top5: 92.69%
[ Thu Jun 30 16:47:13 2022 ] Training epoch: 30
[ Thu Jun 30 16:57:23 2022 ] 	Mean training loss: 0.7426.  Mean training acc: 77.49%.
[ Thu Jun 30 16:57:23 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 16:57:23 2022 ] Eval epoch: 30
[ Thu Jun 30 17:01:09 2022 ] 	Mean test loss of 796 batches: 1.259364475819034.
[ Thu Jun 30 17:01:09 2022 ] 	Top1: 64.83%
[ Thu Jun 30 17:01:10 2022 ] 	Top5: 90.54%
[ Thu Jun 30 17:01:10 2022 ] Training epoch: 31
[ Thu Jun 30 17:11:13 2022 ] 	Mean training loss: 0.7348.  Mean training acc: 77.97%.
[ Thu Jun 30 17:11:13 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 17:11:13 2022 ] Eval epoch: 31
[ Thu Jun 30 17:14:49 2022 ] 	Mean test loss of 796 batches: 1.0834237453551148.
[ Thu Jun 30 17:14:49 2022 ] 	Top1: 68.08%
[ Thu Jun 30 17:14:50 2022 ] 	Top5: 92.11%
[ Thu Jun 30 17:14:50 2022 ] Training epoch: 32
[ Thu Jun 30 17:24:34 2022 ] 	Mean training loss: 0.7378.  Mean training acc: 77.92%.
[ Thu Jun 30 17:24:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 17:24:34 2022 ] Eval epoch: 32
[ Thu Jun 30 17:28:07 2022 ] 	Mean test loss of 796 batches: 1.486814738255949.
[ Thu Jun 30 17:28:08 2022 ] 	Top1: 60.84%
[ Thu Jun 30 17:28:09 2022 ] 	Top5: 87.00%
[ Thu Jun 30 17:28:09 2022 ] Training epoch: 33
[ Thu Jun 30 17:37:52 2022 ] 	Mean training loss: 0.7290.  Mean training acc: 78.04%.
[ Thu Jun 30 17:37:52 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 17:37:52 2022 ] Eval epoch: 33
[ Thu Jun 30 17:41:31 2022 ] 	Mean test loss of 796 batches: 1.1419258652320459.
[ Thu Jun 30 17:41:32 2022 ] 	Top1: 66.87%
[ Thu Jun 30 17:41:33 2022 ] 	Top5: 91.15%
[ Thu Jun 30 17:41:33 2022 ] Training epoch: 34
[ Thu Jun 30 17:51:09 2022 ] 	Mean training loss: 0.7270.  Mean training acc: 78.05%.
[ Thu Jun 30 17:51:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 17:51:10 2022 ] Eval epoch: 34
[ Thu Jun 30 17:54:44 2022 ] 	Mean test loss of 796 batches: 1.2952757340729537.
[ Thu Jun 30 17:54:45 2022 ] 	Top1: 64.69%
[ Thu Jun 30 17:54:45 2022 ] 	Top5: 87.86%
[ Thu Jun 30 17:54:46 2022 ] Training epoch: 35
[ Thu Jun 30 18:04:33 2022 ] 	Mean training loss: 0.7239.  Mean training acc: 78.32%.
[ Thu Jun 30 18:04:34 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 18:04:34 2022 ] Eval epoch: 35
[ Thu Jun 30 18:08:03 2022 ] 	Mean test loss of 796 batches: 1.1841108951736334.
[ Thu Jun 30 18:08:03 2022 ] 	Top1: 67.12%
[ Thu Jun 30 18:08:04 2022 ] 	Top5: 89.64%
[ Thu Jun 30 18:08:04 2022 ] Training epoch: 36
[ Thu Jun 30 18:17:35 2022 ] 	Mean training loss: 0.4182.  Mean training acc: 87.50%.
[ Thu Jun 30 18:17:35 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 18:17:35 2022 ] Eval epoch: 36
[ Thu Jun 30 18:20:51 2022 ] 	Mean test loss of 796 batches: 0.5726217199210546.
[ Thu Jun 30 18:20:59 2022 ] 	Top1: 82.27%
[ Thu Jun 30 18:21:00 2022 ] 	Top5: 96.74%
[ Thu Jun 30 18:21:00 2022 ] Training epoch: 37
[ Thu Jun 30 18:30:35 2022 ] 	Mean training loss: 0.3353.  Mean training acc: 89.87%.
[ Thu Jun 30 18:30:35 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 18:30:35 2022 ] Eval epoch: 37
[ Thu Jun 30 18:34:08 2022 ] 	Mean test loss of 796 batches: 0.5645270291435059.
[ Thu Jun 30 18:34:08 2022 ] 	Top1: 82.70%
[ Thu Jun 30 18:34:09 2022 ] 	Top5: 96.79%
[ Thu Jun 30 18:34:09 2022 ] Training epoch: 38
[ Thu Jun 30 18:44:45 2022 ] 	Mean training loss: 0.3029.  Mean training acc: 90.99%.
[ Thu Jun 30 18:44:45 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Thu Jun 30 18:44:45 2022 ] Eval epoch: 38
[ Thu Jun 30 18:48:54 2022 ] 	Mean test loss of 796 batches: 0.5482803549355448.
[ Thu Jun 30 18:48:54 2022 ] 	Top1: 83.25%
[ Thu Jun 30 18:48:55 2022 ] 	Top5: 96.94%
[ Thu Jun 30 18:48:55 2022 ] Training epoch: 39
[ Thu Jun 30 19:02:12 2022 ] 	Mean training loss: 0.2778.  Mean training acc: 91.73%.
[ Thu Jun 30 19:02:12 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 19:02:12 2022 ] Eval epoch: 39
[ Thu Jun 30 19:06:24 2022 ] 	Mean test loss of 796 batches: 0.5614849894995516.
[ Thu Jun 30 19:06:25 2022 ] 	Top1: 82.89%
[ Thu Jun 30 19:06:25 2022 ] 	Top5: 96.92%
[ Thu Jun 30 19:06:26 2022 ] Training epoch: 40
[ Thu Jun 30 19:19:37 2022 ] 	Mean training loss: 0.2536.  Mean training acc: 92.62%.
[ Thu Jun 30 19:19:37 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 19:19:38 2022 ] Eval epoch: 40
[ Thu Jun 30 19:23:51 2022 ] 	Mean test loss of 796 batches: 0.5646455943041561.
[ Thu Jun 30 19:23:51 2022 ] 	Top1: 83.02%
[ Thu Jun 30 19:23:52 2022 ] 	Top5: 96.83%
[ Thu Jun 30 19:23:52 2022 ] Training epoch: 41
[ Thu Jun 30 19:36:54 2022 ] 	Mean training loss: 0.2385.  Mean training acc: 93.01%.
[ Thu Jun 30 19:36:54 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 19:36:54 2022 ] Eval epoch: 41
[ Thu Jun 30 19:40:38 2022 ] 	Mean test loss of 796 batches: 0.5766686689876133.
[ Thu Jun 30 19:40:39 2022 ] 	Top1: 82.89%
[ Thu Jun 30 19:40:39 2022 ] 	Top5: 96.74%
[ Thu Jun 30 19:40:39 2022 ] Training epoch: 42
[ Thu Jun 30 19:53:16 2022 ] 	Mean training loss: 0.2250.  Mean training acc: 93.55%.
[ Thu Jun 30 19:53:16 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 19:53:16 2022 ] Eval epoch: 42
[ Thu Jun 30 19:57:01 2022 ] 	Mean test loss of 796 batches: 0.6061101044766867.
[ Thu Jun 30 19:57:02 2022 ] 	Top1: 82.28%
[ Thu Jun 30 19:57:02 2022 ] 	Top5: 96.46%
[ Thu Jun 30 19:57:02 2022 ] Training epoch: 43
[ Thu Jun 30 20:09:40 2022 ] 	Mean training loss: 0.2132.  Mean training acc: 93.78%.
[ Thu Jun 30 20:09:40 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 20:09:40 2022 ] Eval epoch: 43
[ Thu Jun 30 20:13:24 2022 ] 	Mean test loss of 796 batches: 0.613304638898178.
[ Thu Jun 30 20:13:24 2022 ] 	Top1: 82.19%
[ Thu Jun 30 20:13:24 2022 ] 	Top5: 96.49%
[ Thu Jun 30 20:13:24 2022 ] Training epoch: 44
[ Thu Jun 30 20:26:07 2022 ] 	Mean training loss: 0.1987.  Mean training acc: 94.42%.
[ Thu Jun 30 20:26:07 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 20:26:07 2022 ] Eval epoch: 44
[ Thu Jun 30 20:29:52 2022 ] 	Mean test loss of 796 batches: 0.6091786642376352.
[ Thu Jun 30 20:29:52 2022 ] 	Top1: 82.32%
[ Thu Jun 30 20:29:53 2022 ] 	Top5: 96.48%
[ Thu Jun 30 20:29:53 2022 ] Training epoch: 45
[ Thu Jun 30 20:42:28 2022 ] 	Mean training loss: 0.1924.  Mean training acc: 94.54%.
[ Thu Jun 30 20:42:28 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 20:42:28 2022 ] Eval epoch: 45
[ Thu Jun 30 20:46:15 2022 ] 	Mean test loss of 796 batches: 0.6171160765441518.
[ Thu Jun 30 20:46:15 2022 ] 	Top1: 82.23%
[ Thu Jun 30 20:46:15 2022 ] 	Top5: 96.37%
[ Thu Jun 30 20:46:15 2022 ] Training epoch: 46
[ Thu Jun 30 20:58:53 2022 ] 	Mean training loss: 0.1857.  Mean training acc: 94.88%.
[ Thu Jun 30 20:58:53 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 20:58:53 2022 ] Eval epoch: 46
[ Thu Jun 30 21:02:37 2022 ] 	Mean test loss of 796 batches: 0.6557543886797362.
[ Thu Jun 30 21:02:37 2022 ] 	Top1: 81.60%
[ Thu Jun 30 21:02:38 2022 ] 	Top5: 96.08%
[ Thu Jun 30 21:02:38 2022 ] Training epoch: 47
[ Thu Jun 30 21:15:22 2022 ] 	Mean training loss: 0.1795.  Mean training acc: 95.04%.
[ Thu Jun 30 21:15:22 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 21:15:22 2022 ] Eval epoch: 47
[ Thu Jun 30 21:19:06 2022 ] 	Mean test loss of 796 batches: 0.6366528511871046.
[ Thu Jun 30 21:19:07 2022 ] 	Top1: 81.82%
[ Thu Jun 30 21:19:07 2022 ] 	Top5: 96.20%
[ Thu Jun 30 21:19:07 2022 ] Training epoch: 48
[ Thu Jun 30 21:31:56 2022 ] 	Mean training loss: 0.1805.  Mean training acc: 95.00%.
[ Thu Jun 30 21:31:56 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 21:31:56 2022 ] Eval epoch: 48
[ Thu Jun 30 21:35:44 2022 ] 	Mean test loss of 796 batches: 0.6694081506537433.
[ Thu Jun 30 21:35:45 2022 ] 	Top1: 81.54%
[ Thu Jun 30 21:35:45 2022 ] 	Top5: 96.09%
[ Thu Jun 30 21:35:45 2022 ] Training epoch: 49
[ Thu Jun 30 21:48:32 2022 ] 	Mean training loss: 0.1732.  Mean training acc: 95.29%.
[ Thu Jun 30 21:48:32 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 21:48:32 2022 ] Eval epoch: 49
[ Thu Jun 30 21:52:20 2022 ] 	Mean test loss of 796 batches: 0.7267637136930497.
[ Thu Jun 30 21:52:20 2022 ] 	Top1: 79.89%
[ Thu Jun 30 21:52:21 2022 ] 	Top5: 95.53%
[ Thu Jun 30 21:52:21 2022 ] Training epoch: 50
[ Thu Jun 30 22:05:03 2022 ] 	Mean training loss: 0.1739.  Mean training acc: 95.13%.
[ Thu Jun 30 22:05:03 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 22:05:03 2022 ] Eval epoch: 50
[ Thu Jun 30 22:08:52 2022 ] 	Mean test loss of 796 batches: 0.7116101276616206.
[ Thu Jun 30 22:08:53 2022 ] 	Top1: 80.32%
[ Thu Jun 30 22:08:53 2022 ] 	Top5: 95.69%
[ Thu Jun 30 22:08:53 2022 ] Training epoch: 51
[ Thu Jun 30 22:21:40 2022 ] 	Mean training loss: 0.1709.  Mean training acc: 95.25%.
[ Thu Jun 30 22:21:40 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 22:21:40 2022 ] Eval epoch: 51
[ Thu Jun 30 22:25:31 2022 ] 	Mean test loss of 796 batches: 0.7260443722857303.
[ Thu Jun 30 22:25:32 2022 ] 	Top1: 79.79%
[ Thu Jun 30 22:25:32 2022 ] 	Top5: 95.53%
[ Thu Jun 30 22:25:32 2022 ] Training epoch: 52
[ Thu Jun 30 22:38:10 2022 ] 	Mean training loss: 0.1727.  Mean training acc: 95.23%.
[ Thu Jun 30 22:38:10 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 22:38:10 2022 ] Eval epoch: 52
[ Thu Jun 30 22:42:02 2022 ] 	Mean test loss of 796 batches: 0.7123245725866838.
[ Thu Jun 30 22:42:03 2022 ] 	Top1: 80.61%
[ Thu Jun 30 22:42:03 2022 ] 	Top5: 95.72%
[ Thu Jun 30 22:42:03 2022 ] Training epoch: 53
[ Thu Jun 30 22:54:46 2022 ] 	Mean training loss: 0.1665.  Mean training acc: 95.37%.
[ Thu Jun 30 22:54:46 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 22:54:46 2022 ] Eval epoch: 53
[ Thu Jun 30 22:58:37 2022 ] 	Mean test loss of 796 batches: 0.74033694068466.
[ Thu Jun 30 22:58:38 2022 ] 	Top1: 80.15%
[ Thu Jun 30 22:58:38 2022 ] 	Top5: 95.30%
[ Thu Jun 30 22:58:38 2022 ] Training epoch: 54
[ Thu Jun 30 23:10:39 2022 ] 	Mean training loss: 0.1702.  Mean training acc: 95.33%.
[ Thu Jun 30 23:10:39 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 23:10:39 2022 ] Eval epoch: 54
[ Thu Jun 30 23:13:45 2022 ] 	Mean test loss of 796 batches: 0.6891837681283304.
[ Thu Jun 30 23:13:45 2022 ] 	Top1: 81.02%
[ Thu Jun 30 23:13:45 2022 ] 	Top5: 95.80%
[ Thu Jun 30 23:13:45 2022 ] Training epoch: 55
[ Thu Jun 30 23:23:36 2022 ] 	Mean training loss: 0.1672.  Mean training acc: 95.43%.
[ Thu Jun 30 23:23:36 2022 ] 	Time consumption: [Data]01%, [Network]98%
[ Thu Jun 30 23:23:36 2022 ] Eval epoch: 55
[ Thu Jun 30 23:27:11 2022 ] 	Mean test loss of 796 batches: 0.6688365989537844.
[ Thu Jun 30 23:27:11 2022 ] 	Top1: 81.32%
[ Thu Jun 30 23:27:12 2022 ] 	Top5: 96.01%
[ Thu Jun 30 23:27:12 2022 ] Training epoch: 56
[ Thu Jun 30 23:37:20 2022 ] 	Mean training loss: 0.0918.  Mean training acc: 98.02%.
[ Thu Jun 30 23:37:20 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 23:37:20 2022 ] Eval epoch: 56
[ Thu Jun 30 23:40:54 2022 ] 	Mean test loss of 796 batches: 0.6158908879543519.
[ Thu Jun 30 23:40:55 2022 ] 	Top1: 83.14%
[ Thu Jun 30 23:40:55 2022 ] 	Top5: 96.44%
[ Thu Jun 30 23:40:55 2022 ] Training epoch: 57
[ Thu Jun 30 23:51:09 2022 ] 	Mean training loss: 0.0711.  Mean training acc: 98.58%.
[ Thu Jun 30 23:51:09 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Thu Jun 30 23:51:09 2022 ] Eval epoch: 57
[ Thu Jun 30 23:54:44 2022 ] 	Mean test loss of 796 batches: 0.6040208908406335.
[ Thu Jun 30 23:54:45 2022 ] 	Top1: 83.42%
[ Thu Jun 30 23:54:45 2022 ] 	Top5: 96.55%
[ Thu Jun 30 23:54:45 2022 ] Training epoch: 58
[ Fri Jul  1 00:04:59 2022 ] 	Mean training loss: 0.0617.  Mean training acc: 98.85%.
[ Fri Jul  1 00:04:59 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 00:04:59 2022 ] Eval epoch: 58
[ Fri Jul  1 00:08:34 2022 ] 	Mean test loss of 796 batches: 0.6152569668311345.
[ Fri Jul  1 00:08:34 2022 ] 	Top1: 83.13%
[ Fri Jul  1 00:08:35 2022 ] 	Top5: 96.41%
[ Fri Jul  1 00:08:35 2022 ] Training epoch: 59
[ Fri Jul  1 00:18:46 2022 ] 	Mean training loss: 0.0562.  Mean training acc: 98.99%.
[ Fri Jul  1 00:18:46 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 00:18:46 2022 ] Eval epoch: 59
[ Fri Jul  1 00:22:21 2022 ] 	Mean test loss of 796 batches: 0.6096765296393304.
[ Fri Jul  1 00:22:21 2022 ] 	Top1: 83.36%
[ Fri Jul  1 00:22:22 2022 ] 	Top5: 96.50%
[ Fri Jul  1 00:22:22 2022 ] Training epoch: 60
[ Fri Jul  1 00:32:39 2022 ] 	Mean training loss: 0.0539.  Mean training acc: 99.08%.
[ Fri Jul  1 00:32:39 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 00:32:39 2022 ] Eval epoch: 60
[ Fri Jul  1 00:36:13 2022 ] 	Mean test loss of 796 batches: 0.6145206059998454.
[ Fri Jul  1 00:36:13 2022 ] 	Top1: 83.32%
[ Fri Jul  1 00:36:14 2022 ] 	Top5: 96.51%
[ Fri Jul  1 00:36:14 2022 ] Training epoch: 61
[ Fri Jul  1 00:46:34 2022 ] 	Mean training loss: 0.0496.  Mean training acc: 99.17%.
[ Fri Jul  1 00:46:34 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 00:46:34 2022 ] Eval epoch: 61
[ Fri Jul  1 00:50:11 2022 ] 	Mean test loss of 796 batches: 0.6171109651463416.
[ Fri Jul  1 00:50:12 2022 ] 	Top1: 83.19%
[ Fri Jul  1 00:50:12 2022 ] 	Top5: 96.44%
[ Fri Jul  1 00:50:13 2022 ] Training epoch: 62
[ Fri Jul  1 01:00:30 2022 ] 	Mean training loss: 0.0479.  Mean training acc: 99.22%.
[ Fri Jul  1 01:00:30 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jul  1 01:00:30 2022 ] Eval epoch: 62
[ Fri Jul  1 01:04:06 2022 ] 	Mean test loss of 796 batches: 0.619331228083477.
[ Fri Jul  1 01:04:07 2022 ] 	Top1: 83.25%
[ Fri Jul  1 01:04:08 2022 ] 	Top5: 96.46%
[ Fri Jul  1 01:04:08 2022 ] Training epoch: 63
[ Fri Jul  1 01:14:32 2022 ] 	Mean training loss: 0.0454.  Mean training acc: 99.32%.
[ Fri Jul  1 01:14:32 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 01:14:32 2022 ] Eval epoch: 63
[ Fri Jul  1 01:18:01 2022 ] 	Mean test loss of 796 batches: 0.6302462131786511.
[ Fri Jul  1 01:18:02 2022 ] 	Top1: 83.00%
[ Fri Jul  1 01:18:02 2022 ] 	Top5: 96.28%
[ Fri Jul  1 01:18:02 2022 ] Training epoch: 64
[ Fri Jul  1 01:28:21 2022 ] 	Mean training loss: 0.0440.  Mean training acc: 99.37%.
[ Fri Jul  1 01:28:21 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Fri Jul  1 01:28:21 2022 ] Eval epoch: 64
[ Fri Jul  1 01:31:54 2022 ] 	Mean test loss of 796 batches: 0.6322119150160994.
[ Fri Jul  1 01:31:54 2022 ] 	Top1: 82.94%
[ Fri Jul  1 01:31:55 2022 ] 	Top5: 96.35%
[ Fri Jul  1 01:31:55 2022 ] Training epoch: 65
[ Fri Jul  1 01:42:15 2022 ] 	Mean training loss: 0.0432.  Mean training acc: 99.34%.
[ Fri Jul  1 01:42:15 2022 ] 	Time consumption: [Data]02%, [Network]98%
[ Fri Jul  1 01:42:15 2022 ] Eval epoch: 65
[ Fri Jul  1 01:45:47 2022 ] 	Mean test loss of 796 batches: 0.6232011419482267.
[ Fri Jul  1 01:45:48 2022 ] 	Top1: 83.31%
[ Fri Jul  1 01:45:48 2022 ] 	Top5: 96.32%
[ Fri Jul  1 01:49:22 2022 ] Best accuracy: 0.8342858265087688
[ Fri Jul  1 01:49:22 2022 ] Epoch number: 57
[ Fri Jul  1 01:49:22 2022 ] Model name: work_dir/ntu120/csub/base_four6a_BL
[ Fri Jul  1 01:49:22 2022 ] Model total number of params: 2128482
[ Fri Jul  1 01:49:22 2022 ] Weight decay: 0.0004
[ Fri Jul  1 01:49:22 2022 ] Base LR: 0.1
[ Fri Jul  1 01:49:22 2022 ] Batch Size: 64
[ Fri Jul  1 01:49:22 2022 ] Test Batch Size: 64
[ Fri Jul  1 01:49:22 2022 ] seed: 1
