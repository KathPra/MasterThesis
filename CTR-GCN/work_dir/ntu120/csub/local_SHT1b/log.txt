[ Mon Oct 17 23:23:18 2022 ] using warm up, epoch: 5
[ Mon Oct 17 23:23:35 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHT1b', 'model_saved_name': 'work_dir/ntu120/csub/local_SHT1b/runs', 'config': 'config/nturgbd120-cross-subject/default.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.local_SHT1b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': None, 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55], 'device': [3], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 0, 'num_epoch': 65, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Mon Oct 17 23:23:35 2022 ] # Parameters: 2133954
[ Mon Oct 17 23:23:35 2022 ] Training epoch: 1
[ Mon Oct 17 23:26:45 2022 ] 	Mean training loss: 2.8810.  Mean training acc: 27.43%.
[ Mon Oct 17 23:26:45 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:26:45 2022 ] Eval epoch: 1
[ Mon Oct 17 23:27:35 2022 ] 	Mean test loss of 796 batches: 2.343541883943069.
[ Mon Oct 17 23:27:35 2022 ] 	Top1: 35.37%
[ Mon Oct 17 23:27:35 2022 ] 	Top5: 71.69%
[ Mon Oct 17 23:27:36 2022 ] Training epoch: 2
[ Mon Oct 17 23:30:46 2022 ] 	Mean training loss: 1.9909.  Mean training acc: 44.76%.
[ Mon Oct 17 23:30:46 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:30:46 2022 ] Eval epoch: 2
[ Mon Oct 17 23:31:36 2022 ] 	Mean test loss of 796 batches: 1.8780615450299565.
[ Mon Oct 17 23:31:36 2022 ] 	Top1: 46.65%
[ Mon Oct 17 23:31:37 2022 ] 	Top5: 80.65%
[ Mon Oct 17 23:31:37 2022 ] Training epoch: 3
[ Mon Oct 17 23:34:47 2022 ] 	Mean training loss: 1.6268.  Mean training acc: 53.74%.
[ Mon Oct 17 23:34:47 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:34:47 2022 ] Eval epoch: 3
[ Mon Oct 17 23:35:37 2022 ] 	Mean test loss of 796 batches: 1.7470501689006335.
[ Mon Oct 17 23:35:37 2022 ] 	Top1: 49.08%
[ Mon Oct 17 23:35:38 2022 ] 	Top5: 83.25%
[ Mon Oct 17 23:35:38 2022 ] Training epoch: 4
[ Mon Oct 17 23:38:48 2022 ] 	Mean training loss: 1.4407.  Mean training acc: 58.55%.
[ Mon Oct 17 23:38:48 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Oct 17 23:38:48 2022 ] Eval epoch: 4
[ Mon Oct 17 23:39:37 2022 ] 	Mean test loss of 796 batches: 1.6039699640256078.
[ Mon Oct 17 23:39:38 2022 ] 	Top1: 54.16%
[ Mon Oct 17 23:39:38 2022 ] 	Top5: 85.56%
[ Mon Oct 17 23:39:38 2022 ] Training epoch: 5
[ Mon Oct 17 23:42:48 2022 ] 	Mean training loss: 1.3405.  Mean training acc: 61.34%.
[ Mon Oct 17 23:42:48 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:42:48 2022 ] Eval epoch: 5
[ Mon Oct 17 23:43:38 2022 ] 	Mean test loss of 796 batches: 1.43520733826424.
[ Mon Oct 17 23:43:38 2022 ] 	Top1: 58.68%
[ Mon Oct 17 23:43:39 2022 ] 	Top5: 87.56%
[ Mon Oct 17 23:43:39 2022 ] Training epoch: 6
[ Mon Oct 17 23:46:49 2022 ] 	Mean training loss: 1.1955.  Mean training acc: 64.90%.
[ Mon Oct 17 23:46:49 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Mon Oct 17 23:46:49 2022 ] Eval epoch: 6
[ Mon Oct 17 23:47:38 2022 ] 	Mean test loss of 796 batches: 1.540287756215987.
[ Mon Oct 17 23:47:39 2022 ] 	Top1: 57.13%
[ Mon Oct 17 23:47:39 2022 ] 	Top5: 87.16%
[ Mon Oct 17 23:47:39 2022 ] Training epoch: 7
[ Mon Oct 17 23:50:49 2022 ] 	Mean training loss: 1.0909.  Mean training acc: 67.67%.
[ Mon Oct 17 23:50:49 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:50:49 2022 ] Eval epoch: 7
[ Mon Oct 17 23:51:39 2022 ] 	Mean test loss of 796 batches: 1.4815656950875142.
[ Mon Oct 17 23:51:40 2022 ] 	Top1: 58.29%
[ Mon Oct 17 23:51:40 2022 ] 	Top5: 88.34%
[ Mon Oct 17 23:51:40 2022 ] Training epoch: 8
[ Mon Oct 17 23:54:50 2022 ] 	Mean training loss: 1.0040.  Mean training acc: 70.36%.
[ Mon Oct 17 23:54:50 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:54:50 2022 ] Eval epoch: 8
[ Mon Oct 17 23:55:40 2022 ] 	Mean test loss of 796 batches: 1.2305443500304343.
[ Mon Oct 17 23:55:40 2022 ] 	Top1: 65.16%
[ Mon Oct 17 23:55:41 2022 ] 	Top5: 90.25%
[ Mon Oct 17 23:55:41 2022 ] Training epoch: 9
[ Mon Oct 17 23:58:51 2022 ] 	Mean training loss: 0.9475.  Mean training acc: 71.91%.
[ Mon Oct 17 23:58:51 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Mon Oct 17 23:58:51 2022 ] Eval epoch: 9
[ Mon Oct 17 23:59:41 2022 ] 	Mean test loss of 796 batches: 1.1375238863966572.
[ Mon Oct 17 23:59:42 2022 ] 	Top1: 67.23%
[ Mon Oct 17 23:59:42 2022 ] 	Top5: 91.84%
[ Mon Oct 17 23:59:42 2022 ] Training epoch: 10
[ Tue Oct 18 00:02:52 2022 ] 	Mean training loss: 0.8964.  Mean training acc: 73.45%.
[ Tue Oct 18 00:02:52 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:02:52 2022 ] Eval epoch: 10
[ Tue Oct 18 00:03:42 2022 ] 	Mean test loss of 796 batches: 1.1255944731397245.
[ Tue Oct 18 00:03:42 2022 ] 	Top1: 67.08%
[ Tue Oct 18 00:03:43 2022 ] 	Top5: 92.02%
[ Tue Oct 18 00:03:43 2022 ] Training epoch: 11
[ Tue Oct 18 00:06:53 2022 ] 	Mean training loss: 0.8637.  Mean training acc: 74.31%.
[ Tue Oct 18 00:06:53 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:06:53 2022 ] Eval epoch: 11
[ Tue Oct 18 00:07:43 2022 ] 	Mean test loss of 796 batches: 1.0950569444565317.
[ Tue Oct 18 00:07:43 2022 ] 	Top1: 67.50%
[ Tue Oct 18 00:07:44 2022 ] 	Top5: 92.38%
[ Tue Oct 18 00:07:44 2022 ] Training epoch: 12
[ Tue Oct 18 00:10:54 2022 ] 	Mean training loss: 0.8358.  Mean training acc: 75.00%.
[ Tue Oct 18 00:10:54 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:10:54 2022 ] Eval epoch: 12
[ Tue Oct 18 00:11:44 2022 ] 	Mean test loss of 796 batches: 1.2351856590365644.
[ Tue Oct 18 00:11:44 2022 ] 	Top1: 65.61%
[ Tue Oct 18 00:11:45 2022 ] 	Top5: 90.68%
[ Tue Oct 18 00:11:45 2022 ] Training epoch: 13
[ Tue Oct 18 00:14:55 2022 ] 	Mean training loss: 0.8111.  Mean training acc: 75.63%.
[ Tue Oct 18 00:14:55 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:14:55 2022 ] Eval epoch: 13
[ Tue Oct 18 00:15:45 2022 ] 	Mean test loss of 796 batches: 1.072514242450496.
[ Tue Oct 18 00:15:45 2022 ] 	Top1: 68.79%
[ Tue Oct 18 00:15:46 2022 ] 	Top5: 92.39%
[ Tue Oct 18 00:15:46 2022 ] Training epoch: 14
[ Tue Oct 18 00:18:56 2022 ] 	Mean training loss: 0.7880.  Mean training acc: 76.36%.
[ Tue Oct 18 00:18:56 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:18:56 2022 ] Eval epoch: 14
[ Tue Oct 18 00:19:46 2022 ] 	Mean test loss of 796 batches: 1.0371771645381223.
[ Tue Oct 18 00:19:46 2022 ] 	Top1: 69.28%
[ Tue Oct 18 00:19:47 2022 ] 	Top5: 92.92%
[ Tue Oct 18 00:19:47 2022 ] Training epoch: 15
[ Tue Oct 18 00:22:57 2022 ] 	Mean training loss: 0.7788.  Mean training acc: 76.60%.
[ Tue Oct 18 00:22:57 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:22:57 2022 ] Eval epoch: 15
[ Tue Oct 18 00:23:47 2022 ] 	Mean test loss of 796 batches: 0.9810553593327053.
[ Tue Oct 18 00:23:47 2022 ] 	Top1: 70.97%
[ Tue Oct 18 00:23:47 2022 ] 	Top5: 93.83%
[ Tue Oct 18 00:23:47 2022 ] Training epoch: 16
[ Tue Oct 18 00:26:57 2022 ] 	Mean training loss: 0.7644.  Mean training acc: 77.09%.
[ Tue Oct 18 00:26:57 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:26:57 2022 ] Eval epoch: 16
[ Tue Oct 18 00:27:47 2022 ] 	Mean test loss of 796 batches: 1.0441452969034113.
[ Tue Oct 18 00:27:48 2022 ] 	Top1: 69.82%
[ Tue Oct 18 00:27:48 2022 ] 	Top5: 93.39%
[ Tue Oct 18 00:27:48 2022 ] Training epoch: 17
[ Tue Oct 18 00:30:58 2022 ] 	Mean training loss: 0.7508.  Mean training acc: 77.48%.
[ Tue Oct 18 00:30:58 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Oct 18 00:30:58 2022 ] Eval epoch: 17
[ Tue Oct 18 00:31:48 2022 ] 	Mean test loss of 796 batches: 1.0349994572487908.
[ Tue Oct 18 00:31:48 2022 ] 	Top1: 70.03%
[ Tue Oct 18 00:31:49 2022 ] 	Top5: 93.12%
[ Tue Oct 18 00:31:49 2022 ] Training epoch: 18
[ Tue Oct 18 00:34:59 2022 ] 	Mean training loss: 0.7429.  Mean training acc: 77.79%.
[ Tue Oct 18 00:34:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:34:59 2022 ] Eval epoch: 18
[ Tue Oct 18 00:35:49 2022 ] 	Mean test loss of 796 batches: 1.0541310536501995.
[ Tue Oct 18 00:35:49 2022 ] 	Top1: 69.40%
[ Tue Oct 18 00:35:49 2022 ] 	Top5: 92.27%
[ Tue Oct 18 00:35:49 2022 ] Training epoch: 19
[ Tue Oct 18 00:38:59 2022 ] 	Mean training loss: 0.7290.  Mean training acc: 78.07%.
[ Tue Oct 18 00:38:59 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:38:59 2022 ] Eval epoch: 19
[ Tue Oct 18 00:39:50 2022 ] 	Mean test loss of 796 batches: 1.1492751808322255.
[ Tue Oct 18 00:39:50 2022 ] 	Top1: 66.92%
[ Tue Oct 18 00:39:50 2022 ] 	Top5: 92.15%
[ Tue Oct 18 00:39:50 2022 ] Training epoch: 20
[ Tue Oct 18 00:43:00 2022 ] 	Mean training loss: 0.7287.  Mean training acc: 78.13%.
[ Tue Oct 18 00:43:00 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:43:00 2022 ] Eval epoch: 20
[ Tue Oct 18 00:43:50 2022 ] 	Mean test loss of 796 batches: 1.0596240312235439.
[ Tue Oct 18 00:43:51 2022 ] 	Top1: 70.18%
[ Tue Oct 18 00:43:51 2022 ] 	Top5: 92.68%
[ Tue Oct 18 00:43:51 2022 ] Training epoch: 21
[ Tue Oct 18 00:47:01 2022 ] 	Mean training loss: 0.7232.  Mean training acc: 78.24%.
[ Tue Oct 18 00:47:01 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:47:01 2022 ] Eval epoch: 21
[ Tue Oct 18 00:47:51 2022 ] 	Mean test loss of 796 batches: 1.0173728715010624.
[ Tue Oct 18 00:47:52 2022 ] 	Top1: 70.82%
[ Tue Oct 18 00:47:52 2022 ] 	Top5: 93.18%
[ Tue Oct 18 00:47:52 2022 ] Training epoch: 22
[ Tue Oct 18 00:51:02 2022 ] 	Mean training loss: 0.7159.  Mean training acc: 78.54%.
[ Tue Oct 18 00:51:02 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:51:02 2022 ] Eval epoch: 22
[ Tue Oct 18 00:51:52 2022 ] 	Mean test loss of 796 batches: 1.1006899553552345.
[ Tue Oct 18 00:51:53 2022 ] 	Top1: 69.00%
[ Tue Oct 18 00:51:53 2022 ] 	Top5: 92.38%
[ Tue Oct 18 00:51:53 2022 ] Training epoch: 23
[ Tue Oct 18 00:55:03 2022 ] 	Mean training loss: 0.7122.  Mean training acc: 78.69%.
[ Tue Oct 18 00:55:03 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 00:55:03 2022 ] Eval epoch: 23
[ Tue Oct 18 00:55:53 2022 ] 	Mean test loss of 796 batches: 0.980154662912515.
[ Tue Oct 18 00:55:54 2022 ] 	Top1: 71.68%
[ Tue Oct 18 00:55:54 2022 ] 	Top5: 93.61%
[ Tue Oct 18 00:55:54 2022 ] Training epoch: 24
[ Tue Oct 18 00:59:04 2022 ] 	Mean training loss: 0.7099.  Mean training acc: 78.69%.
[ Tue Oct 18 00:59:04 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Oct 18 00:59:04 2022 ] Eval epoch: 24
[ Tue Oct 18 00:59:54 2022 ] 	Mean test loss of 796 batches: 1.0530095122492493.
[ Tue Oct 18 00:59:54 2022 ] 	Top1: 69.55%
[ Tue Oct 18 00:59:54 2022 ] 	Top5: 93.21%
[ Tue Oct 18 00:59:55 2022 ] Training epoch: 25
[ Tue Oct 18 01:03:05 2022 ] 	Mean training loss: 0.7046.  Mean training acc: 78.69%.
[ Tue Oct 18 01:03:05 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:03:05 2022 ] Eval epoch: 25
[ Tue Oct 18 01:03:55 2022 ] 	Mean test loss of 796 batches: 0.9574172979024187.
[ Tue Oct 18 01:03:55 2022 ] 	Top1: 71.98%
[ Tue Oct 18 01:03:55 2022 ] 	Top5: 93.45%
[ Tue Oct 18 01:03:55 2022 ] Training epoch: 26
[ Tue Oct 18 01:07:06 2022 ] 	Mean training loss: 0.6995.  Mean training acc: 78.88%.
[ Tue Oct 18 01:07:06 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:07:06 2022 ] Eval epoch: 26
[ Tue Oct 18 01:07:56 2022 ] 	Mean test loss of 796 batches: 0.9682059589792137.
[ Tue Oct 18 01:07:56 2022 ] 	Top1: 72.09%
[ Tue Oct 18 01:07:57 2022 ] 	Top5: 93.39%
[ Tue Oct 18 01:07:57 2022 ] Training epoch: 27
[ Tue Oct 18 01:11:07 2022 ] 	Mean training loss: 0.6979.  Mean training acc: 79.04%.
[ Tue Oct 18 01:11:07 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:11:07 2022 ] Eval epoch: 27
[ Tue Oct 18 01:11:57 2022 ] 	Mean test loss of 796 batches: 1.1092324305194705.
[ Tue Oct 18 01:11:57 2022 ] 	Top1: 69.11%
[ Tue Oct 18 01:11:57 2022 ] 	Top5: 92.29%
[ Tue Oct 18 01:11:58 2022 ] Training epoch: 28
[ Tue Oct 18 01:15:08 2022 ] 	Mean training loss: 0.6960.  Mean training acc: 78.93%.
[ Tue Oct 18 01:15:08 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:15:08 2022 ] Eval epoch: 28
[ Tue Oct 18 01:15:58 2022 ] 	Mean test loss of 796 batches: 1.1327303181116903.
[ Tue Oct 18 01:15:58 2022 ] 	Top1: 69.14%
[ Tue Oct 18 01:15:58 2022 ] 	Top5: 91.44%
[ Tue Oct 18 01:15:59 2022 ] Training epoch: 29
[ Tue Oct 18 01:19:09 2022 ] 	Mean training loss: 0.6874.  Mean training acc: 79.50%.
[ Tue Oct 18 01:19:09 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:19:09 2022 ] Eval epoch: 29
[ Tue Oct 18 01:19:58 2022 ] 	Mean test loss of 796 batches: 0.975823602746779.
[ Tue Oct 18 01:19:59 2022 ] 	Top1: 72.27%
[ Tue Oct 18 01:19:59 2022 ] 	Top5: 93.37%
[ Tue Oct 18 01:19:59 2022 ] Training epoch: 30
[ Tue Oct 18 01:23:10 2022 ] 	Mean training loss: 0.6906.  Mean training acc: 79.12%.
[ Tue Oct 18 01:23:10 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:23:10 2022 ] Eval epoch: 30
[ Tue Oct 18 01:24:00 2022 ] 	Mean test loss of 796 batches: 1.0173834235075132.
[ Tue Oct 18 01:24:00 2022 ] 	Top1: 71.33%
[ Tue Oct 18 01:24:00 2022 ] 	Top5: 92.95%
[ Tue Oct 18 01:24:01 2022 ] Training epoch: 31
[ Tue Oct 18 01:27:11 2022 ] 	Mean training loss: 0.6920.  Mean training acc: 79.15%.
[ Tue Oct 18 01:27:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:27:11 2022 ] Eval epoch: 31
[ Tue Oct 18 01:28:00 2022 ] 	Mean test loss of 796 batches: 0.8667551553878353.
[ Tue Oct 18 01:28:01 2022 ] 	Top1: 74.35%
[ Tue Oct 18 01:28:01 2022 ] 	Top5: 94.73%
[ Tue Oct 18 01:28:01 2022 ] Training epoch: 32
[ Tue Oct 18 01:31:11 2022 ] 	Mean training loss: 0.6860.  Mean training acc: 79.47%.
[ Tue Oct 18 01:31:11 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:31:11 2022 ] Eval epoch: 32
[ Tue Oct 18 01:32:01 2022 ] 	Mean test loss of 796 batches: 1.1086670020454792.
[ Tue Oct 18 01:32:02 2022 ] 	Top1: 70.72%
[ Tue Oct 18 01:32:02 2022 ] 	Top5: 91.92%
[ Tue Oct 18 01:32:02 2022 ] Training epoch: 33
[ Tue Oct 18 01:35:12 2022 ] 	Mean training loss: 0.6763.  Mean training acc: 79.68%.
[ Tue Oct 18 01:35:12 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:35:12 2022 ] Eval epoch: 33
[ Tue Oct 18 01:36:02 2022 ] 	Mean test loss of 796 batches: 1.0447277766863006.
[ Tue Oct 18 01:36:03 2022 ] 	Top1: 69.64%
[ Tue Oct 18 01:36:03 2022 ] 	Top5: 92.92%
[ Tue Oct 18 01:36:03 2022 ] Training epoch: 34
[ Tue Oct 18 01:39:13 2022 ] 	Mean training loss: 0.6801.  Mean training acc: 79.58%.
[ Tue Oct 18 01:39:13 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:39:13 2022 ] Eval epoch: 34
[ Tue Oct 18 01:40:03 2022 ] 	Mean test loss of 796 batches: 1.0092564870851424.
[ Tue Oct 18 01:40:04 2022 ] 	Top1: 70.94%
[ Tue Oct 18 01:40:04 2022 ] 	Top5: 93.53%
[ Tue Oct 18 01:40:04 2022 ] Training epoch: 35
[ Tue Oct 18 01:43:15 2022 ] 	Mean training loss: 0.6796.  Mean training acc: 79.50%.
[ Tue Oct 18 01:43:15 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Oct 18 01:43:15 2022 ] Eval epoch: 35
[ Tue Oct 18 01:44:04 2022 ] 	Mean test loss of 796 batches: 0.9510985168080833.
[ Tue Oct 18 01:44:05 2022 ] 	Top1: 72.08%
[ Tue Oct 18 01:44:05 2022 ] 	Top5: 93.75%
[ Tue Oct 18 01:44:05 2022 ] Training epoch: 36
[ Tue Oct 18 01:47:15 2022 ] 	Mean training loss: 0.3674.  Mean training acc: 89.16%.
[ Tue Oct 18 01:47:15 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:47:15 2022 ] Eval epoch: 36
[ Tue Oct 18 01:48:05 2022 ] 	Mean test loss of 796 batches: 0.5565508592817652.
[ Tue Oct 18 01:48:05 2022 ] 	Top1: 83.38%
[ Tue Oct 18 01:48:06 2022 ] 	Top5: 97.07%
[ Tue Oct 18 01:48:06 2022 ] Training epoch: 37
[ Tue Oct 18 01:51:16 2022 ] 	Mean training loss: 0.2799.  Mean training acc: 91.80%.
[ Tue Oct 18 01:51:16 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:51:16 2022 ] Eval epoch: 37
[ Tue Oct 18 01:52:06 2022 ] 	Mean test loss of 796 batches: 0.5471933742226968.
[ Tue Oct 18 01:52:07 2022 ] 	Top1: 83.57%
[ Tue Oct 18 01:52:07 2022 ] 	Top5: 97.11%
[ Tue Oct 18 01:52:07 2022 ] Training epoch: 38
[ Tue Oct 18 01:55:18 2022 ] 	Mean training loss: 0.2408.  Mean training acc: 93.21%.
[ Tue Oct 18 01:55:18 2022 ] 	Time consumption: [Data]03%, [Network]96%
[ Tue Oct 18 01:55:19 2022 ] Eval epoch: 38
[ Tue Oct 18 01:56:09 2022 ] 	Mean test loss of 796 batches: 0.5507464268286923.
[ Tue Oct 18 01:56:09 2022 ] 	Top1: 83.94%
[ Tue Oct 18 01:56:09 2022 ] 	Top5: 96.96%
[ Tue Oct 18 01:56:09 2022 ] Training epoch: 39
[ Tue Oct 18 01:59:19 2022 ] 	Mean training loss: 0.2156.  Mean training acc: 93.89%.
[ Tue Oct 18 01:59:19 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 01:59:19 2022 ] Eval epoch: 39
[ Tue Oct 18 02:00:09 2022 ] 	Mean test loss of 796 batches: 0.5412229507337862.
[ Tue Oct 18 02:00:10 2022 ] 	Top1: 84.28%
[ Tue Oct 18 02:00:10 2022 ] 	Top5: 97.17%
[ Tue Oct 18 02:00:10 2022 ] Training epoch: 40
[ Tue Oct 18 02:03:20 2022 ] 	Mean training loss: 0.1931.  Mean training acc: 94.63%.
[ Tue Oct 18 02:03:20 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:03:20 2022 ] Eval epoch: 40
[ Tue Oct 18 02:04:10 2022 ] 	Mean test loss of 796 batches: 0.5668741076080194.
[ Tue Oct 18 02:04:11 2022 ] 	Top1: 83.82%
[ Tue Oct 18 02:04:11 2022 ] 	Top5: 96.81%
[ Tue Oct 18 02:04:11 2022 ] Training epoch: 41
[ Tue Oct 18 02:07:21 2022 ] 	Mean training loss: 0.1776.  Mean training acc: 95.20%.
[ Tue Oct 18 02:07:21 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:07:21 2022 ] Eval epoch: 41
[ Tue Oct 18 02:08:11 2022 ] 	Mean test loss of 796 batches: 0.5600622315334165.
[ Tue Oct 18 02:08:11 2022 ] 	Top1: 83.99%
[ Tue Oct 18 02:08:12 2022 ] 	Top5: 96.90%
[ Tue Oct 18 02:08:12 2022 ] Training epoch: 42
[ Tue Oct 18 02:11:22 2022 ] 	Mean training loss: 0.1594.  Mean training acc: 95.70%.
[ Tue Oct 18 02:11:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:11:22 2022 ] Eval epoch: 42
[ Tue Oct 18 02:12:12 2022 ] 	Mean test loss of 796 batches: 0.5678614095770683.
[ Tue Oct 18 02:12:12 2022 ] 	Top1: 83.86%
[ Tue Oct 18 02:12:12 2022 ] 	Top5: 96.90%
[ Tue Oct 18 02:12:12 2022 ] Training epoch: 43
[ Tue Oct 18 02:15:22 2022 ] 	Mean training loss: 0.1482.  Mean training acc: 96.21%.
[ Tue Oct 18 02:15:22 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:15:22 2022 ] Eval epoch: 43
[ Tue Oct 18 02:16:12 2022 ] 	Mean test loss of 796 batches: 0.573192708634177.
[ Tue Oct 18 02:16:13 2022 ] 	Top1: 83.78%
[ Tue Oct 18 02:16:13 2022 ] 	Top5: 96.92%
[ Tue Oct 18 02:16:13 2022 ] Training epoch: 44
[ Tue Oct 18 02:19:23 2022 ] 	Mean training loss: 0.1414.  Mean training acc: 96.30%.
[ Tue Oct 18 02:19:23 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Oct 18 02:19:23 2022 ] Eval epoch: 44
[ Tue Oct 18 02:20:13 2022 ] 	Mean test loss of 796 batches: 0.6034856000400368.
[ Tue Oct 18 02:20:13 2022 ] 	Top1: 83.36%
[ Tue Oct 18 02:20:13 2022 ] 	Top5: 96.57%
[ Tue Oct 18 02:20:13 2022 ] Training epoch: 45
[ Tue Oct 18 02:23:24 2022 ] 	Mean training loss: 0.1299.  Mean training acc: 96.76%.
[ Tue Oct 18 02:23:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:23:24 2022 ] Eval epoch: 45
[ Tue Oct 18 02:24:13 2022 ] 	Mean test loss of 796 batches: 0.6239328387113822.
[ Tue Oct 18 02:24:14 2022 ] 	Top1: 82.73%
[ Tue Oct 18 02:24:14 2022 ] 	Top5: 96.48%
[ Tue Oct 18 02:24:14 2022 ] Training epoch: 46
[ Tue Oct 18 02:27:24 2022 ] 	Mean training loss: 0.1252.  Mean training acc: 96.94%.
[ Tue Oct 18 02:27:24 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:27:24 2022 ] Eval epoch: 46
[ Tue Oct 18 02:28:14 2022 ] 	Mean test loss of 796 batches: 0.6211147894848831.
[ Tue Oct 18 02:28:15 2022 ] 	Top1: 83.09%
[ Tue Oct 18 02:28:15 2022 ] 	Top5: 96.39%
[ Tue Oct 18 02:28:15 2022 ] Training epoch: 47
[ Tue Oct 18 02:31:25 2022 ] 	Mean training loss: 0.1198.  Mean training acc: 97.04%.
[ Tue Oct 18 02:31:25 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:31:25 2022 ] Eval epoch: 47
[ Tue Oct 18 02:32:15 2022 ] 	Mean test loss of 796 batches: 0.628066997245029.
[ Tue Oct 18 02:32:15 2022 ] 	Top1: 82.69%
[ Tue Oct 18 02:32:16 2022 ] 	Top5: 96.55%
[ Tue Oct 18 02:32:16 2022 ] Training epoch: 48
[ Tue Oct 18 02:35:26 2022 ] 	Mean training loss: 0.1183.  Mean training acc: 97.09%.
[ Tue Oct 18 02:35:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:35:26 2022 ] Eval epoch: 48
[ Tue Oct 18 02:36:16 2022 ] 	Mean test loss of 796 batches: 0.6317878199095402.
[ Tue Oct 18 02:36:16 2022 ] 	Top1: 82.74%
[ Tue Oct 18 02:36:16 2022 ] 	Top5: 96.32%
[ Tue Oct 18 02:36:16 2022 ] Training epoch: 49
[ Tue Oct 18 02:39:26 2022 ] 	Mean training loss: 0.1170.  Mean training acc: 97.14%.
[ Tue Oct 18 02:39:26 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:39:27 2022 ] Eval epoch: 49
[ Tue Oct 18 02:40:17 2022 ] 	Mean test loss of 796 batches: 0.6435925560399666.
[ Tue Oct 18 02:40:17 2022 ] 	Top1: 82.66%
[ Tue Oct 18 02:40:18 2022 ] 	Top5: 96.37%
[ Tue Oct 18 02:40:18 2022 ] Training epoch: 50
[ Tue Oct 18 02:43:28 2022 ] 	Mean training loss: 0.1125.  Mean training acc: 97.27%.
[ Tue Oct 18 02:43:28 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:43:28 2022 ] Eval epoch: 50
[ Tue Oct 18 02:44:18 2022 ] 	Mean test loss of 796 batches: 0.6544553716596796.
[ Tue Oct 18 02:44:19 2022 ] 	Top1: 82.45%
[ Tue Oct 18 02:44:19 2022 ] 	Top5: 96.37%
[ Tue Oct 18 02:44:19 2022 ] Training epoch: 51
[ Tue Oct 18 02:47:29 2022 ] 	Mean training loss: 0.1144.  Mean training acc: 97.23%.
[ Tue Oct 18 02:47:29 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:47:29 2022 ] Eval epoch: 51
[ Tue Oct 18 02:48:19 2022 ] 	Mean test loss of 796 batches: 0.6700849496202552.
[ Tue Oct 18 02:48:19 2022 ] 	Top1: 81.67%
[ Tue Oct 18 02:48:20 2022 ] 	Top5: 96.17%
[ Tue Oct 18 02:48:20 2022 ] Training epoch: 52
[ Tue Oct 18 02:51:30 2022 ] 	Mean training loss: 0.1115.  Mean training acc: 97.31%.
[ Tue Oct 18 02:51:30 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:51:30 2022 ] Eval epoch: 52
[ Tue Oct 18 02:52:20 2022 ] 	Mean test loss of 796 batches: 0.6843316337402592.
[ Tue Oct 18 02:52:21 2022 ] 	Top1: 81.87%
[ Tue Oct 18 02:52:21 2022 ] 	Top5: 96.08%
[ Tue Oct 18 02:52:21 2022 ] Training epoch: 53
[ Tue Oct 18 02:55:31 2022 ] 	Mean training loss: 0.1155.  Mean training acc: 97.14%.
[ Tue Oct 18 02:55:31 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:55:31 2022 ] Eval epoch: 53
[ Tue Oct 18 02:56:21 2022 ] 	Mean test loss of 796 batches: 0.6768163663133904.
[ Tue Oct 18 02:56:22 2022 ] 	Top1: 81.96%
[ Tue Oct 18 02:56:22 2022 ] 	Top5: 96.19%
[ Tue Oct 18 02:56:22 2022 ] Training epoch: 54
[ Tue Oct 18 02:59:32 2022 ] 	Mean training loss: 0.1149.  Mean training acc: 97.19%.
[ Tue Oct 18 02:59:32 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 02:59:32 2022 ] Eval epoch: 54
[ Tue Oct 18 03:00:22 2022 ] 	Mean test loss of 796 batches: 0.6836981551824652.
[ Tue Oct 18 03:00:23 2022 ] 	Top1: 81.97%
[ Tue Oct 18 03:00:23 2022 ] 	Top5: 96.03%
[ Tue Oct 18 03:00:23 2022 ] Training epoch: 55
[ Tue Oct 18 03:03:33 2022 ] 	Mean training loss: 0.1157.  Mean training acc: 97.22%.
[ Tue Oct 18 03:03:33 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:03:33 2022 ] Eval epoch: 55
[ Tue Oct 18 03:04:23 2022 ] 	Mean test loss of 796 batches: 0.6925207669682913.
[ Tue Oct 18 03:04:23 2022 ] 	Top1: 81.86%
[ Tue Oct 18 03:04:24 2022 ] 	Top5: 95.84%
[ Tue Oct 18 03:04:24 2022 ] Training epoch: 56
[ Tue Oct 18 03:07:34 2022 ] 	Mean training loss: 0.0624.  Mean training acc: 98.88%.
[ Tue Oct 18 03:07:34 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:07:34 2022 ] Eval epoch: 56
[ Tue Oct 18 03:08:24 2022 ] 	Mean test loss of 796 batches: 0.6198274569127278.
[ Tue Oct 18 03:08:24 2022 ] 	Top1: 83.71%
[ Tue Oct 18 03:08:24 2022 ] 	Top5: 96.40%
[ Tue Oct 18 03:08:24 2022 ] Training epoch: 57
[ Tue Oct 18 03:11:34 2022 ] 	Mean training loss: 0.0455.  Mean training acc: 99.32%.
[ Tue Oct 18 03:11:34 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:11:35 2022 ] Eval epoch: 57
[ Tue Oct 18 03:12:24 2022 ] 	Mean test loss of 796 batches: 0.6110654598448294.
[ Tue Oct 18 03:12:25 2022 ] 	Top1: 83.90%
[ Tue Oct 18 03:12:25 2022 ] 	Top5: 96.50%
[ Tue Oct 18 03:12:25 2022 ] Training epoch: 58
[ Tue Oct 18 03:15:35 2022 ] 	Mean training loss: 0.0390.  Mean training acc: 99.48%.
[ Tue Oct 18 03:15:35 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:15:35 2022 ] Eval epoch: 58
[ Tue Oct 18 03:16:25 2022 ] 	Mean test loss of 796 batches: 0.6070096351664944.
[ Tue Oct 18 03:16:25 2022 ] 	Top1: 84.03%
[ Tue Oct 18 03:16:26 2022 ] 	Top5: 96.59%
[ Tue Oct 18 03:16:26 2022 ] Training epoch: 59
[ Tue Oct 18 03:19:36 2022 ] 	Mean training loss: 0.0352.  Mean training acc: 99.57%.
[ Tue Oct 18 03:19:36 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:19:36 2022 ] Eval epoch: 59
[ Tue Oct 18 03:20:26 2022 ] 	Mean test loss of 796 batches: 0.6084074335893495.
[ Tue Oct 18 03:20:27 2022 ] 	Top1: 84.06%
[ Tue Oct 18 03:20:27 2022 ] 	Top5: 96.48%
[ Tue Oct 18 03:20:27 2022 ] Training epoch: 60
[ Tue Oct 18 03:23:37 2022 ] 	Mean training loss: 0.0331.  Mean training acc: 99.62%.
[ Tue Oct 18 03:23:37 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Oct 18 03:23:37 2022 ] Eval epoch: 60
[ Tue Oct 18 03:24:28 2022 ] 	Mean test loss of 796 batches: 0.6093353099802781.
[ Tue Oct 18 03:24:28 2022 ] 	Top1: 84.01%
[ Tue Oct 18 03:24:28 2022 ] 	Top5: 96.51%
[ Tue Oct 18 03:24:28 2022 ] Training epoch: 61
[ Tue Oct 18 03:27:38 2022 ] 	Mean training loss: 0.0311.  Mean training acc: 99.65%.
[ Tue Oct 18 03:27:38 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:27:38 2022 ] Eval epoch: 61
[ Tue Oct 18 03:28:28 2022 ] 	Mean test loss of 796 batches: 0.6227735215049218.
[ Tue Oct 18 03:28:29 2022 ] 	Top1: 83.81%
[ Tue Oct 18 03:28:29 2022 ] 	Top5: 96.39%
[ Tue Oct 18 03:28:29 2022 ] Training epoch: 62
[ Tue Oct 18 03:31:39 2022 ] 	Mean training loss: 0.0289.  Mean training acc: 99.69%.
[ Tue Oct 18 03:31:39 2022 ] 	Time consumption: [Data]02%, [Network]97%
[ Tue Oct 18 03:31:39 2022 ] Eval epoch: 62
[ Tue Oct 18 03:32:29 2022 ] 	Mean test loss of 796 batches: 0.6119924530939166.
[ Tue Oct 18 03:32:29 2022 ] 	Top1: 84.12%
[ Tue Oct 18 03:32:29 2022 ] 	Top5: 96.47%
[ Tue Oct 18 03:32:29 2022 ] Training epoch: 63
[ Tue Oct 18 03:35:40 2022 ] 	Mean training loss: 0.0275.  Mean training acc: 99.73%.
[ Tue Oct 18 03:35:40 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:35:40 2022 ] Eval epoch: 63
[ Tue Oct 18 03:36:29 2022 ] 	Mean test loss of 796 batches: 0.6169415209582777.
[ Tue Oct 18 03:36:30 2022 ] 	Top1: 83.97%
[ Tue Oct 18 03:36:30 2022 ] 	Top5: 96.39%
[ Tue Oct 18 03:36:30 2022 ] Training epoch: 64
[ Tue Oct 18 03:39:41 2022 ] 	Mean training loss: 0.0273.  Mean training acc: 99.72%.
[ Tue Oct 18 03:39:41 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:39:41 2022 ] Eval epoch: 64
[ Tue Oct 18 03:40:31 2022 ] 	Mean test loss of 796 batches: 0.6211255534069996.
[ Tue Oct 18 03:40:31 2022 ] 	Top1: 83.98%
[ Tue Oct 18 03:40:32 2022 ] 	Top5: 96.33%
[ Tue Oct 18 03:40:32 2022 ] Training epoch: 65
[ Tue Oct 18 03:43:42 2022 ] 	Mean training loss: 0.0265.  Mean training acc: 99.71%.
[ Tue Oct 18 03:43:42 2022 ] 	Time consumption: [Data]03%, [Network]97%
[ Tue Oct 18 03:43:42 2022 ] Eval epoch: 65
[ Tue Oct 18 03:44:32 2022 ] 	Mean test loss of 796 batches: 0.6239572406919608.
[ Tue Oct 18 03:44:32 2022 ] 	Top1: 83.88%
[ Tue Oct 18 03:44:33 2022 ] 	Top5: 96.30%
[ Tue Oct 18 03:45:24 2022 ] Best accuracy: 0.8428091675013256
[ Tue Oct 18 03:45:24 2022 ] Epoch number: 39
[ Tue Oct 18 03:45:24 2022 ] Model name: work_dir/ntu120/csub/local_SHT1b
[ Tue Oct 18 03:45:24 2022 ] Model total number of params: 2133954
[ Tue Oct 18 03:45:24 2022 ] Weight decay: 0.0004
[ Tue Oct 18 03:45:24 2022 ] Base LR: 0.1
[ Tue Oct 18 03:45:24 2022 ] Batch Size: 64
[ Tue Oct 18 03:45:24 2022 ] Test Batch Size: 64
[ Tue Oct 18 03:45:24 2022 ] seed: 1
[ Tue Oct 18 10:08:26 2022 ] Load weights from work_dir/ntu120/csub/local_SHT1b/runs-39-38376.pt.
[ Tue Oct 18 10:08:29 2022 ] using warm up, epoch: 5
[ Thu Oct 27 15:02:57 2022 ] Load weights from work_dir/ntu120/csub/local_SHT1b/runs-65-63960.pt.
[ Thu Oct 27 15:03:02 2022 ] using warm up, epoch: 5
[ Thu Oct 27 15:04:39 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHT1b', 'model_saved_name': 'work_dir/ntu120/csub/local_SHT1b/runs', 'config': 'config/nturgbd120-cross-subject/default_long.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.local_SHT1b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/ntu120/csub/local_SHT1b/runs-65-63960.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 90, 100], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 65, 'num_epoch': 110, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Oct 27 15:04:39 2022 ] # Parameters: 2133954
[ Thu Oct 27 15:04:39 2022 ] Training epoch: 66
[ Thu Oct 27 15:05:59 2022 ] Load weights from work_dir/ntu120/csub/local_SHT1b/runs-65-63960.pt.
[ Thu Oct 27 15:06:04 2022 ] using warm up, epoch: 5
[ Thu Oct 27 15:06:29 2022 ] Parameters:
{'work_dir': 'work_dir/ntu120/csub/local_SHT1b', 'model_saved_name': 'work_dir/ntu120/csub/local_SHT1b/runs', 'config': 'config/nturgbd120-cross-subject/default_long.yaml', 'phase': 'train', 'save_score': False, 'seed': 1, 'log_interval': 100, 'save_interval': 1, 'save_epoch': 30, 'eval_interval': 5, 'print_log': True, 'show_topk': [1, 5], 'feeder': 'feeders.feeder_ntu.Feeder', 'num_worker': 32, 'train_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'train', 'debug': False, 'random_choose': False, 'random_shift': False, 'random_move': False, 'window_size': 64, 'normalization': False, 'random_rot': True, 'p_interval': [0.5, 1], 'vel': False, 'bone': False}, 'test_feeder_args': {'data_path': 'data/ntu120/NTU120_CSub.npz', 'split': 'test', 'window_size': 64, 'p_interval': [0.95], 'vel': False, 'bone': False, 'debug': False}, 'model': 'model.local_SHT1b.Model', 'model_args': {'num_class': 120, 'num_point': 25, 'num_person': 2, 'graph': 'graph.ntu_rgb_d.Graph', 'graph_args': {'labeling_mode': 'spatial'}}, 'weights': 'work_dir/ntu120/csub/local_SHT1b/runs-65-63960.pt', 'ignore_weights': [], 'base_lr': 0.1, 'step': [35, 55, 90, 100], 'device': [4], 'optimizer': 'SGD', 'nesterov': True, 'batch_size': 64, 'test_batch_size': 64, 'start_epoch': 65, 'num_epoch': 110, 'weight_decay': 0.0004, 'lr_decay_rate': 0.1, 'warm_up_epoch': 5}

[ Thu Oct 27 15:06:29 2022 ] # Parameters: 2133954
[ Thu Oct 27 15:06:29 2022 ] Training epoch: 66
[ Thu Oct 27 15:09:50 2022 ] 	Mean training loss: 0.0251.  Mean training acc: 99.77%.
[ Thu Oct 27 15:09:50 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 15:09:51 2022 ] Eval epoch: 66
[ Thu Oct 27 15:10:51 2022 ] 	Mean test loss of 796 batches: 0.6199212417699135.
[ Thu Oct 27 15:10:52 2022 ] 	Top1: 83.98%
[ Thu Oct 27 15:10:53 2022 ] 	Top5: 96.34%
[ Thu Oct 27 15:10:53 2022 ] Training epoch: 67
[ Thu Oct 27 15:14:16 2022 ] 	Mean training loss: 0.0245.  Mean training acc: 99.78%.
[ Thu Oct 27 15:14:16 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:14:16 2022 ] Eval epoch: 67
[ Thu Oct 27 15:15:20 2022 ] 	Mean test loss of 796 batches: 0.6163811657072311.
[ Thu Oct 27 15:15:21 2022 ] 	Top1: 84.01%
[ Thu Oct 27 15:15:22 2022 ] 	Top5: 96.40%
[ Thu Oct 27 15:15:22 2022 ] Training epoch: 68
[ Thu Oct 27 15:18:44 2022 ] 	Mean training loss: 0.0246.  Mean training acc: 99.78%.
[ Thu Oct 27 15:18:44 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:18:44 2022 ] Eval epoch: 68
[ Thu Oct 27 15:19:48 2022 ] 	Mean test loss of 796 batches: 0.6233212960668695.
[ Thu Oct 27 15:19:49 2022 ] 	Top1: 84.00%
[ Thu Oct 27 15:19:50 2022 ] 	Top5: 96.33%
[ Thu Oct 27 15:19:51 2022 ] Training epoch: 69
[ Thu Oct 27 15:23:13 2022 ] 	Mean training loss: 0.0234.  Mean training acc: 99.80%.
[ Thu Oct 27 15:23:13 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 15:23:14 2022 ] Eval epoch: 69
[ Thu Oct 27 15:24:12 2022 ] 	Mean test loss of 796 batches: 0.616378909510434.
[ Thu Oct 27 15:24:13 2022 ] 	Top1: 84.06%
[ Thu Oct 27 15:24:14 2022 ] 	Top5: 96.43%
[ Thu Oct 27 15:24:15 2022 ] Training epoch: 70
[ Thu Oct 27 15:27:38 2022 ] 	Mean training loss: 0.0232.  Mean training acc: 99.80%.
[ Thu Oct 27 15:27:38 2022 ] 	Time consumption: [Data]09%, [Network]88%
[ Thu Oct 27 15:27:38 2022 ] Eval epoch: 70
[ Thu Oct 27 15:28:36 2022 ] 	Mean test loss of 796 batches: 0.616805894099101.
[ Thu Oct 27 15:28:37 2022 ] 	Top1: 84.07%
[ Thu Oct 27 15:28:38 2022 ] 	Top5: 96.39%
[ Thu Oct 27 15:28:38 2022 ] Training epoch: 71
[ Thu Oct 27 15:32:03 2022 ] 	Mean training loss: 0.0228.  Mean training acc: 99.80%.
[ Thu Oct 27 15:32:03 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:32:03 2022 ] Eval epoch: 71
[ Thu Oct 27 15:33:04 2022 ] 	Mean test loss of 796 batches: 0.6243459888916444.
[ Thu Oct 27 15:33:05 2022 ] 	Top1: 83.94%
[ Thu Oct 27 15:33:06 2022 ] 	Top5: 96.34%
[ Thu Oct 27 15:33:06 2022 ] Training epoch: 72
[ Thu Oct 27 15:36:30 2022 ] 	Mean training loss: 0.0223.  Mean training acc: 99.83%.
[ Thu Oct 27 15:36:30 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:36:30 2022 ] Eval epoch: 72
[ Thu Oct 27 15:37:31 2022 ] 	Mean test loss of 796 batches: 0.6161933893796487.
[ Thu Oct 27 15:37:32 2022 ] 	Top1: 84.16%
[ Thu Oct 27 15:37:33 2022 ] 	Top5: 96.38%
[ Thu Oct 27 15:37:33 2022 ] Training epoch: 73
[ Thu Oct 27 15:40:55 2022 ] 	Mean training loss: 0.0222.  Mean training acc: 99.81%.
[ Thu Oct 27 15:40:55 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:40:55 2022 ] Eval epoch: 73
[ Thu Oct 27 15:41:54 2022 ] 	Mean test loss of 796 batches: 0.6112660817221631.
[ Thu Oct 27 15:41:55 2022 ] 	Top1: 84.17%
[ Thu Oct 27 15:41:56 2022 ] 	Top5: 96.49%
[ Thu Oct 27 15:41:56 2022 ] Training epoch: 74
[ Thu Oct 27 15:45:18 2022 ] 	Mean training loss: 0.0215.  Mean training acc: 99.85%.
[ Thu Oct 27 15:45:18 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 15:45:19 2022 ] Eval epoch: 74
[ Thu Oct 27 15:46:18 2022 ] 	Mean test loss of 796 batches: 0.623217099519381.
[ Thu Oct 27 15:46:19 2022 ] 	Top1: 83.90%
[ Thu Oct 27 15:46:20 2022 ] 	Top5: 96.33%
[ Thu Oct 27 15:46:20 2022 ] Training epoch: 75
[ Thu Oct 27 15:49:43 2022 ] 	Mean training loss: 0.0217.  Mean training acc: 99.83%.
[ Thu Oct 27 15:49:43 2022 ] 	Time consumption: [Data]08%, [Network]89%
[ Thu Oct 27 15:49:43 2022 ] Eval epoch: 75
[ Thu Oct 27 15:50:44 2022 ] 	Mean test loss of 796 batches: 0.6270969712161388.
[ Thu Oct 27 15:50:45 2022 ] 	Top1: 83.88%
[ Thu Oct 27 15:50:47 2022 ] 	Top5: 96.31%
[ Thu Oct 27 15:50:47 2022 ] Training epoch: 76
[ Thu Oct 27 15:54:12 2022 ] 	Mean training loss: 0.0211.  Mean training acc: 99.82%.
[ Thu Oct 27 15:54:12 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:54:12 2022 ] Eval epoch: 76
[ Thu Oct 27 15:55:16 2022 ] 	Mean test loss of 796 batches: 0.611880414117708.
[ Thu Oct 27 15:55:17 2022 ] 	Top1: 84.22%
[ Thu Oct 27 15:55:19 2022 ] 	Top5: 96.44%
[ Thu Oct 27 15:55:19 2022 ] Training epoch: 77
[ Thu Oct 27 15:58:42 2022 ] 	Mean training loss: 0.0209.  Mean training acc: 99.87%.
[ Thu Oct 27 15:58:42 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 15:58:42 2022 ] Eval epoch: 77
[ Thu Oct 27 15:59:42 2022 ] 	Mean test loss of 796 batches: 0.6201809568929687.
[ Thu Oct 27 15:59:43 2022 ] 	Top1: 83.97%
[ Thu Oct 27 15:59:45 2022 ] 	Top5: 96.34%
[ Thu Oct 27 15:59:45 2022 ] Training epoch: 78
[ Thu Oct 27 16:03:07 2022 ] 	Mean training loss: 0.0208.  Mean training acc: 99.83%.
[ Thu Oct 27 16:03:07 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:03:07 2022 ] Eval epoch: 78
[ Thu Oct 27 16:04:09 2022 ] 	Mean test loss of 796 batches: 0.6234328869879995.
[ Thu Oct 27 16:04:10 2022 ] 	Top1: 83.95%
[ Thu Oct 27 16:04:11 2022 ] 	Top5: 96.37%
[ Thu Oct 27 16:04:11 2022 ] Training epoch: 79
[ Thu Oct 27 16:07:31 2022 ] 	Mean training loss: 0.0204.  Mean training acc: 99.86%.
[ Thu Oct 27 16:07:31 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 16:07:31 2022 ] Eval epoch: 79
[ Thu Oct 27 16:08:31 2022 ] 	Mean test loss of 796 batches: 0.6222748818278463.
[ Thu Oct 27 16:08:32 2022 ] 	Top1: 83.92%
[ Thu Oct 27 16:08:33 2022 ] 	Top5: 96.34%
[ Thu Oct 27 16:08:33 2022 ] Training epoch: 80
[ Thu Oct 27 16:11:56 2022 ] 	Mean training loss: 0.0209.  Mean training acc: 99.84%.
[ Thu Oct 27 16:11:56 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:11:56 2022 ] Eval epoch: 80
[ Thu Oct 27 16:12:59 2022 ] 	Mean test loss of 796 batches: 0.6268371994883272.
[ Thu Oct 27 16:13:01 2022 ] 	Top1: 83.72%
[ Thu Oct 27 16:13:02 2022 ] 	Top5: 96.32%
[ Thu Oct 27 16:13:02 2022 ] Training epoch: 81
[ Thu Oct 27 16:16:30 2022 ] 	Mean training loss: 0.0199.  Mean training acc: 99.86%.
[ Thu Oct 27 16:16:30 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:16:30 2022 ] Eval epoch: 81
[ Thu Oct 27 16:17:32 2022 ] 	Mean test loss of 796 batches: 0.6277776249033872.
[ Thu Oct 27 16:17:33 2022 ] 	Top1: 83.86%
[ Thu Oct 27 16:17:34 2022 ] 	Top5: 96.35%
[ Thu Oct 27 16:17:34 2022 ] Training epoch: 82
[ Thu Oct 27 16:20:59 2022 ] 	Mean training loss: 0.0196.  Mean training acc: 99.87%.
[ Thu Oct 27 16:20:59 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:20:59 2022 ] Eval epoch: 82
[ Thu Oct 27 16:22:03 2022 ] 	Mean test loss of 796 batches: 0.6199173625539894.
[ Thu Oct 27 16:22:04 2022 ] 	Top1: 84.13%
[ Thu Oct 27 16:22:05 2022 ] 	Top5: 96.37%
[ Thu Oct 27 16:22:05 2022 ] Training epoch: 83
[ Thu Oct 27 16:25:26 2022 ] 	Mean training loss: 0.0202.  Mean training acc: 99.83%.
[ Thu Oct 27 16:25:26 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 16:25:26 2022 ] Eval epoch: 83
[ Thu Oct 27 16:26:27 2022 ] 	Mean test loss of 796 batches: 0.6185653873405714.
[ Thu Oct 27 16:26:28 2022 ] 	Top1: 84.14%
[ Thu Oct 27 16:26:29 2022 ] 	Top5: 96.35%
[ Thu Oct 27 16:26:29 2022 ] Training epoch: 84
[ Thu Oct 27 16:29:51 2022 ] 	Mean training loss: 0.0194.  Mean training acc: 99.89%.
[ Thu Oct 27 16:29:51 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 16:29:51 2022 ] Eval epoch: 84
[ Thu Oct 27 16:30:48 2022 ] 	Mean test loss of 796 batches: 0.6189841631537856.
[ Thu Oct 27 16:30:49 2022 ] 	Top1: 84.02%
[ Thu Oct 27 16:30:50 2022 ] 	Top5: 96.39%
[ Thu Oct 27 16:30:50 2022 ] Training epoch: 85
[ Thu Oct 27 16:34:09 2022 ] 	Mean training loss: 0.0193.  Mean training acc: 99.88%.
[ Thu Oct 27 16:34:09 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 16:34:09 2022 ] Eval epoch: 85
[ Thu Oct 27 16:35:07 2022 ] 	Mean test loss of 796 batches: 0.6254434485887014.
[ Thu Oct 27 16:35:08 2022 ] 	Top1: 83.99%
[ Thu Oct 27 16:35:08 2022 ] 	Top5: 96.31%
[ Thu Oct 27 16:35:09 2022 ] Training epoch: 86
[ Thu Oct 27 16:38:29 2022 ] 	Mean training loss: 0.0196.  Mean training acc: 99.86%.
[ Thu Oct 27 16:38:29 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 16:38:29 2022 ] Eval epoch: 86
[ Thu Oct 27 16:39:27 2022 ] 	Mean test loss of 796 batches: 0.6220311976445081.
[ Thu Oct 27 16:39:29 2022 ] 	Top1: 83.92%
[ Thu Oct 27 16:39:30 2022 ] 	Top5: 96.34%
[ Thu Oct 27 16:39:30 2022 ] Training epoch: 87
[ Thu Oct 27 16:42:52 2022 ] 	Mean training loss: 0.0188.  Mean training acc: 99.88%.
[ Thu Oct 27 16:42:52 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:42:52 2022 ] Eval epoch: 87
[ Thu Oct 27 16:43:51 2022 ] 	Mean test loss of 796 batches: 0.6205394397344646.
[ Thu Oct 27 16:43:52 2022 ] 	Top1: 84.01%
[ Thu Oct 27 16:43:53 2022 ] 	Top5: 96.39%
[ Thu Oct 27 16:43:53 2022 ] Training epoch: 88
[ Thu Oct 27 16:47:14 2022 ] 	Mean training loss: 0.0190.  Mean training acc: 99.89%.
[ Thu Oct 27 16:47:14 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:47:14 2022 ] Eval epoch: 88
[ Thu Oct 27 16:48:11 2022 ] 	Mean test loss of 796 batches: 0.6253104655343533.
[ Thu Oct 27 16:48:12 2022 ] 	Top1: 83.90%
[ Thu Oct 27 16:48:13 2022 ] 	Top5: 96.36%
[ Thu Oct 27 16:48:13 2022 ] Training epoch: 89
[ Thu Oct 27 16:51:36 2022 ] 	Mean training loss: 0.0191.  Mean training acc: 99.86%.
[ Thu Oct 27 16:51:36 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:51:36 2022 ] Eval epoch: 89
[ Thu Oct 27 16:52:32 2022 ] 	Mean test loss of 796 batches: 0.6224125448108917.
[ Thu Oct 27 16:52:33 2022 ] 	Top1: 84.00%
[ Thu Oct 27 16:52:34 2022 ] 	Top5: 96.35%
[ Thu Oct 27 16:52:34 2022 ] Training epoch: 90
[ Thu Oct 27 16:55:55 2022 ] 	Mean training loss: 0.0188.  Mean training acc: 99.87%.
[ Thu Oct 27 16:55:55 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 16:55:55 2022 ] Eval epoch: 90
[ Thu Oct 27 16:56:54 2022 ] 	Mean test loss of 796 batches: 0.6172565542226985.
[ Thu Oct 27 16:56:55 2022 ] 	Top1: 84.04%
[ Thu Oct 27 16:56:56 2022 ] 	Top5: 96.42%
[ Thu Oct 27 16:56:56 2022 ] Training epoch: 91
[ Thu Oct 27 17:00:17 2022 ] 	Mean training loss: 0.0181.  Mean training acc: 99.90%.
[ Thu Oct 27 17:00:17 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:00:17 2022 ] Eval epoch: 91
[ Thu Oct 27 17:01:17 2022 ] 	Mean test loss of 796 batches: 0.6178847690155009.
[ Thu Oct 27 17:01:18 2022 ] 	Top1: 84.02%
[ Thu Oct 27 17:01:19 2022 ] 	Top5: 96.36%
[ Thu Oct 27 17:01:19 2022 ] Training epoch: 92
[ Thu Oct 27 17:04:39 2022 ] 	Mean training loss: 0.0185.  Mean training acc: 99.89%.
[ Thu Oct 27 17:04:39 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:04:39 2022 ] Eval epoch: 92
[ Thu Oct 27 17:05:39 2022 ] 	Mean test loss of 796 batches: 0.6156308512348476.
[ Thu Oct 27 17:05:40 2022 ] 	Top1: 84.10%
[ Thu Oct 27 17:05:42 2022 ] 	Top5: 96.43%
[ Thu Oct 27 17:05:42 2022 ] Training epoch: 93
[ Thu Oct 27 17:09:06 2022 ] 	Mean training loss: 0.0184.  Mean training acc: 99.88%.
[ Thu Oct 27 17:09:06 2022 ] 	Time consumption: [Data]09%, [Network]88%
[ Thu Oct 27 17:09:06 2022 ] Eval epoch: 93
[ Thu Oct 27 17:10:03 2022 ] 	Mean test loss of 796 batches: 0.6147802125044803.
[ Thu Oct 27 17:10:04 2022 ] 	Top1: 84.02%
[ Thu Oct 27 17:10:05 2022 ] 	Top5: 96.39%
[ Thu Oct 27 17:10:06 2022 ] Training epoch: 94
[ Thu Oct 27 17:13:26 2022 ] 	Mean training loss: 0.0179.  Mean training acc: 99.90%.
[ Thu Oct 27 17:13:26 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:13:26 2022 ] Eval epoch: 94
[ Thu Oct 27 17:14:25 2022 ] 	Mean test loss of 796 batches: 0.6210698863332296.
[ Thu Oct 27 17:14:26 2022 ] 	Top1: 84.05%
[ Thu Oct 27 17:14:27 2022 ] 	Top5: 96.37%
[ Thu Oct 27 17:14:27 2022 ] Training epoch: 95
[ Thu Oct 27 17:17:51 2022 ] 	Mean training loss: 0.0178.  Mean training acc: 99.91%.
[ Thu Oct 27 17:17:51 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:17:51 2022 ] Eval epoch: 95
[ Thu Oct 27 17:18:49 2022 ] 	Mean test loss of 796 batches: 0.6217680966303726.
[ Thu Oct 27 17:18:50 2022 ] 	Top1: 83.98%
[ Thu Oct 27 17:18:51 2022 ] 	Top5: 96.36%
[ Thu Oct 27 17:18:51 2022 ] Training epoch: 96
[ Thu Oct 27 17:22:12 2022 ] 	Mean training loss: 0.0185.  Mean training acc: 99.89%.
[ Thu Oct 27 17:22:12 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:22:12 2022 ] Eval epoch: 96
[ Thu Oct 27 17:23:14 2022 ] 	Mean test loss of 796 batches: 0.6173194496653712.
[ Thu Oct 27 17:23:15 2022 ] 	Top1: 84.12%
[ Thu Oct 27 17:23:16 2022 ] 	Top5: 96.46%
[ Thu Oct 27 17:23:16 2022 ] Training epoch: 97
[ Thu Oct 27 17:26:38 2022 ] 	Mean training loss: 0.0177.  Mean training acc: 99.90%.
[ Thu Oct 27 17:26:38 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:26:38 2022 ] Eval epoch: 97
[ Thu Oct 27 17:27:38 2022 ] 	Mean test loss of 796 batches: 0.6188810121211874.
[ Thu Oct 27 17:27:38 2022 ] 	Top1: 84.04%
[ Thu Oct 27 17:27:39 2022 ] 	Top5: 96.41%
[ Thu Oct 27 17:27:40 2022 ] Training epoch: 98
[ Thu Oct 27 17:31:00 2022 ] 	Mean training loss: 0.0171.  Mean training acc: 99.93%.
[ Thu Oct 27 17:31:00 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:31:00 2022 ] Eval epoch: 98
[ Thu Oct 27 17:32:01 2022 ] 	Mean test loss of 796 batches: 0.6125513727322744.
[ Thu Oct 27 17:32:02 2022 ] 	Top1: 84.14%
[ Thu Oct 27 17:32:03 2022 ] 	Top5: 96.48%
[ Thu Oct 27 17:32:03 2022 ] Training epoch: 99
[ Thu Oct 27 17:35:24 2022 ] 	Mean training loss: 0.0170.  Mean training acc: 99.91%.
[ Thu Oct 27 17:35:24 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:35:24 2022 ] Eval epoch: 99
[ Thu Oct 27 17:36:22 2022 ] 	Mean test loss of 796 batches: 0.6169423317751992.
[ Thu Oct 27 17:36:23 2022 ] 	Top1: 84.02%
[ Thu Oct 27 17:36:24 2022 ] 	Top5: 96.34%
[ Thu Oct 27 17:36:25 2022 ] Training epoch: 100
[ Thu Oct 27 17:39:46 2022 ] 	Mean training loss: 0.0163.  Mean training acc: 99.94%.
[ Thu Oct 27 17:39:46 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 17:39:46 2022 ] Eval epoch: 100
[ Thu Oct 27 17:40:46 2022 ] 	Mean test loss of 796 batches: 0.6232383116218613.
[ Thu Oct 27 17:40:47 2022 ] 	Top1: 83.92%
[ Thu Oct 27 17:40:48 2022 ] 	Top5: 96.40%
[ Thu Oct 27 17:40:49 2022 ] Training epoch: 101
[ Thu Oct 27 17:44:22 2022 ] 	Mean training loss: 0.0172.  Mean training acc: 99.91%.
[ Thu Oct 27 17:44:22 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:44:23 2022 ] Eval epoch: 101
[ Thu Oct 27 17:45:30 2022 ] 	Mean test loss of 796 batches: 0.6222120766813432.
[ Thu Oct 27 17:45:31 2022 ] 	Top1: 83.85%
[ Thu Oct 27 17:45:33 2022 ] 	Top5: 96.36%
[ Thu Oct 27 17:45:33 2022 ] Training epoch: 102
[ Thu Oct 27 17:49:07 2022 ] 	Mean training loss: 0.0173.  Mean training acc: 99.91%.
[ Thu Oct 27 17:49:07 2022 ] 	Time consumption: [Data]09%, [Network]90%
[ Thu Oct 27 17:49:07 2022 ] Eval epoch: 102
[ Thu Oct 27 17:50:12 2022 ] 	Mean test loss of 796 batches: 0.623530963398329.
[ Thu Oct 27 17:50:13 2022 ] 	Top1: 83.92%
[ Thu Oct 27 17:50:16 2022 ] 	Top5: 96.32%
[ Thu Oct 27 17:50:16 2022 ] Training epoch: 103
[ Thu Oct 27 17:53:55 2022 ] 	Mean training loss: 0.0170.  Mean training acc: 99.92%.
[ Thu Oct 27 17:53:55 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:53:55 2022 ] Eval epoch: 103
[ Thu Oct 27 17:54:59 2022 ] 	Mean test loss of 796 batches: 0.6192080189834288.
[ Thu Oct 27 17:55:00 2022 ] 	Top1: 84.08%
[ Thu Oct 27 17:55:01 2022 ] 	Top5: 96.39%
[ Thu Oct 27 17:55:02 2022 ] Training epoch: 104
[ Thu Oct 27 17:58:35 2022 ] 	Mean training loss: 0.0172.  Mean training acc: 99.92%.
[ Thu Oct 27 17:58:35 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 17:58:35 2022 ] Eval epoch: 104
[ Thu Oct 27 17:59:41 2022 ] 	Mean test loss of 796 batches: 0.6115906389486325.
[ Thu Oct 27 17:59:43 2022 ] 	Top1: 84.17%
[ Thu Oct 27 17:59:44 2022 ] 	Top5: 96.43%
[ Thu Oct 27 17:59:45 2022 ] Training epoch: 105
[ Thu Oct 27 18:03:20 2022 ] 	Mean training loss: 0.0170.  Mean training acc: 99.92%.
[ Thu Oct 27 18:03:20 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 18:03:20 2022 ] Eval epoch: 105
[ Thu Oct 27 18:04:23 2022 ] 	Mean test loss of 796 batches: 0.6267023776475359.
[ Thu Oct 27 18:04:25 2022 ] 	Top1: 83.86%
[ Thu Oct 27 18:04:26 2022 ] 	Top5: 96.31%
[ Thu Oct 27 18:04:26 2022 ] Training epoch: 106
[ Thu Oct 27 18:08:08 2022 ] 	Mean training loss: 0.0169.  Mean training acc: 99.92%.
[ Thu Oct 27 18:08:08 2022 ] 	Time consumption: [Data]08%, [Network]90%
[ Thu Oct 27 18:08:08 2022 ] Eval epoch: 106
[ Thu Oct 27 18:09:11 2022 ] 	Mean test loss of 796 batches: 0.6258155735836706.
[ Thu Oct 27 18:09:12 2022 ] 	Top1: 83.89%
[ Thu Oct 27 18:09:14 2022 ] 	Top5: 96.28%
[ Thu Oct 27 18:09:14 2022 ] Training epoch: 107
[ Thu Oct 27 18:12:39 2022 ] 	Mean training loss: 0.0163.  Mean training acc: 99.93%.
[ Thu Oct 27 18:12:39 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 18:12:39 2022 ] Eval epoch: 107
[ Thu Oct 27 18:13:39 2022 ] 	Mean test loss of 796 batches: 0.6145372346146547.
[ Thu Oct 27 18:13:40 2022 ] 	Top1: 84.10%
[ Thu Oct 27 18:13:41 2022 ] 	Top5: 96.42%
[ Thu Oct 27 18:13:41 2022 ] Training epoch: 108
[ Thu Oct 27 18:17:09 2022 ] 	Mean training loss: 0.0168.  Mean training acc: 99.92%.
[ Thu Oct 27 18:17:09 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 18:17:09 2022 ] Eval epoch: 108
[ Thu Oct 27 18:18:09 2022 ] 	Mean test loss of 796 batches: 0.612429191938709.
[ Thu Oct 27 18:18:10 2022 ] 	Top1: 84.14%
[ Thu Oct 27 18:18:11 2022 ] 	Top5: 96.46%
[ Thu Oct 27 18:18:12 2022 ] Training epoch: 109
[ Thu Oct 27 18:21:34 2022 ] 	Mean training loss: 0.0165.  Mean training acc: 99.92%.
[ Thu Oct 27 18:21:34 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 18:21:34 2022 ] Eval epoch: 109
[ Thu Oct 27 18:22:32 2022 ] 	Mean test loss of 796 batches: 0.6139129234440438.
[ Thu Oct 27 18:22:33 2022 ] 	Top1: 84.16%
[ Thu Oct 27 18:22:33 2022 ] 	Top5: 96.44%
[ Thu Oct 27 18:22:34 2022 ] Training epoch: 110
[ Thu Oct 27 18:25:56 2022 ] 	Mean training loss: 0.0158.  Mean training acc: 99.96%.
[ Thu Oct 27 18:25:56 2022 ] 	Time consumption: [Data]09%, [Network]89%
[ Thu Oct 27 18:25:56 2022 ] Eval epoch: 110
[ Thu Oct 27 18:26:56 2022 ] 	Mean test loss of 796 batches: 0.6184559655539579.
[ Thu Oct 27 18:26:57 2022 ] 	Top1: 84.09%
[ Thu Oct 27 18:26:58 2022 ] 	Top5: 96.40%
[ Thu Oct 27 18:28:05 2022 ] Best accuracy: 0.8422199964649738
[ Thu Oct 27 18:28:05 2022 ] Epoch number: 76
[ Thu Oct 27 18:28:05 2022 ] Model name: work_dir/ntu120/csub/local_SHT1b
[ Thu Oct 27 18:28:05 2022 ] Model total number of params: 2133954
[ Thu Oct 27 18:28:05 2022 ] Weight decay: 0.0004
[ Thu Oct 27 18:28:05 2022 ] Base LR: 0.1
[ Thu Oct 27 18:28:05 2022 ] Batch Size: 64
[ Thu Oct 27 18:28:05 2022 ] Test Batch Size: 64
[ Thu Oct 27 18:28:05 2022 ] seed: 1
